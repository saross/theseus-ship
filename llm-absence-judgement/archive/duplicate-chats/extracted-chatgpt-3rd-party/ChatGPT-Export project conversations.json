{
  "metadata": {
    "title": "Export project conversations",
    "user": {
      "name": "Shawn"
    },
    "dates": {
      "created": "2025/12/7 22:04:43",
      "updated": "2025/12/8 17:57:53",
      "exported": "2025/12/8 18:01:53"
    },
    "link": "https://chatgpt.com/g/g-p-682fbda4eb1c819180b176f6de9d9cd8-theseus-ship/c/6935ebe8-1f34-8323-870e-bc7cd2fc3825",
    "powered_by": "ChatGPT Exporter (https://www.chatgptexporter.com)"
  },
  "messages": [
    {
      "role": "Prompt",
      "say": "Hi ChatGPT, can you tell me the best and most efficient way to export the conversatons in this project?"
    },
    {
      "role": "Response",
      "say": "Thought for 32s\n\n\nShort version: there’s no native “export this project” button (yet). You have three realistic options:\n\n\nExport all ChatGPT data and then filter down to this project (most robust / scriptable).\n\nManually export individual conversations (OK if there are only a few).\n\nUse a browser extension / third-party tool to bulk export selected chats (convenient but with privacy trade-offs).\n\n\nI’ll walk through each and then tell you what I’d actually recommend for Theseus-Ship.\n\n\n\n1. Built-in account-wide export + filter (most controlled, most “future-proof”)\n\n\nOpenAI’s only official export at the moment is account-wide:\n\n\nClick your profile icon (bottom-left).\n\nGo to Settings → Data controls → Export data.\n\nClick Export, then confirm.\n\nYou’ll get an email with a link to a .zip containing your history (HTML and JSON, typically including a conversations.json plus chat.html). OpenAI Help Center+1\n\n\nThis will include all projects and all conversations, but it’s:\n\n\nFirst-party (no extra privacy risk beyond OpenAI itself).\n\nComplete (you don’t miss anything inside the project).\n\nScriptable (you can reorganise and re-export in whatever formats you like).\n\n\nHow to isolate “this project” from the export\n\n\nInside the .zip you’ll find JSON with one entry per conversation. The exact schema shifts over time, but entries typically include things like an ID, title, timestamps, and metadata about where the chat lives (and with Projects now part of the product, it is very likely there is a project / folder-style identifier or similar). OpenAI Developer Community\n\n\nA pragmatic workflow:\n\n\nInspect the JSON once\nOpen conversations.json in a text editor.\n\nSearch for something distinctive from this project (e.g. “Theseus-Ship” in titles, or a specific message you know is from here).\n\nLook at the nearby fields to see how the project is represented (you might see a project UUID, a folder label, or even your project title somewhere in metadata).\n\nWrite a small script to filter\nIn Python, conceptually you’d:\nLoad conversations.json.\n\nKeep only conversations where:\nthe project/folder field equals your Theseus-Ship project, or\n\nthe title or system instructions contain a known marker (e.g. “Theseus-Ship” or your project description).\n\nEmit each conversation as:\nMarkdown, HTML, or plain text (for archiving in Git, Zotero, Obsidian, whatever).\n\nOr as one big concatenated file if you want a “project log”.\nBecause the precise field names aren’t documented publicly, you’d just adapt the script once after looking at one example entry and then rerun it.\n\nOptional: restructure for research use\nOnce filtered, you can:\nDrop them into a repo with one file per conversation (e.g. 2025-02-23_Improve_Resource_Descriptions.md). MPU Talk\n\nAdd front-matter (title, date, model, tags).\n\nFeed them into whatever analysis environment you like.\n\n\nFor someone in your position, this is probably the most efficient in the long run, especially if Theseus-Ship continues and you’ll want periodic snapshots.\n\n\n\n2. Built-in per-conversation options (fine for a handful of chats)\n\n\nIf you only need a small number of key threads from this project (say 3–5 “canonical” conversations), you can export them individually.\n\n\nCurrent first-party options:\n\n\nShare link for a single conversation\nOpen the conversation.\n\nClick the Share icon at the top.\n\nCopy the link. This gives you a read-only HTML view you can bookmark or mirror. Tactiq\n\nBrowser “Save as…” or Print → PDF\nWith the conversation open, use the browser’s Print → Save as PDF or Save page as… to capture it as HTML/PDF. This is crude but works if you just need a few.\n\n\nPros:\n\n\nVery low friction.\n\nNo need to touch JSON or scripts.\n\n\nCons:\n\n\nTedious for dozens of conversations.\n\nHarder to mine later (no structured metadata).\n\n\n\n3. Browser extensions / third-party tools (convenient, but with caveats)\n\n\nThere are now a few browser extensions and companion apps that can:\n\n\nAdd buttons in the UI to export individual or multiple conversations as Markdown/HTML/JSON. Reddit+2GitHub+2\n\nSometimes let you bulk-select chats in the sidebar (often by folder / label, which may map nicely onto Projects) and export them together. ChatGPT Toolbox\n\n\nExamples mentioned in recent guides:\n\n\nChatGPT Exporter (Chrome/Firefox extension – PDF, Markdown, HTML). Chrome Web Store+1\n\nChatGPT Prompt Genius / ChatGPT Toolbox – extensions that add share/export panels with bulk export. edrawmind.wondershare.com+1\n\n\nThese often support:\n\n\nMulti-select from the sidebar, then “Export” to a given format.\n\nExport to Markdown directly (which is very nice for research workflows).\n\n\nCaveats:\n\n\nThey are third-party, so:\nThey can see the text of the conversations they export.\n\nYou have to be comfortable with that from a data-governance perspective (especially if the project contains sensitive or unpublished material).\n\nYou’ll want to:\nRead their privacy policy.\n\nPrefer open-source projects where you can at least see what they’re doing.\n\n\nFor a project like Theseus-Ship with lots of methodological detail and potentially quasi-confidential notes, you may or may not be happy with that risk.\n\n\n\nWhat I would actually do for “Theseus-Ship”\n\n\nGiven your use case (research, reproducibility, and likely long-term reuse), I’d rank the options:\n\n\nPrimary recommendation – account-wide export + local filtering\nUse OpenAI’s official Export Data to get the full .zip. OpenAI Help Center+1\n\nInspect conversations.json to identify how this project’s threads are tagged.\n\nWrite a small Python script to:\nFilter on the project identifier or a known naming convention.\n\nEmit per-conversation Markdown files plus a simple index (CSV/JSON) with title, date, model, and file path.\nThat gives you a clean, auditable archive, and you can version-control it, cite it, or even treat it as a dataset for your “LLMs as research assistants” work.\n\nSecondary – manual export for a curated subset\nFor a small “canonical corpus” of Theseus-Ship conversations (e.g. those directly referenced in the eventual paper), use:\nShare links (for quick human-readable access), and\n\nPDF/HTML exports for archival copies.\n\nOptional – third-party bulk exporter\nIf you’re comfortable with the privacy angle and want fast Markdown for all project conversations with minimal scripting, choose a reputable open-source extension and bulk-export from within the project’s sidebar.\n\n\nIf you like, in a follow-up I can:\n\n\nSketch a concrete Python script for filtering an export (assuming a likely JSON structure), and\n\nSuggest a simple directory + filename convention for treating Theseus-Ship chats as a proper research dataset."
    },
    {
      "role": "Prompt",
      "say": "Can you help write a script to filter for this project, dates feb 2025 - Auguts 2025? Do you need to see the export first?"
    },
    {
      "role": "Response",
      "say": "Thought for 1m 54s\n\n\nNo, I don’t need to see the export first. We can write a script that should work with a standard conversations.json export and you can tweak it if your schema has minor variations.\n\n\nBelow is a Python script that:\n\n\nLoads conversations.json (which is a list of conversation objects with fields like title, create_time, update_time, and mapping). GitHub\n\nInterprets create_time as a Unix timestamp (seconds since epoch). gramener.com+1\n\nTreats a conversation as part of this project if any message content contains a marker string (for this project, \"Theseus-Ship\" from your system instructions). System and other messages live under mapping → node → message → content → parts, so they are present in the export. GitHub+1\n\nFilters conversations whose creation date falls between 1 February 2025 and 31 August 2025, inclusive.\n\n\nYou can adjust the marker or dates as needed.\n\n\n\nPython script: filter by project marker and date range\n\n\nSave this as e.g. filter_chatgpt_conversations.py in the same directory as your conversations.json.\n\n\n#!/usr/bin/env python3\n\"\"\"\nFilter ChatGPT conversations.json for a specific project and date range.\n\nThis script reads ChatGPT's exported `conversations.json` file (from the\naccount-wide data export), identifies conversations that belong to a\nparticular project by searching for a marker string in the system instructions,\nand then filters those conversations by a date range.\n\nThe result is written to a new JSON file containing only the matching\nconversation objects.\n\"\"\"\n\nimport argparse\nimport json\nfrom datetime import datetime, date, timezone\nfrom pathlib import Path\nfrom typing import Any, Dict, Iterable, List, Optional\n\ndef parse_args() -> argparse.Namespace:\n    \"\"\"\n    Parse command-line arguments.\n\n    Returns\n    -------\n    argparse.Namespace\n        An object with attributes:\n        - input: Path to the input conversations.json file.\n        - output: Path to write the filtered JSON file.\n        - project_marker: String to search for in system / instruction messages.\n        - start_date: Start of the date range (inclusive), YYYY-MM-DD.\n        - end_date: End of the date range (inclusive), YYYY-MM-DD.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=(\n            \"Filter ChatGPT conversations.json for a project (via marker text) \"\n            \"and a date range.\"\n        )\n    )\n    parser.add_argument(\n        \"-i\", \"--input\",\n        type=Path,\n        required=True,\n        help=\"Path to input conversations.json from ChatGPT export.\",\n    )\n    parser.add_argument(\n        \"-o\", \"--output\",\n        type=Path,\n        required=True,\n        help=\"Path to output filtered JSON file.\",\n    )\n    parser.add_argument(\n        \"--project-marker\",\n        type=str,\n        required=True,\n        help=(\n            \"Marker string that appears in the project's system instructions \"\n            \"or other messages (e.g. 'Theseus-Ship').\"\n        ),\n    )\n    parser.add_argument(\n        \"--start-date\",\n        type=str,\n        required=True,\n        help=\"Start date (inclusive) in ISO format, e.g. 2025-02-01.\",\n    )\n    parser.add_argument(\n        \"--end-date\",\n        type=str,\n        required=True,\n        help=\"End date (inclusive) in ISO format, e.g. 2025-08-31.\",\n    )\n    return parser.parse_args()\n\ndef safe_parse_iso_date(value: str) -> date:\n    \"\"\"\n    Parse a YYYY-MM-DD string into a `datetime.date`.\n\n    Parameters\n    ----------\n    value : str\n        Date string in ISO format (YYYY-MM-DD).\n\n    Returns\n    -------\n    datetime.date\n        Parsed date.\n\n    Raises\n    ------\n    ValueError\n        If the string is not a valid ISO date.\n    \"\"\"\n    return date.fromisoformat(value)\n\ndef load_conversations(path: Path) -> List[Dict[str, Any]]:\n    \"\"\"\n    Load the list of conversations from conversations.json.\n\n    Parameters\n    ----------\n    path : pathlib.Path\n        Path to the conversations.json file.\n\n    Returns\n    -------\n    list of dict\n        List where each item is a conversation object from the export.\n    \"\"\"\n    with path.open(\"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n\n    if not isinstance(data, list):\n        raise ValueError(\n            f\"Expected top-level JSON array in {path}, but got {type(data).__name__}\"\n        )\n    return data\n\ndef conversation_date(conv: Dict[str, Any]) -> Optional[date]:\n    \"\"\"\n    Get the conversation creation date as a `datetime.date`, if available.\n\n    Parameters\n    ----------\n    conv : dict\n        A single conversation object from conversations.json.\n\n    Returns\n    -------\n    datetime.date or None\n        The date part of the `create_time` timestamp, or None if missing\n        or invalid.\n\n    Notes\n    -----\n    ChatGPT exports usually store `create_time` as a Unix timestamp (seconds\n    since epoch). This function assumes UTC and then takes the calendar date.\n    \"\"\"\n    ts = conv.get(\"create_time\")\n    if ts is None:\n        return None\n    try:\n        # Some exports use float Unix timestamps.\n        dt = datetime.fromtimestamp(float(ts), tz=timezone.utc)\n    except Exception:\n        return None\n    return dt.date()\n\ndef iter_message_text(conv: Dict[str, Any]) -> Iterable[str]:\n    \"\"\"\n    Yield all textual content fragments from a conversation.\n\n    Parameters\n    ----------\n    conv : dict\n        A single conversation object.\n\n    Yields\n    ------\n    str\n        Textual snippets extracted from message content parts.\n\n    Notes\n    -----\n    The exported structure has the form:\n\n    - conv['mapping'] is a dict of node_id -> node\n    - node['message']['content']['parts'] is typically a list of strings,\n      but parts may also contain objects for multimodal messages.\n\n    This function converts non-string parts to strings, so that simple\n    substring search (e.g. for a project marker) will still work.\n    \"\"\"\n    mapping = conv.get(\"mapping\") or {}\n    if not isinstance(mapping, dict):\n        return\n\n    for node in mapping.values():\n        message = node.get(\"message\")\n        if not message:\n            continue\n        content = message.get(\"content\")\n        if not content:\n            continue\n\n        # Older exports: parts is a list of strings.\n        # Newer / multimodal exports: parts may contain objects.\n        parts = content.get(\"parts\")\n        if not parts:\n            continue\n\n        for part in parts:\n            if isinstance(part, str):\n                yield part\n            else:\n                # Fall back to stringified representation for search purposes.\n                try:\n                    yield json.dumps(part, ensure_ascii=False)\n                except TypeError:\n                    yield str(part)\n\ndef belongs_to_project(conv: Dict[str, Any], marker: str) -> bool:\n    \"\"\"\n    Determine whether a conversation belongs to a project by marker string.\n\n    Parameters\n    ----------\n    conv : dict\n        Conversation object.\n    marker : str\n        Marker string to search for (e.g. 'Theseus-Ship').\n\n    Returns\n    -------\n    bool\n        True if the marker string appears anywhere in the conversation\n        text (typically in system instructions), False otherwise.\n\n    Rationale\n    ---------\n    Projects in ChatGPT often inject a fixed system instruction that\n    includes the project name (e.g. \"You are operating in the context of\n    a wider project called Theseus-Ship\"). Those instructions are stored\n    as system messages in the exported JSON, so searching for a unique\n    marker string is a practical way to identify all conversations that\n    belong to a given project, even if there is no explicit project_id\n    field in the export.\n    \"\"\"\n    marker_lower = marker.lower()\n    for text in iter_message_text(conv):\n        if marker_lower in text.lower():\n            return True\n    return False\n\ndef filter_conversations(\n    conversations: List[Dict[str, Any]],\n    marker: str,\n    start: date,\n    end: date,\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Filter conversations by project marker and date range.\n\n    Parameters\n    ----------\n    conversations : list of dict\n        All conversations loaded from conversations.json.\n    marker : str\n        Project marker string to search for in message text.\n    start : datetime.date\n        Start date (inclusive).\n    end : datetime.date\n        End date (inclusive).\n\n    Returns\n    -------\n    list of dict\n        Subset of conversation objects that both:\n        - contain the marker text; and\n        - have create_time in the given date range.\n    \"\"\"\n    filtered: List[Dict[str, Any]] = []\n\n    for conv in conversations:\n        conv_date = conversation_date(conv)\n        if conv_date is None:\n            continue\n\n        if not (start <= conv_date <= end):\n            continue\n\n        if not belongs_to_project(conv, marker):\n            continue\n\n        filtered.append(conv)\n\n    return filtered\n\ndef main() -> None:\n    \"\"\"\n    Main entry point: orchestrates argument parsing, loading, filtering,\n    and writing the output file.\n    \"\"\"\n    args = parse_args()\n    start = safe_parse_iso_date(args.start_date)\n    end = safe_parse_iso_date(args.end_date)\n\n    if end < start:\n        raise SystemExit(\"ERROR: end-date must be on or after start-date.\")\n\n    conversations = load_conversations(args.input)\n    total = len(conversations)\n\n    filtered = filter_conversations(conversations, args.project_marker, start, end)\n    matched = len(filtered)\n\n    # Write filtered conversations to output file.\n    args.output.parent.mkdir(parents=True, exist_ok=True)\n    with args.output.open(\"w\", encoding=\"utf-8\") as f:\n        json.dump(filtered, f, ensure_ascii=False, indent=2)\n\n    print(f\"Total conversations in input: {total}\")\n    print(f\"Conversations matching project marker '{args.project_marker}': {matched}\")\n    print(f\"Filtered conversations written to: {args.output}\")\n    print(f\"Date range: {start.isoformat()} to {end.isoformat()} (inclusive)\")\n\nif __name__ == \"__main__\":\n    main()\n\n\n\nHow to use it for this project, Feb–Aug 2025\n\n\nAssuming:\n\n\nYou have your export unzipped in a directory.\n\nconversations.json is in that directory. Medium+1\n\nYou saved the script as filter_chatgpt_conversations.py in the same place.\n\n\nRun:\n\n\npython3 filter_chatgpt_conversations.py \\\n  -i conversations.json \\\n  -o conversations_theseus_ship_2025-02_to_2025-08.json \\\n  --project-marker \"Theseus-Ship\" \\\n  --start-date 2025-02-01 \\\n  --end-date   2025-08-31\n\n\nThis will:\n\n\nScan all conversations.\n\nKeep only those:\nwhose creation date is between 1 Feb 2025 and 31 Aug 2025 inclusive, and\n\nwhose text contains \"Theseus-Ship\" somewhere in the messages (typically in the system instructions for this project).\n\n\nYou’ll see a small summary on stdout:\n\n\ntotal conversations in the export\n\nhow many matched the marker and date range\n\nwhere the filtered JSON was written\n\n\n\nA couple of caveats / assumptions (so you can sanity-check)\n\n\nDate semantics: this uses the conversation create_time, not “last activity”. If a conversation started on 31 January 2025 but was heavily used in February, it will be excluded under this logic. If you’d rather filter by last message date, we can extend the script to compute max message timestamp per conversation instead.\n\nProject detection: using \"Theseus-Ship\" as a marker assumes:\nYour project instructions contain that exact string (they do in this project’s system prompt).\n\nThat string does not appear widely in unrelated projects.\nIf you want to be stricter, you can change --project-marker to a longer, more distinctive substring from the system instructions.\n\nSchema variance: most exports follow the conversations.json pattern described above, but OpenAI can and does tweak schemas over time. GitHub+1\nIf you hit an error or matched = 0 when you expect more, the next step would be to open a single conversation object from the JSON and see if field names differ (we can then adjust one or two lines in the script).\n\n\nIf you’d like, you can paste one anonymised conversation object (strip sensitive text, leave structure) and I can help tailor the script exactly to your export format."
    },
    {
      "role": "Prompt",
      "say": "Does 'ChatGPT Toolbox' let me export all of the chats in a project? Does one of the others? Which tool that does this gets the best reviews?"
    },
    {
      "role": "Response",
      "say": "Thought for 1m 58s\n\n\nShort version:\n\n\nChatGPT Toolbox can bulk-export all chats you’ve put into one of its folders, but it does not appear to understand OpenAI’s new Projects concept natively.\n\nSuperpower ChatGPT and ChatGPT Exporter can also bulk-export many or all chats, but again there’s no explicit “per-Project” export; you approximate it with folders or manual selection.\n\nIn terms of ratings, ChatGPT Exporter is the highest-rated export-focused tool, while Superpower ChatGPT and ChatGPT Toolbox are also very well reviewed.\n\n\nBelow is the more nuanced breakdown.\n\n\n\n1. ChatGPT Toolbox – what it can actually do\n\n\nCapabilities\n\n\nOfficial docs and the feature comparison table show that ChatGPT Toolbox adds:\n\n\nBulk export chats\n\nExport to TXT, JSON, and Markdown\n\nFolder export – “export entire folders”\n\nFolders & subfolders specifically framed as a way to organise conversations by project, topic, or client ChatGPT Toolbox+1\n\nBulk actions (bulk delete, bulk archive/unarchive, etc.) ChatGPT Toolbox+1\n\n\nThe Chrome Web Store listing confirms:\n\n“Bulk & Single-Chat Export — Save conversations in TXT or JSON for backups, sharing, or archiving… Folders & Subfolders — Organize unlimited chats; perfect for research, client work, or brainstorming.” Chrome Web Store\n\nThere’s also a dedicated “How to export conversations” guide that explicitly contrasts ChatGPT’s built-in export with Toolbox and lists “Folder Export: Export entire folders” as a unique feature. ChatGPT Toolbox\n\n\nSo, can it export “all chats in a project”?\n\n\nThere is no evidence that Toolbox reads OpenAI’s internal Project metadata. It operates on the visible conversation list plus its own folder system.\n\nHowever, you can create a Toolbox folder per project and put all relevant chats in there. Once that’s done, the Folder Export or Bulk Export functions will export all those conversations in one go.\n\n\nPractically:\n\n\nCreate a Toolbox folder called e.g. Theseus-Ship.\n\nDrag all the relevant chats for that project into that folder.\n\nUse the Bulk / Folder Export option and choose JSON (best for later filtering by date, project, etc.).\n\n\nFrom a functional point of view that gives you “export all chats in a project”, but it’s by folder, not by native Project.\n\n\nPlan caveat\nBulk export and folder-level bulk actions are flagged as Pro-plan features on the pricing page (the free tier is more limited in number of folders and has no bulk actions). ChatGPT Toolbox\n\n\n\n2. Other tools that can bulk-export many / all chats\n\n\na) ChatGPT Exporter (Mark Zhao / pionxzh)\n\n\nThis is a Tampermonkey userscript and a Chrome extension focused on export, not organisation.\n\n\nCapabilities\n\n\nCan export a single conversation or multiple conversations at once.\n\n“Export Multiple Conversations” section in the README:\n“When you click the ‘Export All’ button, the Export Conversations dialog pops up.”\n\nYou can select which conversations to export or “Select All” to export all your conversations. GitHub+1\n\nFormats: text, HTML, Markdown, PNG, and JSON (and JSON-ZIP). GitHub\n\n\nSo if you want every chat in your account, you can just hit Select All → Export. For a subset (e.g. specific dates), you’d either:\n\n\nExport everything and filter later in a script, or\n\nUse its built-in list and manually pick the relevant conversations.\n\n\nThere’s no notion of “Projects” or “folders” inside ChatGPT Exporter itself; it’s strictly an exporter.\n\n\n\nb) Superpower ChatGPT\n\n\nSuperpower is more analogous to ChatGPT Toolbox: a big “meta-layer” on top of ChatGPT that adds folders, search, export, etc.\n\n\nCapabilities\n\n\nFrom the Chrome Web Store listing:\n\n\n“Folders and subfolders for your chats” (with colours, drag & drop, etc.).\n\n“Export: Select and Export any number of your chats from ChatGPT into multiple formats (PDF, .txt, .json, .md).” Chrome Web Store\n\n\nThe Firefox listing also explicitly advertises “export all chats”.\n\n\nSo, in practice:\n\n\nYou can select arbitrary sets of chats and export them.\n\nBecause it supports folders, you can organise by project and then select those project-specific chats for export.\n\n\nThe docs don’t literally say “export folder X only”, but given that export is applied to “any number of your chats” and folders are just how those chats are grouped, it’s a reasonable (though technically inferred) workflow:\n\n\nFilter or view a folder → Select All in that folder → Export.\n\n\nAgain, that’s folder-based, not tied to OpenAI “Projects”.\n\n\n\nc) Other exporters (briefly)\n\n\nThere are a few other options, but they’re either less focussed on bulk export, or more niche:\n\n\nSave ChatGPT Conversation – can save and export conversations to PDF, but is mostly single-chat or simple “save all” with fewer organisational features.\n\nGPT Restore, Memory Forge, etc. – more about cross-platform or long-term “AI memory” than straight project-level exports.\n\n\nFor your use case (project-based research exports) I’d treat these as secondary.\n\n\n\n3. Which of these has the “best” reviews?\n\n\nYou can slice this a few ways (pure rating vs total reviews vs external sites). If we take Chrome Web Store ratings as a quick, comparable signal:\n\n\nChatGPT Exporter – ChatGPT to PDF, MD, and more\n4.8 / 5 from 1.1K ratings Chrome Web Store\n\nVery focused on exporting; lots of incremental version updates, multiple formats.\n\nSuperpower ChatGPT\n4.5 / 5 from 3.3K ratings Chrome Web Store\n\nMuch broader feature set (folders, search, prompts, etc.), so you’re buying into a whole environment, not just an exporter.\n\nChatGPT Toolbox\n4.6 / 5 from 267 ratings on Chrome Web Store Chrome Web Store\n\nOn G2 and other review sites it’s often quoted as ~4.9 / 5 from ~160 reviews, pitched as a “power user” extension with bulk export, folders, prompt management, etc. Trustpilot+2G2+2\n\nAI Prompt Genius / similar prompt-library tools\nAround 3.3 / 5 with ~150 ratings, and they’re mostly about prompt management rather than conversation export. Chrome Web Store\n\n\nIf the question is strictly:\n\n“Which tool that can bulk-export gets the best reviews?”\n\nThen:\n\n\nOn the Chrome Web Store, the top-rated export-capable extension by average rating is ChatGPT Exporter (4.8/5 with 1.1K ratings). Chrome Web Store\n\nFor all-round “power user” extensions with folders + export, ChatGPT Toolbox and Superpower ChatGPT are both very well-reviewed (4.6 and 4.5 respectively) and widely used. Chrome Web Store+1\n\n\n\n4. Recommendation tailored to your “project” use case\n\n\nGiven what you’re trying to do (export conversations for a specific project and then script against them by date):\n\n\nIf you care primarily about clean, script-friendly export and are happy to do your own filtering and organisation afterwards, I’d lean to ChatGPT Exporter:\nHighest rating;\n\nVery flexible export formats (Markdown/JSON/ZIP, etc.);\n\nClear “Export All / Export Multiple” workflow.\n\nIf you want ongoing project-level organisation plus export, I’d look at:\nChatGPT Toolbox – specifically because it has an explicit “Folder Export” feature. This makes the “export this project” action very simple once you’ve put all project chats into one folder. ChatGPT Toolbox+1\n\nSuperpower ChatGPT – similar concept (folders + export any number of chats), with slightly more mature ecosystem and user base, but with the minor ambiguity that folder-scoped export is through “select chats in a folder” rather than a dedicated “Export folder” button. Chrome Web Store\n\n\nNone of them, as far as current documentation shows, can say “Export this OpenAI Project and only this Project” directly. You have to bridge that gap yourself, either with:\n\n\nfolder structures in the extension, or\n\na script that filters an all-history export (e.g. by date range, by title, or by some other heuristic like your Theseus-Ship naming conventions).\n\n\nIf you tell me which extension you decide to use (or if you prefer the official conversations.json export), I can help you design a small Python script to:\n\n\nfilter to this project, and\n\nrestrict to Feb 2025 – August 2025."
    },
    {
      "role": "Prompt",
      "say": "Yeah, the reason I'm asking is that I requested a ChatGPT export nearly 24 hours ago, and no email has shown up with the download link. I've just sent another request, but I'm out of time for waiting and need an alternative. I'd prefer something unpaid, that provides straightforward export of selected chats."
    },
    {
      "role": "Response",
      "say": "Thought for 1m 14s\n\n\nGiven you’re out of patience with the official export (and fair enough), the cleanest unpaid option that lets you export selected chats is:\n\nUse the free version of ChatGPT Exporter (browser extension), then script/date-filter locally.\n\nI’ll give you a concrete workflow, then contrast it with Superpower and Toolbox so you can decide quickly.\n\n\n\n1. Best fit for your constraints: ChatGPT Exporter (free)\n\n\nWhy this fits what you asked for\n\n\nUnpaid: Most features are free; only PDF export requires logging into the extension’s own account. Markdown/text/CSV/JSON exports are free.\n\nSelected chats, not whole account: It explicitly supports “Export Multiple Conversations” where you tick which chats you want, or select all.\n\nNo need to wait for OpenAI export: It can either\nexport directly from your live ChatGPT account, or\n\nexport from a conversations.json file if/when OpenAI finally sends it.\n\nGood reputation & open-source: MIT-licensed on GitHub; widely recommended in recent “how to export ChatGPT” guides and Reddit threads.\n\n\nHow to use it quickly (zero scripting at this stage)\n\n\nInstall the extension\nIn Chrome/Edge/Brave/Firefox, go to the ChatGPT Exporter page on the Chrome Web Store or the extension’s site.\n\nAdd it to your browser.\n\nOpen ChatGPT as usual\nLog in to chatgpt.com in the same browser. The exporter’s UI will either show as:\na small overlay button, or\n\nan item in the browser’s extensions menu.\n\nOpen the “Export Multiple Conversations” dialog\nUse the exporter’s “Export All / Export” button (named slightly differently per version).\n\nThis brings up a list of all your conversations, fetched via the API (no need for the OpenAI export).\n\nSelect only this project’s chats\nYou’ve got a few options here, depending on how you’ve named things:\nBy title / manual selection\nScroll the list and tick the boxes next to all the Theseus-Ship project chats.\n\nBy search/filters, if available in your build\nSome versions let you filter the list; you can search for “Theseus” / project-specific titles and then select matching ones.\nIt’s not project-aware (none of the extensions read OpenAI’s “Project” metadata), so you do this visually by conversation title. But once you do it once, you can re-export later with only incremental selections.\n\nChoose an export format\nFor your later date-filtering and analysis, I’d recommend:\nJSON if you want to script heavily.\n\nMarkdown if you want something human-readable and Git-friendly.\n\nPick one, hit Export. The extension will download a file (or a ZIP of files) directly.\n\nOptional: date filtering afterwards\nOnce you’ve got those exported conversations, you can reuse/adapt the Python script I gave you in the earlier message, but now run it on the exporter’s JSON (or on a joined JSON) to keep only Feb–Aug 2025.\n\n\nPrivacy considerations\n\n\nChatGPT Exporter’s own FAQ explicitly says:\n\n\nAll formats except PDF are handled entirely in your browser, no server involvement.\n\nPDF export uses their server temporarily, but you can avoid PDF entirely and stick with Markdown/JSON.\n\n\nGiven your sensitivity to research data, this is a sane compromise: browser-local processing plus open-source code you can inspect.\n\n\n\n2. Alternative: Superpower ChatGPT (free core, more “ecosystem”)\n\n\nWhat it does well\n\n\nAdds folders, search, and export to ChatGPT.\n\nAllows you to select and export any number of chats into .txt, .json, .md, etc.\n\nMost features (including export) are described as “100% FREE”; Pro adds extra bells and whistles.\n\n\nThis is slightly more “heavyweight” than ChatGPT Exporter – it wants to become your whole ChatGPT management layer – but it’s also a viable free option if you like the idea of folders for ongoing work.\n\n\nWorkflow for your problem\n\n\nRoughly:\n\n\nInstall Superpower ChatGPT.\n\nIn the ChatGPT UI, use its folders to group Theseus-Ship chats.\n\nThen, in that folder or via its selection UI, select all project chats and export to .json or .md.\n\n\nDownside: it’s one more layer of UX in the interface and will collect some personal-data telemetry (see the Chrome Web Store “handles personally identifiable information” notice).\n\n\nIf you want minimalism and transparency, I’d still pick ChatGPT Exporter first.\n\n\n\n3. Why I don’t recommend ChatGPT Toolbox for this specific constraint set\n\n\nChatGPT Toolbox is powerful and well-reviewed, and does support:\n\n\nExport to TXT/JSON/Markdown\n\nBulk export of multiple conversations\n\nFolder-level exports (“export entire folders”)\n\n\nBut:\n\n\nThe free plan includes only limited folders and export; its own pricing docs show a freemium model where advanced bulk actions (including bulk export) are positioned as Premium features.\n\nFor your specific requirement – unpaid + selected chats export – that makes it more brittle than ChatGPT Exporter or Superpower’s free tier.\n\n\nIf, later on, you decide you’re happy to pay a small amount for smooth folder-level project exports and lots of organisational niceties, Toolbox is worth revisiting. But for “I need an unpaid solution today”, I’d deprioritise it.\n\n\n\n4. So, concretely, what should you do right now?\n\n\nIf I boil it down to the minimum action list consistent with your constraints:\n\n\nInstall ChatGPT Exporter in your browser.\n\nUse its Export Multiple Conversations dialog to tick all the Theseus-Ship chats.\n\nExport them in JSON (for scripting) or Markdown (for reading / Git).\n\nLater, run a small Python script to:\nkeep only conversations whose timestamps fall between 1 Feb 2025 and 31 Aug 2025, and\n\noptionally re-save each conversation as its own file with a sensible name.\n\n\nIf you’d like, I can now adapt the earlier Python script specifically to ChatGPT Exporter’s JSON output (its schema is a bit simpler than the official export) so you can just drop in a file and get a date-filtered, per-conversation Markdown pack for Theseus-Ship."
    },
    {
      "role": "Prompt",
      "say": "It appears that mulitple conversation export isn't available in the free version, I'll just export one at a time. How complete is the JSON? For machine analysis (e.g., by you, ChatGPT) would you prefer JSON or markdown?"
    },
    {
      "role": "Response",
      "say": "Thought for 1m 52s\n\n\nShort answer: if you’re doing any serious machine analysis, export JSON. It’s more complete and far easier to work with programmatically than Markdown, and you can always convert JSON → Markdown later if you want human-readable files.\n\n\nLet me unpack that a bit.\n\n\n\nHow “complete” is the JSON export?\n\n\nFor extensions like ChatGPT Exporter:\n\n\nThe JSON export is designed to capture the underlying conversation structure, not just a flat text dump.\n\nIt preserves the full text of the messages you export, including:\nUser and assistant messages\n\nCode blocks, tables and formulas (the same structures that appear in Markdown / HTML)\n\nIt typically includes some metadata such as:\nConversation title\n\nMessage order\n\nRole (user / assistant)\n\nTimestamps or IDs (depending on the exporter version)\n\n\nYou should assume it’s “complete” for:\n\n\nEverything you can see in the chat (text, code, tables)\n\nThe ordering and speaker roles for those messages\n\n\nIt generally will not be complete for:\n\n\nHidden system prompts / internal instructions delivered by OpenAI behind the scenes. Extensions can only access what’s returned via the web API; they don’t see the entire internal system prompt stack.\n\nBinary attachments like uploaded PDFs, images, or datasets. At best, you’ll get:\nA textual reference (e.g. “You uploaded file X.pdf”),\n\nOr a link / placeholder, not the actual file contents.\n\nSome rich artefacts from tools (e.g. images generated by DALL·E, file outputs from Code Interpreter) may appear only as links or descriptive text, not as embedded binaries.\n\n\nFor your Theseus-Ship work — which is predominantly text, code, and tables — JSON from a decent exporter will be sufficiently complete for analysis.\n\n\n\nJSON vs Markdown for machine analysis\n\n\nFrom the perspective of me (ChatGPT) or any other analysis pipeline, there are three relevant questions:\n\n\nCan I distinguish who said what and when?\n\nCan I reliably segment and reference messages?\n\nCan I enrich / transform the data later?\n\n\nJSON\n\n\nPros\n\n\nStructured: you get explicit fields like role, content, and often timestamps or IDs. That makes it trivial to:\nCount turns, token lengths, or distribution of roles.\n\nAnalyse dialogue patterns (e.g. “Show me only my prompts”, “find all assistant answers that mention FAIMS”).\n\nExtensible: you can add your own fields later (e.g. tags, topic labels, model annotations) without breaking anything.\n\nRound-trippable: you can re-serialize JSON into other formats (Markdown, CSV, Parquet) as needed.\n\nWhen you pass JSON to me in a prompt, you can say:“Here’s a list of messages as JSON; treat each array element as a single turn in the conversation and analyse X.”\nThat’s unambiguous and easy to parse.\n\n\nCons\n\n\nVerbose and a bit ugly to eyeball directly.\n\nSlightly more overhead in the context window compared with a very compact Markdown summary (but for a single conversation this usually isn’t critical).\n\n\nMarkdown\n\n\nPros\n\n\nHighly readable for humans. Great if you’re mostly reading, annotating, or version-controlling it as text.\n\nPreserves visual formatting (headings, code blocks) that’s pleasant when browsing in a Git repo, Obsidian, etc.\n\nAlso easy for me to read: I can absolutely analyse a Markdown transcript.\n\n\nCons\n\n\nStructurally ambiguous: unless there’s a strict template, “who said what when” is inferred from formatting (e.g. “User: …” lines) rather than explicit fields.\n\nHarder to script: you need ad-hoc parsing or regex to reconstruct roles, timestamps, etc.\n\nIf you want to later do serious statistics or modelling on the conversation, you often end up converting Markdown back into some pseudo-structured form anyway.\n\n\n\nWhat I’d recommend you do now\n\n\nGiven you’re exporting one conversation at a time, and you’re explicitly thinking about machine analysis:\n\n\nExport as JSON per conversation.\nThat will give you a set of structured objects that you can:\nStore in a simple dataset (one JSON per conversation), or\n\nConcatenate into a single JSONL file later.\n\nIf you also want a human-friendly archive, you can:\nEither export both JSON and Markdown per conversation now, or\n\nExport JSON only, then run a small script later to generate Markdown from JSON (very straightforward).\n\nWhen you want me (or another LLM) to analyse things in a future chat:\nPaste either:\nA compacted JSON snippet (or a slice of it), with instructions like “ interpret each element as {role, content}”, or\n\nA Markdown transcript derived from the JSON.\n\nFor anything that looks like “do corpus-level statistics, tag segments, detect patterns”, JSON will usually be the tidier option.\n\n\nIf you tell me roughly how many conversations you expect to export and what kind of analysis you have in mind (e.g. “track how our definition of research software evolved over time”), I can sketch a minimal JSON schema and a tiny Python script that will happily ingest those per-chat JSON files and give you a ready-to-analyse dataset."
    }
  ]
}