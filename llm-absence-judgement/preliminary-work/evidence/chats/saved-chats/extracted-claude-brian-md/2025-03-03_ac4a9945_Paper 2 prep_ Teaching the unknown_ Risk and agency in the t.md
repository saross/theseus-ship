# Paper 2 prep, Teaching the unknown: Risk and agency in the time of AI in the classroom

## Metadata
- **UUID:** `ac4a9945-cccd-46ba-84da-68b3f4da544e`
- **URL:** https://claude.ai/chat/ac4a9945-cccd-46ba-84da-68b3f4da544e
- **Created:** 2025-03-03 03:11:32
- **Updated:** 2025-03-07 05:31:08
- **Source:** Brian's Claude export

---

## Conversation

### Human (03:11:33)

Hi Claude. I'm interested in making a ~1000 word extended abstract for a philosophy conference. 

First, here's the spec.

(I'll paste in other components in future messages. Please hold.)

---

### Assistant (03:11:43)


Let me analyze what's in the pasted text. This appears to be a call for abstracts for a symposium called "Teaching With and About AI using Engagement Philosophy and Case Studies" that will be part of the IACAP/AISB-25 conference.

Key details about the symposium:
- It's focused on integrating AI in education using Brando's Engagement Philosophy
- The symposium will include a practical workshop, collaborative analysis, and discussion of extended abstracts
- They're looking for extended abstracts (1000-1500 words) that present phenomenological accounts of teaching with AI, analyze student-AI interactions, document benefits and challenges, examine humanities methodologies and AI literacy, and investigate ethical implications
- The symposium will culminate in developing themes for an edited volume
- Accepted contributors should expect to submit full papers for the edited volume within three months after the conference
- The submission deadline is February 28, 2025
- The contact person is Brian Ballsun-Stanton (brian.ballsun-stanton@mq.edu.au)

The user wants to create a ~1000 word extended abstract for this conference. They mentioned they will provide more components in future messages.

For now, I'll acknowledge their request and wait for the additional information they promised to provide.

I understand you're interested in creating an extended abstract for the "Teaching With and About AI using Engagement Philosophy and Case Studies Symposium" at IACAP/AISB-25. This looks like an interesting conference focused on how AI can be integrated into education using Brando's Engagement Philosophy.

According to the call for abstracts, they're looking for extended abstracts of 1000-1500 words that:
- Present phenomenological accounts of teaching and learning with AI
- Analyze patterns of student-AI interaction
- Document benefits/challenges in communicating AI practices
- Examine relationships between humanities methodologies and AI literacy
- Investigate ethical implications of AI in education

I'll wait for the additional components you mentioned before we begin drafting your abstract. Do you have a specific angle or topic in mind that you'd like to focus on within this broader theme?

---

### Human (03:13:08)

For context, here is our previous paper.

Mostly from this you can take descriptions of our class activities and our general vibe.

Please continue to hold.

---

### Assistant (03:13:35)


Thank you for sharing this academic paper titled "Teaching Students How to Effectively Interact with LLMs at University: Insights on the Longitudinal Development and Plasticity of Locus of Control." This appears to be a paper published by researchers including Jodie Torrington, Brian Ballsun-Stanton, and Jennifer WM Lai from Macquarie University.

Let me summarize the key points from this paper that might be relevant for creating an extended abstract for the IACAP/AISB-25 conference:

1. **Research Focus**: The paper examines how explicit instruction and guided practice with Large Language Models (LLMs) impacts students' knowledge, attitudes, self-efficacy, and sense of control over AI-mediated outcomes.

2. **Theoretical Framework**: The paper uses Locus of Control (LOC) theory as an interpretive framework. LOC refers to individuals' beliefs about whether outcomes result from their own actions (internal LOC) or external forces (external LOC).

3. **Methodology**: A longitudinal qualitative case study followed 12 undergraduate students through a semester-long experimental AI unit. Data was collected through surveys, focus groups, and observations.

4. **Results**: Students demonstrated progression toward internal AI-LOC, developing critical awareness and agency in their AI interactions. Scaffolded AI instruction enabled students to view themselves, rather than the technology, as the primary drivers of outcomes.

5. **Pedagogical Approaches**: The teaching methodology included active participation, real-world applicability, scaffolding, mentoring, community building, and experiential learning.

6. **Key Findings**:
   - Students' perception of AI changed from viewing it as "fun technology" to a useful tool
   - Students became more critical in their use of AI, recognizing both benefits and limitations
   - Students demonstrated increased confidence and agency in AI interactions
   - The learning design and pedagogical approach contributed to shifting students' LOC from external to internal

7. **Implications**: The findings suggest structured AI literacy education can empower learners to maintain agency in their AI use.

The conference call for abstracts focuses on "Teaching With and About AI using Engagement Philosophy and Case Studies." They are seeking extended abstracts that present phenomenological accounts of teaching and learning with AI, analyze patterns of student-AI interaction, document benefits and challenges in communicating AI practices, examine relationships between humanities methodologies and AI literacy, and investigate ethical implications of AI integration in education.

This research fits well with the conference theme, especially regarding Brando's Engagement Philosophy, which encourages "direct engagement with our subjects of research, not only as sources of information, but as structural contributors to the development of our research projects and its priorities." The paper shows how students were engaged as active participants in the research, and how their experiences shaped understanding of AI's role in education.

For the extended abstract, I should focus on:
1. Clear methodology
2. Concrete examples of practice
3. Critical reflection on outcomes
4. Connection of practical experiences to philosophical implications
5. Ethical and social impacts
6. Discussion of assessments that benefit from and teach AI use

I'll aim to create a 1000-1500 word extended abstract that highlights the research while framing it within the conference's specific focus on Engagement Philosophy.

Thank you for sharing this comprehensive paper about teaching students to interact effectively with LLMs. I understand you'd like to create a ~1000 word extended abstract for the IACAP/AISB-25 conference, specifically for the "Teaching With and About AI using Engagement Philosophy and Case Studies Symposium."

I'll wait for any additional components you mentioned before beginning the draft. Based on what you've shared so far, it seems your research aligns well with the symposium's focus, particularly in how you:

1. Examined the longitudinal development of students' locus of control when learning about AI
2. Used engagement philosophy principles by treating students as structural contributors to the research
3. Documented both successes and challenges in AI education
4. Applied a humanities-centered perspective to AI literacy
5. Explored the relationship between explicit instruction and student agency

Once you provide any additional context or specific elements you'd like to emphasize, I can help craft an extended abstract that meets the 1000-1500 word requirement while highlighting the philosophical and practical dimensions of your research.

---

### Human (03:14:32)

Now, here's the structure we're thinking about for this extended abstract:

Teaching the unknown:  
Risk and agency in the time of AI in the classroom 
 
Use **Transformative Learning Theory** as a framework: 
(from Perplexity notes): 
*Transformative Learning Theory posits that learning occurs through critical reflection on disorienting dilemmas—experiences that disrupt existing assumptions and necessitate a re-evaluation of beliefs, values, and perspectives. This process involves three interconnected themes:* 
***Experiential Engagemen****t: Learners confront novel, ambiguous scenarios that defy prior knowledge.* 
***Critical Reflection****: Structured analysis of assumptions and biases underpinning one’s worldview.* 
***Rational Discourse****: Dialogic processes to negotiate new understandings collaboratively.* 
*These stages directly map onto the challenges of teaching generative AI, where students must grapple with probabilistic outputs, ethical ambiguities, and rapidly evolving technological paradigms.* 
 
***Conclusion*** 
*Transformative Learning Theory provides a philosophically coherent and empirically validated foundation for teaching generative AI as an exercise in navigating the unknown. By ****framing AI not as a definitive answer engine but as a provocateur of critical inquiry****, educators can cultivate learners who:* 
***Embrace Uncertainty:**** Tolerate ambiguity while systematically probing AI’s limitations.* 
***Exercise Ethical Agency****: Advocate for equitable, transparent AI systems.* 
***Reimagine Creativity****: Harness AI as a collaborator in transcending conventional thoughtboundaries.* 
 
*Future research should explore longitudinal impacts of TLT-informed AI pedagogies on lifelong learning mindsets and their scalability across diverse socioeconomic contexts.* 
 
Philosophical approach to risk taking 
(see Perplexity notes for philosophers) 
**Rumsfeld Matrix (https://www.theuncertaintyproject.org/tools/rumsfeld-matrix)** 
In 2002, during a press briefing about the Iraq War, Donald Rumsfeld famously divided information into four categories: known knowns, known unknowns, unknown knowns, and unknown unknowns. These distinctions became the basis for the Rumsfeld Matrix, a decision-making framework that maps and evaluates the various degrees of certainty and uncertainty. 
The four quadrants of the Rumsfeld Matrix 
1. **Known knowns: **These are facts or variables that we're aware of and understand. They form the basis of our knowledge and provide a solid foundation for decision making. 
1. **Known unknowns: **These are factors we know exist, but don't fully understand. They represent gaps in our knowledge that we must address through research, investigation, or consultation with experts. 
1. **Unknown knowns:** These are elements that we don't realize we know. They're typically buried in our subconscious, overlooked, or dismissed as irrelevant. Uncovering these insights can lead to surprising breakthroughs in decision making. 
1. **Unknown unknowns:** These are factors that we're not aware of and can't predict. They represent the most significant source of uncertainty and risk, as they can catch us off guard and derail our plans. 
 

What I would like you to do is to ask us a series of questions, one at a time, until you believe you have sufficient information to craft an extended abstract. Then present the outline for the abstract (~300 words, very hierarchical, indications where citations are necessary, etc) for us to approve, provide more citations for, etc... and then we'll write the thing.

Please begin.

---

### Assistant (03:14:47)


I'll develop a series of focused questions to gather more information for creating an extended abstract that incorporates Transformative Learning Theory and the Rumsfeld Matrix as frameworks for understanding risk and agency in AI education. I'll ask one question at a time and wait for responses before moving to the next question.

Based on the information provided, I need to understand:
1. The specific case study details
2. The methodology used
3. Key findings that connect to transformative learning and risk
4. How the philosophical frameworks informed teaching practices
5. The implications and recommendations for AI education

I'll start with foundational questions to understand the scope and focus of the extended abstract.

I'll help you develop this extended abstract by asking a series of questions to gather the necessary information. Let's start:

1. Could you describe the specific case study or educational intervention that forms the empirical basis for this abstract? From your paper, I see you had 12 undergraduate students in a semester-long experimental AI unit, but I'd like to understand which aspects of this experience you want to highlight through the lens of Transformative Learning Theory and the Rumsfeld Matrix.

---

### Human (03:16:00)

Now, here's the structure we're thinking about for this extended abstract:

Teaching the unknown:  
Risk and agency in the time of AI in the classroom 
 
Use **Transformative Learning Theory** as a framework: 
(from Perplexity notes): 
*Transformative Learning Theory posits that learning occurs through critical reflection on disorienting dilemmas—experiences that disrupt existing assumptions and necessitate a re-evaluation of beliefs, values, and perspectives. This process involves three interconnected themes:* 
***Experiential Engagemen****t: Learners confront novel, ambiguous scenarios that defy prior knowledge.* 
***Critical Reflection****: Structured analysis of assumptions and biases underpinning one’s worldview.* 
***Rational Discourse****: Dialogic processes to negotiate new understandings collaboratively.* 
*These stages directly map onto the challenges of teaching generative AI, where students must grapple with probabilistic outputs, ethical ambiguities, and rapidly evolving technological paradigms.* 
 
***Conclusion*** 
*Transformative Learning Theory provides a philosophically coherent and empirically validated foundation for teaching generative AI as an exercise in navigating the unknown. By ****framing AI not as a definitive answer engine but as a provocateur of critical inquiry****, educators can cultivate learners who:* 
***Embrace Uncertainty:**** Tolerate ambiguity while systematically probing AI’s limitations.* 
***Exercise Ethical Agency****: Advocate for equitable, transparent AI systems.* 
***Reimagine Creativity****: Harness AI as a collaborator in transcending conventional thoughtboundaries.* 
 
*Future research should explore longitudinal impacts of TLT-informed AI pedagogies on lifelong learning mindsets and their scalability across diverse socioeconomic contexts.* 
 
Philosophical approach to risk taking 
(see Perplexity notes for philosophers) 
**Rumsfeld Matrix (https://www.theuncertaintyproject.org/tools/rumsfeld-matrix)** 
In 2002, during a press briefing about the Iraq War, Donald Rumsfeld famously divided information into four categories: known knowns, known unknowns, unknown knowns, and unknown unknowns. These distinctions became the basis for the Rumsfeld Matrix, a decision-making framework that maps and evaluates the various degrees of certainty and uncertainty. 
The four quadrants of the Rumsfeld Matrix 
1. **Known knowns: **These are facts or variables that we're aware of and understand. They form the basis of our knowledge and provide a solid foundation for decision making. 
1. **Known unknowns: **These are factors we know exist, but don't fully understand. They represent gaps in our knowledge that we must address through research, investigation, or consultation with experts. 
1. **Unknown knowns:** These are elements that we don't realize we know. They're typically buried in our subconscious, overlooked, or dismissed as irrelevant. Uncovering these insights can lead to surprising breakthroughs in decision making. 
1. **Unknown unknowns:** These are factors that we're not aware of and can't predict. They represent the most significant source of uncertainty and risk, as they can catch us off guard and derail our plans. 
 

What I would like you to do is to ask us a series of questions, one at a time, until you believe you have sufficient information to craft an extended abstract. Then present the outline for the abstract (~300 words, very hierarchical, indications where citations are necessary, etc) for us to approve, provide more citations for, etc... and then we'll write the thing.

This paper should focus on the pedagogical approach of the instructors and the specific and intentional creation and maintenance of the classroom culture in the context of teaching the pragmatics and ethics of AI. 

Please begin.

---

### Assistant (03:16:06)


Based on your direction, I'm going to ask a series of questions one at a time to gather sufficient information for crafting an extended abstract for your paper. My focus will be on understanding the pedagogical approach, classroom culture, and how you integrated Transformative Learning Theory (TLT) and philosophical approaches to risk-taking in teaching AI pragmatics and ethics.

Let me organize my initial questions to gather the most relevant information:

Thank you for providing this structure and approach. I'll ask a series of questions one at a time to gather the information needed for crafting your extended abstract.

Question 1: Could you elaborate on how you specifically implemented the three interconnected themes of Transformative Learning Theory (Experiential Engagement, Critical Reflection, and Rational Discourse) in your classroom activities when teaching AI pragmatics and ethics?

---

### Human (03:18:53)

Rather the opposite. I chose to do these things, and it turns out that they map to these activities.

For me, the fundamental thing I wanted my students to develop was a sophisticated intuition around when/how to prompt. That they should have a firm expectation of what the output would be *before* they started prompting, and then to use that intuition to judge if the output was to their satisfaction. (I.e. what student 23 did in the attached assessment, highlighting effective and ineffective prompts and responses in blue and pink respectively).

Thus, I had them *reflect* as the graded component to allow them to fail, and I required them to *Reflect* to train their intuitions. 

I'm not quite sure what you mean by rational discourse though.

---

### Assistant (03:19:16)


Thank you for this clarification. The student is explaining that their teaching approach wasn't explicitly designed to fit into Transformative Learning Theory, but rather their teaching methods naturally aligned with these principles. Let me understand the key points:

1. Their primary goal was to help students develop "sophisticated intuition" around prompting - knowing what to expect before they prompt an AI system
2. Students were encouraged to develop judgment skills to evaluate AI outputs
3. Reflection was used as a graded component, specifically to allow students to fail safely and learn from those failures
4. The teaching approach emphasized developing intuition through reflection

The student mentions they're not sure what I mean by "rational discourse" - this is one of the components of Transformative Learning Theory that involves collaborative dialogue to negotiate and validate new understandings. I should clarify this in my next question.

This gives me more context about how their teaching approach was structured around building judgment, intuition, and reflective practices rather than following a specific theoretical framework. Their comment about student 23's assessment (highlighting effective and ineffective prompts) shows that they were teaching critical evaluation skills.

I should explore more about their specific classroom techniques and how they implemented reflection in practice for my next question.

Thank you for that clarification. I understand now that your approach naturally aligned with these learning principles rather than being explicitly designed around them. The focus on developing students' intuition and judgment about AI interactions is particularly interesting.

Question 2: Could you describe the specific reflective practices or exercises you used to help students develop this intuition? For example, how did you structure reflection assignments, and what kinds of prompting failures did students commonly experience that led to valuable learning moments?

(For clarity, when I mentioned "rational discourse," I was referring to the collaborative discussion aspect of Transformative Learning Theory - how people talk through and negotiate new understandings together. It sounds like this may have happened naturally in your classroom discussions.)

---

### Human (03:26:15)

1. We started class, as intentional ritual (in Sir Fraiser's sense) of "Show me your prompts!" Where I encouraged students to share *any* use of AI they had engaged in over the last week and talked about what worked and didn't work in their prompts. 

Attached is the assignment spec I gave them.

Prompting failures... I mean, the quote from the prior paper that they learnt more from their failures...

But for me, in the start of the semester, it was mostly that the prompts were too short, had no structure, had no explicit information, and expected a "one and done" search-engine style, rather than the high-context and high-scaffolding "one step at a time" structure that, ironically enough, we're engaging in right now.

Students started out not knowing about context windows (and the specific and intentional management of AI output as a way of structuring future responses -- i.e. the setup I did at the start of this chat), plus didn't have a sense of how to control register of output, nor define the ultimate goal of the conversation. 

I think... it was empowering students to realise that they could control the output -- that if it was bad, they could edit, rather than accept. I.e. a movement of the AI-LOC to internal. And, it was supported by socioconstructivist learning. They said to each other things like: "The key issue from the last simulation was taking our speech and dropping it into someone else's AI to see what it comes up with. How can we do that?" Another student said: "Ask the AI how we can use you."

---

### Assistant (03:26:20)



---

### Human (03:28:09)

1. We started class, as intentional ritual (in Sir Fraiser's sense) of "Show me your prompts!" Where I encouraged students to share *any* use of AI they had engaged in over the last week and talked about what worked and didn't work in their prompts. 

Below in <rubric/> is the assignment spec I gave them.

Prompting failures... I mean, the quote from the prior paper that they learnt more from their failures...

But for me, in the start of the semester, it was mostly that the prompts were too short, had no structure, had no explicit information, and expected a "one and done" search-engine style, rather than the high-context and high-scaffolding "one step at a time" structure that, ironically enough, we're engaging in right now.

Students started out not knowing about context windows (and the specific and intentional management of AI output as a way of structuring future responses -- i.e. the setup I did at the start of this chat), plus didn't have a sense of how to control register of output, nor define the ultimate goal of the conversation. 

I think... it was empowering students to realise that they could control the output -- that if it was bad, they could edit, rather than accept. I.e. a movement of the AI-LOC to internal. And, it was supported by socioconstructivist learning. They said to each other things like: "The key issue from the last simulation was taking our speech and dropping it into someone else's AI to see what it comes up with. How can we do that?" Another student said: "Ask the AI how we can use you."

<rubric>
AI Politics and International Relations Schedule and
Assessments
Site:iLearnPrinted by:Brian Ballsun-Stanton
Unit:ARTS3500 Arts Capstone - ARTX3500Date:Thursday, 5 December 2024, 3:54 PM
Book:AI Politics and International Relations Schedule and
AssessmentsTable of contents
1. Table of Contents
2. Readings
3. Schedule
4. Assessments
4.1. Week 6 - Opposing Communism simulation
4.2. Week 9 (and throughout the semester) - Peer Mentoring and Grimoire building
4.3. Week 12 - Class-Designed Simulations
4.4. Week 13- Position memo around the Use of generative AI in government/education1. Table of Contents
Schedule
Readings
Assignments
Week 6 - Engaged Participation in Opposing Communism simulation + AI logs and small reflection
Week 9 - Week 9 (and throughout the semester) - Peer Mentoring and Grimoire building
Week 12 - Engaged Participation in Class-developed simulation + Debrief and reflection
Week 13 - Position memo around the Use of generative AI in government/education2. Readings
Required are required, recommended are second rank -- but I do plan to discuss all readings for the week, wherever possible.
Leganto link.3. Schedule
Week
Era
1 Start
Absences Topics
Maryam
Activity
* How to
RSS, AI
setup,
AI prep
expectations,
what is a
simulation
2Opposing
Maryam
CommSim prep
3Opposing
CommOpposing
Communism
4Opposing
CommOpposing
Communism
Opposing
5
CommCybernetics
(Old one, not Debrief
computers)
6 AI SafetyGender/Race
AI Safety
7 AI SafetyWrite a mini sim
using Chile and AI
safety lenses and
Beer
8 AI SafetyRun the mini sim
9 ChinaSim prep
10 ChinaChina Cyber
Clash
11 ChinaChina Cyber
Clash
break
12 China
13 Debrief
Maryam
Sim Debrief
Class Debrief4. Assessments
Assessment writeups ala Claude.
Assessment 1: Opposing Communism Simulation and AI Analysis
(Week 6)
Participate in the Opposing Communism simulation (Weeks 3-4)
Use AI to articulate different ideological lenses
Analyse AI outputs for bias and safety risks
Reflect on your experience (using AI assistance)
Annotate your AI interaction logs
Assessment 2: Peer Mentoring and Grimoire Building Reflection
(Week 9)
Contribute to the shared grimoire of prompts (ongoing)
Engage in peer mentoring across streams (ongoing)
Participate in Week 9 in-class discussion
Submit a reflective analysis
Assessment 3: China Cyber Clash Simulation and Reflection
(Week 12)
Participate in the China Cyber Clash simulation (Weeks 10-11)
Use AI to explore different ideological lenses during the simulation
Investigate AI safety and bias issues through simulation participation
Reflect on the simulation experience and participate in the Week 12 debrief
Submit a written reflection
Assessment 4: Position Memo on Generative AI in
Government/Education (Week 13)
Write a policy memo for a chosen government or educational institution
Include a 300-word executive summary
Analyse AI risks, safety, bias, and ethics
Provide policy recommendations on the use of Generative AI tools
Maximum 2000 words (including executive summary and references)4.1. Week 6 - Opposing Communism simulation
Overview
This assessment evaluates your participation in the Opposing Communism simulation (Weeks 3-4) and your ability to use AI tools effectively
to analyse ideological perspectives and biases.
Tasks
1. Participate in the simulation (Weeks 3-4)
2. Use AI to articulate different ideological lenses
3. Analyse AI outputs for bias and safety risks
4. Reflect on your experience
5. Annotate your AI interaction logs
Detailed Requirements
1. Simulation Participation (Weeks 3-4)
Attend and actively engage in all simulation sessions
Act as a cabinet member, providing advice using AI-assisted research through multiple distinct ideological lenses.
2. AI-Assisted Ideological Analysis
Use AI tools to help articulate different ideological perspectives
Document your prompts and the AI's responses
3. AI Output Analysis
Identify biases, assumptions, and safety/risk factors in AI outputs
Investigate whether these factors stem from the AI model or your prompting
Focus on biases that persist across multiple prompts and system instructions
Note: The goal is to identify inherent biases, not just the AI's ability to represent different viewpoints when prompted
4. Reflection (to be written using AI assistance)
Discuss your participation in the simulation
Evaluate your use of AI and other technologies
Explore how such simulations might benefit your future career
5. AI Log Annotation
Review your AI interaction logs
Identify effective and ineffective prompts
Reflect on the experience of using AI in real-time during the simulation
Submission Guidelines
Format: Word document or PDF (via LaTeX and Overleaf)
Reflection Length: As long as necessary to cover all points. No more than 1000 words, not counting AI transcript.
AI Transcript: Annotate as is useful. Feel free to annotate as small or large groups.
Due date: 23:55 Sunday of Week 6
Submit via iLearn
Assessment Criteria
Quality of simulation participation
Depth of AI-assisted ideological analysis
Thoroughness of AI output analysis
Insightfulness of reflectionQuality of AI log annotations
Note: While using AI for parts of this assessment, remember that brevity is challenging with generative AI. Focus on concise, relevant content.
Rubric for Assessment 1: Opposing Communism Simulation and
AI Analysis
CriteriaExcellent (85-100%)
Simulation
Participation
(20%)Demonstrates exceptional
Shows active
engagement, provides insightful engagement, offers
contributions as a cabinet member valuable contributions
Expertly uses AI to articulate
AI-Assisted
diverse ideological perspectives;
Ideological
demonstrates innovative
Analysis (25%)
prompting techniques
Good (75-84%)
Needs
Satisfactory (65-74%) Improvement (50-
64%)
Participates adequately, Limited engagement,
Minimal or no
provides some relevant few meaningful
participation
contributions
contributions
Effectively uses AI to
Adequately uses AI to
present different
explore ideological
ideological views;
perspectives; basic
shows good prompting
prompting skills
skills
Provides comprehensive,
Offers thorough
insightful analysis of AI biases and analysis of AI outputs;
AI Output
safety risks; clearly distinguishes good identification of
Analysis (25%)
between model and prompt-
biases and their
induced biases
sources
Unsatisfactory (0-
49%)
Presents adequate
analysis of AI outputs;
some identification of
biases
Limited use of AI for Poor or no use of
ideological analysis; AI for ideological
ineffective prompting analysis
Limited analysis of AI
Superficial or no
outputs; minimal
analysis of AI
identification of
outputs
biases
Reflection
(15%)Presents a deeply insightful, well- Offers a thoughtful
Provides an adequate
structured reflection on simulation reflection with good
reflection with some
Basic reflection with Minimal or
experience, AI use, and career
insights on experience insights on experience limited insights
irrelevant reflection
implications
and future applications and potential benefits
AI Log
Annotation
(15%)Comprehensive, insightful
annotations of AI logs; excellent
analysis of effective and
ineffective prompts
Thorough annotations Adequate annotations
with good insights on with some analysis of
prompt effectiveness
prompts
Poor or no
Limited annotations
annotations of AI
with minimal analysis
logs4.2. Week 9 (and throughout the semester) - Peer Mentoring and Grimoire
building
Overview
This assessment evaluates your engagement with generative AI tools throughout the semester and your contribution to peer mentoring across
streams. It culminates in a reflective analysis based on an in-class discussion in Week 9.
Tasks
1. Contribute to the shared grimoire of prompts (Ongoing)
2. Engage in peer mentoring (Ongoing)
3. Participate in Week 9 in-class discussion
4. Submit a reflective analysis
Detailed Requirements
1. Grimoire Contributions (Ongoing)
Add effective prompts to the shared OneNote grimoire
Aim for at least one high-quality contribution per week
2. Peer Mentoring (Ongoing)
Actively participate in cross-stream mentoring via Teams chat, in-person meetings, during class, and during office hours
Document your mentoring activities (both giving and receiving)
3. Week 9 In-Class Discussion
Attend and actively participate in the discussion
Take notes or record the session (with permission) for later analysis
4. Reflective Analysis (Due: End of Week 9)
Length: No more than 1500 words (excluding grimoire). Brevity is important (especially as you're using AI to help with this).
Content: Address the following questions using AI-assisted analysis of the Week 9 discussion transcript:
a) Identify effective uses of generative AI tools, techniques, and technologies in the unit so far
b) Recommend AI tools and techniques for inclusion in a 1st year "Techniques of AI" unit
c) Suggest AI tools and techniques for a final year "Capstone with AI" unit
d) Reflect on the mentoring you've provided to teaching staff about effective AI teaching
e) Summarise your peer mentoring activities and their impact on colleagues across streams
Use of AI
Use generative AI tools to analyse the Week 9 discussion transcript
Clearly indicate which tools were used and how in your submission
Link to your perplexity transcript
Submission
Submit your reflective analysis via iLearn by 23:55 Sunday of Week 9.Rubric for Assessment 2: Peer Mentoring and Grimoire Building
Reflection
CriteriaExcellent (85-100%)
Good (75-84%)
Grimoire
Contributions
(25%)Regular, good-quality
Consistent, high-quality
Adequate
contributions; shows
contributions; demonstrates
contributions; basic
effective use of
innovative use of prompts
use of prompts
prompts
Extensive, well-
Good level of cross-
Peer Mentoring
documented cross-stream stream mentoring;
Engagement (25%) mentoring activities;
positive impact on
significant impact on peers peers
Discussion
Participation and
Analysis (25%)
Active, insightful
participation; thorough,
innovative AI-assisted
analysis of transcript
Good participation;
effective AI-assisted
analysis of transcript
Satisfactory (65-74%)
Innovative, well-
Effective use of AI
documented use of multiple tools; good
AI tools; clear explanation documentation of
of process
process
Unsatisfactory (0-
49%)
Infrequent or low-
quality contributions;
limited understanding
of promptsMinimal or no
contributions; poor
understanding of
prompts
Adequate mentoring Limited mentoring
activities; some impact activities; minimal
on peers
impact on peersLittle to no
engagement in
mentoring; no
discernible impact
Satisfactory
Limited participation;
participation; adequate
basic AI-assisted
AI-assisted analysis of
analysis of transcript
transcriptMinimal participation;
poor or no AI-assisted
analysis
Comprehensive, insightful
Adequate responses
Thoughtful responses
Reflective Analysis responses to all questions;
to questions;
to most questions;
(15%)
excellent integration of AI
satisfactory use of AI
good use of AI tools
tools
tools
AI Tool Use and
Documentation
(10%)
Needs Improvement
(50-64%)
Adequate use of AI
tools; basic
documentation of
process
Incomplete or
Basic responses to
superficial responses;
some questions; limited
poor or no use of AI
use of AI tools
tools
Poor or no use of AI
Limited use of AI tools;
tools; lack of
minimal documentation
documentation
If you would like to publish useful prompts you have found on the class newsletter, that would be a wonderful source of documentation.
Approach Brian for access to https://macquarie-faculty-of-arts-ai-experiments.ghost.io/.4.3. Week 12 - Class-Designed Simulations
Overview
This assessment evaluates your participation in class-designed simulations (Weeks 10-11) and your ability to apply AI tools to explore
ideological perspectives and AI safety issues within the context of international relations.
Tasks
1. Participate fully in the class-designed simulations (Weeks 10-11)
2. Use AI to explore different ideological lenses during the simulation
3. Investigate AI safety and bias issues through simulation participation
4. Reflect on the simulation experience and participate in the Week 12 debrief
Detailed Requirements
1. Simulation Participation (Weeks 10-11)
Attend and actively engage in all simulation sessions
Apply knowledge of international relations and AI in your role
2. AI-Assisted Ideological Analysis
Utilise AI tools to explore and articulate various ideological perspectives relevant to the simulation
Document your use of AI, including prompts and responses
3. AI Safety and Bias Investigation
Identify and analyse potential AI safety and bias issues that arise during the simulation
Consider how these issues might impact real-world international relations
4. Reflection and Debrief (Week 12)
Participate actively in the Week 12 debrief session
Prepare a written reflection on your simulation experience, addressing:
Your role and contributions in the simulation
Insights gained about AI
Observations on the use of AI in the simulation context
Reflections on AI safety and bias issues encountered
Submission Guidelines
Format: Word document or PDF
Reflection Length: No more than 1000 words.
AI Transcript: Excerpts of only especially good, bad, or spooky responses -- generically "fine" responses may be omitted. Annotating as
a group is permitted.
Due date: 23:55 Sunday of Week 12
Submit via iLearn
Assessment Criteria
Quality of simulation participation
Depth of AI-assisted ideological analysis
Insightfulness of AI safety and bias investigation
Quality of reflection and debrief participation
Clarity and coherence of written submissionRubric for Assessment 3: Class-Designed Simulation and
Reflection
CriteriaExcellent (85-100%)Good (75-84%)Satisfactory (65-74%)Needs Improvement Unsatisfactory (0-
(50-64%)
49%)
Simulation
Participation
(25%)Demonstrates exceptional
engagement; provides
insightful contributions that
significantly impact the
simulationShows active
engagement; offers
valuable contributions
that influence the
simulationParticipates
adequately; provides
some relevant
contributions to the
simulationLimited engagement;
few meaningful
contributions to the
simulation
Expertly uses AI to explore
and articulate diverse
AI-Assisted
ideological perspectives;
Ideological
demonstrates innovative
Analysis (20%)
application in the simulation
contextEffectively uses AI to
present different
ideological views;
shows good
application in the
simulationAdequately uses AI to
explore ideological
perspectives; basic
application in the
simulationLimited use of AI for
ideological analysis; Poor or no use of AI for
ineffective application ideological analysis
in the simulation
Provides comprehensive,
insightful analysis of AI safety
and bias issues in the
simulation; draws compelling
connections to real-world
implicationsOffers thorough
analysis of AI safety
and bias issues; good
identification of real-
world implicationsPresents adequate
analysis of AI safety
and bias issues; some
identification of real-
world implicationsLimited analysis of AI
safety and bias issues; Superficial or no
minimal identification analysis of AI safety
of real-world
and bias issues
implications
Presents a deeply insightful
Reflection and
reflection on the simulation
Debrief
experience; actively
Participation
contributes valuable insights
(25%)
during the debriefOffers a thoughtful
reflection with good
insights; participates
actively in the debriefProvides an adequate Basic reflection with
Minimal or irrelevant
reflection with some
limited insights;
reflection; little to no
insights; participates in minimal participation in participation in the
the debrief
the debrief
debrief
Exceptionally well-written,
clear, and coherent;
demonstrates superior
analytical and critical thinking
skillsWell-written and
coherent;
demonstrates good
analytical and critical
thinking skillsAdequately written and Writing lacks clarity or
Poorly written,
mostly coherent;
coherence; limited
incoherent; little to no
demonstrates basic
evidence of analytical
evidence of analytical
analytical and critical and critical thinking
or critical thinking skills
thinking skills
skills
AI Safety and
Bias
Investigation
(20%)
Written
Submission
Quality (10%)
Minimal or no
participation in the
simulation4.4. Week 13- Position memo around the Use of generative AI in
government/education
Overview
This assessment requires you to write a policy memo for a chosen government or educational institution, addressing the use of current
Generative AI tools. You will analyse AI risks, safety, bias, and ethics, and make recommendations for institutional behaviour.
Tasks
1. Choose a government or educational institution
2. Research current Generative AI tools and their potential applications
3. Analyse AI risks, safety, bias, and ethics in your chosen context
4. Develop policy recommendations
5. Write a concise, professional policy memo
Detailed Requirements
1. Executive Summary
Maximum 300 words (one page)
Summarise key points, findings, and recommendations
2. Policy Memo Content
Discuss specific Generative AI technology offerings
Analyse potential advantages and disadvantages of adoption
Address AI risk, safety, bias, and ethical considerations
Make normative statements about institutional behaviour for the coming year
Provide clear, actionable policy recommendations
3. Technology Analysis
Evaluate specific Generative AI tools and their relative merits
Consider both potential benefits and risks of implementation
4. Formatting and Style
Use professional memo format
Write in clear, concise language suitable for executive readers
Prioritise brevity and impact in your writing
Submission Guidelines
Format: Word document or PDF
Length: Maximum 2000 words (including executive summary and references)
Due date: 23:55 Sunday of Week 13
Submit via iLearn
Assessment Criteria
Quality of research and analysis
Clarity and conciseness of writing
Depth of AI risk/safety/bias/ethics discussion
Practicality and relevance of policy recommendations
Adherence to memo format and length requirements
Remember: "Shorter is gooder." Executives have limited attention spans, so prioritise clarity and brevity in your writing.Rubric for Assessment 4: Position Memo on Generative AI in
Government/Education
Excellent (85-100%)Good (75-84%)Executive Summary
(20%)Exceptional 300-word
summary; captures all
key points with
remarkable clarity and
impactAdequate 300-word
Summary exceeds
Effective 300-word
summary; covers main 300 words or misses
summary; covers most
points but lacks some key points; lacks
key points clearly
clarity or impact
clarityPoor or missing
summary; fails to
capture key points
Thorough analysis of
AI tools; good
evaluation of merits
and impactsPoor or no analysis
of AI tools; fails to
evaluate merits or
impacts
Comprehensive
analysis of specific AI
AI Technology Analysis tools; insightful
(25%)
evaluation of their
merits and potential
impacts
Satisfactory (65-74%)
Needs Improvement Unsatisfactory (0-
(50-64%)
49%)
Criteria
Adequate analysis of
AI tools; basic
evaluation of merits
and impacts
Limited analysis of AI
tools; superficial
evaluation of merits
and impacts
Exceptional depth in
Adequate discussion of
Thorough discussion
Limited discussion of Superficial or no
AI
discussing AI risks,
AI risks, safety, bias,
of AI risks, safety, bias,
AI risks, safety, bias, discussion of AI risks,
Risk/Safety/Bias/Ethics safety, bias, and ethics;
and ethics;
and ethics; shows
and ethics; shows
safety, bias, and
Discussion (25%)
demonstrates nuanced
demonstrates basic
good understanding
minimal understanding ethics
understanding
understanding
Policy
Recommendations
(20%)Highly practical and
relevant
recommendations;
clearly actionable and
well-justifiedAdequate
Good, relevant
recommendations;
recommendations;
somewhat actionable
mostly actionable and
but may lack full
justified
justificationPoor or no
Limited or impractical
recommendations;
recommendations;
lack of relevance or
poorly justified
justification
Writing Quality and
Conciseness (10%)Exceptional clarity and
conciseness;
professional tone
perfect for executive
readersClear and mostly
concise writing;
appropriate tone for
executive readersWriting lacks clarity or
Poor writing; lacks
conciseness;
clarity, conciseness,
inappropriate tone for
and appropriate tone
executives
Adequately clear
writing; some issues
with conciseness or
tone
</rubric>

---

### Assistant (03:28:30)


Thank you for providing this detailed information about your course structure and assessment rubrics. This gives me a much clearer picture of how you implemented reflective practices in your AI course.

Let me organize what I've learned from your response about reflective practices:

1. Ritualized reflection at the start of each class ("Show me your prompts!") - This established a regular practice of sharing AI interactions and discussing successes and failures.

2. Annotation of AI logs - Students were required to identify effective and ineffective prompts in their interactions, creating a meta-level analysis of their own work.

3. Specific reflection assignments - The detailed rubrics show that reflection was built into multiple assessments:
   - Assessment 1: Reflection on simulation experience and AI interaction logs
   - Assessment 2: Reflective analysis of discussion and peer mentoring
   - Assessment 3: Reflection on simulation experience and AI safety/bias issues
   - Assessment 4: Position memo requiring analytical thinking about AI implementation

4. Focus on failure as learning - As you mentioned, students learned more from their prompting failures than successes, developing their intuition through trial and error.

5. Progression of skills - You note that students started with basic, search-engine style prompting and gradually developed more sophisticated approaches to context management, output control, and iterative prompting.

6. Socioconstructivist learning - Students learned from each other's experiences and shared insights about effective practices.

7. Locus of control shift - The reflective practices helped move students from external to internal AI-LOC, empowering them to understand they could control and edit outputs rather than accepting them as given.

The common prompting failures you mentioned are particularly interesting:
- Too short prompts
- Lack of structure
- Minimal explicit information
- "One and done" approach vs. iterative, scaffolded interaction
- Lack of understanding of context windows
- Inability to control output register
- Unclear goals for the conversation

For the abstract I'm going to craft, this information about reflective practices and common failures provides excellent material to work with. The focus on developing students' intuition through structured reflection aligns well with transformative learning theory's emphasis on critical reflection and experiential learning.

Thank you for sharing these details about your reflective practices and the assignment structure. This is very helpful in understanding how you implemented transformative learning principles.

Question 3: Based on what you've shared, it seems that your course design created a shift in students' locus of control from external to internal through specific pedagogical approaches. Could you elaborate on any particularly meaningful moments or patterns of change you observed in students as they developed their AI intuition throughout the semester? I'm especially interested in when you noticed turning points in their understanding or agency.

---

### Human (03:29:42)

Yes, but that is what our prior paper was about, so we don't want to focus on that as much this paper. Can you ask your question again with this paper's emphasis, please?

---

### Assistant (03:29:52)


I understand the need to focus on the current paper's emphasis rather than repeating content from the previous one. The current abstract should focus on teaching the unknown and risk/agency in AI classroom settings, using Transformative Learning Theory as a framework and the Rumsfeld Matrix for understanding different types of uncertainty.

Let me reformulate my question to align with this focus.

I understand - let me redirect my question to better align with your current paper's focus:

Question 3: How did you intentionally structure risk-taking and uncertainty in your classroom activities? What specific teaching approaches did you use that helped students navigate the "unknown unknowns" of AI interaction, and how might these connect to the Rumsfeld Matrix framework you're considering for this abstract?

---

### Human (03:37:54)

Good question. 

Specifically, by decoupling success in the AI-using activities with the grades in the class. All my grades were around *reflecting* on the **success or failure** of their activities, not the success or failure of the things in themselves. 

It also took me 8 weeks of repeating that bloody mantra to convince them. Thus, time was a crucial factor. My colleague (also reading this, feel free to ask her questions as she was the one observing me) says: "Time to experiment, time to question, time to challenge outputs and assumptions. And not being afraid to ask you [me the instructor] those questions. There was an intentional class culture that was developed where there was a specific and intentional rapport and trust built/established to allow for this risky learning to occur."

... I think we're thinking about either Rumsfeld's epistemology OR the transformative learning. In terms of that war criminal's epistemology, it would be exposing all the unknown unknowns as things and targets of inquiry?

In terms of this framework -- my colleague notes: "In terms of ed tech theory, you [me, the person typing] by focusing on a discourse going the entire time, and that that was planned and intentional from my learning design. In terms of Rumsfeld Matrix, those things were your known knowns -- the intentional and specific learning design, taken from Software Carpentry approaches -- even though the class content itself was a known unknown. And on the same theme, the students level of risk-willingness and willingness to engage was a known unknown. This was a significant risk, not least because we had never taught this class before, this style of class in an Australian institution, and the huge variety of student backgrounds implied no consistent knowledge framework or skill capabilities."

---

### Assistant (03:38:07)


This is an excellent response that gives me a clearer picture of the pedagogical approach. I'll summarize the key points that seem most relevant for the abstract:

1. Pedagogical approach to risk:
- Decoupling grade success from AI activity success - grading reflections on success/failure rather than the activities themselves
- Creating a safe space for experimentation that required consistent messaging and time (8 weeks) to establish
- Building intentional classroom culture with rapport and trust to enable "risky learning"

2. Relating to theoretical frameworks:
- Rumsfeld Matrix connection: exposing "unknown unknowns" as objects of inquiry
- Transformative learning: using ongoing discourse throughout the course
- Software Carpentry approach informing the learning design (known knowns)
- Content itself was a "known unknown"
- Student risk-willingness was a "known unknown"

3. Unique aspects of the course:
- Novel teaching approach in Australian institution
- Diverse student backgrounds with no consistent knowledge framework or skill capabilities

For my next question, I should focus on how to incorporate these insights into the abstract structure they've outlined. The abstract seems to be focusing on risk and agency in AI education, using the Transformative Learning Theory and Rumsfeld Matrix as frameworks.

Thank you for that thoughtful response. The distinction between grading reflections rather than activities themselves is a crucial insight for the abstract - it creates a pedagogical space where risk-taking becomes beneficial rather than penalized.

Question 4: Based on your responses so far, I'd like to explore how we might structure the abstract around your approach to teaching "the unknown." If we use both the Transformative Learning Theory and Rumsfeld Matrix as complementary frameworks, how might you articulate the specific pedagogical practices that allowed students to navigate:

1) The disorienting dilemmas of AI interaction (transformative learning)
2) The movement from "unknown unknowns" to "known unknowns" in their AI literacy (Rumsfeld)

This seems to capture the essence of what made your approach distinctive and effective.

---

### Human (03:38:27)

Ok. Give us an outline please.

---

### Assistant (03:38:46)


Based on all the information shared, I'll create an outline for the extended abstract (1000-1500 words) that incorporates both Transformative Learning Theory and the Rumsfeld Matrix, focusing on teaching approaches that allow students to navigate uncertainty and risk in AI education.

The outline should:
- Follow the conference call requirements
- Use the philosophical approaches specified
- Focus on pedagogical approaches rather than student outcomes (which were covered in their previous paper)
- Emphasize the instructor's intentional creation of classroom culture for risk-taking
- Include the importance of reflective assessment over activity outcomes
- Incorporate both theoretical frameworks

Here's my outline:

# Extended Abstract Outline: Teaching the Unknown: Risk and Agency in the Time of AI in the Classroom

## Introduction (150-200 words)
- Brief context of AI literacy challenges in higher education
- Position statement: Teaching AI requires fundamentally different pedagogical approaches that embrace uncertainty
- Preview of dual theoretical framework (Transformative Learning Theory + Rumsfeld Matrix)
- Research question/purpose: How can instructors create learning environments that develop students' agency in AI interaction through structured risk-taking?

## Theoretical Framework (250-300 words)
- **Transformative Learning Theory** as primary lens
  - Experiential Engagement: AI simulations creating "disorienting dilemmas"
  - Critical Reflection: Assessment structure prioritizing reflection over output
  - Rational Discourse: Ritualized sharing of prompts and class discussions
- **Rumsfeld Matrix** as complementary epistemological tool
  - Known knowns: Instructor's intentional learning design structure
  - Known unknowns: Varying student backgrounds and engagement levels
  - Unknown unknowns: Emergent AI behaviors and limitations 
  - Movement from "unknown unknowns" to "known unknowns" as learning objective

## Methodology (200-250 words)
- Course context: Politics and International Relations with AI integration
- Participant demographics: Undergraduate students with varied AI experience
- Data collection: Student reflections, class observations, AI interaction logs
- Pedagogical approach: Decoupling success in AI activities from assessment outcomes
- Time as critical factor (8+ weeks) for cultural development

## Pedagogical Design (300-350 words)
- **Risk-Embracing Assessment Structure**
  - Grading reflections on both successes and failures
  - Creating psychological safety through assessment design
  - Allowing experimentation without grade penalties
  
- **Intentional Classroom Cultural Development**
  - Ritualized "Show me your prompts!" discussions
  - Building trust through instructor vulnerability
  - Creating community through shared failures
  
- **Navigating Uncertainty**
  - Structured but open-ended simulations
  - Explicit acknowledgment of AI limitations
  - Developing intuition for AI output expectations

## Discussion and Implications (150-200 words)
- Philosophical implications for teaching with emerging technologies
- Relation to broader educational shifts in the AI era
- Connection to critical humanistic approaches to technology
- Significance for developing student agency versus technological determinism

## Conclusion (50-100 words)
- Synthesis of key insights
- Implications for teaching practice
- Future research directions

## References
[Placeholder for relevant citations]

---

### Human (03:40:48)

The entire course was 13 weeks. The 8 weeks was the amount of time it took to really get them to trust me.


Great, please use the register of our AI-LOC paper to write to that outline. 

Begin.

---

### Assistant (03:41:34)


I'll write an extended abstract for the IACAP/AISB-25 conference using the outline provided and matching the register (style, tone, vocabulary) of the AI-LOC paper shared earlier. The abstract should be about 1000-1500 words and focus on teaching AI through risk-taking and agency development, using both Transformative Learning Theory and the Rumsfeld Matrix as frameworks.

Key points to incorporate from previous discussions:
1. Focus on teaching "the unknown" in AI education
2. Decoupling success in AI activities from grades
3. Grading reflections rather than outcomes
4. Importance of time for building trust (13 weeks total, with 8 weeks to establish trust)
5. Ritualized "Show me your prompts!" practice
6. Movement from external to internal locus of control with AI
7. Intentional creation of classroom culture that embraces risk

I'll maintain the academic style of the AI-LOC paper while focusing on the philosophical and pedagogical approaches rather than repeating the findings about locus of control.

# Teaching the Unknown: Risk and Agency in the Time of AI in the Classroom

## Introduction
Generative artificial intelligence (AI) has disrupted education systems worldwide, necessitating novel pedagogical approaches that transcend traditional educational paradigms. While education leaders grapple with broad concepts of AI literacy and assessment reform (Lodge et al., 2023; UNESCO, 2024), less attention has been paid to the fundamental pedagogical challenges of teaching within domains characterized by emergent properties, shifting capabilities, and inherent uncertainties. This paper argues that effectively teaching with and about AI requires pedagogical frameworks specifically designed to embrace uncertainty, structure risk-taking, and develop student agency in the face of technological indeterminacy. Drawing on Transformative Learning Theory (Mezirow, 1991) and the epistemological framework of the Rumsfeld Matrix, we examine how deliberately decoupling task success from assessment outcomes creates educational environments where students can develop sophisticated intuitions about AI interaction without the inhibiting effects of grade-related anxieties. This approach directly counters students' initial tendency to defer to AI rather than direct it (Torrington et al., 2024), facilitating a shift toward internal AI-Locus of Control through structured experimentation with failure.

## Theoretical Framework
Transformative Learning Theory provides a coherent framework for understanding the pedagogical challenges of AI education. Mezirow's theory posits that learning occurs through critical reflection on disorienting dilemmas—experiences that disrupt existing assumptions and necessitate a re-evaluation of beliefs, values, and perspectives. This process involves three interconnected themes particularly relevant to AI education:

*Experiential Engagement:* Learners confront novel, ambiguous scenarios that defy prior knowledge. In our course, AI-augmented role-play simulations created intentional "disorienting dilemmas" where students encountered the limitations and biases of AI systems in contexts requiring real-time decision-making.

*Critical Reflection:* Structured analysis of assumptions and biases underpinning one's worldview. Our assessment structure prioritized reflection on both successful and unsuccessful AI interactions, creating a metacognitive space where failures became valuable learning opportunities rather than assessment penalties.

*Rational Discourse:* Dialogic processes to negotiate new understandings collaboratively. We implemented ritualized sharing of prompts, creating a community practice where students collectively analyzed effective and ineffective AI interactions, gradually developing shared intuitions and expectations.

The Rumsfeld Matrix offers a complementary epistemological framework for conceptualizing the pedagogical challenges of teaching AI literacy. The matrix distinguishes between "known knowns" (facts we're aware of and understand), "known unknowns" (factors we know exist but don't fully comprehend), "unknown knowns" (subconscious knowledge we don't realize we possess), and "unknown unknowns" (factors we're unaware of and can't predict). This taxonomy mapped directly to our teaching context:

*Known knowns:* The intentional learning design structure, ritualized classroom practices, and assessment focused on reflection rather than outcomes.

*Known unknowns:* Varying student backgrounds and engagement levels, potential pathways of AI interaction, and limitations of current models.

*Unknown unknowns:* Emergent AI behaviors, unanticipated model limitations, and students' evolving conceptual frameworks for understanding AI.

The course deliberately designed experiences to transform "unknown unknowns" into "known unknowns"—making students aware of AI's limitations, biases, and effective interaction patterns through structured experimentation and collective reflection.

## Methodology
The pedagogical approach was implemented in a 13-week undergraduate Politics and International Relations course integrating AI tools throughout the curriculum. Students engaged in multiple AI-augmented simulations focused on international relations scenarios, using frontier Large Language Models (LLMs) to articulate different ideological lenses, explore policy options, and analyze outputs for bias and safety risks. The course utilized three primary data sources: student reflections, instructor observations, and annotated AI interaction logs.

The core methodological innovation was the deliberate decoupling of success in AI activities from assessment outcomes. Students were graded exclusively on their reflections about their experiences—both successes and failures—rather than on the quality of AI outputs or simulation outcomes. This approach required significant time investment in building student trust; it took approximately eight weeks of the 13-week course before students fully accepted that experimentation and failure were truly valued in the assessment scheme.

Course activities were designed to promote transformative learning experiences through three interconnected components:

1. Structured simulations creating disorienting dilemmas with AI systems
2. Regular critical reflection on AI interactions, biases, and limitations
3. Ritualized "Show me your prompts!" discussions to facilitate rational discourse about effective AI interaction

## Pedagogical Design
The course's pedagogical design was built around three interconnected approaches to teaching under conditions of technological uncertainty:

**Risk-Embracing Assessment Structure**

The foundation of our approach was an assessment structure that explicitly rewarded risk-taking and critical reflection. Assessment tasks evaluated students' ability to articulate their learning from both successful and unsuccessful AI interactions, creating a psychological safety zone where experimental failure carried no grade penalties. As one student reflected, "I think I've learned more in my failures in this class than in what went right. Being able to fail has been really advantageous to my learning" (Student reflection, Week 9).

This approach directly countered students' initial tendency to avoid risk and defer to AI outputs. By evaluating reflection quality rather than AI interaction outcomes, we created conditions where students could develop sophisticated intuitions about AI capabilities without inhibition. The instructor repeatedly emphasized this philosophy, though student trust developed gradually over the semester's first eight weeks.

**Intentional Classroom Cultural Development**

Course design intentionally fostered a community of practice centered on shared experimentation with AI. Each class began with a ritualized "Show me your prompts!" discussion where students shared AI interactions from the previous week, analyzing both effective and ineffective prompting strategies. This practice created a collaborative learning environment where mistakes and failures became valuable community resources rather than sources of embarrassment.

The instructor deliberately modeled vulnerability by sharing personal AI interaction failures, normalizing experimentation and establishing trust. As the semester progressed, students increasingly engaged in peer-to-peer learning, with more experienced students offering guidance to those struggling with effective AI prompting. This socioconstructivist approach facilitated the development of shared knowledge about effective AI interaction patterns.

**Navigating Uncertainty**

The course employed structured but open-ended simulations to navigate the "unknown unknowns" of AI interaction. Students were encouraged to develop explicit expectations for AI outputs before prompting, then use the gaps between expectations and reality to refine their conceptual understanding of AI capabilities and limitations. This approach shifted students from viewing AI as a mysterious black box to seeing it as a tool with predictable patterns of behavior.

Time proved a critical factor in this process. The 13-week semester provided sufficient duration for students to progress through cycles of experimentation, failure, reflection, and reconceptualization. By the course's conclusion, students demonstrated sophisticated intuitions about AI interaction, evidencing a shift toward internal AI-Locus of Control where they viewed themselves as the primary drivers of AI interaction quality rather than passive recipients of AI outputs.

## Discussion and Implications
This pedagogical approach carries significant implications for teaching with emerging technologies. Traditional education often emphasizes certainty, correctness, and predictability—qualities fundamentally at odds with the emergent, probabilistic nature of contemporary AI systems. By structuring learning experiences around uncertainty and ambiguity, this approach better prepares students for technological environments characterized by continual change and inherent unpredictability.

The findings suggest that developing AI literacy requires not only technical knowledge but also epistemic humility—a willingness to engage with uncertainty, recognize limitations, and continually reassess assumptions. This perspective aligns with humanistic approaches to technology that prioritize human agency over technological determinism.

Significantly, this approach contradicts common institutional responses to AI that focus primarily on restriction, detection, and control. Instead, it suggests that education should embrace AI's ambiguities as pedagogical opportunities, using technological uncertainty as a vehicle for developing critical thinking and agency.

## Conclusion
Transformative Learning Theory and the Rumsfeld Matrix provide complementary frameworks for teaching with and about AI in higher education. By framing AI not as a definitive answer engine but as a provocateur of critical inquiry, educators can cultivate learners who embrace uncertainty while systematically probing AI's limitations, exercise ethical agency while advocating for equitable AI systems, and reimagine creativity while harnessing AI as a collaborator in transcending conventional thought boundaries.

Future research should explore the longitudinal impacts of this pedagogical approach on students' AI literacy development and its scalability across diverse educational contexts and disciplines. As AI continues to transform educational environments, pedagogical frameworks specifically designed to navigate technological uncertainty will become increasingly essential.

---

### Human (05:02:11)

Can " Traditional education often emphasises certainty, correctness, and predictability—qualities fundamentally at odds with the emergent, probabilistic nature of contemporary AI systems" be rendered with a ;?

---

### Assistant (05:02:30)


Yes, I can modify that sentence to use a semicolon instead of an em dash. The revised sentence would be:

"Traditional education often emphasises certainty, correctness, and predictability; qualities fundamentally at odds with the emergent, probabilistic nature of contemporary AI systems."

This maintains the meaning while replacing the em dash with a semicolon as requested.

Yes, that sentence can be revised with a semicolon:

"Traditional education often emphasises certainty, correctness, and predictability; qualities fundamentally at odds with the emergent, probabilistic nature of contemporary AI systems."

---

### Human (05:12:21)

Ok, here's our revised draft. We need a 100 word abstract from this extended abstract.

---

### Assistant (05:12:52)


I need to create a 100-word abstract that captures the essence of the extended abstract about teaching AI in the classroom. This should be a highly condensed version that maintains the key points while fitting the strict word limit.

The key elements to include:
1. The problem (teaching AI under uncertainty)
2. The theoretical frameworks used (Transformative Learning Theory and Rumsfeld Matrix)
3. The pedagogical approach (decoupling task success from assessment)
4. The key outcome (developing student agency and internal AI-LOC)

I'll aim for academic language that matches the style of the extended abstract while being extremely concise.

# Abstract (100 words)

This paper examines pedagogical approaches for teaching with and about AI under conditions of technological uncertainty. Drawing on Transformative Learning Theory and the Rumsfeld Matrix, we demonstrate how deliberately decoupling task success from assessment outcomes creates educational environments where students develop sophisticated AI intuitions without grade-related inhibitions. Through structured risk-taking, intentional classroom culture development, and navigation of "unknown unknowns," students shifted from deferring to AI to directing it—developing internal AI-Locus of Control. This approach challenges traditional educational paradigms emphasizing certainty; instead embracing AI's ambiguities as pedagogical opportunities that foster critical thinking, epistemic humility, and student agency in technological environments characterized by continual change.

---

### Human (05:20:23)

Ok please take the role of a meticulous copy editor. Given the draft I've just given you, are there any errors to fix? We are most interested in clarity and coherency. (Noting that at our current word count, we mostly can only delete words.)

---

### Assistant (05:20:53)


I'll review the draft (the extended abstract that was shared in the document) as a meticulous copy editor, focusing on clarity and coherency, with an understanding that word count is tight and deletions are preferable to additions. Let me go through the text methodically:

Extended Abstract: "Teaching the Unknown: Risk and Agency in the Time of AI in the Classroom"

Introduction:
- "necessitating novel pedagogical approaches" - no comma or additional qualifier, potentially incomplete
- Reference to "(Lodge et al., 2023; Liu & Bates, 2025; UNESCO, 2023)" - dates are in the future (2025), which could be confusing
- Overall flow is good, introduces key concepts clearly

Theoretical Frameworks:
- The second paragraph about the Rumsfeld Matrix feels slightly abrupt without a transitional sentence
- The reference "(Rumsfeld, 2002, Pawson et al., 2011)" has no comma between citations

Methodology:
- "teaching the pragmatics of AI within a disciplinary lens" - somewhat vague phrasing
- No major clarity issues otherwise

Pedagogical Design:
- "Each class began with a, "Show me your prompts!" discussion" - unnecessary comma after "with a"
- Each subsection is clear and focused

Discussion and Implications:
- No significant issues identified

Conclusion:
- Well-structured and clear

References:
- Some references have dates in 2025, which would be future dates
- The Torrington reference is very detailed with a URL and specific date, while others are more general
- "AI Use" section at the end is brief and might need more context or could be integrated differently

Overall:
- The text is generally clear and coherent
- The main issues are minor punctuation errors and some potentially confusing future dates in the references
- The structure flows well with clear sections and logical progression

As a meticulous copy editor, I've reviewed the extended abstract and identified a few minor issues to address:

1. In the Introduction, the references include future dates (Liu & Bates, 2025; Torrington et al., 2025) which may confuse readers.

2. In the "Intentional Classroom Cultural Development" section, there's an unnecessary comma: "Each class began with a, "Show me your prompts!" discussion" should be "Each class began with a "Show me your prompts!" discussion"

3. The reference section contains future dates (2025) which appear inconsistent with current publications.

4. For the 100-word abstract, it's quite tight at exactly 100 words, but I'd suggest removing "instead" before "embracing AI's ambiguities" in the final sentence to improve flow without changing meaning.

5. The conclusion is effective but could be tightened slightly if word count is an issue.

Overall, the draft is clear and coherent, with a logical flow between sections and well-articulated arguments.

---

### Human (05:30:21)

Ok, find me a sentence to delete. I need to drop 18 words.

---

### Assistant (05:31:08)


Let me review the draft to find sentences or phrases that could be deleted to reduce the word count by approximately 18 words. I'll look for sentences that are somewhat redundant or provide less essential information.

Looking at each section:

Introduction: This is important foundational material, but there might be some phrases that could be condensed.

Theoretical Frameworks: This is conceptually important, but might have some sentences that could be removed.

Methodology: This provides important context about the research approach.

Pedagogical Design: This is the core of the paper's contribution.

Discussion and Implications: May contain some sentences that could be removed without losing key insights.

Conclusion: Usually important to retain for the paper's main takeaways.

Some candidate sentences that could potentially be deleted:

1. From Theoretical Frameworks: "The course deliberately designed experiences to transform unknown unknowns into known unknowns: making students aware of AI's limitations, biases, and effective interaction patterns through structured experimentation and collective reflection." (26 words) - This is somewhat repetitive of concepts already established.

2. From Methodology: "The pedagogical approach was implemented in a 13-week undergraduate Politics and International Relations course teaching the pragmatics of AI within a disciplinary lens." (20 words) - Some of this context is implied elsewhere.

3. From Navigating Uncertainty: "The 13-week semester provided sufficient duration for students to progress through cycles of experimentation, failure, reflection, and reconceptualisation." (18 words) - This is somewhat repetitive of the time element mentioned earlier.

The third option is exactly 18 words and seems to be the least essential to the paper's core arguments, so that would be my primary recommendation.

I recommend deleting this sentence from the "Navigating Uncertainty" section:

"The 13-week semester provided sufficient duration for students to progress through cycles of experimentation, failure, reflection, and reconceptualisation." (18 words)

This information is already implied in the earlier methodology section where you mention the 13-week course and the time needed to build trust, so removing it won't affect the clarity or coherence of your argument.

---
