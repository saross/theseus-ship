{
  "title": "AI Research Limitations Analysis",
  "create_time": 1739498949.831638,
  "update_time": 1749447269.849189,
  "mapping": {
    "aaa152d0-6f87-4395-af9a-704aecfd3686": {
      "id": "aaa152d0-6f87-4395-af9a-704aecfd3686",
      "message": null,
      "parent": null,
      "children": [
        "bc71db26-c66f-47d5-a6ea-cfabb79b48e3"
      ]
    },
    "bc71db26-c66f-47d5-a6ea-cfabb79b48e3": {
      "id": "bc71db26-c66f-47d5-a6ea-cfabb79b48e3",
      "message": {
        "id": "bc71db26-c66f-47d5-a6ea-cfabb79b48e3",
        "author": {
          "role": "system",
          "name": null,
          "metadata": {}
        },
        "create_time": null,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 0.0,
        "metadata": {
          "is_visually_hidden_from_conversation": true
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "aaa152d0-6f87-4395-af9a-704aecfd3686",
      "children": [
        "73872dc4-a987-49e9-91df-dd5dd1dfcae8",
        "210b030c-2171-4404-b48e-c1232381ac18"
      ]
    },
    "73872dc4-a987-49e9-91df-dd5dd1dfcae8": {
      "id": "73872dc4-a987-49e9-91df-dd5dd1dfcae8",
      "message": {
        "id": "73872dc4-a987-49e9-91df-dd5dd1dfcae8",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1739498949.83329,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "# Instructions\n\nThink step by step on the inputs that I give you. This project is to take user inputs which have been transcribed from audio, and are intended to build out the user's notes.\n\nDo not ask questions unless prompted, instead have a <think/> zone before your responses, then process user input in the form a transcript, and help to integrate it into the outline for the draft document.\n\nYour feedback or praise in this process is not wanted, instead, transform user inputs. Ask questions if there are elements which are unclear.\n\nAny outlines that you work on should be in markdown in an artefact.\n\n# Task 1\nTo begin, please synthesise yesterday's chat into the paper notes. We're getting ready to integrate another transcript.\n\n<chat1>\nI'll help you develop your academic paper through dictation. From your notes, I can see you're working on a thoughtful analysis of AI's limitations in research contexts, particularly focusing on the distinction between linguistic capability and true judgment/agency. Would you like to start dictating your thoughts? I can help organize them and suggest ways to develop the arguments further.\nI notice a few interesting threads in your current draft that could be expanded:\n\nThe connection between \"mundane utility\" and the absence of true agency\nYour comparison to first-week PhD students as a benchmark\nThe role of judgment in making novel connections across domains\n\nWhere would you like to begin? I can also ask clarifying questions about specific sections if that would be helpful for your dictation process.\u00a0CopyRetryBBMessage garbled, trying againEdit2 / 2I see your message was cut off. Would you like to try dictating your thoughts again? I'm ready to help organize and capture your ideas for the academic paper based on the draft you shared earlier.\u00a0CopyRetryBBOkay. So Thinking about the failure of deep research yesterday, generating a newspaper article. We can absolutely assert That'd be detail here is not of judgment. And and, of course, the necessary induction which maps to judge It does notEditI notice you're dictating thoughts about deep research's failure specifically regarding newspaper article generation, and touching on concepts of judgment and induction. However, some parts were unclear - could you try rephrasing the key point about judgment and induction again?\nFrom what I understood, you're suggesting that:\n\nThere was a specific failure case with deep research generating a newspaper article\nThis demonstrates a lack of judgment\nThere's a connection between judgment and induction\n\nWould you like to elaborate on any of these points? I'm particularly interested in the specific failure case you observed, as it could serve as a concrete example in your paper.\u00a0CopyRetryBBSo insofar as it produced a newspaper article that looked like a newspaper article. But Didn't follow the guidelines. I've quite literally the 2 elements that we, provided before. Like, we we made an article, and Claude We made an article in o one pro without search. And so deep research, even though it demonstrated no. Deep research, even though it purports to have agentic behavior, Doesn't. And so, therefore, here's where we need to to define Here's where we need to define what it means to be agentic. Because if we are to treat this like anything If we are to treat this like anything beyond a marketing term, We have to have very clear definitions. And so Edgentic machine. As a precursor to whatever we call AGI, is something that is goal following. For something to be goal following, it must be able to both Figure out when it is appropriate No. It must be able to figure out if it solved the problem. At the end of the day, I A goal following machine is a machine that Not only performs functional decomposition on any given task. Right? And so so that that functional decomposition is fine. But iOS machine that can judge. There's that word again. It's a machine that can judge if it has accomplished the task and moreover, if it has accomplished the task well, I e Has it not has it produced words, that vaguely mapped the vibes of the input, but has it generalized from the, specific data of the input. The actual problem that is trying to be solved and can it judge if it has solved that prob? And so deep research isn't agenic. And it's not agentic because it cannot take a goal as input and help to achieve that goal. Now to be clear, they're not particularly saying that it can, and and we can we can narrow Right? We can say, okay. This is narrowly scoped. This is Only for lit reviews, quote, unquote. Pausing here to reset.EditLet me help organize these key points about agency and judgment that you're dictating. I'll structure them to potentially fit into your paper's section on \"Agentic Systems\":\nThe core argument you're developing seems to be:\n\nDeep Research's failure case with the newspaper article demonstrates a fundamental issue:\n\nIt can produce content that superficially resembles the target format\nBut it failed to follow explicit guidelines, showing lack of true goal-following behavior\n\n\nThis leads to a necessary refinement of what \"agentic\" means in AI systems:\n\nAn agentic machine (as a precursor to AGI) must be fundamentally goal-following\nTrue goal-following requires:\na. Functional decomposition of tasks (which current systems can do)\nb. Ability to judge task completion\nc. Ability to judge task completion quality\nd. Capacity to generalize from specific inputs to understand the underlying problem\n\n\nThe key distinction:\n\nCurrent systems can \"produce words that vaguely map the vibes of the input\"\nBut they cannot generalize from specific data to understand and evaluate if they've solved the actual underlying problem\n\n\nTherefore, Deep Research isn't truly agentic because:\n\nIt cannot meaningfully take a goal as input\nIt cannot effectively help achieve that goal\nEven in its narrowly scoped domain of literature reviews\n\n\n\nWould you like to continue developing any of these points further? I notice this builds particularly well on your paper's existing section about goal-related characteristics of agentic systems.\u00a0CopyRetryBBAnd so even if they say even if this is narrowly scoped, even if this is only for lit reviews, and and we we also have to to say that this is a descriptive lit review, which lacks the spark of insight that makes a literature review useful. As in, why did you so a literature, for it to be useful, to go why did you choose these sources? What message are you trying to communicate? If you're merely regurgitating source That is That is the performance of literature review. Without any of the real substance of literature review. Because you are describing. You are not producing insight. Again, it's the lack of insight. It's the lack of induction because a literature review by virtue of how a thing is grouped, a literature review by virtue of what is selected and what is not selected. And a literature review by virtue of its organization supports a broader Claude. It supports the story. Or it supports research or whatever you wanna say there. And so because literature reviewEditLet me help develop this crucial point about the nature of meaningful literature reviews and how it relates to your broader argument about AI limitations. You're articulating an important distinction between superficial performance and genuine insight in literature reviews:\n\nThe Nature of Meaningful Literature Reviews:\n\nNot merely a collection of sources\nDefined by intentional choices in:\n\nSource selection and exclusion\nOrganization and grouping\nSupporting a broader narrative or research agenda\n\n\n\n\nDeep Research's Fundamental Limitation:\n\nCan perform \"descriptive\" literature reviews\nBut lacks the crucial elements that make reviews useful:\n\nPurpose-driven source selection\nIntentional organization\nGeneration of novel insights\nInductive reasoning to support broader claims\n\n\n\n\nThe \"Spark of Insight\" Problem:\n\nCurrent AI systems can regurgitate and reorganize\nBut cannot provide the critical \"why\" behind:\n\nSource selection\nOrganization choices\nConnection to broader scholarly conversations\n\n\n\n\n\nThis seems to connect strongly to your earlier points about judgment and induction. Would you like to continue developing how this specific limitation in literature reviews exemplifies the broader problem of AI's lack of true agency?\u00a0CopyRetryBBAnd so because literature review As produced by deep research, it uses words adequately. Like, it's not it's not an interesting literature review, but all the words are there, and they're in the right order, and it's long enough to be orders of magnitude better than prior models. It is a useful tool. It is something that will take in a prompt, Decompose decompose that prompt into a series of searches. These fairly large context fairly large context in the in the vibe of a to to synthesize and stitch together points. But It is the negative space where the problem lies. Is we don't see it being systematic. So so in our observations, we see it running some searches, and then effectively getting bored. And we never see it questioning if its present attempt is appropriate. And so what we see, therefore, Is when we tell deep research to do something, It will and this is this is the common failure mode of LMS, and this is the common failure mode of deep research. That it will always produce an output. Right? It will it will always produce an output, and it will never go, oh, wait. I like, it it will never question the assumptions. And it will never go, oh, I just did all of this research, just did all of this research onto the wrong thing. Did you mean this, that, or the other? And so because it cannot forget, because it cannot judge the appropriateness, of its models. Yay. Not models. Choking to the context window. It is something that Takes as gospel It's first search results. And so it quote, knows, end quote, how to search. It runs a bunch of searches. It dithers about in the thinking, we never see it making an outline. We never see it revising an outline. We never see it Cutting Right? Like, the fact that The fact that it didn't includes by default everything that it searches for and never has a winnowing pass of, oh, this wasn't right. Is the uncanny valley of research for deep research. Oh, I like that quote. The uncanny valley of Let's make sure that that gets into the paper.EditLet me help organize this significant observation about Deep Research's behavior and the \"uncanny valley of research\" concept you've identified. This builds on your earlier points about agency while adding specific behavioral observations:\n\nSurface-Level Competence:\n\nProduces coherent, well-formed text\nCan perform basic functional decomposition\nHandles large context windows\nRepresents significant improvement over prior models\n\n\nThe \"Uncanny Valley of Research\" (excellent phrase):\n\nKey behavioral limitations observed:\n\nNever questions its assumptions\nNever revises its approach mid-process\nNo evidence of outline creation or revision\nLacks winnowing or filtering process\nTakes initial search results as \"gospel\"\n\"Gets bored\" rather than being systematic\nAlways produces output regardless of appropriateness\n\n\n\n\nCritical Missing Elements:\n\nNo self-questioning\nNo mid-process correction\nNo adaptation based on intermediate results\nNo recognition of potential misalignment with intended goals\n\n\n\nThis observation about Deep Research always producing output without questioning assumptions seems to connect strongly to your earlier points about judgment and agency. Would you like to develop the \"uncanny valley of research\" concept further? It could serve as a powerful central metaphor for your paper's argument about the gap between superficial competence and true research capability.\u00a0CopyRetryBBOkay. Eastern Archaeology. I've never used to before to do your bike That is turned off at So far. But then Issue for iOS There's 64 issues. The correct change 2 would have been starting issue 1, and just if you buy this, I wanna have to do that. I'm sorry. Oh, that's so put that down as a 2 day. I need to rerun the IP search. Maybe, like, walks at 5. Because now that I'm thinking about it, it never actually Well, best thing is it either never So Update or it never said Is that Because the increase goes by the 5th of instruction we give and not the instructions we give, It's actually not paid That construction site. Okay. Because might not This is the operation. Oh, It's not usually operationalized at school, and So so if it I'll start it at 1. It would be better if we didn't answer that. That's fine. It would be aware of its inefficient size. As a researcher, The reason why we haven't done this research previously. Is because it's boring before. Right. Just dial in. Cuba. But because it cannot stay on task for a sustained period, It is not agenda. It is an it is in the unhanded balance.EditI'm having some trouble following parts of your dictation clearly - it seems there might have been some garbling or background noise. Let me focus on the key points I could understand:\n\nThere seems to be an issue about search scope or parameters:\n\nSomething about 64 issues\nA suggestion that starting from issue 1 would have been better\nA need to rerun some searches\n\n\nAn important observation about operational limitations:\n\nThe system follows instructions but not necessarily in the most efficient way\nThere's something about it not being properly \"operationalized\"\n\n\nA key point about sustained attention:\n\nThe system cannot \"stay on task for a sustained period\"\nThis relates to your earlier points about it not being truly agentic\nYou mentioned something about it being \"in the unhanded balance\"\n\n\n\nWould you mind clarifying some of these points, particularly about the operational aspects and what specific search issue you encountered? This seems like it could be another concrete example of the system's limitations.\nAlso, you mentioned something about why this research hasn't been done previously - could you elaborate on that point?\n</chat1>"
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "serialization_metadata": {
            "custom_symbol_offsets": []
          },
          "dictation": false,
          "request_id": "911983b29ecca81f-SYD",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "bc71db26-c66f-47d5-a6ea-cfabb79b48e3",
      "children": [
        "9937d8d2-e6be-4cb0-bdc2-7763650a1718"
      ]
    },
    "210b030c-2171-4404-b48e-c1232381ac18": {
      "id": "210b030c-2171-4404-b48e-c1232381ac18",
      "message": {
        "id": "210b030c-2171-4404-b48e-c1232381ac18",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1739499011.257339,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "# Instructions\n\nThink step by step on the inputs that I give you. This project is to take user inputs which have been transcribed from audio, and are intended to build out the user's notes.\n\nDo not ask questions unless prompted, instead have a <think/> zone before your responses, then process user input in the form a transcript, and help to integrate it into the outline for the draft document.\n\nYour feedback or praise in this process is not wanted, instead, transform user inputs. Ask questions if there are elements which are unclear.\n\nAny outlines that you work on should be in markdown in an artefact.\n\n# Task 1\nTo begin, please synthesise yesterday's chat into the paper notes. We're getting ready to integrate another transcript.\n\n<chat1>\nI'll help you develop your academic paper through dictation. From your notes, I can see you're working on a thoughtful analysis of AI's limitations in research contexts, particularly focusing on the distinction between linguistic capability and true judgment/agency. Would you like to start dictating your thoughts? I can help organize them and suggest ways to develop the arguments further.\nI notice a few interesting threads in your current draft that could be expanded:\n\nThe connection between \"mundane utility\" and the absence of true agency\nYour comparison to first-week PhD students as a benchmark\nThe role of judgment in making novel connections across domains\n\nWhere would you like to begin? I can also ask clarifying questions about specific sections if that would be helpful for your dictation process.\u00a0CopyRetryBBMessage garbled, trying againEdit2 / 2I see your message was cut off. Would you like to try dictating your thoughts again? I'm ready to help organize and capture your ideas for the academic paper based on the draft you shared earlier.\u00a0CopyRetryBBOkay. So Thinking about the failure of deep research yesterday, generating a newspaper article. We can absolutely assert That'd be detail here is not of judgment. And and, of course, the necessary induction which maps to judge It does notEditI notice you're dictating thoughts about deep research's failure specifically regarding newspaper article generation, and touching on concepts of judgment and induction. However, some parts were unclear - could you try rephrasing the key point about judgment and induction again?\nFrom what I understood, you're suggesting that:\n\nThere was a specific failure case with deep research generating a newspaper article\nThis demonstrates a lack of judgment\nThere's a connection between judgment and induction\n\nWould you like to elaborate on any of these points? I'm particularly interested in the specific failure case you observed, as it could serve as a concrete example in your paper.\u00a0CopyRetryBBSo insofar as it produced a newspaper article that looked like a newspaper article. But Didn't follow the guidelines. I've quite literally the 2 elements that we, provided before. Like, we we made an article, and Claude We made an article in o one pro without search. And so deep research, even though it demonstrated no. Deep research, even though it purports to have agentic behavior, Doesn't. And so, therefore, here's where we need to to define Here's where we need to define what it means to be agentic. Because if we are to treat this like anything If we are to treat this like anything beyond a marketing term, We have to have very clear definitions. And so Edgentic machine. As a precursor to whatever we call AGI, is something that is goal following. For something to be goal following, it must be able to both Figure out when it is appropriate No. It must be able to figure out if it solved the problem. At the end of the day, I A goal following machine is a machine that Not only performs functional decomposition on any given task. Right? And so so that that functional decomposition is fine. But iOS machine that can judge. There's that word again. It's a machine that can judge if it has accomplished the task and moreover, if it has accomplished the task well, I e Has it not has it produced words, that vaguely mapped the vibes of the input, but has it generalized from the, specific data of the input. The actual problem that is trying to be solved and can it judge if it has solved that prob? And so deep research isn't agenic. And it's not agentic because it cannot take a goal as input and help to achieve that goal. Now to be clear, they're not particularly saying that it can, and and we can we can narrow Right? We can say, okay. This is narrowly scoped. This is Only for lit reviews, quote, unquote. Pausing here to reset.EditLet me help organize these key points about agency and judgment that you're dictating. I'll structure them to potentially fit into your paper's section on \"Agentic Systems\":\nThe core argument you're developing seems to be:\n\nDeep Research's failure case with the newspaper article demonstrates a fundamental issue:\n\nIt can produce content that superficially resembles the target format\nBut it failed to follow explicit guidelines, showing lack of true goal-following behavior\n\n\nThis leads to a necessary refinement of what \"agentic\" means in AI systems:\n\nAn agentic machine (as a precursor to AGI) must be fundamentally goal-following\nTrue goal-following requires:\na. Functional decomposition of tasks (which current systems can do)\nb. Ability to judge task completion\nc. Ability to judge task completion quality\nd. Capacity to generalize from specific inputs to understand the underlying problem\n\n\nThe key distinction:\n\nCurrent systems can \"produce words that vaguely map the vibes of the input\"\nBut they cannot generalize from specific data to understand and evaluate if they've solved the actual underlying problem\n\n\nTherefore, Deep Research isn't truly agentic because:\n\nIt cannot meaningfully take a goal as input\nIt cannot effectively help achieve that goal\nEven in its narrowly scoped domain of literature reviews\n\n\n\nWould you like to continue developing any of these points further? I notice this builds particularly well on your paper's existing section about goal-related characteristics of agentic systems.\u00a0CopyRetryBBAnd so even if they say even if this is narrowly scoped, even if this is only for lit reviews, and and we we also have to to say that this is a descriptive lit review, which lacks the spark of insight that makes a literature review useful. As in, why did you so a literature, for it to be useful, to go why did you choose these sources? What message are you trying to communicate? If you're merely regurgitating source That is That is the performance of literature review. Without any of the real substance of literature review. Because you are describing. You are not producing insight. Again, it's the lack of insight. It's the lack of induction because a literature review by virtue of how a thing is grouped, a literature review by virtue of what is selected and what is not selected. And a literature review by virtue of its organization supports a broader Claude. It supports the story. Or it supports research or whatever you wanna say there. And so because literature reviewEditLet me help develop this crucial point about the nature of meaningful literature reviews and how it relates to your broader argument about AI limitations. You're articulating an important distinction between superficial performance and genuine insight in literature reviews:\n\nThe Nature of Meaningful Literature Reviews:\n\nNot merely a collection of sources\nDefined by intentional choices in:\n\nSource selection and exclusion\nOrganization and grouping\nSupporting a broader narrative or research agenda\n\n\n\n\nDeep Research's Fundamental Limitation:\n\nCan perform \"descriptive\" literature reviews\nBut lacks the crucial elements that make reviews useful:\n\nPurpose-driven source selection\nIntentional organization\nGeneration of novel insights\nInductive reasoning to support broader claims\n\n\n\n\nThe \"Spark of Insight\" Problem:\n\nCurrent AI systems can regurgitate and reorganize\nBut cannot provide the critical \"why\" behind:\n\nSource selection\nOrganization choices\nConnection to broader scholarly conversations\n\n\n\n\n\nThis seems to connect strongly to your earlier points about judgment and induction. Would you like to continue developing how this specific limitation in literature reviews exemplifies the broader problem of AI's lack of true agency?\u00a0CopyRetryBBAnd so because literature review As produced by deep research, it uses words adequately. Like, it's not it's not an interesting literature review, but all the words are there, and they're in the right order, and it's long enough to be orders of magnitude better than prior models. It is a useful tool. It is something that will take in a prompt, Decompose decompose that prompt into a series of searches. These fairly large context fairly large context in the in the vibe of a to to synthesize and stitch together points. But It is the negative space where the problem lies. Is we don't see it being systematic. So so in our observations, we see it running some searches, and then effectively getting bored. And we never see it questioning if its present attempt is appropriate. And so what we see, therefore, Is when we tell deep research to do something, It will and this is this is the common failure mode of LMS, and this is the common failure mode of deep research. That it will always produce an output. Right? It will it will always produce an output, and it will never go, oh, wait. I like, it it will never question the assumptions. And it will never go, oh, I just did all of this research, just did all of this research onto the wrong thing. Did you mean this, that, or the other? And so because it cannot forget, because it cannot judge the appropriateness, of its models. Yay. Not models. Choking to the context window. It is something that Takes as gospel It's first search results. And so it quote, knows, end quote, how to search. It runs a bunch of searches. It dithers about in the thinking, we never see it making an outline. We never see it revising an outline. We never see it Cutting Right? Like, the fact that The fact that it didn't includes by default everything that it searches for and never has a winnowing pass of, oh, this wasn't right. Is the uncanny valley of research for deep research. Oh, I like that quote. The uncanny valley of Let's make sure that that gets into the paper.EditLet me help organize this significant observation about Deep Research's behavior and the \"uncanny valley of research\" concept you've identified. This builds on your earlier points about agency while adding specific behavioral observations:\n\nSurface-Level Competence:\n\nProduces coherent, well-formed text\nCan perform basic functional decomposition\nHandles large context windows\nRepresents significant improvement over prior models\n\n\nThe \"Uncanny Valley of Research\" (excellent phrase):\n\nKey behavioral limitations observed:\n\nNever questions its assumptions\nNever revises its approach mid-process\nNo evidence of outline creation or revision\nLacks winnowing or filtering process\nTakes initial search results as \"gospel\"\n\"Gets bored\" rather than being systematic\nAlways produces output regardless of appropriateness\n\n\n\n\nCritical Missing Elements:\n\nNo self-questioning\nNo mid-process correction\nNo adaptation based on intermediate results\nNo recognition of potential misalignment with intended goals\n\n\n\nThis observation about Deep Research always producing output without questioning assumptions seems to connect strongly to your earlier points about judgment and agency. Would you like to develop the \"uncanny valley of research\" concept further? It could serve as a powerful central metaphor for your paper's argument about the gap between superficial competence and true research capability.\u00a0CopyRetryBBOkay. Eastern Archaeology. I've never used to before to do your bike That is turned off at So far. But then Issue for iOS There's 64 issues. The correct change 2 would have been starting issue 1, and just if you buy this, I wanna have to do that. I'm sorry. Oh, that's so put that down as a 2 day. I need to rerun the IP search. Maybe, like, walks at 5. Because now that I'm thinking about it, it never actually Well, best thing is it either never So Update or it never said Is that Because the increase goes by the 5th of instruction we give and not the instructions we give, It's actually not paid That construction site. Okay. Because might not This is the operation. Oh, It's not usually operationalized at school, and So so if it I'll start it at 1. It would be better if we didn't answer that. That's fine. It would be aware of its inefficient size. As a researcher, The reason why we haven't done this research previously. Is because it's boring before. Right. Just dial in. Cuba. But because it cannot stay on task for a sustained period, It is not agenda. It is an it is in the unhanded balance.EditI'm having some trouble following parts of your dictation clearly - it seems there might have been some garbling or background noise. Let me focus on the key points I could understand:\n\nThere seems to be an issue about search scope or parameters:\n\nSomething about 64 issues\nA suggestion that starting from issue 1 would have been better\nA need to rerun some searches\n\n\nAn important observation about operational limitations:\n\nThe system follows instructions but not necessarily in the most efficient way\nThere's something about it not being properly \"operationalized\"\n\n\nA key point about sustained attention:\n\nThe system cannot \"stay on task for a sustained period\"\nThis relates to your earlier points about it not being truly agentic\nYou mentioned something about it being \"in the unhanded balance\"\n\n\n\nWould you mind clarifying some of these points, particularly about the operational aspects and what specific search issue you encountered? This seems like it could be another concrete example of the system's limitations.\nAlso, you mentioned something about why this research hasn't been done previously - could you elaborate on that point?\n</chat1>\n\nTime is of no consequence here. Please think deeply and carefully about this. The goal is to help me organise my thoughts, not to be quick. Double check your work and be self-critical. Please do an excellent job here."
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "request_id": "91198531dd81a81f-SYD",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "bc71db26-c66f-47d5-a6ea-cfabb79b48e3",
      "children": [
        "76d1b01f-4278-4094-9c50-1a7e96ff92f7"
      ]
    },
    "9937d8d2-e6be-4cb0-bdc2-7763650a1718": {
      "id": "9937d8d2-e6be-4cb0-bdc2-7763650a1718",
      "message": {
        "id": "9937d8d2-e6be-4cb0-bdc2-7763650a1718",
        "author": {
          "role": "tool",
          "name": "a8km123",
          "metadata": {}
        },
        "create_time": 1739498965.679159,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "**Synthesizing documents**\n\nCombining friendly lectures into one document, with a clear structure and citations, is quite a task. I've checked the coherence and clarity of the content and corrected a grammar issue.\n\n**Constructing the outline**\n\nI'm pie"
          ]
        },
        "status": "in_progress",
        "end_turn": null,
        "weight": 0.0,
        "metadata": {
          "finished_text": "Finished reasoning",
          "initial_text": "Reasoning",
          "summarization_headline": "AI Limitations in Research Contexts",
          "permissions": [
            {
              "type": "notification",
              "status": "requested",
              "notification_channel_id": "jawbone",
              "notification_channel_name": "Tasks",
              "notification_priority": 4
            }
          ],
          "message_type": null,
          "model_slug": "o1-pro",
          "default_model_slug": "o1-pro",
          "parent_id": "73872dc4-a987-49e9-91df-dd5dd1dfcae8",
          "finish_details": {
            "type": "interrupted"
          },
          "request_id": "911983b29ecca81f-SYD",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "73872dc4-a987-49e9-91df-dd5dd1dfcae8",
      "children": []
    },
    "76d1b01f-4278-4094-9c50-1a7e96ff92f7": {
      "id": "76d1b01f-4278-4094-9c50-1a7e96ff92f7",
      "message": {
        "id": "76d1b01f-4278-4094-9c50-1a7e96ff92f7",
        "author": {
          "role": "tool",
          "name": "a8km123",
          "metadata": {}
        },
        "create_time": 1739499161.849934,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "**Transcribing and organizing**\n\nI\u2019m noting the user's request to transcribe audio, integrate it into the draft, and avoid feedback or praise. This involves synthesizing the chat, focusing on clarity and task execution within the document.\n\n**Organizing and integrating**\n\nI\u2019m collecting and synthesizing notes from yesterday's chat. The final answer will be in markdown, with a <think/> zone, avoiding feedback or praise unless asked.\n\n**Formulating the outline**\n\nSynthesizing and organizing dictations into a coherent, structured Markdown outline. Avoiding extraneous comments or questions, ensuring clarity and precision.\n\n**Crafting the outline**\n\nUnderstanding AI's limitations: absence of judgment, agency, and crucial cognitive processes. Integrating insights on AI's computations and biases into a structured Markdown outline."
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 0.0,
        "metadata": {
          "finished_text": "Reasoned for 2m 29s",
          "initial_text": "Reasoning",
          "summarization_headline": "AI Limitations in Research Contexts",
          "permissions": [
            {
              "type": "notification",
              "status": "requested",
              "notification_channel_id": "jawbone",
              "notification_channel_name": "Tasks",
              "notification_priority": 4
            }
          ],
          "message_type": null,
          "model_slug": "o1-pro",
          "default_model_slug": "o1-pro",
          "parent_id": "210b030c-2171-4404-b48e-c1232381ac18",
          "request_id": "91198531dd81a81f-SYD",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "210b030c-2171-4404-b48e-c1232381ac18",
      "children": [
        "85af235c-f22d-4f29-ae33-920bf81411b7"
      ]
    },
    "85af235c-f22d-4f29-ae33-920bf81411b7": {
      "id": "85af235c-f22d-4f29-ae33-920bf81411b7",
      "message": {
        "id": "85af235c-f22d-4f29-ae33-920bf81411b7",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1739499161.85005,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "<think/>\n\nBelow is an updated, synthesized set of paper notes in Markdown, integrating the key points from yesterday\u2019s conversation in <chat1>. These notes focus on AI\u2019s limitations in research contexts, emphasizing the gap between linguistic competence and genuine judgment or agency, and highlighting the concept of the \u201cuncanny valley of research.\u201d \n\n---\n\n# Draft Paper Notes\n\n## 1. Introduction\n- **Context**: The paper examines AI\u2019s limitations in conducting deep research. While Large Language Model (LLM)-based systems (e.g., \u201cDeep Research\u201d) exhibit notable linguistic capabilities, they fall short in crucial areas related to judgment, induction, and genuine agency.  \n- **Focus**: Drawing on observed failure cases (such as generating newspaper articles or superficial literature reviews), the paper argues that current AI systems are incapable of true goal-following behavior and lack the \u201cspark of insight\u201d essential for meaningful research.\n\n---\n\n## 2. Linguistic Capability vs. True Agency\n- **Linguistic Fluency**  \n  - LLMs can produce coherent, well-formed text on demand.  \n  - They can appear more advanced than previous models, handling large contexts and varied prompts.\n\n- **Limitations of Agency**  \n  - **Absence of Judgment**: AI systems do not demonstrate self-critical evaluation of their outputs.  \n  - **No Real Goal-Following**: They do not verify if their responses truly align with an intended goal.  \n  - **No Iterative Self-Correction**: They produce outputs regardless of correctness or relevance, showing no mechanism to pause, reassess, or ask for clarification unless prompted externally.\n\n---\n\n## 3. Failure Case: Newspaper Article Generation\n- **Superficial Format Matching**  \n  - The system produces text that _looks_ like a newspaper article but fails to follow explicit guidelines.  \n  - Suggests that it \u201cmaps the vibes\u201d of the request rather than deeply understanding it.\n\n- **Lack of Agency and Judgment**  \n  - Indicates no internal checkpoint or reflection on whether the final product meets the original criteria.  \n  - Highlights the necessity of clarifying what \u201cagentic\u201d means for AI: an ability to set goals, decompose tasks, and evaluate success.\n\n---\n\n## 4. The Problem with \u201cDescriptive\u201d Literature Reviews\n- **Nature of a Meaningful Literature Review**  \n  - Involves purposeful source selection, organization, and a guiding narrative or research question.  \n  - Must be driven by insight: _why_ certain sources are used, _how_ they connect, and _what_ broader claims they support.\n\n- **Deep Research\u2019s Limitation**  \n  - It can compile relevant-sounding references but fails to generate true insight or build a coherent argument.  \n  - Merely \u201cdescriptive\u201d rather than interpretive or critical, neglecting the inductive leap required for a useful review.  \n  - Reveals the absence of deeper judgment and the inability to produce novel connections among sources.\n\n---\n\n## 5. Defining Agentic Systems\n- **Characteristics of True Agentic Behavior**  \n  1. **Goal-Following**: Receives a goal and actively pursues it.  \n  2. **Judgment**: Evaluates whether the task is truly fulfilled and whether the solution is satisfactory.  \n  3. **Functional Decomposition**: Breaks down tasks into sub-tasks.  \n  4. **Quality Control**: Engages in self-questioning, revises outlines or approaches, and discards irrelevant leads.\n\n- **Contrast with Current AI**  \n  - Present systems can decompose tasks superficially but do not reflect on outcomes or correctness.  \n  - Lack an internal mechanism to judge success or failure beyond text fluency.\n\n---\n\n## 6. The \u201cUncanny Valley of Research\u201d\n- **Surface-Level Competence**  \n  - LLMs can assemble text that appears detailed and aligned with research standards (formal structure, references, length).  \n  - However, this often masks a deeper lack of systematic methodology.\n\n- **Key Behavioral Gaps**  \n  - **No Self-Questioning**: The model does not pause to verify alignment with the intended research goal.  \n  - **No Refinement Pass**: The model fails to prune irrelevant or incorrect materials\u2014it simply accumulates results.  \n  - **\u201cGetting Bored\u201d**: In observations, the system sometimes stops or shifts behavior without completing a thorough investigation.  \n  - **Always Produces an Output**: It never declines or flags impossibilities; it just generates text.\n\n- **Why This Matters**  \n  - The resulting work product sits in an \u201cuncanny valley\u201d: it _looks_ like rigorous research, but lacks the critical elements of scrutiny, iteration, and genuine insight.\n\n---\n\n## 7. Further Observations and Operational Limitations\n- **Inefficient Scope**: The system might run a large number of searches but does not systematically evaluate or filter them.  \n- **Lack of Persistence**: It cannot \u201cstay on task\u201d for a sustained period with a single overarching goal.  \n- **No Meta-Understanding of Process**: Fails to track whether prior steps were correct or if a change of course is needed.  \n- **Why Such Research Has Been Neglected**:  \n  - Investigating these behaviors can be tedious; previous models made it even more so.  \n  - Now that LLMs are more advanced, the superficial resemblance to research is compelling enough to merit close study\u2014but the underlying gaps remain.\n\n---\n\n## 8. Conclusion and Next Steps\n- AI systems show remarkable progress in generating human-like text, yet they lack genuine agentic qualities essential for deep research.  \n- The \u201cuncanny valley of research\u201d highlights the danger of conflating textual fluency with actual understanding or judgment.  \n- Future studies should further clarify the definition of agency in AI and explore frameworks that allow systems to engage in self-questioning, iterative refinement, and purposeful goal alignment.\n\n---\n\nThese notes integrate the content from the conversation in <chat1> and reflect the paper\u2019s evolving argument about AI limitations, especially regarding true agency, judgment, and the shortfalls of current systems in conducting meaningful research."
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 1.0,
        "metadata": {
          "message_type": null,
          "model_slug": "o1-pro",
          "default_model_slug": "o1-pro",
          "parent_id": "76d1b01f-4278-4094-9c50-1a7e96ff92f7",
          "request_id": "91198531dd81a81f-SYD",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "76d1b01f-4278-4094-9c50-1a7e96ff92f7",
      "children": [
        "50593157-7b9c-4d3c-b030-17589c218828",
        "98bb14e8-77ab-43bc-8a4a-1b6d700a451b"
      ]
    },
    "50593157-7b9c-4d3c-b030-17589c218828": {
      "id": "50593157-7b9c-4d3c-b030-17589c218828",
      "message": {
        "id": "50593157-7b9c-4d3c-b030-17589c218828",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1739499210.526705,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "Ok. Here is the next transcript\n\n<chat2>\n\nUm,\n\nSo the structure of the paper is you have our discussion of why these things are not presented. We have our discussion of human being utility and our experience. These\n\nAnd our experiences are using it for research. And then we have the discussion of what, what do we need? The tool that genuinely does.\n\nHow? Facilitate. What these things are good are how do we interact with these things knowing that there are deficiently And so, the first thing that we need is, A cursor to do this. Right. The, the first thing that we need is.\n\nEach step in the to-do list. So, We can get the user's judgement as. Correctness. Because the thing is, is that for research And this is not. This is not the oh I'm not able to access that we saw in 7th February like This is going to be, oh, this lineup.\n\nOpener is. This output is back. This is not a quick. I should remove this. Because fundamentally, Fundamentally, what we see is that\n\nThey don't consider jud. Put more to the point. They don't have the inductive capacity of the intuition, whatever to know when they should. And therefore, Until we figure out some new technological advance that is we need to Anchor. Um, that\n\nSo, We need to be able to New a brown art todo list, right? It is, it is insufficient Is the current quote, agentic only great things do just take a step, right? Like the idea of a wonderful model of research is laughable. Yes. Uh, we should have that a note towards um the problems of sdlcs and why that's such a problem for us.\n\nUm,\n\nThis to-do list should should first off. Allow us to see what's in the context window. And to see what we're working on, but the the fundamental thing that these large language models don't have is the ability to forget to judge. That a certain line of thinking is bad, then to remove it because We know.\n\nBy virtue of how they work. These large language models. Will anchor. Long text. In their context window. Which means that\n\nAs they anchor on this text, if it's the wrong text. Not only. Not only is it excluding? Um, Content that we want but it's biasing the output in ways. That's not appropriate. And so, therefore, When we build literature for our deep research, We effectively need.\n\nAn indication of What sources? It has considered. What it's using and more to the point, what it's disusing. Um, and so So effectively. Considering that we're playing the game of of, um, Limiting context windows and it's it's hilarious. That 200 000 tokens is limited but what we're talking about.\n\nI've I've easily blown the context window out with trying to drop in nine papers. So Two hundred thousand tokens. Is not sufficient to do researching. Therefore we need a way of managing. Our tokens. And, What this means and we also need introspection. We need to be able to validate this.\n\nWe need ha transparency, not newly in the encoded thoughts. But okay at this step we have a This paper. We are pulling these quotes from it. Here is our summary of and understanding here is where in our document we should be using this paper when we get to this part of our document load the entire paper into the context window for this paragraph.\n\nRight. And so this is why outlines are so useful? Is because they allow us to go up when we get to that part of the outline when we get to that part of the mechanism. Whatever, that's not the right word, but whatever. Go change your context window, your working context window.\n\nTo go. Spin off a line of thought or whatever to apply. That paper to this paragraph, within the context of the section and and the document And so, We need. But, We also need human judgement, right? The first draught is always shit. The first lines of research are seldom the most correct lines, and so therefore, These systems have to leverage human judgement.\n\nAnd and not in the double confirm that deep research does right now, right? Because deep research right now. Takes this takes the entire context window. You push deep research. And then it it crunches down what it thinks its task is. And then you say go or you give it a bit of feedback when it goes.\n\nThat's not what I'm talking about, right? This is not agentic. It is not goal following We cannot treat it as gold following. We must treat it as a tool. It's just a tool. It is a tool that can be useful. It's a tool that can be thoughtful. It's just a tool.\n\nDon't remember if I talked about deleting. But we also need tombstones, we need to have indications of thoughts that we've had that are bad. And we have to be able to remove them durably. From the context window but we need to have proof that we've had this thought and chosen not to have it.\n\nUm, Which is. Ironic. But whatever.\n\nOkay. What time is it?\n\nWe have to outline. We have forgetting.\n\nWe have userjulent.\n\nAnd then we have\n\nAnd then we have different. Stages of interaction, where finding literature. Extracting, the literature and building the outline building, the first draught revising, the draught editing, and then outputting Should all be documented. And so this is why we We can't necessarily follow a waterfall sdlc. When we're producing 10 000 word, research reports.\n\nWe have to consider. Instead. That we have to treat each step in its own step that we need to have different mechanisms for Keep contracted this information. We need to choose which of these parts we're pulling from. And at every stage we have to rely on human judgement. Knowing that the AI's judgements is deficient but more to the point, not only is it deficient, it doesn't know that it's deficiency, doesn't know when to play the judgement.\n\nCool.\n</chat2>\n\nPlease continue to take extra time to think."
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "serialization_metadata": {
            "custom_symbol_offsets": []
          },
          "dictation": false,
          "request_id": "91198a0f4ac8a81f-SYD",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "85af235c-f22d-4f29-ae33-920bf81411b7",
      "children": [
        "e72987d4-3e76-43dd-92c4-7913248130ca"
      ]
    },
    "98bb14e8-77ab-43bc-8a4a-1b6d700a451b": {
      "id": "98bb14e8-77ab-43bc-8a4a-1b6d700a451b",
      "message": {
        "id": "98bb14e8-77ab-43bc-8a4a-1b6d700a451b",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1739499275.031177,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "Ok. Here is the next transcript\n<draft_paper>\n\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1in]{geometry}\n\\usepackage{parskip}\n\n\\title{An Absence of Judgment: On AI's Fundamental Limitations in Research}\n\\author{}\n\\date{}\n\n\\begin{document}\n\n\\maketitle\n\n\\section{Introduction}\nLarge language models are fundamentally incapable of judgment, despite their ability to mimic the language of judgment. This distinction necessitates examining not only their linguistic output but also the concrete actions and outcomes that their words produce. However, this lack merely prevents us from treating them as true agents, \\textit{not} as extracting mundane utility from them as tools. This paper is an investigation into the creation of a research-grade dataset using OpenAI's Deep Research in February 2025, acting as a case study --- and our ``autoethnographic'' reflection upon the use of this tool for what Zvi Moshowitz calls ``mundane utility.\"\n\nHere, we will also give our understanding of the necessary prerequsities for an ``agentic'' tool, and why we believe that this infrastructure, at this time, does not satisfy that criteria. We will also discuss the fundamental lack of judgement that these models exhibit, and why it is this core incapability which prevents an accumulation of patterns-shaped-like-knowledge to answer Dwarkesh's question to Cohen: ``what do you make of the fact that these things have basically the entire corpus of human knowledge memorized and they haven\u2019t been able to make a single new connection that has led to a discovery? Whereas if even a moderately intelligent person had this much stuff memorized, they would notice \u2014 Oh, this thing causes this symptom.'' We assert that the lack of induction exhibited by even currently accessible frontier models like o3-mini-high, answers this question. To be clear, this paper is a description of what we have experienced in our attempt to actively use these models to research and answer an academic question --- not merely to conduct a \\textit{descriptive} literature review, but to find that central spark of insight which represents a contribution to the literature. We do not say that these capabilities are forever barred to these models, merely that they do not exhibit them yet and that the common errors in estimating the capabilities of these models based on \\textit{what they say} rather than \\textit{how they act} can lead to confusion as to their actual capabilities and hinder finding places of mundane utility in our use of these tools. \n\n\n\\section{Agentic Systems}\n\n#  \"Agentic\" Systems vs Normal Software\n\n## Goal-Related Characteristics\n1. Goal Following vs Goal Setting\n   - Agentic systems are goal-following systems\n   - This contrasts with AGI, which can set its own goals\n   - Key distinction: Agentic systems require external input for goals\n\n## Agentic Characteristics\n1. Goal Processing Capabilities\n   - Accept external goals as input\n   - Collaborate with users to operationalize goals\n   - Functionally decompose goals into manageable components\n\n2. Execution Capabilities\n   - Create plans for goal completion\n   - Invoke appropriate software and APIs\n   - Monitor and assess progress\n\n3. Assessment and Reporting\n   - Make judgments about goal completion\n   - Provide reports to users (like Claude)\n   - Include success/failure evaluation based on system's judgment\n\n\\section{Deep Research and AI Capabilities}\n\n\\subsection{Current State}\nThe implementation of O3 for research purposes, while advanced, reveals fundamental limitations. This connects to broader discussions, as highlighted in Cohen's repost of DAKISH regarding AI's inability to produce truly groundbreaking research. While these systems demonstrate acceptable fluency and solid domain knowledge, they lack crucial elements of genuine research capability.\n\n% One question I had for you while we were talking about the intelligence stuff was, as a scientist yourself, what do you make of the fact that these things have basically the entire corpus of human knowledge memorized and they haven\u2019t been able to make a single new connection that has led to a discovery? Whereas if even a moderately intelligent person had this much stuff memorized, they would notice \u2014 Oh, this thing causes this symptom. This other thing also causes this symptom. There\u2019s a medical cure right here.\n\n% Shouldn\u2019t we be expecting that kind of stuff?\n\n% It\u2019s a very good question. In 2023, I quipped, \u201cI think they have, we just haven\u2019t asked them.\u201d Maybe, but less clear today. Dwarkesh reports that there have been no good answers.\n% https://feeds.feedblitz.com/~/912665402/0/marginalrevolution~Dwarkeshs-Question.html\n\n\n\\subsection{Fundamental Limitations}\n\\begin{itemize}\n    \\item Absence of goal-setting and goal-following behavior\n    \\item Constraint to the Next Token paradigm\n    \\item Limited self-reflexivity, characterized by:\n        \\begin{itemize}\n            \\item Simple search execution\n            \\item Information synthesis without true comprehension\n        \\end{itemize}\n    \\item Inability to genuinely evaluate goal accomplishment\n        \\begin{itemize}\n            \\item System assumes task completion at each output\n            \\item Lacks true self-assessment capability\n        \\end{itemize}\n\\end{itemize}\n\n\\subsection{Comparative Analysis}\nUsing a first-week PhD student as our prototypical target, we observe that while AI systems can mimic goal-following behavior, they fundamentally lack the authentic research capabilities demonstrated by even novice human researchers.\n\n\\section{Practical Applications}\n\n\\subsection{Literature Reviews}\nInitial applications in literature review processes have shown promising results, particularly in:\n\\begin{itemize}\n    \\item Dataset preparation and collection for research purposes\n    \\item Improvement over previous superficial review methodologies\n\\end{itemize}\n\n\\section{Future Development}\n\\subsection{Areas Requiring Further Investigation}\n\\begin{itemize}\n    \\item The Normal Intuitive Pattern concept requires elaboration\n    \\item Connection between mundane utility and tool-using behavior\n    \\item Precise definition of agentic behavior in research contexts\n    \\item Concrete manifestations of judgment absence in research outputs\n\\end{itemize}\n\n\n\\end{document}\n</draft_paper>\n\n<chat2>\n\nUm,\n\nSo the structure of the paper is you have our discussion of why these things are not presented. We have our discussion of human being utility and our experience. These\n\nAnd our experiences are using it for research. And then we have the discussion of what, what do we need? The tool that genuinely does.\n\nHow? Facilitate. What these things are good are how do we interact with these things knowing that there are deficiently And so, the first thing that we need is, A cursor to do this. Right. The, the first thing that we need is.\n\nEach step in the to-do list. So, We can get the user's judgement as. Correctness. Because the thing is, is that for research And this is not. This is not the oh I'm not able to access that we saw in 7th February like This is going to be, oh, this lineup.\n\nOpener is. This output is back. This is not a quick. I should remove this. Because fundamentally, Fundamentally, what we see is that\n\nThey don't consider jud. Put more to the point. They don't have the inductive capacity of the intuition, whatever to know when they should. And therefore, Until we figure out some new technological advance that is we need to Anchor. Um, that\n\nSo, We need to be able to New a brown art todo list, right? It is, it is insufficient Is the current quote, agentic only great things do just take a step, right? Like the idea of a wonderful model of research is laughable. Yes. Uh, we should have that a note towards um the problems of sdlcs and why that's such a problem for us.\n\nUm,\n\nThis to-do list should should first off. Allow us to see what's in the context window. And to see what we're working on, but the the fundamental thing that these large language models don't have is the ability to forget to judge. That a certain line of thinking is bad, then to remove it because We know.\n\nBy virtue of how they work. These large language models. Will anchor. Long text. In their context window. Which means that\n\nAs they anchor on this text, if it's the wrong text. Not only. Not only is it excluding? Um, Content that we want but it's biasing the output in ways. That's not appropriate. And so, therefore, When we build literature for our deep research, We effectively need.\n\nAn indication of What sources? It has considered. What it's using and more to the point, what it's disusing. Um, and so So effectively. Considering that we're playing the game of of, um, Limiting context windows and it's it's hilarious. That 200 000 tokens is limited but what we're talking about.\n\nI've I've easily blown the context window out with trying to drop in nine papers. So Two hundred thousand tokens. Is not sufficient to do researching. Therefore we need a way of managing. Our tokens. And, What this means and we also need introspection. We need to be able to validate this.\n\nWe need ha transparency, not newly in the encoded thoughts. But okay at this step we have a This paper. We are pulling these quotes from it. Here is our summary of and understanding here is where in our document we should be using this paper when we get to this part of our document load the entire paper into the context window for this paragraph.\n\nRight. And so this is why outlines are so useful? Is because they allow us to go up when we get to that part of the outline when we get to that part of the mechanism. Whatever, that's not the right word, but whatever. Go change your context window, your working context window.\n\nTo go. Spin off a line of thought or whatever to apply. That paper to this paragraph, within the context of the section and and the document And so, We need. But, We also need human judgement, right? The first draught is always shit. The first lines of research are seldom the most correct lines, and so therefore, These systems have to leverage human judgement.\n\nAnd and not in the double confirm that deep research does right now, right? Because deep research right now. Takes this takes the entire context window. You push deep research. And then it it crunches down what it thinks its task is. And then you say go or you give it a bit of feedback when it goes.\n\nThat's not what I'm talking about, right? This is not agentic. It is not goal following We cannot treat it as gold following. We must treat it as a tool. It's just a tool. It is a tool that can be useful. It's a tool that can be thoughtful. It's just a tool.\n\nDon't remember if I talked about deleting. But we also need tombstones, we need to have indications of thoughts that we've had that are bad. And we have to be able to remove them durably. From the context window but we need to have proof that we've had this thought and chosen not to have it.\n\nUm, Which is. Ironic. But whatever.\n\nOkay. What time is it?\n\nWe have to outline. We have forgetting.\n\nWe have userjulent.\n\nAnd then we have\n\nAnd then we have different. Stages of interaction, where finding literature. Extracting, the literature and building the outline building, the first draught revising, the draught editing, and then outputting Should all be documented. And so this is why we We can't necessarily follow a waterfall sdlc. When we're producing 10 000 word, research reports.\n\nWe have to consider. Instead. That we have to treat each step in its own step that we need to have different mechanisms for Keep contracted this information. We need to choose which of these parts we're pulling from. And at every stage we have to rely on human judgement. Knowing that the AI's judgements is deficient but more to the point, not only is it deficient, it doesn't know that it's deficiency, doesn't know when to play the judgement.\n\nCool.\n</chat2>\n\nPlease continue to take extra time to think."
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "request_id": "91198ba27b3ea7f5-SYD",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "85af235c-f22d-4f29-ae33-920bf81411b7",
      "children": [
        "66950f0c-56a2-4fec-91ef-ec2e9770074f"
      ]
    },
    "e72987d4-3e76-43dd-92c4-7913248130ca": {
      "id": "e72987d4-3e76-43dd-92c4-7913248130ca",
      "message": {
        "id": "e72987d4-3e76-43dd-92c4-7913248130ca",
        "author": {
          "role": "tool",
          "name": "a8km123",
          "metadata": {}
        },
        "create_time": 1739499235.856085,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "**Piecing together**\n\nI\u2019m examining the transcript to understand the paper's structure, identifying three key sections: why certain details are absent, the utility of human experimentation, and necessary features for the tool, including user judgment and managing context windows.\n\n**Integrating insights**\n\nI\u2019m thinking about the transcript's contributions to a new approach that balances stages and highlights AI's judgment gap. This involves interweaving these key points with existing paper sections.\n\n**Synthesizing insights**\n\nI\u2019m integrating key points from the transcript, focusing on an iterative approach, user verification of user reasoning, and tracking thoughts. This enhances the paper\u2019s outline, addressing the \"lack of judgment\" issue.\n\n**Integrating concepts**\n\nI\u2019m developing a new section on"
          ]
        },
        "status": "in_progress",
        "end_turn": null,
        "weight": 0.0,
        "metadata": {
          "finished_text": "Finished reasoning",
          "initial_text": "Reasoning",
          "summarization_headline": "Request for o1 pro mode",
          "permissions": [
            {
              "type": "notification",
              "status": "requested",
              "notification_channel_id": "jawbone",
              "notification_channel_name": "Tasks",
              "notification_priority": 4
            }
          ],
          "message_type": null,
          "model_slug": "o1-pro",
          "default_model_slug": "o1-pro",
          "parent_id": "50593157-7b9c-4d3c-b030-17589c218828",
          "finish_details": {
            "type": "interrupted"
          },
          "request_id": "91198a0f4ac8a81f-SYD",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "50593157-7b9c-4d3c-b030-17589c218828",
      "children": []
    },
    "66950f0c-56a2-4fec-91ef-ec2e9770074f": {
      "id": "66950f0c-56a2-4fec-91ef-ec2e9770074f",
      "message": {
        "id": "66950f0c-56a2-4fec-91ef-ec2e9770074f",
        "author": {
          "role": "tool",
          "name": "a8km123",
          "metadata": {}
        },
        "create_time": 1739499567.029759,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "**Structuring the paper**\n\nI\u2019m laying out the paper into sections: addressing why things are omitted, exploring human experience and utility, research applications, what the tool should achieve, facilitation methods, integrating a to-do list for user feedback, reasoning about context, and detailing an iterative process for literature review and writing tasks.\n\n**Synthesizing new insights**\n\nI\u2019m combining the latest transcript with the existing paper notes, focusing on integrating key points like a step-by-step to-do list and user feedback.\n\n**Crafting an iterative structure**\n\nI'm piecing together an iterative framework that emphasizes user judgment at each stage, ensuring tasks are partitioned effectively, from literature search to final output.\n\n**Synthesizing key themes**\n\nI'm pulling together a new version of \"Draft Paper Notes,\" merging latex snippet content with insights from the transcript. Focus is on step-by-step planning, context window management, and user-guided feedback."
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 0.0,
        "metadata": {
          "finished_text": "Finished reasoning",
          "initial_text": "Reasoning",
          "summarization_headline": "Request for o1 pro mode",
          "permissions": [
            {
              "type": "notification",
              "status": "requested",
              "notification_channel_id": "jawbone",
              "notification_channel_name": "Tasks",
              "notification_priority": 4
            }
          ],
          "message_type": null,
          "model_slug": "o1-pro",
          "default_model_slug": "o1-pro",
          "parent_id": "98bb14e8-77ab-43bc-8a4a-1b6d700a451b",
          "request_id": "91198ba27b3ea7f5-SYD",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "98bb14e8-77ab-43bc-8a4a-1b6d700a451b",
      "children": [
        "b123b1cf-0724-439a-b2b5-f5026c085707"
      ]
    },
    "b123b1cf-0724-439a-b2b5-f5026c085707": {
      "id": "b123b1cf-0724-439a-b2b5-f5026c085707",
      "message": {
        "id": "b123b1cf-0724-439a-b2b5-f5026c085707",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1739499567.029837,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "<think/>\n\nBelow is a revised set of paper notes in **Markdown**, integrating the content of the new transcript (<chat2>) into the previously drafted outline (which reflected <draft_paper> and prior discussions). The new points focus on the iterative workflow needed for a truly useful research tool, the importance of human judgment at each step, the need for \u201ctombstones\u201d (explicitly discarded lines of thinking), and the requirement for structured outlines to properly manage context windows.\n\n---\n\n# Draft Paper Notes\n\n## 1. Introduction\n- **Context**: Large language models (LLMs) offer significant linguistic capabilities but lack genuine judgment. Despite their ability to output text resembling deep analysis, these systems fall short of true research functionality.  \n- **Purpose**:  \n  - Investigate the limitations of current AI systems (e.g., \u201cDeep Research\u201d) in producing genuine scholarly insight.  \n  - Examine how human judgment remains indispensable for research tasks.  \n  - Propose an iterative workflow that treats AI as a tool rather than an agent, illustrating the necessity of user oversight, step-by-step verification, and context management.\n\n---\n\n## 2. Linguistic Capability vs. Judgment\n- **Linguistic Fluency**  \n  - LLMs produce well-formed text that _appears_ coherent and authoritative.  \n  - Often confuses observers into believing the model has deeper understanding.\n\n- **Core Limitation: Lack of Judgment**  \n  - The models do not \u201cknow\u201d when their output is correct, relevant, or complete.  \n  - They are incapable of self-correcting or discarding flawed lines of reasoning without human intervention.\n\n---\n\n## 3. Why AI Tools Are Still Useful\n- **Mundane Utility**  \n  - Despite lacking true judgment, LLM-based systems remain valuable tools for drafting text, summarizing sources, and managing large volumes of information.  \n  - Zvi Moshowitz\u2019s concept of \u201cmundane utility\u201d frames how these models can be helpful when properly constrained and guided.\n\n- **Case Study: Deep Research**  \n  - Experimenting with OpenAI\u2019s Deep Research (February 2025) shows that while the system can compile sources and produce text that reads like a literature review, it fails to demonstrate genuine inductive reasoning.\n\n---\n\n## 4. Agentic Systems vs. Normal Software\n\n### 4.1 Defining Agentic Systems\n- **Goal-Following vs. Goal-Setting**  \n  - Agentic systems: accept external goals and actively work to achieve them (functional decomposition, monitoring progress, and so forth).  \n  - AGI: fully autonomous in setting new goals.  \n\n### 4.2 Criteria for Agentic Behavior\n1. **Goal Processing**  \n   - Accept external goals.  \n   - Collaborate with users to refine or operationalize goals.  \n2. **Execution**  \n   - Create step-by-step plans.  \n   - Call relevant software or APIs.  \n   - Manage progress over time.  \n3. **Assessment and Reporting**  \n   - Provide meaningful judgment about success or failure.  \n   - Convey reasons for decisions made.  \n\n### 4.3 Comparing Current AI to Agentic Ideals\n- LLMs can \\emph{simulate} these capabilities (e.g., they might produce outlines or search for sources) but do not truly \u201cjudge\u201d or \u201cevaluate\u201d the outcome.  \n- They continue until they produce an output\u2014any output\u2014without questioning whether the approach is aligned with a genuine goal or if partial steps are invalid.\n\n---\n\n## 5. Failure Cases in Research\n- **Newspaper Article Generation**:  \n  - The system creates text in the style requested but violates explicit instructions.  \n  - Illustrates \u201csurface compliance\u201d rather than true adherence to guidelines.  \n- **Superficial Literature Reviews**:  \n  - Produces references and summaries in a coherent format.  \n  - Lacks the inductive spark that clarifies \\emph{why} particular sources matter or \\emph{how} they connect in a deeper research narrative.\n\n---\n\n## 6. The \u201cUncanny Valley of Research\u201d\n- **Surface-Level Competence**:  \n  - Outputs are polished enough to appear like real academic writing.  \n- **Hidden Gaps**:  \n  - No self-questioning or winnowing process to remove irrelevant threads.  \n  - Remains anchored to initial context\u2014even if it is mistaken.  \n  - Always produces an output, never signaling \u201cI may have pursued the wrong path; should we revise?\u201d\n\n---\n\n## 7. Proposed Workflow for Effective Research Tools\n\nThe new transcript highlights that any system aiming to be \\emph{truly} useful for deep research must involve **iterative, human-led oversight**. We cannot simply hand the entire task over to an \u201cagentic\u201d LLM. Instead, we need an approach that:\n\n### 7.1 Incorporates a Step-by-Step To-Do List\n1. **Clear, Atomic Steps**  \n   - Break research tasks into smaller units: e.g., finding literature, summarizing a single paper, drafting an outline, writing a paragraph.  \n   - This structured approach offsets the LLM\u2019s tendency to produce indefinite or meandering results.\n2. **Human Judgment at Each Step**  \n   - The user (human researcher) validates correctness or relevance before proceeding.  \n   - Without human intervention, the model has no mechanism to recognize invalid directions.\n\n### 7.2 Uses Outlines and Context Management\n- **Modular Context**  \n  - Load only the relevant paper or excerpt when focusing on a given section.  \n  - Avoid polluting the context window with outdated or irrelevant text.  \n- **Explicit Summaries per Paper**  \n  - The system should store each source\u2019s summary separately.  \n  - When writing a specific paragraph, load and reference only the needed summaries, not the entire corpus.  \n\n### 7.3 Enables \u201cForgetting\u201d and Tombstones\n- **Discarding Incorrect Threads**  \n  - Mark certain lines of thought as invalid (\u201ctombstones\u201d) so the system does not keep dragging them into future steps.  \n  - Maintain a record that such lines were considered and rejected, ensuring clarity for human collaborators.\n- **Avoiding Contamination**  \n  - Once a line of reasoning is flagged as erroneous, it is \\emph{removed} from the LLM\u2019s active context.  \n  - This prevents \u201canchoring\u201d on flawed premises.\n\n### 7.4 Iterative Drafting and Revision\n1. **Discrete Phases**  \n   - Literature collection  \n   - First-pass outline  \n   - Paragraph-level drafting  \n   - Full document synthesis  \n   - Revision  \n2. **User Oversight**  \n   - At each phase, the user must confirm the system\u2019s direction and correctness, especially when bridging from one phase to the next.\n\n### 7.5 Avoiding the Illusion of Agency\n- **Tool, Not Agent**  \n  - Current LLMs are sophisticated text-generation \\emph{tools}, not truly agentic researchers.  \n  - Overreliance on them for self-directed tasks leads to confusion and suboptimal outcomes.\n- **User-Driven Goals and Quality Control**  \n  - The LLM cannot reliably judge the quality of its own answers.  \n  - Researchers must provide acceptance criteria (e.g., is this summary correct? Does this step align with the research question?).\n\n---\n\n## 8. Practical Applications\n\n### 8.1 Literature Review\n- **Enhanced Summaries**:  \n  - Use LLMs to compile quick summaries \\emph{per source}.  \n  - Incorporate them into a structured outline with \\emph{clearly separated} sections.\n- **Token Management**:  \n  - Avoid overstuffing the context window with \\emph{all} references at once.  \n  - Keep the process modular to mitigate the LLM\u2019s capacity limits.\n\n### 8.2 Example: First-Week PhD Student vs. LLM\n- A first-week PhD student can show curiosity, question contradictory findings, or flag incomplete lines of thought.  \n- An LLM can produce well-formed text but will not spontaneously cross-check for relevance, correctness, or deeper insight.\n\n---\n\n## 9. Future Development\n\n### 9.1 Requirements for Next-Generation Research Tools\n- **Contextual Transparency**:  \n  - Systems should expose exactly what sources or text are active in the context window.  \n  - Clear summaries of any transformations performed on those sources.\n- **Adaptive Memory Management**:  \n  - Ability to \u201cforget\u201d flawed threads while preserving an audit trail for accountability.  \n  - Minimizes contamination from prior mistakes.\n\n### 9.2 Judging Progress\n- **Human-Tool Collaboration**:  \n  - The user must consistently exercise judgment.  \n  - Evaluate partial outputs for correctness and alignment with overarching goals.\n- **Avoiding Waterfall Pitfalls**:  \n  - Treat research as an iterative loop, not a rigid pipeline.  \n  - Each major step (finding literature, building an outline, drafting text) should be cyclical and informed by feedback.\n\n---\n\n## 10. Conclusion\n- AI systems currently provide immense \u201cmundane utility\u201d by efficiently generating text and synthesizing large volumes of data. However, they remain non-agentic in the deeper sense: they lack self-critique, inductive insight, and the ability to definitively judge correctness.  \n- To harness these tools for meaningful research, we must adopt an iterative, user-led process that leverages human judgment at each milestone. Tools should:  \n  - Segment tasks into smaller, verifiable steps.  \n  - Systematically manage context to avoid contaminating future outputs.  \n  - Provide ways to discard or \u201ctombstone\u201d invalid reasoning.  \n- By acknowledging and designing around the models\u2019 limitations, researchers can benefit from their powerful language capabilities while preserving essential human oversight.\n\n---\n\nThese notes now integrate the latest discussion (<chat2>), highlighting the need for structured, human-directed workflows, tombstones for invalid ideas, modular outlines for context management, and repeated user judgment to guide AI-driven research."
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 1.0,
        "metadata": {
          "message_type": null,
          "model_slug": "o1-pro",
          "default_model_slug": "o1-pro",
          "parent_id": "66950f0c-56a2-4fec-91ef-ec2e9770074f",
          "request_id": "91198ba27b3ea7f5-SYD",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "66950f0c-56a2-4fec-91ef-ec2e9770074f",
      "children": []
    }
  },
  "moderation_results": [],
  "current_node": "b123b1cf-0724-439a-b2b5-f5026c085707",
  "plugin_ids": null,
  "conversation_id": "67aea5c5-accc-8004-afd5-d9705a33d3b6",
  "conversation_template_id": null,
  "gizmo_id": null,
  "gizmo_type": null,
  "is_archived": false,
  "is_starred": null,
  "safe_urls": [
    "https://feeds.feedblitz.com/~/912665402/0/marginalrevolution~Dwarkeshs-Question.html"
  ],
  "blocked_urls": [],
  "default_model_slug": "o1-pro",
  "conversation_origin": null,
  "is_read_only": null,
  "voice": null,
  "async_status": null,
  "disabled_tool_ids": [],
  "is_do_not_remember": null,
  "memory_scope": "global_enabled",
  "context_scopes": null,
  "sugar_item_id": null,
  "sugar_item_visible": false,
  "pinned_time": null,
  "is_study_mode": false,
  "owner": null,
  "id": "67aea5c5-accc-8004-afd5-d9705a33d3b6"
}