{
  "uuid": "a2a8e2e6-a9b3-4302-89ed-ca720d2cfb2e",
  "name": "Cooperative AI Tools for Humanities Research",
  "summary": "",
  "created_at": "2025-04-05T03:27:49.274080Z",
  "updated_at": "2025-04-05T03:27:56.546875Z",
  "account": {
    "uuid": "17538ba7-7aa5-450c-9d3f-69ab346ad799"
  },
  "chat_messages": [
    {
      "uuid": "70c3b601-4ce7-4b54-b615-ea312053fcd3",
      "text": "Hi Claude. Can you crunch this down to a 100 word description, please?",
      "content": [
        {
          "start_timestamp": "2025-04-04T19:23:29.410571Z",
          "stop_timestamp": "2025-04-04T19:23:29.410571Z",
          "flags": null,
          "type": "text",
          "text": "Hi Claude. Can you crunch this down to a 100 word description, please?",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-04-05T03:27:50.444691Z",
      "updated_at": "2025-04-05T03:27:50.444691Z",
      "attachments": [
        {
          "file_name": "paste.txt",
          "file_size": 11227,
          "file_type": "txt",
          "extracted_content": "Humanities AI Workbench: Developing Human-LLM Cooperative Tools and Qualitative Benchmarks for Enhancing Humanities Research\nLarge Language Models (LLMs) hold significant promise for enhancing humanities research, yet current implementations often suffer from fundamental limitations in judgment that risk diminishing human agency. This project proposes a Humanities AI Workbench, explicitly designed to foster cooperative interactions between human researchers and LLMs, supporting the entire research lifecycle while preserving essential scholarly judgment and intellectual autonomy.\nThe Workbench is grounded in two novel conceptual frameworks: The first, \"technoscholasticism\" identifies how LLMs privilege textual authority over critical assessment of knowledge claims (paper in progress), determining source quality by textual markers rather than real-world correspondence and defaulting to heavily cited authorities regardless of appropriateness (paper in progress). The second, \"AI-Locus of Control\" examines how AI interactions can shift perceived agency from humans to machines, potentially undermining the researcher's role in knowledge creation (Torrington, Ballsun-Stanton, and Lai 2025). \nUnlike approaches that envision automated research, our Humanities AI Workbench will facilitate cooperation between researchers and LLMs across the research lifecycle, from ideation and research design through bibliographic research, dataset generation, software creation, analysis, and composition. The Workbench will enable model substitution, allowing researchers to select appropriate LLMs for different tasks as capabilities evolve. By emphasizing FAIRification (Findability, Accessibility, Interoperability, and Reusability) of LLM contributions, including chain-of-thought reasoning and references, we will establish new standards for transparent and reproducible AI-assisted humanities research. This approach enables researchers to maintain agency while benefiting from LLM capabilities in idea generation, pattern recognition, and text manipulation.\nThe Workbench will be developed through a proposed partnership with the Australian Research Data Commons (ARDC, noting that ARDC collaboration has been discussed with leadership but will need to pass an approval process should the EOI advance). \nOur interdisciplinary research team uniquely positions us to deliver this project:\nBrian Ballsun-Stanton contributes expertise in Philosophy of Data, extensive experience in AI integration within educational contexts, and technical leadership in research software engineering (e.g., Ballsun-Stanton, et al. 2018, Kudina, et al. 2025, Ballsun-Stanton and Hipolito, 2024, Ballsun-Stanton, et al 2023, Smith, et al. 2024, and has delivered over 30 workshops and events on AI pragmatics, research use, ethics, and policy.).\nShawn Ross offers experience in archaeological and historical scholarship, digital research, implementation of FAIR principles, and software business analysis and product management (e.g., Ross et al. 2018; Sobotkova, et al., 2021; Suominen et al. 2024).\nJodie Torrington provides expertise in educational psychology, particularly self-regulated learning, professional development coursework creation, and extensive experience in developing innovative pedagogical approaches involving AI. (e.g. Torrington, et al. 2024, Bower, et al. 2024)\nTechnical Components \nEach component of the Humanities AI Workbench addresses one phase of the humanities research lifecycle:\nIdeation: Tools enabling iterative exploration of research questions, fostering critical thinking, epistemic humility, and openness to multiple scholarly perspectives through AI-supported proleptic reasoning (Kudina et al., 2025).\nResearch Design: Systems assisting researchers in articulating research questions and developing robust methodologies. This includes support for structured hypothesis generation, methodological rigour, and preregistration processes where appropriate (Ross & Ballsun-Stanton 2022).\nBibliographic Research: Advanced literature review tools providing transparent critical evaluations of sources, explicitly addressing biases and gaps in existing scholarship, and guiding scholars toward underrepresented perspectives or neglected topics.\nHuman Ethics and Data Management: Toolkit development supporting researchers and ethics committees in responsibly incorporating AI into research, including informed consent processes clearly explaining AI involvement (Smith et al., 2024).\nDataset Generation: Data tools enabling the assembly, cleaning, documentation, and FAIR-compliant description of multimodal datasets (text, geospatial data, multimedia). This supports improved machine-readable metadata and integration with emerging international standards (Ross et al., 2022).\nSoftware Creation: Facilitation of the transition from desktop-based analyses to reproducible, transparent programmatic dataset creation and analysis. This component incorporates educational safeguards ensuring researchers fully understand and control the software and code they utilize. (i.e.Hermankova, et al. 2024, Github/MyBinder)\nAnalysis: Development of transparent analytical workflows explicitly linked to underlying data, ensuring reproducibility and addressing technoscholastic limitations by maintaining clear ties to empirical realities.\nComposition: Writing support tools that iteratively assist scholars in drafting and refining scholarly work, preserving authorial originality, and enhancing rather than constraining researchers' intellectual creativity.\nTechnical Architecture\nThe Workbench will leverage the ARDC\u2019s national infrastructure services, including NeCTAR, BinderHub, and Virtual Desktop services to implement a flexible, modular architecture. Recognising rapid evolution of model capability, services, and wrappers, this architecture supports model substitution, we will focus on LLM methods, prompts, and scripts that can be deployed in common environments. Our project will also host open-source models to facilitate culturally and otherwise sensitive data and expose researchers to a broader range of models. \nWe will develop guidance at each stage about how researchers can improve the FAIR and CARE compliance of their own digital research objects, and to align their LLM interactions with these principles, facilitating ethical and effective use of AI for their own research.\nEach Workbench component will be complemented by rigorous qualitative benchmarking protocols, ensuring ongoing evaluation and refinement. These benchmarks incorporate perspectives from diverse scholarly traditions, including philosophical, educational, and Indigenous epistemologies.\nAddressing HAVI Priorities\nOur project addresses key challenges around Heterogeneity and Contextual Understanding:\nDeveloping robust qualitative benchmarks and benchmark rubrics and protocols to evaluate cultural and historical accuracy, thoughtfulness of writing, and representation and diversity of perspectives in LLM-generated content. \nCreating comprehensive, culturally aware prompting strategies, documented in a \"grimoire,\" (Mollick 2023) that encourage respectful and diverse epistemological engagements.\nEmploying technoscholastic judgment criteria (epistemic humility, inductive capacity, and correspondence with reality) to guide rigorous scholarly evaluation of AI outputs.\nCreating professional development material, classes, and enhancing user interface designs and interactions based on the AI-Locus of Control framework to explicitly reinforce researcher agency and critical judgment. (Torrington and Ballsun-Stanton 2025)\nOur project also incorporates Multimodal and Multilingual Capabilities:\nUtilising multimedia, structured data, and geospatial data management tools essential for humanities researchers, especially in archaeology and historical fields.\nIntegrating multilingual capabilities through collaboration with initiatives like the Language Data Commons of Australia, facilitating research across linguistic barriers.\nCollaborating closely with Indigenous knowledge experts to ensure Indigenous perspectives and epistemologies are appropriately integrated, respecting CARE principles.\nBroader Impacts\nEnhanced Research Quality. Our Workbench will enhance humanities research quality by merging human judgment with AI-driven efficiencies, streamlining routine tasks, and enhancing analytical rigour.\nNew Standards for AI Transparency. By adopting FAIR principles and documentation standards, our project will set new benchmarks for transparent, reproducible, and accountable AI-assisted research.\nNational Research Infrastructure. Deployment on ARDC\u2019s national infrastructure ensures equitable access, supporting a wide spectrum of humanities researchers, including those at institutions with limited resources.\nCross-Disciplinary Applicability. The modular design enables researchers from diverse humanities disciplines to adapt tools and methodologies to their individual scholarly requirements, promoting broad disciplinary engagement.\nInternational Leadership and Best Practices. Our comprehensive approach, emphasising FAIR and CARE principles, ethical engagement, and cultural inclusivity, positions Australia as a global leader in the responsible, effective integration of AI in humanities research.\nResources and Professional Training. We will develop extensive resources including professional development materials, explicit instruction classroom and asynchronous teaching materials (White et. al. 2022), comprehensive documentation, and detailed prompt \"grimoires.\" These materials will support humanities scholars in acquiring essential skills in AI literacy, enhancing their critical thinking and methodological rigor.\nOur national-scale demonstrator project positions Australia as an international exemplar in ethical, inclusive, and responsible AI-enhanced humanities scholarship, fundamentally prioritizing human intellectual judgment, cultural diversity, and academic rigor throughout the research lifecycle.\nProject Timeline (36-months)\nMonths 1-3: Co-design & Requirements Gathering Engaging stakeholders, defining scope, and validating user requirements. Recruit postgraduate students.\nMonths 4-6: Technical Elaboration & Architecture Planning Finalizing technical architecture, selecting LLM models, and integrating FAIR/CARE principles. Qualitative benchmark development begins.\nMonths 7-9: Prototype Development Developing initial functional prototype and conducting internal usability tests. Qualitative benchmark testing against commonly available frontier models and services.\nMonths 10-18: Iterative Development & User Feedback Iteratively refining the system based on structured user feedback and quality assurance.\nMonths 19-24: Demonstration Service Deployment Deploying the demonstration service, initiating public use, and providing initial user training. Benchmark validation of project tools and prompts.\nMonths 25-36: Extended Continuous Improvement & Refinement Ongoing enhancements driven by extensive user feedback, broad training initiatives, resource expansion, and continual adaptation to technological advancements. Completion of PhD theses related to the project.\n"
        }
      ],
      "files": [
        {
          "file_name": "paste.txt"
        }
      ]
    },
    {
      "uuid": "567c7fd8-5f57-4efb-9e01-a8fdedb770a3",
      "text": " Here's a 100-word description of the document:\n\nThe Humanities AI Workbench project aims to develop tools fostering cooperative interactions between humanities researchers and Large Language Models (LLMs). Based on frameworks addressing \"technoscholasticism\" and \"AI-Locus of Control,\" it preserves human agency while enhancing research capabilities. The Workbench supports all research phases\u2014ideation, design, bibliographic research, dataset generation, software creation, analysis, and composition\u2014through a modular architecture enabling model substitution. Developed in partnership with the Australian Research Data Commons, it emphasizes FAIR principles, transparent AI contributions, and qualitative benchmarking. The project addresses contextual understanding and multimodal capabilities while establishing new standards for transparent, reproducible AI-assisted humanities research.",
      "content": [
        {
          "start_timestamp": "2025-04-05T03:27:51.633808Z",
          "stop_timestamp": "2025-04-05T03:27:54.460714Z",
          "flags": null,
          "type": "text",
          "text": " Here's a 100-word description of the document:\n\nThe Humanities AI Workbench project aims to develop tools fostering cooperative interactions between humanities researchers and Large Language Models (LLMs). Based on frameworks addressing \"technoscholasticism\" and \"AI-Locus of Control,\" it preserves human agency while enhancing research capabilities. The Workbench supports all research phases\u2014ideation, design, bibliographic research, dataset generation, software creation, analysis, and composition\u2014through a modular architecture enabling model substitution. Developed in partnership with the Australian Research Data Commons, it emphasizes FAIR principles, transparent AI contributions, and qualitative benchmarking. The project addresses contextual understanding and multimodal capabilities while establishing new standards for transparent, reproducible AI-assisted humanities research.",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-04-05T03:27:55.101394Z",
      "updated_at": "2025-04-05T03:27:55.101394Z",
      "attachments": [],
      "files": []
    }
  ]
}