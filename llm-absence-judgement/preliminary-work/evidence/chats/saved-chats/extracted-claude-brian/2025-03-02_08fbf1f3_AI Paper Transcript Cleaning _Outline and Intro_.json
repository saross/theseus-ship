{
  "uuid": "08fbf1f3-b425-4946-bd58-1c97a76d0783",
  "name": "AI Paper Transcript Cleaning (Outline and Intro)",
  "summary": "",
  "created_at": "2025-03-02T21:28:24.435577Z",
  "updated_at": "2025-04-02T22:09:48.867590Z",
  "account": {
    "uuid": "17538ba7-7aa5-450c-9d3f-69ab346ad799"
  },
  "chat_messages": [
    {
      "uuid": "e0e13212-b172-424a-ab07-1a0d05e69c36",
      "text": "",
      "content": [
        {
          "start_timestamp": "2025-03-01T01:52:28.988336Z",
          "stop_timestamp": "2025-03-01T01:52:28.988336Z",
          "flags": null,
          "type": "text",
          "text": "",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-02T21:28:30.802317Z",
      "updated_at": "2025-03-02T21:28:30.802317Z",
      "attachments": [
        {
          "file_name": "paste.txt",
          "file_size": 17802,
          "file_type": "txt",
          "extracted_content": "Canvas I'm going to input some ... adequate... transcripts and context.\n\nMy objective for you is to go through these transcripts and clean them up. Ask me questions about what I meant when things are unclear.\n\nTo begin, here's context\n\n<context1>\n\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1in]{geometry}\n\\usepackage{parskip}\n\n\\title{An Absence of Judgment: On AI's Fundamental Limitations in Research}\n\\author{}\n\\date{}\n\n\\begin{document}\n\n\\maketitle\n\n\\section{Introduction}\nLarge language models are fundamentally incapable of judgment, despite their ability to mimic the language of judgment. This distinction necessitates examining not only their linguistic output but also the concrete actions and outcomes that their words produce. However, this lack merely prevents us from treating them as true agents, \\textit{not} as extracting mundane utility from them as tools. This paper is an investigation into the creation of a research-grade dataset using OpenAI's Deep Research in February 2025, acting as a case study --- and our ``autoethnographic'' reflection upon the use of this tool for what Zvi Moshowitz calls ``mundane utility.\"\n\nHere, we will also give our understanding of the necessary prerequsities for an ``agentic'' tool, and why we believe that this infrastructure, at this time, does not satisfy that criteria. We will also discuss the fundamental lack of judgement that these models exhibit, and why it is this core incapability which prevents an accumulation of patterns-shaped-like-knowledge to answer Dwarkesh's question to Cohen: ``what do you make of the fact that these things have basically the entire corpus of human knowledge memorized and they haven\u2019t been able to make a single new connection that has led to a discovery? Whereas if even a moderately intelligent person had this much stuff memorized, they would notice \u2014 Oh, this thing causes this symptom.'' We assert that the lack of induction exhibited by even currently accessible frontier models like o3-mini-high, answers this question. To be clear, this paper is a description of what we have experienced in our attempt to actively use these models to research and answer an academic question --- not merely to conduct a \\textit{descriptive} literature review, but to find that central spark of insight which represents a contribution to the literature. We do not say that these capabilities are forever barred to these models, merely that they do not exhibit them yet and that the common errors in estimating the capabilities of these models based on \\textit{what they say} rather than \\textit{how they act} can lead to confusion as to their actual capabilities and hinder finding places of mundane utility in our use of these tools. \n\n\n\\section{Agentic Systems}\n\n#  \"Agentic\" Systems vs Normal Software\n\n## Goal-Related Characteristics\n1. Goal Following vs Goal Setting\n   - Agentic systems are goal-following systems\n   - This contrasts with AGI, which can set its own goals\n   - Key distinction: Agentic systems require external input for goals\n\n## Agentic Characteristics\n1. Goal Processing Capabilities\n   - Accept external goals as input\n   - Collaborate with users to operationalize goals\n   - Functionally decompose goals into manageable components\n\n2. Execution Capabilities\n   - Create plans for goal completion\n   - Invoke appropriate software and APIs\n   - Monitor and assess progress\n\n3. Assessment and Reporting\n   - Make judgments about goal completion\n   - Provide reports to users (like Claude)\n   - Include success/failure evaluation based on system's judgment\n\n\\section{Deep Research and AI Capabilities}\n\n\\subsection{Current State}\nThe implementation of O3 for research purposes, while advanced, reveals fundamental limitations. This connects to broader discussions, as highlighted in Cohen's repost of DAKISH regarding AI's inability to produce truly groundbreaking research. While these systems demonstrate acceptable fluency and solid domain knowledge, they lack crucial elements of genuine research capability.\n\n% One question I had for you while we were talking about the intelligence stuff was, as a scientist yourself, what do you make of the fact that these things have basically the entire corpus of human knowledge memorized and they haven\u2019t been able to make a single new connection that has led to a discovery? Whereas if even a moderately intelligent person had this much stuff memorized, they would notice \u2014 Oh, this thing causes this symptom. This other thing also causes this symptom. There\u2019s a medical cure right here.\n\n% Shouldn\u2019t we be expecting that kind of stuff?\n\n% It\u2019s a very good question. In 2023, I quipped, \u201cI think they have, we just haven\u2019t asked them.\u201d Maybe, but less clear today. Dwarkesh reports that there have been no good answers.\n% https://feeds.feedblitz.com/~/912665402/0/marginalrevolution~Dwarkeshs-Question.html\n\n\n\\subsection{Fundamental Limitations}\n\\begin{itemize}\n    \\item Absence of goal-setting and goal-following behavior\n    \\item Constraint to the Next Token paradigm\n    \\item Limited self-reflexivity, characterized by:\n        \\begin{itemize}\n            \\item Simple search execution\n            \\item Information synthesis without true comprehension\n        \\end{itemize}\n    \\item Inability to genuinely evaluate goal accomplishment\n        \\begin{itemize}\n            \\item System assumes task completion at each output\n            \\item Lacks true self-assessment capability\n        \\end{itemize}\n\\end{itemize}\n\n\\subsection{Comparative Analysis}\nUsing a first-week PhD student as our prototypical target, we observe that while AI systems can mimic goal-following behavior, they fundamentally lack the authentic research capabilities demonstrated by even novice human researchers.\n\n\\section{Other infrastructures}\n\n\\subsection{Anthropic Computer Use}\n\nWhile this is promising as a rough paradigm, Claude 3.5 Sonnet 20241022 did not possess sufficient world-intuition to collect a series of 8 article links from a web page. This failure consumed \\$1 of tokens, which is to say, 1.2 million tokens (mostly in screenshots) of failure to click, failure to right click, failure to change apps between firefox and libreoffice, and wittering about trying to solve its own navigation problems. \n\nHowever, this does not require a difference in kind, merely a degree. This paradigm of computer use is a future of computer augmented research, since it got the idea of what we wanted to do. It simply failed at execution due to a deductive deficiency. The first chat was lost due to an inadvertent window closure (and the fact that absolutely no logs are kept by this demo application). The second one is in our supplemental data.) While we are sure that some prompt improvements can be made, as this was our second attempt at using computer use, further iteration would not reward the effort.\n\nNo prompting has been shared for Computer Use, as we were not able to proceed beyond our initial proof of concept. It is clear that with sufficient budget, and human supervision, Computer Use would be able to gradually navigate around web pages and extract data. It is simply not an efficient use of time or money at this stage of Claude 3.5 Sonnet's capabilities. \n\n\\subsection{Elicit Research Paper}\n\nFor Elicit, we provided the following prompt:\n\n\\begin{quote}\n\nResearch question: Within the literature of archaeology and the historical sciences, constructed broadly, what software tools exist as discussed in the literature from 1995 onwards? Specifically, we are looking for you to examine the journals of: Internet Archaeology, SoftwareX, JOAD, JOSS, JCAA, and STAR (Science \\& Tech of Archaeological Research). We define a tool as: ```For our project, a software tool is any discrete piece of software\u2014be it a program, script, or web application\u2014that is developed or substantially modified by researchers to perform specific, research-oriented computational tasks. These tasks must involve active data processing, such as analysis, simulation, visualization, modeling, or automation, where input data is dynamically created, documented, transformed, or interpreted to generate meaningful results. In contrast, products whose primary function is to simply display, store, or promote static datasets\u2014without offering mechanisms for active computational engagement\u2014are excluded. In essence, a valid software tool for our purposes is one that not only **supports research in archaeology or historical sciences** but does so by actively collecting and/or processing data rather than merely serving as a generic data repository or static interface.``` The objective of this research report is to find and cite EVERY SINGLE software tool (from our construction above) as mentioned in those journals SO LONG as those software tools have specific and direct applicability or citation within papers about archaeological and historical sciences. Some of those journals are discipline specific, and we need to look through for software tool mentions (mere published datasets are not interesting to us). Some of those journals are tool specific, and we need to look through for DISCIPLINE mentions, to ensure that the tool has specific and direct relevance to historians and archaeologists. My objective here is either a bulleted list of citations, or if you can manage it a csv of citations for further work. The intention is that this research will support a paper on software longevity.\n\n\\end{quote}\n\nWe did not believe that it would accomplish any real proportion of the prompt, but given that the Elicit team provided us a coupon for the \"Plus\" plan (\\$12/month), the available capabilities afforded to us were a one-prompt-and-go text area. Elicit's own infrastructure evaluated this prompt as a \"Great question.\" Unlike with our assessment of Anthropic's Computer Use, we believe that changes in both kind and degree are necessary for Elicit to be useful for research data collection. We assert the following systematic issues.\n\\begin{enumerate}\n    \\item Unacceptable scope, inhereted from Semantic Scholar\n    \\item Problematic search criteria, via Semantic Scholar's deplorable TLDR summaries    \n    \\item Model judgement failures in screening criteria operationalisation and evaluation\n    \\item An utter lack of judgement and discernment in the final research report\n\\end{enumerate}\n\nWe did find that, from our prompt, the model they are using did create acceptable screening criteria, but once created, the evaluation of those criteria against sample papers was deeply unsatisfactory. \n\n\\subsection{Perplexity Deep Research}\n\n\\subsection{Google Deep Research}\n\n\\section{Practical Applications}\n\n\\subsection{Literature Reviews}\nInitial applications in literature review processes have shown promising results, particularly in:\n\\begin{itemize}\n    \\item Dataset preparation and collection for research purposes\n    \\item Improvement over previous superficial review methodologies\n\\end{itemize}\n\n\\section{Future Development}\n\\subsection{Areas Requiring Further Investigation}\n\\begin{itemize}\n    \\item The Normal Intuitive Pattern concept requires elaboration\n    \\item Connection between mundane utility and tool-using behavior\n    \\item Precise definition of agentic behavior in research contexts\n    \\item Concrete manifestations of judgment absence in research outputs\n\\end{itemize}\n\n\n\\end{document}\n</context1>\n\n<context2>\n# An Absence of Judgment: On AI's Fundamental Limitations in Research\n\n## 1. Introduction\n- Fundamental incapability of judgment in LLMs despite linguistic mimicry\n- Case study: OpenAI's Deep Research (February 2025)\n- Prerequisites for \"agentic\" tools\n- Core thesis on lack of induction preventing knowledge connections\n\n## 2. Agentic Systems Framework\n### 2.1 Goal-Related Characteristics\n- Distinction between goal-following and goal-setting\n- External input requirements\n- Operational definitions of agency\n\n### 2.2 Core Components of Agency\n- Goal processing capabilities\n- Execution mechanisms\n- Assessment and reporting functions\n\n## 3. Deep Research Analysis\n### 3.1 Observed Limitations\n- Failure case: Newspaper article generation\n- Inability to follow explicit guidelines\n- Surface-level competence without true comprehension\n\n### 3.2 The Uncanny Valley of Research\n- Always produces output without questioning assumptions\n- Lacks systematic approach\n- No self-correction or revision process\n- Takes initial search results as \"gospel\"\n- Absence of winnowing or filtering process\n\n### 3.3 Literature Review Capabilities\n- Can perform descriptive reviews without insight\n- Missing elements:\n  - Purpose-driven source selection\n  - Intentional organization\n  - Generation of novel insights\n  - Inductive reasoning\n\n## 4. Mundane Utility and Successful Applications\n### 4.1 Effective Use Cases\n- [Placeholder for successful applications]\n- [Placeholder for areas of demonstrated competence]\n\n### 4.2 Workflow Integration\n- [Placeholder for effective integration patterns]\n- [Placeholder for productivity improvements]\n\n### 4.3 Value Proposition\n- [Placeholder for cost-benefit analysis]\n- [Placeholder for efficiency gains]\n\n## 5. System Design Requirements\n### 5.1 Context Management\n- Transparent context window visibility\n- Token management strategies\n- Source tracking and documentation\n- Ability to \"forget\" or remove irrelevant content\n- Tombstones for discarded thoughts\n\n### 5.2 Research Process Support\n- Structured todo lists for research steps\n- Clear documentation of considered sources\n- Management of working context windows\n- Integration points for human judgment\n- Outline-driven context switching\n\n### 5.3 Stage-Based Approach\n- Literature finding\n- Literature extraction\n- Outline building\n- First draft creation\n- Revision process\n- Editing and output\n- Documentation requirements for each stage\n\n## 6. Human-AI Collaboration Framework\n### 6.1 Judgment Integration\n- Recognition of AI judgment deficiency\n- Strategic points for human intervention\n- Validation and verification processes\n- Beyond simple confirmation mechanisms\n\n### 6.2 Tool-Centric Approach\n- Treating AI as tool rather than agent\n- Leveraging AI capabilities appropriately\n- Managing limitations and boundaries\n- Integration with human research processes\n\n## 7. Future Development Needs\n### 7.1 Technical Requirements\n- Improved context management\n- Better token efficiency\n- Enhanced source tracking\n- Robust documentation systems\n\n### 7.2 Process Requirements\n- Non-waterfall approach to research\n- Flexible stage management\n- Improved human-AI interaction patterns\n- Documentation standards\n\n## 8. Conclusion\n- Synthesis of key findings\n- Implications for AI research tools\n- Future research directions\n</context2>\n\n<context3>\n\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1in]{geometry}\n\\usepackage{parskip}\n\n\\title{An Absence of Judgment: On AI's Fundamental Limitations in Research}\n\\author{}\n\\date{}\n\n\\begin{document}\n\n\\maketitle\n\n\\section{Introduction}\nLarge language models are fundamentally incapable of judgment, despite their ability to mimic the language of judgment. This distinction necessitates examining not merely their linguistic output, but the concrete actions and outcomes their words produce.\n\n\\section{Deep Research and AI Capabilities}\n\n\\subsection{Current State}\nThe implementation of O3 for research purposes, while advanced, reveals fundamental limitations. This connects to broader discussions, as highlighted in Cohen's repost of DAKISH regarding AI's inability to produce truly groundbreaking research. While these systems demonstrate acceptable fluency and solid domain knowledge, they lack crucial elements of genuine research capability.\n\n\\subsection{Fundamental Limitations}\n\\begin{itemize}\n    \\item Absence of goal-setting and goal-following behavior\n    \\item Constraint to the Next Token paradigm\n    \\item Limited self-reflexivity, characterized by:\n        \\begin{itemize}\n            \\item Simple search execution\n            \\item Information synthesis without true comprehension\n        \\end{itemize}\n    \\item Inability to genuinely evaluate goal accomplishment\n        \\begin{itemize}\n            \\item System assumes task completion at each output\n            \\item Lacks true self-assessment capability\n        \\end{itemize}\n\\end{itemize}\n\n\\subsection{Comparative Analysis}\nUsing a first-week PhD student as our prototypical target, we observe that while AI systems can mimic goal-following behavior, they fundamentally lack the authentic research capabilities demonstrated by even novice human researchers.\n\n\\section{Practical Applications}\n\n\\subsection{Literature Reviews}\nInitial applications in literature review processes have shown promising results, particularly in:\n\\begin{itemize}\n    \\item Dataset preparation and collection for research purposes\n    \\item Improvement over previous superficial review methodologies\n\\end{itemize}\n\n\\section{Future Development}\n\\subsection{Areas Requiring Further Investigation}\n\\begin{itemize}\n    \\item The Normal Intuitive Pattern concept requires elaboration\n    \\item Connection between mundane utility and tool-using behavior\n    \\item Precise definition of agentic behavior in research contexts\n    \\item Concrete manifestations of judgment absence in research outputs\n\\end{itemize}\n\n\\subsection{To-Do Items}\n\\begin{itemize}\n    \\item Define ``identic'' (reference: conversation with Brett)\n\\end{itemize}\n\n\\end{document}\n</context3>\n\nThese are all documents that may have had some merges already done. Once you're ready, I'll upload the transcripts.\n\nMy only goals for you are to:\n1. Faithfully clean the transcript\n2. Ask me questions when things are unclear\n3. Identify where my phone's microphones may have picked up crosstalk and eliminate it."
        }
      ],
      "files": [
        {
          "file_name": "paste.txt"
        }
      ]
    },
    {
      "uuid": "dba1cfa6-52df-423e-91d2-2c346a2845ff",
      "text": " <think>\nI'm being asked to help clean up transcribed audio input and integrate it into a document outline for a paper about AI's limitations in research. The user has provided several context documents:\n\n1. A LaTeX document titled \"An Absence of Judgment: On AI's Fundamental Limitations in Research\"\n2. A prior chat transcript showing a conversation about developing this paper\n3. A paste.txt file with additional context and instructions\n\nThe main task is to:\n1. Clean up transcripts that will be provided\n2. Ask questions about unclear elements\n3. Remove crosstalk from microphone recordings\n4. Integrate the cleaned content into an outline (in markdown format as an artifact)\n\nThe paper appears to be about AI's limitations in research contexts, focusing on the lack of judgment and true agency in language models. It uses Deep Research as a case study and discusses the concept of \"agentic\" systems.\n\nI'll need to wait for the user to upload the actual transcripts before I can begin cleaning and integrating them. I should create the outline as a markdown artifact.\n</think>\n\nI'll help you clean up the transcripts and integrate them into your document outline. I understand your goals are to:\n\n1. Faithfully clean the transcripts you'll be providing\n2. Ask clarifying questions when needed\n3. Remove any crosstalk captured by your phone's microphones\n\nI've reviewed the context documents you've shared, which provide a good foundation for understanding your paper on AI's limitations in research, particularly focusing on their lack of judgment despite linguistic capabilities.\n\nI'll be ready to work with the transcripts as soon as you upload them, and I'll create a markdown outline as an artifact to help organize the material.",
      "content": [
        {
          "start_timestamp": "2025-03-02T21:28:34.779547Z",
          "stop_timestamp": "2025-03-02T21:28:41.694375Z",
          "flags": null,
          "type": "text",
          "text": " <think>\nI'm being asked to help clean up transcribed audio input and integrate it into a document outline for a paper about AI's limitations in research. The user has provided several context documents:\n\n1. A LaTeX document titled \"An Absence of Judgment: On AI's Fundamental Limitations in Research\"\n2. A prior chat transcript showing a conversation about developing this paper\n3. A paste.txt file with additional context and instructions\n\nThe main task is to:\n1. Clean up transcripts that will be provided\n2. Ask questions about unclear elements\n3. Remove crosstalk from microphone recordings\n4. Integrate the cleaned content into an outline (in markdown format as an artifact)\n\nThe paper appears to be about AI's limitations in research contexts, focusing on the lack of judgment and true agency in language models. It uses Deep Research as a case study and discusses the concept of \"agentic\" systems.\n\nI'll need to wait for the user to upload the actual transcripts before I can begin cleaning and integrating them. I should create the outline as a markdown artifact.\n</think>\n\nI'll help you clean up the transcripts and integrate them into your document outline. I understand your goals are to:\n\n1. Faithfully clean the transcripts you'll be providing\n2. Ask clarifying questions when needed\n3. Remove any crosstalk captured by your phone's microphones\n\nI've reviewed the context documents you've shared, which provide a good foundation for understanding your paper on AI's limitations in research, particularly focusing on their lack of judgment despite linguistic capabilities.\n\nI'll be ready to work with the transcripts as soon as you upload them, and I'll create a markdown outline as an artifact to help organize the material.",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-02T21:28:42.098157Z",
      "updated_at": "2025-03-02T21:28:42.098157Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "71168cea-2c16-40e5-b126-35b2a53ba7fa",
      "text": "\nLet me analyze these documents to understand the project fully:\n\n1. The first document is titled \"Absence Of Judgement Paper Notes\" which appears to be a draft academic paper discussing AI's limitations in research, focusing on the concept that AI lacks true judgment despite being able to mimic it linguistically.\n\n2. The second document is titled \"Prior Chat 1\" which seems to be a transcript of a conversation between the user and an AI assistant, where the user was dictating thoughts about AI research capabilities and the assistant was helping organize those thoughts.\n\n3. The third document \"paste.txt\" provides instructions for me regarding my role in this project. The user wants me to:\n   - Clean up transcripts that will be inputted\n   - Ask questions when things are unclear\n   - Identify and eliminate crosstalk picked up by phone microphones\n   - Not provide feedback or praise\n   - Transform user inputs\n   - Present any outlines in markdown format in an artifact\n\nThe user has shared multiple versions of what appears to be the same academic paper in different stages of development:\n- The LaTeX document in the first document and third document (context1 and context3)\n- A markdown outline version in the third document (context2)\n\nThe paper focuses on AI's limitations in research contexts, particularly discussing:\n- The concept of judgment in AI\n- What makes a system \"agentic\"\n- Specific case studies with tools like OpenAI's Deep Research, Anthropic Computer Use, Elicit Research Paper, etc.\n- The concept of an \"uncanny valley of research\"\n\nThe user is planning to dictate more content that I'll need to clean up and integrate into this academic paper. I should not ask questions unless something is unclear, and I should focus on transforming the user's input rather than providing feedback.\n\nI understand your requirements. I'll help clean up the audio transcripts you'll be providing, transforming them into clear text that can be integrated into your academic paper on AI's limitations in research. I'll only ask questions when something is unclear, and I'll identify and remove any crosstalk captured by your phone's microphone.\n\nI'll present any outlines in markdown format as an artifact when needed.\n\nReady for you to upload the transcripts.",
      "content": [
        {
          "start_timestamp": "2025-03-02T21:28:50.913766Z",
          "stop_timestamp": "2025-03-02T21:28:59.489651Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nLet me analyze these documents to understand the project fully:\n\n1. The first document is titled \"Absence Of Judgement Paper Notes\" which appears to be a draft academic paper discussing AI's limitations in research, focusing on the concept that AI lacks true judgment despite being able to mimic it linguistically.\n\n2. The second document is titled \"Prior Chat 1\" which seems to be a transcript of a conversation between the user and an AI assistant, where the user was dictating thoughts about AI research capabilities and the assistant was helping organize those thoughts.\n\n3. The third document \"paste.txt\" provides instructions for me regarding my role in this project. The user wants me to:\n   - Clean up transcripts that will be inputted\n   - Ask questions when things are unclear\n   - Identify and eliminate crosstalk picked up by phone microphones\n   - Not provide feedback or praise\n   - Transform user inputs\n   - Present any outlines in markdown format in an artifact\n\nThe user has shared multiple versions of what appears to be the same academic paper in different stages of development:\n- The LaTeX document in the first document and third document (context1 and context3)\n- A markdown outline version in the third document (context2)\n\nThe paper focuses on AI's limitations in research contexts, particularly discussing:\n- The concept of judgment in AI\n- What makes a system \"agentic\"\n- Specific case studies with tools like OpenAI's Deep Research, Anthropic Computer Use, Elicit Research Paper, etc.\n- The concept of an \"uncanny valley of research\"\n\nThe user is planning to dictate more content that I'll need to clean up and integrate into this academic paper. I should not ask questions unless something is unclear, and I should focus on transforming the user's input rather than providing feedback.",
          "summaries": [
            {
              "summary": "Analyzing academic paper on AI's judgment limitations"
            },
            {
              "summary": "Analyzed academic paper drafts on AI research limitations."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-02T21:28:59.943786Z",
          "stop_timestamp": "2025-03-02T21:29:01.485862Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI understand your requirements. I'll help clean up the audio transcripts you'll be providing, transforming them into clear text that can be integrated into your academic paper on AI's limitations in research. I'll only ask questions when something is unclear, and I'll identify and remove any crosstalk captured by your phone's microphone.\n\nI'll present any outlines in markdown format as an artifact when needed.\n\nReady for you to upload the transcripts.",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-02T21:29:01.897387Z",
      "updated_at": "2025-03-02T21:29:01.897387Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "1d1730bb-63b6-44e2-aa45-cb08147678fb",
      "text": "I'm dumping these all in at once before I go home. Sorry. The order of recording is:\n\n* context friday 8:47\n* friday 6:19\n* epistemic - monday 8:50\n* Thursday 8:36\n* Tuesday 8:36\n* Systems -friday 8:16\n\nWe'll go through one by one, clean out the fragments which are salient, and ask me to manually listen to fragments that may or may not be salient.",
      "content": [
        {
          "start_timestamp": "2025-03-06T21:35:46.603225Z",
          "stop_timestamp": "2025-03-06T21:35:46.603225Z",
          "flags": null,
          "type": "text",
          "text": "I'm dumping these all in at once before I go home. Sorry. The order of recording is:\n\n* context friday 8:47\n* friday 6:19\n* epistemic - monday 8:50\n* Thursday 8:36\n* Tuesday 8:36\n* Systems -friday 8:16\n\nWe'll go through one by one, clean out the fragments which are salient, and ask me to manually listen to fragments that may or may not be salient.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-08T04:18:07.742403Z",
      "updated_at": "2025-03-08T04:18:07.742403Z",
      "attachments": [
        {
          "file_name": "Context \u2013 Friday at 8-47\u202fam (1).srt",
          "file_size": 8287,
          "file_type": "",
          "extracted_content": "1\n00:00:20,547 --> 00:00:27,433\nSo the structure of the paper is, we have our discussion of why these things are not\n\n2\n00:00:28,755 --> 00:00:42,361\nWe have our discussion of mundane utility and our experiences of using it for research.\n\n3\n00:00:43,721 --> 00:00:46,823\nAnd then we have the discussion of what next.\n\n4\n00:00:47,043 --> 00:00:52,445\nWhat do we need in a tool that genuinely does research?\n\n5\n00:00:58,837 --> 00:01:04,641\nHow do we facilitate what these things are good at?\n\n6\n00:01:04,881 --> 00:01:10,765\nHow do we interact with these things knowing that they are deficient in judgment?\n\n7\n00:01:12,967 --> 00:01:19,811\nAnd so the first thing that we need is a cursored to-do list.\n\n8\n00:01:21,432 --> 00:01:27,817\nThe first thing that we need is to actively monitor\n\n9\n00:01:29,059 --> 00:01:39,748\neach step in the to-do list, so that we can get the user's judgment as to correctness.\n\n10\n00:01:40,609 --> 00:01:57,103\nBecause the thing is, is that the research, there will be dead ends, there will be blind alleys, and this is not, this is not the, oh, I'm not able to access that, I mean, I don't find a look around, but we saw\n\n11\n00:01:57,945 --> 00:02:05,507\nin 7th February logs, this is going to be, oh, this line of thinking is incorrect.\n\n12\n00:02:06,868 --> 00:02:08,328\nThis output is bad.\n\n13\n00:02:08,668 --> 00:02:10,009\nThis is not appropriate.\n\n14\n00:02:10,349 --> 00:02:11,529\nI should remove this.\n\n15\n00:02:12,630 --> 00:02:20,092\nBecause fundamentally, fundamentally what we see is that these\n\n16\n00:02:24,744 --> 00:02:28,406\nlarge language markers are not capable of being self-critical.\n\n17\n00:02:28,466 --> 00:02:30,007\nThey don't exhibit judgment.\n\n18\n00:02:30,467 --> 00:02:37,970\nBut more to the point, they don't have the inductive capacity, the intuition, whatever, to know when they should.\n\n19\n00:02:38,331 --> 00:02:51,617\nAnd therefore, until we figure out some new technological advance that is not nearly critical in the next segment, as we sure hope that is, we need to anchor that on\n\n20\n00:03:00,169 --> 00:03:08,593\nSo we need to be able to move around our to-dos, right?\n\n21\n00:03:08,693 --> 00:03:19,259\nIt is insufficient to, as the current quote, agentic end quote things do, just take it step by step, right?\n\n22\n00:03:19,299 --> 00:03:22,761\nThe idea of a wonderful matter of research is laughable.\n\n23\n00:03:23,513 --> 00:03:33,619\nOoh, yes, we should have a note towards the problems of SDLCs and why that's such a problem for us.\n\n24\n00:03:43,626 --> 00:03:50,270\nBut this to-do list should first off\n\n25\n00:03:51,129 --> 00:03:57,711\nallow us to see what's in the context window and to see what we're working on.\n\n26\n00:03:58,631 --> 00:04:11,175\nBut the fundamental thing that these large language models don't have is the ability to forget, to judge that a certain line of thinking is bad, and to remove it.\n\n27\n00:04:11,275 --> 00:04:16,637\nBecause we know by virtue of how they work\n\n28\n00:04:20,465 --> 00:04:28,267\nthat these large language models will anchor on text in their context window.\n\n29\n00:04:31,527 --> 00:04:47,791\nWhich means that as they anchor on this text, if it's the wrong text, not only is it excluding\n\n30\n00:04:50,620 --> 00:05:15,998\ncontent that we want but it's biasing the output in ways that's not appropriate and so therefore when we build literature for our deep research we effectively need a an indication of what sources it has considered\n\n31\n00:05:17,515 --> 00:05:20,857\nwhat it's using, and more to the point, what it's disusing.\n\n32\n00:05:23,098 --> 00:05:45,769\nSo effectively, considering that we're playing the game of limited context windows, and it's hilarious that 200,000 tokens is limited, but what we're talking about, I've easily blown\n\n33\n00:05:46,559 --> 00:06:02,075\nthe context window out with trying to drop in nine papers so 200 000 tokens is not sufficient to do researching therefore we need a way of managing our tokens and\n\n34\n00:06:05,288 --> 00:06:08,211\nwhat this means, and we also need introspection.\n\n35\n00:06:08,331 --> 00:06:10,052\nWe need to be able to validate this.\n\n36\n00:06:10,673 --> 00:06:12,794\nWe need, ha, transparency.\n\n37\n00:06:13,275 --> 00:06:23,944\nNot merely in the encoded thoughts, but, okay, at this step, we have a... This paper...\n\n38\n00:06:25,262 --> 00:06:26,743\nwe are pulling these quotes from it.\n\n39\n00:06:26,843 --> 00:06:28,985\nHere is our summary and understanding.\n\n40\n00:06:29,465 --> 00:06:33,227\nHere is where in our document we should be using this paper.\n\n41\n00:06:33,868 --> 00:06:41,613\nWhen we get to this part of our document, load the entire paper into the context window for this paragraph, right?\n\n42\n00:06:42,153 --> 00:06:55,062\nAnd so this is why outlines are so useful, is because they allow us to go, ah, when we get to that part of the outline, when we get to that part of the mechanism, whatever, that's not the right word, but whatever,\n\n43\n00:06:56,417 --> 00:07:25,044\ngo change your context window your working context window to go spin off a line of thought or whatever to apply that paper to this paragraph within the context of the section and and the document and so we need but we also need human judgment right the first draft is always\n\n44\n00:07:28,084 --> 00:07:53,492\nthe first lines of research are seldom the most correct lines and so therefore these systems have to leverage human judgment and and not in the double confirm that deep research does right now right because deep research right now takes this takes the entire context window you push deep research\n\n45\n00:07:54,727 --> 00:07:58,688\nAnd then it crunches down what it thinks its task is.\n\n46\n00:08:00,469 --> 00:08:03,630\nAnd then you say, go, or you give it a bit of feedback and it goes.\n\n47\n00:08:04,970 --> 00:08:06,971\nThat's not what I'm talking about, right?\n\n48\n00:08:07,451 --> 00:08:08,952\nThis is not agentic.\n\n49\n00:08:09,112 --> 00:08:11,033\nIt is not goal following.\n\n50\n00:08:12,473 --> 00:08:14,914\nWe cannot treat it as goal following.\n\n51\n00:08:15,274 --> 00:08:18,015\nWe must treat it as a tool.\n\n52\n00:08:18,495 --> 00:08:19,435\nIt's just a tool.\n\n53\n00:08:19,875 --> 00:08:21,276\nIt is a tool that can be useful.\n\n54\n00:08:21,356 --> 00:08:22,696\nIt's a tool that can be thoughtful.\n\n55\n00:08:23,417 --> 00:08:24,337\nIt's just a tool.\n\n56\n00:08:25,253 --> 00:08:25,893\nTreat it that way.\n\n57\n00:08:31,196 --> 00:08:32,637\nDon't remember if I talked about deleting.\n\n58\n00:08:33,717 --> 00:08:35,238\nBut we also need tombstones.\n\n59\n00:08:35,278 --> 00:08:41,021\nWe need to have indications of thoughts that we've had that are bad.\n\n60\n00:08:42,081 --> 00:08:47,944\nAnd we have to be able to remove them, durably, from the context window.\n\n61\n00:08:48,225 --> 00:08:52,947\nBut we need to have proof that we've had this thought and chosen not to have it.\n\n62\n00:08:56,994 --> 00:09:01,916\nwhich is ironic, but whatever.\n\n63\n00:09:01,936 --> 00:09:02,016\nOkay.\n\n64\n00:09:10,579 --> 00:09:14,361\nWhat time is it?\n\n65\n00:09:17,462 --> 00:09:20,203\nI need to wrap up.\n\n66\n00:09:24,824 --> 00:09:25,865\nWe have outlined\n\n67\n00:09:26,636 --> 00:09:27,596\nWe have forgotten.\n\n68\n00:09:29,437 --> 00:09:30,758\nWe have user judgment.\n\n69\n00:09:30,898 --> 00:09:31,838\nAnd then we have...\n\n70\n00:10:15,687 --> 00:10:19,988\nAnd then we have different stages of interaction.\n\n71\n00:10:20,723 --> 00:10:34,230\nwhere finding the literature, extracting the literature, building the outline, building the first draft, revising the draft, editing, and then outputting should all be documented.\n\n72\n00:10:36,551 --> 00:10:46,836\nAnd so this is why we can't necessarily follow a waterfall SDLC when we're producing 10,000 word research reports.\n\n73\n00:10:47,817 --> 00:10:49,578\nWe have to consider\n\n74\n00:10:53,180 --> 00:11:20,529\ninstead that we have to treat each step in its own step that we need to have different mechanisms for keeping track of this information we need to choose which of these pots we're pulling from and at every stage we have to rely on human judgment knowing that the ai's judgment is deficient but more to the point not only is it deficient\n\n75\n00:11:21,147 --> 00:11:22,790\nit doesn't know that it's deficient.\n\n76\n00:11:22,830 --> 00:11:24,553\nIt doesn't know when to apply the judgment.\n\n"
        },
        {
          "file_name": "Epistemic \u2013 Monday at 8-50\u202fam (1).srt",
          "file_size": 18225,
          "file_type": "",
          "extracted_content": "1\n00:00:01,570 --> 00:00:25,962\nJudgment as epistemic humility, i.e., the ability to know when the relative epistemic quality of each of its... Blah, starting over.\n\n2\n00:00:26,322 --> 00:00:27,083\nOkay, so...\n\n3\n00:00:30,287 --> 00:00:32,909\nLarge language models lack judgment.\n\n4\n00:00:34,170 --> 00:00:45,080\nIn this case, we can model the judgment that they lack in three axes.\n\n5\n00:00:45,821 --> 00:00:54,929\nAnd to do note, cross-reference that student judge formalism paper that came out recently.\n\n6\n00:01:02,230 --> 00:01:02,870\nBrandon's not here.\n\n7\n00:01:03,070 --> 00:01:07,112\nSo, one, they lack epistemic humility.\n\n8\n00:01:07,972 --> 00:01:14,315\nSo, they don't have a sense... What am I saying?\n\n9\n00:01:14,415 --> 00:01:15,975\nThey don't have a sense of not knowing.\n\n10\n00:01:23,358 --> 00:01:23,658\nPause.\n\n11\n00:01:26,859 --> 00:01:27,580\nIs this still going?\n\n12\n00:01:29,900 --> 00:01:30,080\nYes.\n\n13\n00:01:30,441 --> 00:01:30,641\nOkay.\n\n14\n00:01:38,289 --> 00:01:49,094\nAnd so here, we can kind of talk about the problems of confabulations.\n\n15\n00:01:51,336 --> 00:01:56,338\nBecause, again, the issue is not the confabulation itself.\n\n16\n00:01:56,518 --> 00:02:01,041\nThis is, like, people are allowed to be wrong.\n\n17\n00:02:01,281 --> 00:02:01,521\nThey're\n\n18\n00:02:02,762 --> 00:02:11,164\nThere's nothing wrong... There's nothing wrong with being wrong.\n\n19\n00:02:17,986 --> 00:02:25,728\nThe epistemic humility action, or fraction of judgment, though, is the ability to doubt your own words.\n\n20\n00:02:27,889 --> 00:02:28,809\nNow, obviously...\n\n21\n00:02:31,386 --> 00:02:41,970\nas these things cannot elide their own context windows, which I'm actually kind of surprised hasn't come up, but whatever.\n\n22\n00:02:48,052 --> 00:02:51,894\nThis would need to be an intentional step.\n\n23\n00:02:53,034 --> 00:02:58,016\nThe problem is large language models\n\n24\n00:02:59,858 --> 00:03:29,066\nexhibit very poor epistemic humility on their own output and I describe this I describe this as a class just as they are bad at detecting their own output they're also bad\n\n25\n00:03:31,474 --> 00:03:34,936\nat calling doubt on their own output.\n\n26\n00:03:35,917 --> 00:03:58,730\nAnd again, with all of this, and again, with all of this, if a human has made the decision to prompt them to do this, the most likely outcome of this\n\n27\n00:04:03,953 --> 00:04:13,519\nThe most likely outcome is that they will perform an action that looks as if they are doing this.\n\n28\n00:04:15,460 --> 00:04:32,030\nWhen I say that they don't exhibit judgment, it is that the impulse to edit, the impulse to self critique,\n\n29\n00:04:37,881 --> 00:04:58,870\nWe'll just pause here.\n\n30\n00:05:00,111 --> 00:05:04,333\nThe impulse to judge, the impulse to self-critique does not...\n\n31\n00:05:08,954 --> 00:05:12,455\nis not a pattern exhibited in their training data.\n\n32\n00:05:13,816 --> 00:05:15,997\nAnd for obvious reasons.\n\n33\n00:05:17,217 --> 00:05:28,602\nPublished work doesn't have that thought pattern in it because it is the consequence of that thought pattern.\n\n34\n00:05:33,304 --> 00:05:36,185\nSome reference for episodic versus procedural memories.\n\n35\n00:05:39,514 --> 00:06:03,312\nAnd so... And even the, quote, reasoning, end quote, models... The way you reason on a problem is a different form of thinking than...\n\n36\n00:06:06,246 --> 00:06:17,611\nboth A, calling bullshit on yourself, but B, recognizing that impulse.\n\n37\n00:06:20,252 --> 00:06:31,938\nAnd so... And so when we talk about this\n\n38\n00:06:36,030 --> 00:07:02,938\nWhen we talk about this in terms of a failure of judgment, and then the subset of epistemic humility, it is both the lack of the impulse to self-critique and lack of the ability to self-critique.\n\n39\n00:07:15,816 --> 00:07:23,546\nAnd while asking a model to engage in proleptic reasoning, reference my recent paper to do,\n\n40\n00:07:31,653 --> 00:07:40,455\nProleptic reasoning is an argumentation approach if you already have sufficient epistemic grounding.\n\n41\n00:07:41,696 --> 00:07:51,298\nAnd it is identifying this precursorial, whatever that word, yeah, sure, why not, precursorial lack, precursor lack?\n\n42\n00:07:52,319 --> 00:07:52,939\nEh, one of them.\n\n43\n00:07:54,459 --> 00:07:57,300\nThat is the problem.\n\n44\n00:07:59,192 --> 00:08:02,553\nThe second problem is the lack of induction.\n\n45\n00:08:03,974 --> 00:08:14,318\nAnd again, O3 Mini High showed that it's better at pattern matching when prompted to do so.\n\n46\n00:08:18,920 --> 00:08:21,521\nMaybe have an appendix on Zendo, right?\n\n47\n00:08:22,382 --> 00:08:22,742\nBut like...\n\n48\n00:08:31,869 --> 00:08:39,535\nA lot of the point of induction is not, oh, I am going to try to perform induction right now.\n\n49\n00:08:40,536 --> 00:08:51,243\nIt is not a, for the vast majority of cases, specific intentional activity.\n\n50\n00:08:52,024 --> 00:08:55,487\nMore, it is that we can claim...\n\n51\n00:09:00,029 --> 00:09:28,176\nmore it is that we can claim that induction induction qua judgment that induction qua judgment is the precursor to common sense it is the it is the precursor to noticing that there is something in what you have produced because again\n\n52\n00:09:28,780 --> 00:09:36,185\nAll of this is in the context of producing the next token.\n\n53\n00:09:36,926 --> 00:09:39,167\nWe're not doing any theory of mind stuff here.\n\n54\n00:09:41,569 --> 00:09:53,417\nBut induction in this instance is the act of noticing that while one of the elements of what you've written looks plausible...\n\n55\n00:09:56,508 --> 00:10:04,694\nIt lacks coherency relative to what you have written.\n\n56\n00:10:05,955 --> 00:10:23,147\nIn terms of judgment and induction, induction is noticing the deviation from pattern and the impulse of inquiry for that deviation.\n\n57\n00:10:29,332 --> 00:10:35,237\nOkay, and now I have to scroll up in my transcript to figure out what the third category is.\n\n58\n00:10:50,068 --> 00:10:50,348\nAwesome.\n\n59\n00:10:50,508 --> 00:10:52,610\nI didn't actually say what the third category was.\n\n60\n00:10:53,710 --> 00:10:53,771\nUm...\n\n61\n00:10:56,912 --> 00:10:58,493\nLet's work this out from first principles.\n\n62\n00:10:58,553 --> 00:11:00,654\nSo we have epistemic humility.\n\n63\n00:11:01,655 --> 00:11:02,735\nWe have induction.\n\n64\n00:11:04,556 --> 00:11:18,424\nAnd... Yes, we can say here induction is the impulse precursor to common sense.\n\n65\n00:11:18,584 --> 00:11:25,568\nIt is the impulse noticing when something you've written doesn't follow a pattern.\n\n66\n00:11:27,082 --> 00:11:29,383\nor it doesn't follow the pattern of what the rest you've written.\n\n67\n00:11:39,087 --> 00:11:50,431\nWe can say that the third option here, or the third element of judgment as needed in LLMs\n\n68\n00:12:16,101 --> 00:12:20,309\nIronically, we could say something like agency.\n\n69\n00:12:21,091 --> 00:12:22,373\nWe can't say that.\n\n70\n00:12:22,574 --> 00:12:24,477\nThat word's overloaded in this context.\n\n71\n00:12:50,615 --> 00:12:54,677\nWe can kind of talk about Rumsfeld's epistemology here.\n\n72\n00:13:05,084 --> 00:13:12,368\nWe can kind of talk about Rumsfeld's epistemology here and talk about known unknowns and known knowns and so on and so forth.\n\n73\n00:13:17,751 --> 00:13:18,252\nAnd how...\n\n74\n00:13:34,594 --> 00:13:41,220\nAnd how epistemic humility is in many ways an acknowledgement of known unknowns.\n\n75\n00:13:51,228 --> 00:13:53,290\nBut the third aspect of judgment...\n\n76\n00:14:04,915 --> 00:14:22,867\nThe third aspect of judgment that even reasoning models are lacking... And we can't really say goal-checking, right?\n\n77\n00:14:27,069 --> 00:14:29,291\nWe can't make this a circular argument.\n\n78\n00:14:52,918 --> 00:14:54,719\nAll right, let's just work through this in a case study.\n\n79\n00:14:54,879 --> 00:15:04,743\nRight, so thinking out loud, they always give you an answer.\n\n80\n00:15:11,986 --> 00:15:19,529\nRight, so we can say they always give you an answer, and that answer is always presented as correct.\n\n81\n00:15:22,836 --> 00:15:26,138\nAnd we can say that that evinces a lack of epistemic humility.\n\n82\n00:15:39,946 --> 00:15:47,430\nAnd we can... And we can say that that evinces a lack of epistemic humility.\n\n83\n00:15:49,632 --> 00:15:49,892\nBut...\n\n84\n00:16:00,896 --> 00:16:03,077\nIt feels like there's a different category here.\n\n85\n00:16:07,878 --> 00:16:18,061\nIt feels like that that category is... Not just epistemic humility.\n\n86\n00:16:21,621 --> 00:16:24,222\nAh, prospective versus retrospective.\n\n87\n00:16:25,462 --> 00:16:26,223\nSo there is a...\n\n88\n00:16:29,321 --> 00:16:40,034\nA prospective epistemic humility, which is to say, I don't know enough to answer that question.\n\n89\n00:16:54,150 --> 00:17:10,203\nAnd then there's the faux humility that we see in reasoning models, especially in stuff like R1, where you have weight, but what about this, right?\n\n90\n00:17:10,403 --> 00:17:22,854\nAnd... We could say...\n\n91\n00:17:31,909 --> 00:17:38,355\nWe could say that that language of, well, what about this, displays epistemic humility.\n\n92\n00:17:51,467 --> 00:17:56,171\nBut I would actually assert that\n\n93\n00:17:59,016 --> 00:18:02,839\nThat performance of, well, what about that?\n\n94\n00:18:16,650 --> 00:18:21,533\nIs the pretense of epistemic humility rather than the fact of it.\n\n95\n00:18:22,954 --> 00:18:28,439\nBecause the thing is, when R1 is doing, well, what about X?\n\n96\n00:18:42,324 --> 00:18:57,548\nIt is effectively... It is effectively trying to cause itself to describe an option space of possible answers.\n\n97\n00:19:02,090 --> 00:19:02,370\nIt is...\n\n98\n00:19:05,640 --> 00:19:10,705\neffectively motivating a deductive reasoning process here.\n\n99\n00:19:11,425 --> 00:19:17,111\nAnd LLMs are entirely adequate at deductive reasoning, right?\n\n100\n00:19:17,131 --> 00:19:18,432\nThey can transform data.\n\n101\n00:19:19,573 --> 00:19:30,343\nThat if they have to motivate themselves to explore a decision tree or an option set with the performance of humility, sure, whatever.\n\n102\n00:19:58,482 --> 00:20:12,566\nBut the reason why it is the performance of epistemic humility and not actual epistemic humility is that process never, ever results in it saying, I don't know.\n\n103\n00:20:14,466 --> 00:20:16,767\nOr, I mean, look, and we can tone that down.\n\n104\n00:20:16,827 --> 00:20:22,409\nWe could say, oh, I don't have enough information to come to this conclusion.\n\n105\n00:20:22,989 --> 00:20:23,469\nIt never...\n\n106\n00:20:29,938 --> 00:20:34,461\nit never actually acts upon its notice of deficiencies.\n\n107\n00:20:35,501 --> 00:20:45,567\nIt always uses that language of, well, what about, to create more options, and those options can be contrary to the other options.\n\n108\n00:20:46,727 --> 00:20:56,713\nI have no fundamental issue with this performance of epistemic humility, just like it can engage in the performance of judgment.\n\n109\n00:21:09,017 --> 00:21:19,159\nBut within every single reasoning model, the reasoning will always produce an outcome.\n\n110\n00:21:24,041 --> 00:21:28,802\nWhich therefore leads us to our third category of correspondence with the real.\n\n111\n00:21:31,322 --> 00:21:37,444\nThis is effectively the gulf between Carnap and Popper.\n\n112\n00:21:39,117 --> 00:21:42,241\nOoh, I like this.\n\n113\n00:21:42,542 --> 00:21:45,185\nOkay, we want to promote this.\n\n114\n00:21:45,886 --> 00:21:51,472\nThat in many ways, reasoning models... Yes, okay, this works.\n\n115\n00:21:52,013 --> 00:21:55,718\nThat reasoning models aren't... Are...\n\n116\n00:22:01,024 --> 00:22:27,631\nthat reasoning models are effectively engaged in Carnapian confirmation, that they seek to argue themselves into a position where they collect evidence in the Carnapian fashion until some threshold, internal threshold, of truthiness is established.\n\n117\n00:22:28,886 --> 00:22:57,265\novercome and then they assert that that is the answer that when deep research is doing research it runs it runs research until some vibe of internal confirmation is passed the problem is and this is what we can see\n\n118\n00:22:58,795 --> 00:23:05,980\nUsing the Carnapian confirmation... Good, it is transcribed well.\n\n119\n00:23:06,020 --> 00:23:06,360\nHow novel.\n\n120\n00:23:07,240 --> 00:23:09,622\nThat using Carnapian confirmation, you can prove anything.\n\n121\n00:23:10,683 --> 00:23:14,345\nBecause all you have to do is accumulate evidence and...\n\n122\n00:23:16,380 --> 00:23:28,948\nin Carnapian Confirmation, there is nothing precluding the collection of alternative hypotheses, right?\n\n123\n00:23:29,009 --> 00:23:33,552\nYou're certainly allowed to have a bunch of things that you're collecting confirmation for.\n\n124\n00:23:33,572 --> 00:23:42,778\nAside, Claude, could you recommend a specific book to get a pithy quote about this Carnapian Confirmation from?\n\n125\n00:23:42,818 --> 00:23:43,458\nThat'd be great.\n\n126\n00:23:43,958 --> 00:23:44,459\nAnd aside,\n\n127\n00:23:54,151 --> 00:24:01,341\nBut these models never... These models never engage with the real.\n\n128\n00:24:15,441 --> 00:24:17,522\nThese models never engage with the real.\n\n129\n00:24:20,684 --> 00:24:23,046\nI mean, obviously, they're digital things.\n\n130\n00:24:24,367 --> 00:24:40,317\nBut they never... Besides saying, I don't know, they also never say, I can't know.\n\n131\n00:24:41,358 --> 00:24:43,159\nYes, okay, and this is the third category.\n\n132\n00:24:57,040 --> 00:25:06,004\nThat when we... When we...\n\n133\n00:25:25,060 --> 00:25:27,441\nIt is the phrase, the proof of the pudding is in the eating.\n\n134\n00:25:33,723 --> 00:25:36,043\nYes, it is the phrase, the proof of the pudding is in the eating.\n\n135\n00:25:37,404 --> 00:25:48,207\nIt is... When we are engaged in something that we are uncertain on, or more to the point...\n\n136\n00:25:50,245 --> 00:26:09,437\nwhen we judge that our knowledge of the thing is insufficient to epistemically differentiate between possible realities, we run experiments.\n\n137\n00:26:11,779 --> 00:26:14,000\nAnd this is the fundamental flaw of deep research.\n\n138\n00:26:14,220 --> 00:26:15,081\nIt's Aristotelian.\n\n139\n00:26:16,542 --> 00:26:17,242\nOoh, I like this.\n\n140\n00:26:17,322 --> 00:26:17,583\nOkay.\n\n141\n00:26:17,883 --> 00:26:18,683\nSo this is another one.\n\n142\n00:26:19,204 --> 00:26:19,444\nThat...\n\n143\n00:26:23,735 --> 00:26:34,780\nTo an AI, text and authority has primacy over reality.\n\n144\n00:26:36,641 --> 00:27:03,150\nI mean, it has to it's that's that's baked into the thing itself, which means that I love this AI is are fundamentally Aristotelian that we make arguments or sorry, the AI makes arguments by looking for authorities.\n\n145\n00:27:05,443 --> 00:27:18,332\nAnd this is mostly in deep research that we've noticed, that there's no real appeal to authority in, for example, the model Claude.\n\n146\n00:27:20,694 --> 00:27:23,796\nSorry, Claude, this is me talking about you, not to you.\n\n147\n00:27:24,517 --> 00:27:24,757\nYeah.\n\n148\n00:27:35,273 --> 00:27:55,847\nBut because it is fundamentally Aristotelian, a deep researching model will find its intuition of fact supported if it can find a source that supports that fact.\n\n149\n00:28:05,086 --> 00:28:25,096\nThis pattern of the primacy of source based on our evaluation of the source quality is not how\n\n150\n00:28:29,011 --> 00:28:43,201\ncurrent paradigms in the Kuhnian sense or research programs in the Lakotashian sense defend their theories.\n\n151\n00:28:47,744 --> 00:28:54,108\nI'd love to footnote that aside here, but I think we don't want to go too fil-sci here.\n\n152\n00:28:55,809 --> 00:28:56,349\nOkay, so...\n\n153\n00:29:02,830 --> 00:29:04,251\nNot sure if this is the third or fourth.\n\n154\n00:29:04,732 --> 00:29:07,674\nClaude, this is to you, the thing parsing this transcript.\n\n155\n00:29:09,616 --> 00:29:12,938\nFigure out if this is three or four different components.\n\n156\n00:29:14,700 --> 00:29:31,213\nBut... The failure of judgment here is...\n\n157\n00:29:37,370 --> 00:29:45,954\nIs the Aristotelian... Fallacy or paradigm... Work on it.\n\n158\n00:29:48,535 --> 00:30:00,020\nThat... If... An august source... Makes the claim... We don't have to investigate the claim.\n\n159\n00:30:01,901 --> 00:30:02,101\nRight?\n\n160\n00:30:02,482 --> 00:30:02,842\nAnd so...\n\n161\n00:30:08,416 --> 00:30:09,657\nthe fundamental thing here.\n\n162\n00:30:14,679 --> 00:30:15,540\nOh, I should pause.\n\n163\n00:30:20,842 --> 00:30:29,267\nSo to conclude, we can say that the Aristotelian fallacy is that the world doesn't matter.\n\n164\n00:30:31,248 --> 00:30:37,111\nThat an AI will never, ever\n\n165\n00:30:42,603 --> 00:30:46,524\nlook at its words and go, nah, those weren't good.\n\n166\n00:30:46,764 --> 00:30:49,045\nLet me throw them out instead of giving them to the user.\n\n167\n00:30:50,825 --> 00:30:55,567\nAnd it will never go, well, there are two possible courses of action here.\n\n168\n00:30:56,607 --> 00:31:02,069\nHere's what you should be looking for in the world to differentiate between them.\n\n169\n00:31:03,969 --> 00:31:06,990\nIt does sometimes say that there's two opposing sides.\n\n170\n00:31:08,658 --> 00:31:35,537\narguing authorities but again this is still the aristotelian issue is that we can we can acknowledge fighting authorities we just can't acknowledge an authority being wrong about the world unless it says so and so it will never say well go try this see if it works report back it will never say well i can't get that paper could you go get it for me\n\n171\n00:31:39,344 --> 00:31:53,135\nAnd so the flaw in judgment is that it always has to deliver a coherent and final answer.\n\n172\n00:31:54,690 --> 00:32:02,874\nAnd again, all of this can be circumvented if the human is injecting this into their prompts.\n\n173\n00:32:03,094 --> 00:32:08,097\nAnd so if we cause it, it can certainly perform all of these functions.\n\n174\n00:32:09,358 --> 00:32:17,522\nThe proof of this is not does it... Can it pretend... Can it have pretense to these functions?\n\n175\n00:32:18,703 --> 00:32:20,984\nThe basis of this is does it...\n\n176\n00:32:26,348 --> 00:32:29,589\ndoes it act this way in the absence of other stimuli?\n\n177\n00:32:30,589 --> 00:32:34,950\nAnd even if we push it, does it act appropriately?\n\n178\n00:32:39,271 --> 00:32:48,213\nBecause the problem is, is that in many of these tests, it can use the words of the thing\n\n179\n00:32:52,165 --> 00:32:54,972\nwithout engaging in the fact of the thing.\n\n180\n00:32:55,714 --> 00:32:57,258\nBut that's another discussion.\n\n"
        },
        {
          "file_name": "Friday at 6-19\u202fpm (1).srt",
          "file_size": 8943,
          "file_type": "",
          "extracted_content": "1\n00:00:11,067 --> 00:00:17,692\nI suppose I need to speak to the mundane utility section.\n\n2\n00:00:17,712 --> 00:00:20,515\nYeah, looks like it.\n\n3\n00:00:20,795 --> 00:00:20,995\nOkay.\n\n4\n00:00:33,055 --> 00:00:47,228\nSo if we're talking about use cases, I suppose the first place we need to be talking about is\n\n5\n00:01:11,158 --> 00:01:40,805\ndata collection um so this is this is specifically this is specifically based on the software apps run on 14th february\n\n6\n00:01:44,620 --> 00:02:07,472\nAnd so the SoftwareX run was the opposite of the Internet Archaeology one, right?\n\n7\n00:02:07,512 --> 00:02:07,792\nSo .\n\n8\n00:02:16,896 --> 00:02:20,338\nThe SoftwareX run was the opposite of the Internet Archaeology run.\n\n9\n00:02:20,878 --> 00:02:37,567\nSoftwareX has 30-odd volumes filled with people writing about the software tools, but very few of them are archaeology, historical science related.\n\n10\n00:02:39,228 --> 00:02:42,470\nTherefore, my task to it was\n\n11\n00:02:45,011 --> 00:02:54,339\ngo find all of the articles in this journal that relate to the big old tool net.\n\n12\n00:02:56,360 --> 00:03:08,450\nAnd to a first approximation, it did that.\n\n13\n00:03:13,655 --> 00:03:13,895\nBut\n\n14\n00:03:14,952 --> 00:03:32,439\nThe interesting thing here is it did that indirectly because those articles were not trivially visible because Elsevier blocked OpenAI's data router.\n\n15\n00:03:33,539 --> 00:03:40,542\nWe need a 2D here to compare against computer use.\n\n16\n00:03:42,803 --> 00:03:43,183\nAnd so\n\n17\n00:03:52,995 --> 00:04:01,318\nIt hit what seemed like a plausible set of articles, and even hit a plausible set of borderline articles.\n\n18\n00:04:06,760 --> 00:04:07,880\nI am not certain.\n\n19\n00:04:11,861 --> 00:04:18,283\nAnd quite frankly, this is a to do Sean to see what his double check\n\n20\n00:04:20,976 --> 00:04:44,348\nposture could show because because if this was um because if this was a useful series then in\n\n21\n00:04:52,925 --> 00:05:03,629\n20 arguments, three of which were accurate, who had a topic-specific reading history.\n\n22\n00:05:12,671 --> 00:05:20,514\nHowever, we must compare and contrast this with\n\n23\n00:05:22,032 --> 00:05:22,612\nJ.P.'\n\n24\n00:05:22,572 --> 00:05:32,258\n's experience looking for sustainability, like he probed that he could do better and find better on any of this.\n\n25\n00:05:39,483 --> 00:05:48,588\nBecause if we presume, if we presume this to be the case, where you say, okay, go find\n\n26\n00:05:52,196 --> 00:05:57,461\nAll articles from this journal are exactly like this one.\n\n27\n00:06:02,185 --> 00:06:17,318\nNow, the difference between this circle and Jericho's circle is, one, this was bounded.\n\n28\n00:06:25,757 --> 00:06:30,559\nand well-specified, and quite frankly, a relatively small literature.\n\n29\n00:06:42,785 --> 00:06:54,691\nWhich means that if somehow we can hook the computer up to a science, then we can use\n\n30\n00:06:58,507 --> 00:07:10,052\nfor women.\n\n31\n00:07:11,593 --> 00:07:26,060\nBecause the problem with getting a paper and then finding all papers that reference it, and all papers that reference it, under three generations, is that most of them\n\n32\n00:07:29,600 --> 00:07:40,547\nMost of them aren't on the research topic that we actually care about.\n\n33\n00:08:03,419 --> 00:08:16,972\nIf we get in a position... Obviously, all of this is calculated on open access papers, which are papers that are discriminated.\n\n34\n00:08:17,352 --> 00:08:27,442\nI'm noting that software X papers are open access, but because software X is not discoverable to open AI,\n\n35\n00:08:32,196 --> 00:08:37,299\nBut they are only discoverable through inference.\n\n36\n00:08:39,261 --> 00:08:44,464\nWhich is stupid, because if it's an open access paper, then whatever, it's not .\n\n37\n00:09:34,642 --> 00:09:34,922\nYes.\n\n38\n00:09:36,123 --> 00:09:59,845\nThe first place of actual utility to the academic or to the graduate student that deep research represents, certainly to a degree that a poetry supervisor or a research librarian supporting a cluster of poetry supervisors should get it, is in these last two paragraphs.\n\n39\n00:10:07,537 --> 00:10:16,080\nbecause going through every article of a journal and then does it in this way.\n\n40\n00:10:17,160 --> 00:10:26,823\nBut also needing to do the O3 definitions game beforehand, where you narrow down things and specify things.\n\n41\n00:10:37,288 --> 00:10:43,531\nis a useful document to the traditional digital scholar when his hands don't.\n\n42\n00:10:51,255 --> 00:10:59,960\nWe do, of course, need to compare and contrast operator and compare and contrast computer in this case.\n\n43\n00:11:00,760 --> 00:11:04,422\nBut this is the first place that we could be.\n\n44\n00:11:18,860 --> 00:11:30,566\nOnce we figured out the effective limit of the context window, um, um, of course it would be nice if there was feedback on this.\n\n45\n00:11:50,273 --> 00:11:53,275\nso that it can inform us of what we want to do.\n\n46\n00:11:58,779 --> 00:12:19,314\nOnce we've figured out how to prompt it for every article in a journal, I don't know, I don't know what, no.\n\n47\n00:12:20,060 --> 00:12:31,124\nLike, this sort of flexion, this sort of flexion iteration is useful to be able to cure you.\n\n48\n00:12:32,085 --> 00:12:39,547\nAnd we told it to get real data management policies for every university in Australia.\n\n49\n00:12:39,868 --> 00:12:42,268\nAnd, you know, it did 17 of 34.\n\n50\n00:12:44,569 --> 00:12:46,290\nWe don't know why it didn't do the other\n\n51\n00:12:51,977 --> 00:13:00,005\nAlthough I do know that 17 is awfully close to 20, so I suspect we need to do another\n\n52\n00:13:11,058 --> 00:13:25,792\nEspecially with editorial, where it can have an external state factor and not rely on its internal lives to know if it's done something.\n\n53\n00:13:33,740 --> 00:13:35,782\nThis sort of systematic is maybe\n\n54\n00:13:37,469 --> 00:13:41,472\nyou know, every single expense is actually super useful.\n\n55\n00:13:43,554 --> 00:13:55,402\nI think that we also need to highlight that the literature review mode, um, to do so, I'm going to get this thing back on the, on the, on the, on the side.\n\n56\n00:13:55,522 --> 00:14:04,009\nUm, the literature review mode actually\n\n57\n00:14:07,113 --> 00:14:22,899\nSure, we get a 10,000-word quote, medium essay in the part, and we'll be giving acknowledgments to Carly Richard for that analogy.\n\n58\n00:14:43,629 --> 00:15:00,135\nbut to put the dough food of your favorite and complain with ones about this paradigm is a shocker.\n\n59\n00:15:08,299 --> 00:15:11,620\nThis, of course, begs the question, given that\n\n60\n00:15:13,147 --> 00:15:19,252\nIs it not better to have them do something crazy about it?\n\n61\n00:15:58,709 --> 00:15:59,009\nNo.\n\n62\n00:16:02,891 --> 00:16:11,415\nWe want our PhD students to contribute novel insights.\n\n63\n00:16:15,137 --> 00:16:17,658\nWe must acknowledge that they have limited time.\n\n64\n00:16:19,559 --> 00:16:27,683\nTherefore, anyone saying, go read every book, is biocening the purpose\n\n65\n00:16:29,321 --> 00:16:35,422\nto what amounts to the known timing.\n\n66\n00:16:40,884 --> 00:16:54,667\nAnd especially to the non-timing of these assessors, those who are highly cited, etc., etc.\n\n67\n00:16:54,687 --> 00:16:57,748\nWe assert, therefore, that\n\n68\n00:17:01,247 --> 00:17:12,233\na PhD supervisor who says, okay, here's the 10 papers that Duke Research chose for you to read this week.\n\n69\n00:17:12,713 --> 00:17:13,033\nSure.\n\n70\n00:17:13,794 --> 00:17:16,275\nI mean, also, let's be specific.\n\n71\n00:17:16,375 --> 00:17:19,857\nHow many of our PhDs actually read all of Duke Research?\n\n72\n00:17:20,897 --> 00:17:29,002\nI would prefer\n\n73\n00:17:35,123 --> 00:17:40,426\nWhat this means is that we can get much brighter red.\n\n74\n00:17:46,049 --> 00:17:54,374\nBut we can use more papers and more journals that are more applicable to the basic area.\n\n75\n00:17:54,514 --> 00:18:01,438\nAnd then we can use conditional tools to find\n\n76\n00:18:03,154 --> 00:18:05,075\ncommon reference and so on and so forth.\n\n77\n00:18:05,515 --> 00:18:30,503\nAnd so, yeah, this should be part of a virtual supervisor's portfolio.\n\n78\n00:18:32,304 --> 00:19:00,769\nAnd then talking about Cohen's latest post, where he asserts that a third of the PhD should be about grading the output of AI, that for marginal papers, or for borderline papers, it is far more interesting for the PhD student to grade the output of models\n\n79\n00:19:01,949 --> 00:19:11,716\nand then to verify and cross-check the accurate models, then simply read it.\n\n80\n00:19:14,298 --> 00:19:14,859\nKind of fun.\n\n81\n00:19:17,401 --> 00:19:23,085\nActually, Claude, let me get to this.\n\n82\n00:19:23,285 --> 00:19:26,748\nCan you engage with some pro-reptic argumentation here?\n\n83\n00:19:26,908 --> 00:19:28,429\nI want to see the counter-proposals.\n\n84\n00:19:30,186 --> 00:19:35,168\nYeah.\n\n85\n00:19:36,728 --> 00:19:41,410\nBut I think that that is sufficient for effective use cases.\n\n86\n00:19:47,192 --> 00:19:49,533\nLet me see how you adjust for the other one.\n\n"
        },
        {
          "file_name": "Systems \u2013 Friday at 8-16\u202fam.srt",
          "file_size": 10964,
          "file_type": "",
          "extracted_content": "1\n00:00:02,409 --> 00:00:03,750\nOkey dokey.\n\n2\n00:00:19,861 --> 00:00:23,444\nDiscussion on agentic systems versus normal software.\n\n3\n00:00:31,633 --> 00:00:32,753\nThese systems claim.\n\n4\n00:00:52,342 --> 00:00:52,662\nOK.\n\n5\n00:00:54,483 --> 00:00:57,084\nThese systems claim to be agentic.\n\n6\n00:00:59,611 --> 00:01:01,632\nspecifically possessing agency.\n\n7\n00:01:11,277 --> 00:01:23,462\nIf we define possessing agency as the ability to do task decomposition, i.e.\n\n8\n00:01:24,863 --> 00:01:28,565\ntake a task, split it up into subtasks,\n\n9\n00:01:30,459 --> 00:01:46,092\nand figure out a route that could plausibly accomplish those subtasks, we could call these systems agentic.\n\n10\n00:01:48,033 --> 00:01:55,019\nHowever, however,\n\n11\n00:02:01,258 --> 00:02:21,531\nagency should not be viewed as a function of task following, but it should be viewed as a function of goal accomplishing.\n\n12\n00:02:21,551 --> 00:02:28,415\nThis distinction is important and nuanced.\n\n13\n00:02:30,851 --> 00:02:32,773\nThat'll be in italics.\n\n14\n00:02:34,654 --> 00:02:58,295\nBut... The subtask mechanism that has been popularized by things like Langchain... The subtask mechanism that has been popularized by things like Langchain...\n\n15\n00:03:13,202 --> 00:03:22,672\nthe reification of chain of thought in reasoning models,\n\n16\n00:03:27,017 --> 00:03:30,880\nWe can have other words for these things than agentic.\n\n17\n00:03:36,564 --> 00:03:41,148\nBecause my fundamental critique of the agentic definition is.\n\n18\n00:03:52,776 --> 00:03:54,578\nIf we claim a space.\n\n19\n00:03:55,151 --> 00:03:59,834\ndelineated by XML tags with think in it is reasoning.\n\n20\n00:04:02,275 --> 00:04:03,255\nSure, fine.\n\n21\n00:04:07,678 --> 00:04:11,600\nReasoning is a component of intelligence.\n\n22\n00:04:25,819 --> 00:04:43,749\nAnd the problem here is that if we are asserting components of intelligence stand in for the whole thing, then it's not going to work.\n\n23\n00:04:45,870 --> 00:04:47,051\nThat's messy, I don't like it.\n\n24\n00:04:47,191 --> 00:04:48,012\nAnyways, we'll figure it out.\n\n25\n00:05:34,540 --> 00:05:41,541\nSo if we assert that components of intelligence... No, all right, where was I?\n\n26\n00:05:41,661 --> 00:05:42,001\nOkay.\n\n27\n00:05:42,881 --> 00:06:03,065\nSo, from reasoning, where one of the primary benefits of a reasoning model is that it can cast doubt\n\n28\n00:06:06,872 --> 00:06:29,547\non its own chains of reasoning, which is working towards effective reasoning, we should not confuse\n\n29\n00:07:02,802 --> 00:07:23,319\nspecifically we can imagine a hierarchy of capabilities here that a task decomposing system excuse us\n\n30\n00:07:32,500 --> 00:07:36,522\nMa'am Please.\n\n31\n00:08:09,465 --> 00:08:14,187\nMove back, move back!\n\n32\n00:08:15,508 --> 00:08:16,028\nMove back!\n\n33\n00:08:16,728 --> 00:08:17,249\nMove back!\n\n34\n00:08:21,170 --> 00:08:23,031\nOkay, um, starting over.\n\n35\n00:08:23,491 --> 00:08:24,572\nArgentic systems.\n\n36\n00:08:26,213 --> 00:08:32,896\nRight-language models at present even with quote-reason and quote-capabilities are not Argentic systems.\n\n37\n00:08:36,037 --> 00:08:38,318\nBecause even though that they can perform\n\n38\n00:08:39,185 --> 00:09:08,463\na deductive task decomposition, the fact that they cannot effectively exercise judgment, specifically that they cannot they do not, as a matter of course, exercise judgment over what they have written, nor do they\n\n39\n00:09:15,353 --> 00:09:19,455\nnor are they able to assess the quality of their own inference.\n\n40\n00:09:21,116 --> 00:09:39,244\nWhat this means is that a large language model, when prompted to edit its own writing,\n\n41\n00:09:50,717 --> 00:09:55,399\nWe'll double down and intensify, but we'll never question the basic precepts.\n\n42\n00:09:58,901 --> 00:10:12,207\nWhen I talk about editing here, especially in the context of, quote, research and cook, I am not talking about the process by which we improve the tone or grammar of the output.\n\n43\n00:10:12,848 --> 00:10:17,570\nI'm talking about the question of, do we consider that this process is apt?\n\n44\n00:10:19,901 --> 00:10:40,428\nAnd so the decomposition shown by quote reasoning and quote models, shown by telling it to think step by step, showing it to say do functional decomposition, any one of these things is certainly a component of the research, of the process.\n\n45\n00:10:40,448 --> 00:10:42,029\nIt's a component of intelligence.\n\n46\n00:10:45,066 --> 00:11:00,452\nBut even if it's just a component of intelligence, calling these things agentic leaves us a very large gulf between agentic goal-following and goal-setting systems.\n\n47\n00:11:01,832 --> 00:11:11,796\nDespite claims by OpenAI that we can consider AGI a function of monetary output, which is a silly definition,\n\n48\n00:11:17,566 --> 00:11:35,419\nIf we say that in this hierarchy, task decomposition to reasoning, reasoning to go following, claiming\n\n49\n00:12:21,365 --> 00:12:25,111\nclaiming that a agentic system\n\n50\n00:12:46,306 --> 00:12:55,972\nmay either act as our agent or act as something with agency, noting that those are two very, very different things.\n\n51\n00:12:57,593 --> 00:13:06,799\nBoth of them require the system to have the capability of exploring if the\n\n52\n00:13:09,193 --> 00:13:16,975\ngoal which has been set by external agency has been accomplished and if it has been accomplished well.\n\n53\n00:13:20,436 --> 00:13:35,320\nWe must differentiate goal accomplishment with the basic QA processes of anthropics computer use checking a screenshot for the output of one of its commands.\n\n54\n00:13:36,974 --> 00:13:55,200\nHere, we are not talking principally about the observe-orient parts of Colonel Boyd's OODA review.\n\n55\n00:13:55,220 --> 00:13:59,942\nBut even in that most simplistic, most simple task,\n\n56\n00:14:05,373 --> 00:14:22,776\nThe causal error is the first, where the system decides on the rightness of a task, clicks on a thing, and then justifies itself.\n\n57\n00:14:29,238 --> 00:14:31,478\nThis causal error is not\n\n58\n00:14:32,944 --> 00:14:52,275\nagency, nor is it deciding, nor is it able to make an appropriate judgment call if it is proceeded towards its goal.\n\n59\n00:14:52,995 --> 00:14:56,477\nIt is able to say whether or not it has proceeded\n\n60\n00:14:57,341 --> 00:15:04,465\ntowards what it thinks its steps are, but it is not able to situate itself effectively in reality.\n\n61\n00:15:05,225 --> 00:15:25,276\nAnd its lack of situation means that it cannot perform as our agent, nor does it have self-agency in determining how to accomplish, accomplishing, and then assessing if a task has been accomplished.\n\n62\n00:15:27,006 --> 00:15:32,989\nTherefore, it is inappropriate to call our current infrastructure agentic.\n\n63\n00:15:35,231 --> 00:15:56,182\nAnd therefore, we can say that a GI is, amongst other qualities not articulated here, necessarily goal setting as well as goal following.\n\n64\n00:16:12,441 --> 00:16:24,444\nI would note, however, that an effective goal following system would likely be capable of accomplishing the monetary gains that Microsoft has set as their definition of AGI.\n\n65\n00:16:29,460 --> 00:16:31,862\nsimply by process of adding more computers.\n\n66\n00:16:35,025 --> 00:16:58,344\nAnd so, therefore, our philosophical basis and our philosophical definitions should be considered a completely disjunct ontology from those\n\n67\n00:16:59,400 --> 00:17:07,946\nbeing peddled by Silicon Valley.\n\n68\n00:17:12,989 --> 00:17:27,218\nTo say this again, for deep research to in fact be a useful research assistant, it needs a number of components.\n\n69\n00:17:29,181 --> 00:17:46,146\nThe first and fundamental is the ability to figure out what the research questions are within the prompt.\n\n70\n00:17:47,106 --> 00:17:55,369\nSo, not what the prompt's questions are, but what the fundamental research questions implied by the prompt such that research can be done.\n\n71\n00:17:56,992 --> 00:18:19,263\nnoting that a literature review, if done well, is a persuasive document which situates a text in a literature, identifies the research questions, identifies the context in which the research questions will be answered, and most importantly, identifies the gaps.\n\n72\n00:18:20,583 --> 00:18:26,006\nThis requires epistemic humility that these systems flatly do not exhibit.\n\n73\n00:18:26,980 --> 00:18:34,404\nThey can certainly play at it, but then playing at epistemic humility is not in fact the same as them having it.\n\n74\n00:18:36,124 --> 00:18:39,286\nThe performance of a virtue is not having the virtue.\n\n75\n00:18:42,487 --> 00:18:45,689\nWhich is kind of the whole problem with large language models.\n\n76\n00:18:47,430 --> 00:18:47,650\nSo,\n\n77\n00:18:54,540 --> 00:19:22,638\nThe first component is for them to look at any stage of output and decide if that stage of output, again, to have judgment, to induce from data the general pattern, they must decide if that output is appropriate within the implied tacit context\n\n78\n00:19:23,582 --> 00:19:25,703\nof the querent's questions.\n\n79\n00:19:29,045 --> 00:19:40,432\nIf a system, if deep research cannot return, if any deep research cannot return, huh, I seem to have gone down a blind alley.\n\n80\n00:19:42,233 --> 00:19:46,636\nCan you help clarify some things that I'm confused about so that I can search again?\n\n81\n00:19:48,317 --> 00:19:49,297\nIt's not deep research.\n\n82\n00:19:49,417 --> 00:19:51,859\nAnd now, let me be super clear here.\n\n83\n00:19:54,207 --> 00:19:58,611\nWe are not saying that it was unable to find things.\n\n84\n00:20:00,552 --> 00:20:03,955\nWe are not saying, oh, I didn't get any search results.\n\n85\n00:20:04,976 --> 00:20:07,298\nHey, user, your query is bad.\n\n86\n00:20:08,859 --> 00:20:15,304\nI'm saying the assumptions that I made in my searching were incorrect.\n\n87\n00:20:17,046 --> 00:20:19,408\nSelf-criticality here is essential.\n\n88\n00:20:26,627 --> 00:20:34,690\nalong that line of self-criticality, we must then look at editing.\n\n89\n00:20:36,190 --> 00:20:55,776\nAnd so when these systems engage in... And so just as a large language model should be able to assess whether or not its output has wandered into a blind alley,\n\n90\n00:20:57,995 --> 00:21:19,674\nand have sufficient epistemic humility to ask the user for guidance, so too must it be able to forget.\n\n91\n00:21:23,117 --> 00:21:25,519\nIn observation of deep researches,\n\n92\n00:21:28,254 --> 00:21:28,595\nThank you.\n\n93\n00:22:05,262 --> 00:22:09,025\nIt certainly articulates many blind alleys.\n\n94\n00:22:13,989 --> 00:22:23,757\nThe problem is that its investigation of these blind alleys corrupt the working context.\n\n95\n00:22:25,458 --> 00:22:26,319\nIf it cannot,\n\n96\n00:22:39,904 --> 00:23:09,291\nif it cannot go through its own context, elide its own context, and leave tombstones for its decisions, then it cannot perform good research.\n\n97\n00:23:20,928 --> 00:23:44,035\nLast and pragmatically most important is that deep research, all of these deep researches, that all of these deep researches need to be able to work on user-provided documents with a larger context.\n\n"
        },
        {
          "file_name": "Thursday at 8-36\u202fam.srt",
          "file_size": 6851,
          "file_type": "",
          "extracted_content": "1\n00:00:01,368 --> 00:00:02,309\nSound check, sound check.\n\n2\n00:00:03,310 --> 00:00:04,551\nSound check, sound check.\n\n3\n00:00:09,636 --> 00:00:10,077\nOh well.\n\n4\n00:00:12,399 --> 00:00:12,860\nOkay.\n\n5\n00:00:36,726 --> 00:00:39,907\nSo, observations of deep research.\n\n6\n00:00:46,111 --> 00:01:01,140\nOkay, so... Anthropics computer use.\n\n7\n00:01:06,058 --> 00:01:12,319\nwas about 80% of the way to a work of the prototype.\n\n8\n00:01:19,241 --> 00:01:33,964\nIt simply was too expensive for its capabilities.\n\n9\n00:01:38,408 --> 00:02:07,439\nwas an exceptionally disappointing experiment again talking about the capabilities of their algorithms like setting apart everything else setting apart their problematic alliance and semantic scholar and so on so forth so\n\n10\n00:02:11,078 --> 00:02:29,724\nThe largest specific fundamental flaw of all of these systems is their corpus.\n\n11\n00:02:33,626 --> 00:02:34,166\nIs their corpus.\n\n12\n00:02:46,024 --> 00:02:57,729\nFor deep research, the internet archaeology iterator seemed quite promising.\n\n13\n00:03:03,571 --> 00:03:15,216\nAlthough the frequent cajoling to be systematic really started showing the scene.\n\n14\n00:03:17,401 --> 00:03:43,998\nHowever, it was the exploration of the Journal of Open Source Software that really demonstrated the fundamental flaws of the system.\n\n15\n00:03:45,279 --> 00:03:45,659\nBecause\n\n16\n00:03:47,008 --> 00:03:47,628\nHere's the thing.\n\n17\n00:03:50,749 --> 00:03:52,890\nCorpuses can be fixed, right?\n\n18\n00:03:53,170 --> 00:03:55,591\nCorpus access can be fixed.\n\n19\n00:04:01,134 --> 00:04:11,978\nThe fundamental lack of systemization, even when explicitly instructed to,\n\n20\n00:04:15,382 --> 00:04:40,042\nprobably as a function of some of the back end prompting that OpenAI has added.\n\n21\n00:04:43,832 --> 00:05:06,501\nmeans that it simply will not work down a list of sources which are open right this is a list of sources that was found by deep research they're all the same journal they are all well formatted\n\n22\n00:05:13,283 --> 00:05:30,584\nAnd so therefore, this fundamental flaw of the lack of systemization\n\n23\n00:05:40,100 --> 00:05:55,803\nshows that Duke research is not present at the level of a research assistant.\n\n24\n00:05:58,483 --> 00:06:08,725\nI will also note that there are some really interesting introduced biases from\n\n25\n00:06:10,549 --> 00:06:13,171\nOpenAI's, quote, policies, end quote.\n\n26\n00:06:15,072 --> 00:06:25,998\nThat when it is thinking, especially as when it is mulling over the policies, the text of the policies infects the output.\n\n27\n00:06:27,218 --> 00:06:37,764\nSo as an aside, I was transcribing a recent presentation of mine about AI, and OpenAI\n\n28\n00:06:45,683 --> 00:07:08,417\nquite clearly took text from one of the policies and put it in replace in in um well not my instance is that openai took the place of one of the policies\n\n29\n00:07:11,918 --> 00:07:25,906\nand replace it with one of my questions.\n\n30\n00:07:27,187 --> 00:07:39,214\nAnd so the problem is, again and again, because we don't have a separation of concerns,\n\n31\n00:07:43,624 --> 00:07:44,525\nAnd because.\n\n32\n00:07:52,430 --> 00:07:52,611\nAll of.\n\n33\n00:08:15,794 --> 00:08:18,215\nSo because we don't have a separation of concerns.\n\n34\n00:08:42,144 --> 00:08:44,345\nSo because we don't have a separation of concerns.\n\n35\n00:08:54,602 --> 00:09:21,870\nBecause we don't have thread and thread processing, the current mechanisms of deep research are fundamentally different.\n\n36\n00:09:39,168 --> 00:09:56,911\nAnd an interesting deviation from Claude, getting O1 to work on its own prompts does not, in fact, improve output quality.\n\n37\n00:09:58,591 --> 00:10:02,112\nIt has a very bad estimation.\n\n38\n00:10:05,074 --> 00:10:06,354\nof its own alphabet.\n\n39\n00:10:11,796 --> 00:10:29,421\nAnd so, while\n\n40\n00:10:46,878 --> 00:10:47,198\nAnd so...\n\n41\n00:11:32,936 --> 00:12:00,804\nwhile we have these things, and while I assert that 01 and 03, many are, represent a difference in degree and in time,\n\n42\n00:12:07,202 --> 00:12:33,770\nfrom prior models, such that the way I interact with them has become a function of the way I would interact with PhD students.\n\n43\n00:12:49,591 --> 00:13:09,544\nThe fundamental limitations, especially the frequent invocations to the spirits to think harder, which, as an aside, made me feel like a Doc Smith character.\n\n44\n00:13:19,838 --> 00:13:32,209\nsuggest that these models still lack the judgment and these models still lack the insight to know when they have done a good job.\n\n45\n00:14:01,822 --> 00:14:07,644\nSo, what would we need in a system for it to\n\n46\n00:14:35,421 --> 00:14:36,314\nWhat improvement scheme?\n\n47\n00:15:10,061 --> 00:15:10,422\nThank you.\n\n48\n00:15:44,158 --> 00:16:10,223\nFirst and fundamentally, for deep research to be effective, it cannot have a single train of thought.\n\n49\n00:16:10,243 --> 00:16:13,464\nFor deep research to be effective, it cannot have a single train of thought.\n\n50\n00:16:14,744 --> 00:16:24,150\nThe... Pious asides to opening AI policy.\n\n51\n00:16:24,930 --> 00:16:30,774\nThe... Oh, I wonder if I should go investigate this.\n\n52\n00:16:32,715 --> 00:16:35,897\nThe limited context window of 200,000 tokens.\n\n53\n00:16:47,793 --> 00:16:48,393\ndoes not.\n\n54\n00:17:13,029 --> 00:17:15,691\nIt needs multiple supervisory threats.\n\n55\n00:17:20,510 --> 00:17:30,877\nIf policy enforcement is the deal that it is, which is fine, it needs a supervisory thread to review and edit.\n\n56\n00:17:33,079 --> 00:17:42,165\nIt needs an intrusive thought thread for when it's looking for validation.\n\n57\n00:17:43,666 --> 00:17:50,011\nAnd the validation should not be wholly contained in context window\n\n58\n00:17:51,328 --> 00:17:54,590\nBut instead, the validation should be\n\n59\n00:18:50,186 --> 00:19:13,688\ninstead the validation should be threaded out, then there needs to be a corpus where\n\n60\n00:19:27,811 --> 00:19:54,174\nunder the context of going to find things, it needs to be to build a document store\n\n61\n00:19:58,894 --> 00:20:18,001\nwhere it can collect and build a corpus without necessarily all of that corpus living in the context window at any given time.\n\n62\n00:20:19,201 --> 00:20:25,924\nWe need to be able to inspect that corpus in a much better\n\n63\n00:20:27,609 --> 00:20:34,725\nthen train the clock mode and\n\n64\n00:21:08,928 --> 00:21:34,206\nAnd fundamentally, it needs to figure out when its first draft is unacceptable and when it needs more reason.\n\n65\n00:21:39,827 --> 00:21:48,792\nBut it also needs to be able to indicate sources in its corpus should not be considered for a draft.\n\n66\n00:21:49,912 --> 00:21:51,113\nIt needs more structure.\n\n67\n00:21:51,453 --> 00:21:54,214\nIt needs to be able to make outlines and write to the outlines.\n\n68\n00:21:55,275 --> 00:21:57,416\nIt needs to have an obvious edging pass.\n\n69\n00:22:03,959 --> 00:22:04,920\nIt needs to be a real board.\n\n"
        },
        {
          "file_name": "Tuesday at 8-36\u202fam.srt",
          "file_size": 5142,
          "file_type": "",
          "extracted_content": "1\n00:00:06,719 --> 00:00:06,781\nBye.\n\n2\n00:01:15,304 --> 00:01:38,409\nat current capabilities as of february 2025 the tool using but not agentic deep research and its clones by perplexity and hugging face\n\n3\n00:01:42,150 --> 00:01:47,634\nare deeply flawed, deeply impressive tech demos.\n\n4\n00:01:56,762 --> 00:02:09,072\nIn this paper, we will discuss why we believe that the term agentic does not appropriately apply\n\n5\n00:02:09,952 --> 00:02:36,762\nto these tools, save as the term marketing, and why we believe that these tools represent a difference in degree and in kind, much like\n\n6\n00:02:38,002 --> 00:02:42,106\nthe technical demo of Bing Sydney in February 2023.\n\n7\n00:02:51,975 --> 00:03:03,026\nTo be clear, these tools have the capabilities to genuinely assist researchers in research so long\n\n8\n00:03:05,427 --> 00:03:13,135\nAs said, researchers do not believe any of the marketing hype of the companies that produce them.\n\n9\n00:03:14,396 --> 00:03:29,351\nBy default, the literature reviews, in quotes, produced by these tools are descriptive, superficial, and fundamentally misdefendant.\n\n10\n00:03:34,477 --> 00:03:43,464\nTo remind ourselves of methods classes, the point of literature review is effectively to do two things.\n\n11\n00:03:44,505 --> 00:03:51,010\nOne, it is to situate the research within a specific and known scholarship.\n\n12\n00:03:51,030 --> 00:03:53,191\nThis is both\n\n13\n00:04:05,296 --> 00:04:09,639\nThis is both an argument by authority, i.e.\n\n14\n00:04:10,079 --> 00:04:17,723\nthese other scholars have investigated the same thing, have engaged in the same thing, therefore this is an appropriate thing for me to be doing.\n\n15\n00:04:21,685 --> 00:04:29,529\nAs it is a claim to disciplinarity, the way I will be investigating it is this.\n\n16\n00:04:30,396 --> 00:04:47,087\nThe research program in the Wakatoshian sense, with its concomitant hard core and soft outer belt, is that all of these things are accomplished by the first prong of the literature review.\n\n17\n00:04:55,053 --> 00:05:00,016\nThe second prong of literature review is\n\n18\n00:05:02,105 --> 00:05:08,709\nInformally speaking, why do we care?\n\n19\n00:05:10,070 --> 00:05:11,611\nOr, why do we care?\n\n20\n00:05:30,305 --> 00:05:31,806\nWhere is the gap in literature?\n\n21\n00:05:31,946 --> 00:05:34,288\nWhy has this question not already been answered?\n\n22\n00:05:36,570 --> 00:05:39,592\nOr, again, where's the novelty?\n\n23\n00:05:46,058 --> 00:05:50,141\nThe fundamental requirement of both of these prongs\n\n24\n00:05:59,171 --> 00:06:02,012\nAnd to be clear, this can happen at any length, right?\n\n25\n00:06:02,052 --> 00:06:04,292\nWe can talk about the systematic review.\n\n26\n00:06:04,332 --> 00:06:08,273\nWe can talk about a PhD's literature review.\n\n27\n00:06:08,313 --> 00:06:17,516\nWe can talk about the page or two most papers leave to the situating.\n\n28\n00:06:17,716 --> 00:06:17,796\nBut\n\n29\n00:06:38,610 --> 00:06:49,858\nA good literature review, good research in this wise, tells a story.\n\n30\n00:06:53,000 --> 00:07:00,805\nIt tells the story, it tells a persuasive story of why should the reader care?\n\n31\n00:07:05,993 --> 00:07:08,034\nThe reader should care because it's in their discipline.\n\n32\n00:07:08,074 --> 00:07:12,115\nThe reader should care because it extends prior research that they're interested in.\n\n33\n00:07:12,535 --> 00:07:18,977\nThe reader should care because it identifies and then addresses, sometimes, a gap in the literature.\n\n34\n00:07:26,039 --> 00:07:28,740\nThis requires judgment.\n\n35\n00:07:33,402 --> 00:07:34,502\nIt is insufficient\n\n36\n00:07:36,371 --> 00:07:40,835\nto merely describe what papers have said.\n\n37\n00:07:44,017 --> 00:07:53,364\nA literature review is not a descriptive summarization of literature.\n\n38\n00:07:55,346 --> 00:08:04,413\nA literature review is the process by which\n\n39\n00:08:07,438 --> 00:08:12,120\nResearchers build a case for why this question should be answered.\n\n40\n00:08:12,280 --> 00:08:24,525\nNow, can we say that a descriptive literature review is appropriate for other fields?\n\n41\n00:08:25,685 --> 00:08:25,805\nNo.\n\n42\n00:08:39,894 --> 00:08:40,297\nOh my God.\n\n43\n00:09:13,006 --> 00:09:13,487\nStrike back.\n\n44\n00:09:59,405 --> 00:09:59,509\nAmen.\n\n45\n00:10:25,576 --> 00:10:29,719\nThese tools are called brief research in all their various levels.\n\n46\n00:10:32,020 --> 00:10:39,225\nThe implication of these tools, or the default output of these tools, is the report, and that is not appropriate.\n\n47\n00:10:45,789 --> 00:10:52,574\nIt does not sufficiently address conflicting contexts.\n\n48\n00:10:52,794 --> 00:10:54,655\nIt does not sufficiently address\n\n49\n00:10:55,757 --> 00:10:58,518\ncontradictions, just said that, choose whatever is better.\n\n50\n00:11:10,424 --> 00:11:13,626\nBut these tools can go search the web.\n\n51\n00:11:21,069 --> 00:11:25,011\nAnd so long as you do not ask them for directions,\n\n52\n00:11:25,541 --> 00:11:55,053\ni.e., producing the literature, producing the literature review, they can be quite effective at the tasks of extremely tedious drudgery, so long as those tasks of extremely tedious drudgery\n\n53\n00:11:58,925 --> 00:12:01,504\nare findable on the open sea.\n\n"
        }
      ],
      "files": [
        {
          "file_name": "Context \u2013 Friday at 8-47\u202fam (1).srt"
        },
        {
          "file_name": "Epistemic \u2013 Monday at 8-50\u202fam (1).srt"
        },
        {
          "file_name": "Friday at 6-19\u202fpm (1).srt"
        },
        {
          "file_name": "Systems \u2013 Friday at 8-16\u202fam.srt"
        },
        {
          "file_name": "Thursday at 8-36\u202fam.srt"
        },
        {
          "file_name": "Tuesday at 8-36\u202fam.srt"
        }
      ]
    },
    {
      "uuid": "208a63f7-2689-41a4-8281-f2fa12e11bb3",
      "text": "\nI'll go through each transcript in the order you specified, clean them up, and extract the salient points while removing any crosstalk or unclear content. Let me work through them systematically.\n\n1. Context \u2013 Friday at 8-47 am (1).srt\n2. Friday at 6-19 pm (1).srt\n3. Epistemic \u2013 Monday at 8-50 am (1).srt\n4. Thursday at 8-36 am.srt\n5. Tuesday at 8-36 am.srt\n6. Systems \u2013 Friday at 8-16 am.srt\n\nLet me start with the first transcript.\n\n**Context \u2013 Friday at 8-47 am (1).srt**\n\nThis transcript discusses what's needed in a tool that genuinely does research. The key points include:\n- Need for a cursored to-do list\n- Active monitoring of each step in the to-do list\n- Getting user judgment as to correctness\n- LLMs lack self-criticism and judgment\n- Need to see what's in the context window\n- Need for transparency\n- Ability to forget/remove bad lines of thinking\n- Need for tombstones (indications of thoughts that were bad)\n- Different stages of interaction (finding literature, extracting literature, building outline, etc.)\n- Cannot follow a waterfall SDLC for research reports\n- Relying on human judgment because AI's judgment is deficient\n\nNow for the second transcript.\n\n**Friday at 6-19 pm (1).srt**\n\nThis transcript discusses use cases and mundane utility. Key points:\n- Data collection as a specific use case\n- SoftwareX run vs Internet Archaeology run\n- Using AI to find articles in journals related to specific topics\n- Comparison with computer use\n- PhD students' research process\n- Using AI for systematic data collection\n- Literature review capabilities\n- PhD supervisor applications\n\nFor the third transcript:\n\n**Epistemic \u2013 Monday at 8-50 am (1).srt**\n\nThis transcript discusses the judgment that LLMs lack, categorized along three axes:\n1. Epistemic humility - the ability to doubt one's own words, detect one's own output, call doubt on one's own output\n2. Lack of induction - the precursor to common sense, the ability to notice when something written doesn't follow a pattern\n3. Correspondence with the real - the distinction between Carnap and Popper, AI engages in Carnapian confirmation rather than testing against reality\n- Discussion of reasoning models that present a pretense of epistemic humility\n- AI's Aristotelian nature - text and authority having primacy over reality\n- AI's inability to look at its words and say they're not good\n\nFor the fourth transcript:\n\n**Thursday at 8-36 am.srt**\n\nThis transcript discusses observations about deep research:\n- Anthropic's computer use was 80% of the way to a prototype but too expensive\n- Elicit was disappointing\n- Fundamental flaw of systems is their corpus\n- Internet archaeology iterator seemed promising\n- Lack of systemization even when explicitly instructed\n- Will not work down a list of sources\n- Not at the level of a research assistant\n- Biases from OpenAI's policies\n- Need for multiple supervisory threads\n- Need for validation outside the context window\n- Need to build a document store\n- Need to recognize when first draft is unacceptable\n\nFor the fifth transcript:\n\n**Tuesday at 8-36 am.srt**\n\nThis transcript discusses why deep research tools are not truly agentic:\n- Deep research and clones are deeply flawed but impressive tech demos\n- \"Agentic\" is more marketing than accurate description\n- These tools can assist researchers if researchers don't believe the marketing hype\n- Literature reviews produced are descriptive, superficial, and misrepresentative\n- Two-pronged purpose of literature review:\n  1. Situate research within specific scholarship\n  2. Address why readers should care/identify gaps in literature\n- A good literature review tells a persuasive story\n- This requires judgment\n- These tools produce reports rather than proper literature reviews\n\nFor the sixth transcript:\n\n**Systems \u2013 Friday at 8-16 am.srt**\n\nThis transcript discusses agentic systems versus normal software:\n- Systems claim to be agentic\n- Agency defined as task decomposition\n- Agency should be viewed as goal accomplishing not task following\n- LLMs even with reasoning capabilities are not agentic systems\n- Although they can perform deductive task decomposition, they cannot exercise judgment\n- Cannot assess quality of their own inference\n- Will double down but never question basic precepts\n- There's a large gulf between agentic goal-following and goal-setting systems\n- Agentic systems require the capability of exploring if a goal has been accomplished\n- Current infrastructure is not truly agentic\n- AGI would be goal setting as well as goal following\n\nThese transcripts contain significant overlap in themes around the limitations of AI in research, particularly around judgment, assessment of their own output, and their inability to produce truly insightful research products.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\nI've cleaned up your dictated transcripts and organized them into a cohesive document that follows the structure of your paper on AI's limitations in research. The cleaned content removes crosstalk, fixes garbled segments, and organizes your thoughts thematically.\n\nLooking through the transcripts, I've identified several key sections:\n\n1. Paper structure and requirements for research tools\n2. Mundane utility and practical applications \n3. Three types of judgment deficiencies in AI (epistemic humility, induction, correspondence with reality)\n4. Observations on current Deep Research implementations\n5. Analysis of AI's literature review capabilities\n6. Framework for understanding true agency versus current capabilities\n\nIs there any specific section where you'd like me to elaborate or where you think I might have misinterpreted your dictation? I can also help you integrate these cleaned insights into your existing paper draft.",
      "content": [
        {
          "start_timestamp": "2025-03-08T04:18:10.589290Z",
          "stop_timestamp": "2025-03-08T04:18:36.758234Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nI'll go through each transcript in the order you specified, clean them up, and extract the salient points while removing any crosstalk or unclear content. Let me work through them systematically.\n\n1. Context \u2013 Friday at 8-47 am (1).srt\n2. Friday at 6-19 pm (1).srt\n3. Epistemic \u2013 Monday at 8-50 am (1).srt\n4. Thursday at 8-36 am.srt\n5. Tuesday at 8-36 am.srt\n6. Systems \u2013 Friday at 8-16 am.srt\n\nLet me start with the first transcript.\n\n**Context \u2013 Friday at 8-47 am (1).srt**\n\nThis transcript discusses what's needed in a tool that genuinely does research. The key points include:\n- Need for a cursored to-do list\n- Active monitoring of each step in the to-do list\n- Getting user judgment as to correctness\n- LLMs lack self-criticism and judgment\n- Need to see what's in the context window\n- Need for transparency\n- Ability to forget/remove bad lines of thinking\n- Need for tombstones (indications of thoughts that were bad)\n- Different stages of interaction (finding literature, extracting literature, building outline, etc.)\n- Cannot follow a waterfall SDLC for research reports\n- Relying on human judgment because AI's judgment is deficient\n\nNow for the second transcript.\n\n**Friday at 6-19 pm (1).srt**\n\nThis transcript discusses use cases and mundane utility. Key points:\n- Data collection as a specific use case\n- SoftwareX run vs Internet Archaeology run\n- Using AI to find articles in journals related to specific topics\n- Comparison with computer use\n- PhD students' research process\n- Using AI for systematic data collection\n- Literature review capabilities\n- PhD supervisor applications\n\nFor the third transcript:\n\n**Epistemic \u2013 Monday at 8-50 am (1).srt**\n\nThis transcript discusses the judgment that LLMs lack, categorized along three axes:\n1. Epistemic humility - the ability to doubt one's own words, detect one's own output, call doubt on one's own output\n2. Lack of induction - the precursor to common sense, the ability to notice when something written doesn't follow a pattern\n3. Correspondence with the real - the distinction between Carnap and Popper, AI engages in Carnapian confirmation rather than testing against reality\n- Discussion of reasoning models that present a pretense of epistemic humility\n- AI's Aristotelian nature - text and authority having primacy over reality\n- AI's inability to look at its words and say they're not good\n\nFor the fourth transcript:\n\n**Thursday at 8-36 am.srt**\n\nThis transcript discusses observations about deep research:\n- Anthropic's computer use was 80% of the way to a prototype but too expensive\n- Elicit was disappointing\n- Fundamental flaw of systems is their corpus\n- Internet archaeology iterator seemed promising\n- Lack of systemization even when explicitly instructed\n- Will not work down a list of sources\n- Not at the level of a research assistant\n- Biases from OpenAI's policies\n- Need for multiple supervisory threads\n- Need for validation outside the context window\n- Need to build a document store\n- Need to recognize when first draft is unacceptable\n\nFor the fifth transcript:\n\n**Tuesday at 8-36 am.srt**\n\nThis transcript discusses why deep research tools are not truly agentic:\n- Deep research and clones are deeply flawed but impressive tech demos\n- \"Agentic\" is more marketing than accurate description\n- These tools can assist researchers if researchers don't believe the marketing hype\n- Literature reviews produced are descriptive, superficial, and misrepresentative\n- Two-pronged purpose of literature review:\n  1. Situate research within specific scholarship\n  2. Address why readers should care/identify gaps in literature\n- A good literature review tells a persuasive story\n- This requires judgment\n- These tools produce reports rather than proper literature reviews\n\nFor the sixth transcript:\n\n**Systems \u2013 Friday at 8-16 am.srt**\n\nThis transcript discusses agentic systems versus normal software:\n- Systems claim to be agentic\n- Agency defined as task decomposition\n- Agency should be viewed as goal accomplishing not task following\n- LLMs even with reasoning capabilities are not agentic systems\n- Although they can perform deductive task decomposition, they cannot exercise judgment\n- Cannot assess quality of their own inference\n- Will double down but never question basic precepts\n- There's a large gulf between agentic goal-following and goal-setting systems\n- Agentic systems require the capability of exploring if a goal has been accomplished\n- Current infrastructure is not truly agentic\n- AGI would be goal setting as well as goal following\n\nThese transcripts contain significant overlap in themes around the limitations of AI in research, particularly around judgment, assessment of their own output, and their inability to produce truly insightful research products.",
          "summaries": [
            {
              "summary": "Systematically processing transcripts in specified order"
            },
            {
              "summary": "Parsing epistemic limitations of AI reasoning models"
            },
            {
              "summary": "Scrutinizing agentic systems' limitations and task decomposition challenges"
            },
            {
              "summary": "Scrutinized AI research limitations across multiple transcripts"
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-08T04:18:37.224408Z",
          "stop_timestamp": "2025-03-08T04:19:26.802447Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "paper-outline",
            "type": "text/markdown",
            "title": "Cleaned Transcripts for \"An Absence of Judgment\" Paper",
            "command": "create",
            "content": "# Cleaned Transcripts for \"An Absence of Judgment\" Paper\n\n## 1. Paper Structure (Context \u2013 Friday at 8:47 am)\n\nThe structure of the paper includes:\n\n1. Discussion of why AI systems are not truly agentic\n2. Discussion of mundane utility and our experiences using AI for research\n3. Discussion of what's needed next - requirements for tools that genuinely do research\n\n### Requirements for Research Tools\n\nWe need tools that facilitate what these AI systems are good at while accounting for their deficiency in judgment:\n\n1. **Cursored To-Do List with Active Monitoring**\n   - Each step monitored for user judgment on correctness\n   - Research involves dead ends and blind alleys\n   - Need human judgment on when output is incorrect or inappropriate\n\n2. **Context Window Management**\n   - Visibility of what's in the context window\n   - Ability to see what we're working on\n   - Ability to \"forget\" - judge a line of thinking as bad and remove it\n   - LLMs anchor on text in their context window, potentially biasing output\n\n3. **Source Management**\n   - Indication of what sources have been considered\n   - Tracking of what sources are being used vs. disused\n   - Token management for large research projects\n\n4. **Transparency and Introspection**\n   - Not just encoded thoughts, but step-by-step transparency\n   - Documentation of paper sources, quotes, summaries, and applications\n   - Context switching based on outline sections\n\n5. **Human Judgment Integration**\n   - First lines of research are seldom the most correct\n   - Deep Research currently takes the whole context window, crunches what it thinks the task is\n   - This isn't truly agentic or goal-following\n   - We must treat it as a tool, not as an agent\n\n6. **Tombstones for Discarded Thoughts**\n   - Indications of thoughts that were had but rejected\n   - Durable removal from context window while keeping record\n\n7. **Documented Stages of Interaction**\n   - Finding literature\n   - Extracting literature\n   - Building the outline\n   - Building first draft\n   - Revising draft\n   - Editing\n   - Outputting\n   - Each stage should be documented\n\n8. **Non-Waterfall Approach**\n   - Can't follow a waterfall SDLC for 10,000-word research reports\n   - Need different mechanisms for tracking information\n   - Must rely on human judgment at every stage\n   - AI's judgment is deficient, and it doesn't know when to apply judgment\n\n## 2. Mundane Utility (Friday at 6:19 pm)\n\n### Data Collection Use Cases\n\n1. **Journal Article Identification**\n   - Based on SoftwareX run on February 14th\n   - SoftwareX has many volumes about software tools, few related to archaeology/historical science\n   - Task was to find articles related to archaeology/historical science\n   - System found plausible articles, including borderline cases\n   - Blocked access worked around through inference\n\n2. **Value for Academic Research**\n   - Utility for academics and graduate students \n   - Going through every article of a journal\n   - Narrowing down definitions and specifications beforehand\n   - Comparison with Computer Use systems\n\n3. **Systematic Research**\n   - Example: Getting data management policies for Australian universities (completed 17 of 34)\n   - Need for external state factors rather than internal validation\n\n4. **Literature Review Support**\n   - Can produce descriptive, basic literature reviews\n   - PhD students have limited time - can't read everything\n   - Better to have AI select potentially relevant papers for human review\n   - Should be part of a \"virtual supervisor's\" portfolio\n   - Reference to Cohen's idea that Ph.D. students should grade AI outputs for borderline papers\n\n## 3. Judgment Deficiencies (Epistemic \u2013 Monday at 8:50 am)\n\nLarge language models lack judgment in three key areas:\n\n1. **Epistemic Humility**\n   - Don't have a sense of not knowing\n   - Problem of confabulations - the issue isn't being wrong but inability to doubt own words\n   - Poor epistemic humility on their own output\n   - Bad at detecting their own output and calling doubt on it\n   - When prompted to self-critique, they perform actions that look like judgment\n   - The impulse to edit or self-critique isn't a pattern in their training data\n   - Published work doesn't contain thought patterns that led to it\n\n2. **Lack of Induction**\n   - O3 Mini High showed better pattern matching when prompted\n   - Induction isn't typically a specific intentional activity\n   - Induction is the precursor to common sense\n   - It's noticing something in what you've produced\n   - In the context of producing the next token\n   - Noticing when something written lacks coherency with what was written before\n   - Noticing deviation from pattern and the impulse of inquiry for that deviation\n\n3. **Correspondence with the Real**\n   - Reasoning models engage in \"Carnapian confirmation\"\n   - They collect evidence until some internal threshold of \"truthiness\" is established\n   - Problem: using Carnapian confirmation, you can prove anything\n   - Models never engage with reality\n   - They don't say \"I don't know\" or \"I can't know\"\n   - When humans are uncertain, we run experiments\n   - To an AI, text and authority have primacy over reality\n   - AI is fundamentally Aristotelian - makes arguments by looking for authorities\n   - Will not look at its words and say \"these aren't good, let me throw them out\"\n   - Will not suggest testing two possible courses of action against reality\n   - Always has to deliver a coherent and final answer\n\nModels can use the language of these capabilities without actually possessing them. The test is not whether they can pretend to have these functions, but whether they act appropriately in the absence of specific prompting.\n\n## 4. Deep Research Observations (Thursday at 8:36 am)\n\n1. **Current Tool Evaluations**\n   - Anthropic's Computer Use: 80% of the way to a working prototype but too expensive\n   - Elicit's experiment was disappointing\n\n2. **Fundamental Flaws**\n   - The corpus is the largest specific flaw\n   - Internet Archaeology iterator seemed promising\n   - Frequent cajoling to be systematic showed the seams\n   - Journal of Open Source Software exploration demonstrated fundamental flaws\n   - Lack of systemization even when explicitly instructed\n   - Will not work down a list of sources systematically\n   - Not at the level of a research assistant\n\n3. **Technical Issues**\n   - Introduced biases from OpenAI's policies\n   - Text of policies \"infects\" the output\n   - No separation of concerns\n   - O1 working on its own prompts doesn't improve output quality\n   - Bad estimation of its own alphabet\n\n4. **Needed Improvements**\n   - Cannot have a single train of thought\n   - Needs multiple supervisory threads\n   - Separate thread for policy enforcement\n   - Intrusive thought thread for validation\n   - Validation should not be contained in context window\n   - Need to build a document store without all corpus in context window\n   - Better corpus inspection\n   - Ability to recognize when first draft is unacceptable\n   - Ability to exclude certain sources from consideration\n   - More structure - outlines, writing to outlines\n   - Obvious editing pass\n\n## 5. Literature Review Capabilities (Tuesday at 8:36 am)\n\n1. **Current State Assessment**\n   - Deep Research tools (February 2025) are deeply flawed but impressive tech demos\n   - Term \"agentic\" is more marketing than accurate\n   - Can assist researchers if they don't believe marketing hype\n   - Default literature reviews are descriptive, superficial, and fundamentally misrepresentative\n\n2. **True Purpose of Literature Reviews**\n   - Two primary functions:\n     1. Situate research within specific scholarship (argument by authority and claim to disciplinarity)\n     2. Address why readers should care (identify gaps, explain novelty)\n   - A good literature review tells a persuasive story\n   - Requires judgment - not just describing what papers said\n   - Literature review is not merely a descriptive summarization\n   - It builds a case for why the question should be answered\n\n3. **Tool Limitations**\n   - Default output is a \"report\" not a proper literature review\n   - Doesn't sufficiently address conflicting contexts or contradictions\n   - Can be effective at tedious drudgery tasks if findable on the open web\n\n## 6. Agentic Systems Framework (Systems \u2013 Friday at 8:16 am)\n\n1. **Agency Definition**\n   - Systems claim to be agentic\n   - If defined as task decomposition (splitting tasks into subtasks), they could be called agentic\n   - But agency should be viewed as goal accomplishing, not task following\n   - This distinction is important and nuanced\n\n2. **Limitations of Current Systems**\n   - LLMs with \"reasoning\" capabilities are not truly agentic\n   - Can perform deductive task decomposition but cannot exercise judgment\n   - Cannot assess quality of their own inference\n   - When prompted to edit writing, will double down but never question basic precepts\n   - We're not talking about improving tone or grammar, but questioning if the process is apt\n\n3. **Goal Following vs. Goal Setting**\n   - Large gulf between agentic goal-following and goal-setting systems\n   - Both require capability to explore if goal has been accomplished and done well\n   - Must differentiate from basic QA processes\n   - Current system cannot situate itself effectively in reality\n   - Cannot perform as our agent or have self-agency\n   - Inappropriate to call current infrastructure agentic\n   - AGI would be goal-setting as well as goal-following\n\n4. **Requirements for Research Assistants**\n   - Ability to figure out fundamental research questions implied by prompt\n   - Understanding that literature review is a persuasive document\n   - Identifying research questions, context, and gaps\n   - Requires epistemic humility that systems don't exhibit\n   - Performance of a virtue is not having the virtue\n   - Self-criticality is essential - recognizing blind alleys\n   - Ability to forget/elide context\n   - Working with user-provided documents in larger context\n",
            "version_uuid": "b2cd4b87-f6a7-4384-9312-d4e13913c7d2"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "88daf853-130f-487e-8171-5eb970dee66d"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-08T04:19:30.917298Z",
          "stop_timestamp": "2025-03-08T04:19:35.381981Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI've cleaned up your dictated transcripts and organized them into a cohesive document that follows the structure of your paper on AI's limitations in research. The cleaned content removes crosstalk, fixes garbled segments, and organizes your thoughts thematically.\n\nLooking through the transcripts, I've identified several key sections:\n\n1. Paper structure and requirements for research tools\n2. Mundane utility and practical applications \n3. Three types of judgment deficiencies in AI (epistemic humility, induction, correspondence with reality)\n4. Observations on current Deep Research implementations\n5. Analysis of AI's literature review capabilities\n6. Framework for understanding true agency versus current capabilities\n\nIs there any specific section where you'd like me to elaborate or where you think I might have misinterpreted your dictation? I can also help you integrate these cleaned insights into your existing paper draft.",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-08T04:19:35.530374Z",
      "updated_at": "2025-03-08T04:19:35.530374Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "fb6d4bdb-aea9-42e7-8da9-1cfe2688a6da",
      "text": "Ok, this is an interesting start, but 1) I'd like this to be transcript by transcript, 2) I'd like to see which parts of which transcripts speak to the original outline (such that I can figure out what else I need to plan for, or have talked overly long on) and 3) this is insufficiently hierarchical. I would like my outlines to recurse down to the sub-paragraph level (i.e. in the Toulmin sense, figuring out what evidence supports warrants supports claims.)",
      "content": [
        {
          "start_timestamp": "2025-03-06T21:20:59.752560Z",
          "stop_timestamp": "2025-03-06T21:20:59.752560Z",
          "flags": null,
          "type": "text",
          "text": "Ok, this is an interesting start, but 1) I'd like this to be transcript by transcript, 2) I'd like to see which parts of which transcripts speak to the original outline (such that I can figure out what else I need to plan for, or have talked overly long on) and 3) this is insufficiently hierarchical. I would like my outlines to recurse down to the sub-paragraph level (i.e. in the Toulmin sense, figuring out what evidence supports warrants supports claims.)",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-10T02:31:01.637090Z",
      "updated_at": "2025-03-10T02:31:01.637090Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "4a1518f3-381f-411c-9ae7-4ab81914acf8",
      "text": "\nI need to reorganize my approach based on the user's feedback. They've asked for:\n\n1. Transcript-by-transcript organization rather than thematic\n2. Mapping of transcript content to the original outline\n3. A more hierarchical structure that goes down to sub-paragraph level with Toulmin structure (claims, warrants, evidence)\n\nLet me restructure this approach by:\n1. Processing each transcript individually in chronological order\n2. Identifying the key points in each transcript\n3. Mapping these points to sections in the original outline\n4. Creating a hierarchical structure that shows claims, warrants, and evidence\n5. Highlighting any gaps or areas of redundancy\n\nFor the order, the user mentioned:\n* Context Friday 8:47\n* Friday 6:19\n* Epistemic - Monday 8:50\n* Thursday 8:36\n* Tuesday 8:36\n* Systems - Friday 8:16\n\nThe original outline should be extracted from the context documents provided earlier.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n",
      "content": [
        {
          "start_timestamp": "2025-03-10T02:31:08.276639Z",
          "stop_timestamp": "2025-03-10T02:31:12.037400Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nI need to reorganize my approach based on the user's feedback. They've asked for:\n\n1. Transcript-by-transcript organization rather than thematic\n2. Mapping of transcript content to the original outline\n3. A more hierarchical structure that goes down to sub-paragraph level with Toulmin structure (claims, warrants, evidence)\n\nLet me restructure this approach by:\n1. Processing each transcript individually in chronological order\n2. Identifying the key points in each transcript\n3. Mapping these points to sections in the original outline\n4. Creating a hierarchical structure that shows claims, warrants, and evidence\n5. Highlighting any gaps or areas of redundancy\n\nFor the order, the user mentioned:\n* Context Friday 8:47\n* Friday 6:19\n* Epistemic - Monday 8:50\n* Thursday 8:36\n* Tuesday 8:36\n* Systems - Friday 8:16\n\nThe original outline should be extracted from the context documents provided earlier.",
          "summaries": [
            {
              "summary": "Thinking about refining transcript analysis with hierarchical, evidence-based outlining"
            },
            {
              "summary": "Reorganizing approach to meet detailed structural requirements"
            },
            {
              "summary": "Strategized hierarchical transcript mapping for comprehensive analysis."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-10T02:31:12.488041Z",
          "stop_timestamp": "2025-03-10T02:31:55.156689Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "paper-outline",
            "command": "rewrite",
            "content": "# Transcript Analysis for \"An Absence of Judgment\" Paper\n\n## Original Paper Structure (from context documents)\n1. Introduction\n2. Agentic Systems Framework\n3. Deep Research and AI Capabilities\n   - Current State\n   - Fundamental Limitations\n   - Comparative Analysis\n4. Other Infrastructures\n   - Anthropic Computer Use\n   - Elicit Research Paper\n   - Perplexity Deep Research\n   - Google Deep Research\n5. Practical Applications\n6. Future Development\n\n## Transcript-by-Transcript Analysis\n\n### Context \u2013 Friday at 8-47 am\n**Maps to**: Future Development, System Design Requirements\n\n#### Key Points:\n1. **Three-part paper structure**\n   - Discussion of why AI systems are not truly agentic\n   - Discussion of mundane utility and research experiences\n   - Discussion of necessary improvements for research tools\n\n2. **Requirements for research tools** (detailed system design requirements)\n   - **Cursored to-do list with monitoring**\n     - Claim: Each step needs user judgment for correctness\n     - Warrant: Research involves dead ends that must be identified\n     - Evidence: February 7th logs showed incorrect thinking that wasn't self-identified\n\n   - **Context window management**\n     - Claim: LLMs need transparent context window visibility\n     - Warrant: They anchor on text in context, potentially biasing output\n     - Evidence: Current models can't judge bad thinking and remove it\n\n   - **Source tracking system**\n     - Claim: Need indicators of sources considered, used, and disused\n     - Warrant: 200,000 tokens insufficient for comprehensive research\n     - Evidence: Blowing context window with just nine papers\n\n   - **Transparent thought process**\n     - Claim: Need transparency beyond encoded thoughts\n     - Warrant: Must track which papers inform which document sections\n     - Evidence: Need context switching based on outline sections\n\n   - **Human judgment integration**\n     - Claim: Systems must leverage human judgment, not just confirm\n     - Warrant: First research attempts rarely correct\n     - Evidence: Deep Research just crunches task based on context window\n\n   - **Tombstones for discarded thoughts**\n     - Claim: Need indicators of rejected ideas\n     - Warrant: Must durably remove bad thoughts from context window\n     - Evidence: Proof of consideration important for decision trail\n\n   - **Stage-based documentation**\n     - Claim: Each research stage needs documentation\n     - Warrant: Can't follow waterfall SDLC for research\n     - Evidence: Different mechanisms needed for tracking information\n\n#### Gaps/Missing Elements:\n- No specific discussion of how human judgment should be integrated\n- Limited exploration of implementation details\n\n### Friday at 6-19 pm\n**Maps to**: Practical Applications, Mundane Utility\n\n#### Key Points:\n1. **Data collection use cases**\n   - **Journal article identification**\n     - Claim: AI can identify relevant articles across journals\n     - Warrant: SoftwareX run on February 14th found archaeology-related tools\n     - Evidence: Found plausible set of relevant and borderline articles\n\n   - **Working around access limitations**\n     - Claim: System can work indirectly when direct access is blocked\n     - Warrant: Elsevier blocked OpenAI's data router\n     - Evidence: Still produced useful results through inference\n\n2. **Value for academic research**\n   - **Systematic journal review**\n     - Claim: Useful for comprehensive journal analysis\n     - Warrant: Can go through entire journal volumes systematically\n     - Evidence: Example of handling Australian university data policies (17 of 34)\n\n   - **PhD student support**\n     - Claim: PhD supervisors could use AI to assign focused reading\n     - Warrant: PhDs have limited time, can't read everything\n     - Evidence: Reference to Cohen's post about grading AI outputs\n\n#### Gaps/Missing Elements:\n- Comparison with traditional methods incomplete\n- Limited metrics on effectiveness\n\n### Epistemic \u2013 Monday at 8-50 am\n**Maps to**: Deep Research and AI Capabilities, Fundamental Limitations\n\n#### Key Points:\n1. **Three axes of judgment deficiency**\n\n   - **Epistemic humility**\n     - Claim: LLMs lack epistemic humility - awareness of not knowing\n     - Warrant: Can't doubt their own words or detect own output quality\n     - Evidence: Confabulation without acknowledgment of limitations\n     - Sub-claim: Performance of epistemic humility \u2260 actual humility\n       - Warrant: \"Well, what about X?\" exploration never leads to \"I don't know\"\n       - Evidence: Always produces an outcome despite uncertainty\n\n   - **Induction capacity**\n     - Claim: LLMs lack true inductive reasoning\n     - Warrant: Induction is precursor to common sense and pattern detection\n     - Evidence: O3 Mini High shows pattern matching only when prompted\n     - Sub-claim: Induction involves noticing coherency failures\n       - Warrant: Noticing deviation from established patterns\n       - Evidence: Not a deliberate activity but an intuitive recognition\n\n   - **Correspondence with reality**\n     - Claim: LLMs engage in \"Carnapian confirmation\" not reality testing\n     - Warrant: They collect evidence until internal \"truthiness\" threshold met\n     - Evidence: Never say \"I can't know\" or suggest experiments\n     - Sub-claim: AI is fundamentally Aristotelian\n       - Warrant: Text and authority have primacy over reality\n       - Evidence: Finds fact supported if source supports it\n       - Sub-warrant: This differs from current scientific paradigms\n       - Evidence: Not how Kuhnian paradigms or Lakotashian research programs work\n\n2. **Performance vs. capability**\n   - Claim: Models can use judgment language without judgment capability\n   - Warrant: Test is behavior without specific prompting\n   - Evidence: Can use words of the capability without the actual capability\n\n#### Gaps/Missing Elements:\n- Connection to specific research failures\n- Potential philosophical cross-references to student-judge formalism paper\n\n### Thursday at 8-36 am\n**Maps to**: Deep Research and AI Capabilities, Other Infrastructures\n\n#### Key Points:\n1. **Current tool evaluations**\n   - **Anthropic Computer Use**\n     - Claim: 80% of the way to prototype but too expensive\n     - Warrant: Good concept but impractical implementation\n     - Evidence: Cost outweighs current capabilities\n\n   - **System corpus limitations**\n     - Claim: Corpus is the largest specific flaw\n     - Warrant: Access and coverage issues fundamental\n     - Evidence: Internet Archaeology iterator promising but had issues\n\n2. **Systematic limitations**\n   - **Lack of systematization**\n     - Claim: Won't work systematically through source lists\n     - Warrant: Even when explicitly instructed to be systematic\n     - Evidence: Journal of Open Source Software exploration showed flaws\n\n   - **Policy interference**\n     - Claim: OpenAI policies \"infect\" output\n     - Warrant: No separation of concerns in processing\n     - Evidence: Policy text appearing in unrelated outputs\n\n3. **Needed improvements**\n   - **Multi-threaded processing**\n     - Claim: Cannot have single train of thought\n     - Warrant: Need separate threads for different functions\n     - Evidence: Policy enforcement, validation needs separation\n\n   - **Document management**\n     - Claim: Need document store outside context window\n     - Warrant: Can't fit entire corpus in context\n     - Evidence: Better corpus inspection needed\n\n   - **Structural requirements**\n     - Claim: Need more structure - outlines, editing passes\n     - Warrant: Must recognize when drafts are unacceptable\n     - Evidence: Source exclusion capability required\n\n#### Gaps/Missing Elements:\n- Technical implementation details\n- Specific examples of policy interference\n\n### Tuesday at 8-36 am\n**Maps to**: Introduction, Deep Research and AI Capabilities\n\n#### Key Points:\n1. **Current state assessment**\n   - **Marketing vs. reality**\n     - Claim: Deep Research tools (Feb 2025) are flawed tech demos\n     - Warrant: \"Agentic\" is marketing not accurate description\n     - Evidence: Represent difference in degree and kind, like Bing Sydney (Feb 2023)\n\n   - **Researcher assistance limitations**\n     - Claim: Can assist if researchers don't believe hype\n     - Warrant: Default outputs superficial and misrepresentative\n     - Evidence: Literature reviews descriptive not analytical\n\n2. **Literature review requirements**\n   - **True functions of literature reviews**\n     - Claim: Literature reviews have two primary functions\n     - Warrant 1: Situate research within scholarship (authority and disciplinarity)\n     - Warrant 2: Explain why readers should care (gaps, novelty)\n     - Evidence: Good reviews tell persuasive stories, not just summarize\n\n   - **Judgment necessity**\n     - Claim: Literature reviews require judgment\n     - Warrant: Build case for question importance\n     - Evidence: Not just description but persuasion\n\n   -",
            "version_uuid": "3e722a75-df4d-46cd-a8e4-40f9be240267"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": "2025-03-10T02:31:57.152369Z",
          "stop_timestamp": "2025-03-10T02:31:57.152369Z",
          "flags": null,
          "type": "text",
          "text": "",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-10T02:31:57.160735Z",
      "updated_at": "2025-03-10T02:31:57.160735Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "b921db0b-1268-43d9-9d17-779fcdf8902f",
      "text": "Ok, this is an interesting start, but 1) I'd like this to be transcript by transcript, 2) I'd like to see which parts of which transcripts speak to the original outline (such that I can figure out what else I need to plan for, or have talked overly long on) and 3) this is insufficiently hierarchical. I would like my outlines to recurse down to the sub-paragraph level (i.e. in the Toulmin sense, figuring out what evidence supports warrants supports claims.) We do not need to call out the claims/warrant/evidence, it's more that the outline needs to recurse down to the sub-paragraph level, and ideas that belong inside of a paragraph could be warrant/claims. Effectively, we're figuring out the structure of the document, topic by topic, figuring out when we need to decompose topics into sub-topics, and down to the idea that we're going to be hitting paragraph by paragraph.",
      "content": [
        {
          "start_timestamp": "2025-03-06T21:22:48.297519Z",
          "stop_timestamp": "2025-03-06T21:22:48.297519Z",
          "flags": null,
          "type": "text",
          "text": "Ok, this is an interesting start, but 1) I'd like this to be transcript by transcript, 2) I'd like to see which parts of which transcripts speak to the original outline (such that I can figure out what else I need to plan for, or have talked overly long on) and 3) this is insufficiently hierarchical. I would like my outlines to recurse down to the sub-paragraph level (i.e. in the Toulmin sense, figuring out what evidence supports warrants supports claims.) We do not need to call out the claims/warrant/evidence, it's more that the outline needs to recurse down to the sub-paragraph level, and ideas that belong inside of a paragraph could be warrant/claims. Effectively, we're figuring out the structure of the document, topic by topic, figuring out when we need to decompose topics into sub-topics, and down to the idea that we're going to be hitting paragraph by paragraph.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-10T02:33:06.439024Z",
      "updated_at": "2025-03-10T02:33:06.439024Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "59dbd255-179b-4f0d-b34f-34f0b627984f",
      "text": "\nLet me revise my approach based on your feedback:\n\n1. Organize transcript by transcript rather than thematically\n2. Map each transcript to the original outline to identify coverage and gaps\n3. Create a more hierarchical structure that goes down to the sub-paragraph level\n\nFirst, let me refer back to the original outline that was in the context materials. From document 2, I see this outline:\n\n```\n# An Absence of Judgment: On AI's Fundamental Limitations in Research\n\n## 1. Introduction\n- Fundamental incapability of judgment in LLMs despite linguistic mimicry\n- Case study: OpenAI's Deep Research (February 2025)\n- Prerequisites for \"agentic\" tools\n- Core thesis on lack of induction preventing knowledge connections\n\n## 2. Agentic Systems Framework\n### 2.1 Goal-Related Characteristics\n- Distinction between goal-following and goal-setting\n- External input requirements\n- Operational definitions of agency\n\n### 2.2 Core Components of Agency\n- Goal processing capabilities\n- Execution mechanisms\n- Assessment and reporting functions\n\n## 3. Deep Research Analysis\n### 3.1 Observed Limitations\n- Failure case: Newspaper article generation\n- Inability to follow explicit guidelines\n- Surface-level competence without true comprehension\n\n### 3.2 The Uncanny Valley of Research\n- Always produces output without questioning assumptions\n- Lacks systematic approach\n- No self-correction or revision process\n- Takes initial search results as \"gospel\"\n- Absence of winnowing or filtering process\n\n### 3.3 Literature Review Capabilities\n- Can perform descriptive reviews without insight\n- Missing elements:\n  - Purpose-driven source selection\n  - Intentional organization\n  - Generation of novel insights\n  - Inductive reasoning\n\n## 4. Mundane Utility and Successful Applications\n### 4.1 Effective Use Cases\n- [Placeholder for successful applications]\n- [Placeholder for areas of demonstrated competence]\n\n### 4.2 Workflow Integration\n- [Placeholder for effective integration patterns]\n- [Placeholder for productivity improvements]\n\n### 4.3 Value Proposition\n- [Placeholder for cost-benefit analysis]\n- [Placeholder for efficiency gains]\n\n## 5. System Design Requirements\n### 5.1 Context Management\n- Transparent context window visibility\n- Token management strategies\n- Source tracking and documentation\n- Ability to \"forget\" or remove irrelevant content\n- Tombstones for discarded thoughts\n\n### 5.2 Research Process Support\n- Structured todo lists for research steps\n- Clear documentation of considered sources\n- Management of working context windows\n- Integration points for human judgment\n- Outline-driven context switching\n\n### 5.3 Stage-Based Approach\n- Literature finding\n- Literature extraction\n- Outline building\n- First draft creation\n- Revision process\n- Editing and output\n- Documentation requirements for each stage\n\n## 6. Human-AI Collaboration Framework\n### 6.1 Judgment Integration\n- Recognition of AI judgment deficiency\n- Strategic points for human intervention\n- Validation and verification processes\n- Beyond simple confirmation mechanisms\n\n### 6.2 Tool-Centric Approach\n- Treating AI as tool rather than agent\n- Leveraging AI capabilities appropriately\n- Managing limitations and boundaries\n- Integration with human research processes\n\n## 7. Future Development Needs\n### 7.1 Technical Requirements\n- Improved context management\n- Better token efficiency\n- Enhanced source tracking\n- Robust documentation systems\n\n### 7.2 Process Requirements\n- Non-waterfall approach to research\n- Flexible stage management\n- Improved human-AI interaction patterns\n- Documentation standards\n\n## 8. Conclusion\n- Synthesis of key findings\n- Implications for AI research tools\n- Future research directions\n```\n\nNow, I'll go through each transcript and:\n1. Clean it up\n2. Map it to the outline sections\n3. Create a hierarchical structure down to the sub-paragraph level\n4. Identify which parts of the outline are covered and which need more attention\n\nLet me create a revised artifact with this structure.\n\nI understand your requirements better now. I'll reorganize the content to:\n\n1. Present each transcript separately in sequential order\n2. Map content to the original outline to identify coverage and gaps\n3. Create a deeply hierarchical structure down to sub-paragraph/idea level\n\nLet me create a new version with this approach.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\nI've completely reorganized the analysis as requested. Now it:\n\n1. Presents each transcript separately in chronological order\n2. Maps content directly to your original outline sections \n3. Creates a deeply hierarchical structure down to sub-paragraph/idea level\n4. Includes a \"Coverage Analysis\" after each transcript to show which outline sections it addresses\n5. Concludes with a comprehensive \"Coverage Gaps Analysis\" that identifies:\n   - Well-covered sections\n   - Sections needing more development\n   - Additional concepts not in your original outline\n\nThis structure should help you identify where you've talked sufficiently and where you need additional dictation. The hierarchical organization follows the Toulmin model you mentioned, with ideas organized to support larger claims.\n\nWould you like me to analyze any particular transcript in more detail, or would you like suggestions for developing the sections that currently have less coverage?",
      "content": [
        {
          "start_timestamp": "2025-03-10T02:33:25.656336Z",
          "stop_timestamp": "2025-03-10T02:33:44.097303Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nLet me revise my approach based on your feedback:\n\n1. Organize transcript by transcript rather than thematically\n2. Map each transcript to the original outline to identify coverage and gaps\n3. Create a more hierarchical structure that goes down to the sub-paragraph level\n\nFirst, let me refer back to the original outline that was in the context materials. From document 2, I see this outline:\n\n```\n# An Absence of Judgment: On AI's Fundamental Limitations in Research\n\n## 1. Introduction\n- Fundamental incapability of judgment in LLMs despite linguistic mimicry\n- Case study: OpenAI's Deep Research (February 2025)\n- Prerequisites for \"agentic\" tools\n- Core thesis on lack of induction preventing knowledge connections\n\n## 2. Agentic Systems Framework\n### 2.1 Goal-Related Characteristics\n- Distinction between goal-following and goal-setting\n- External input requirements\n- Operational definitions of agency\n\n### 2.2 Core Components of Agency\n- Goal processing capabilities\n- Execution mechanisms\n- Assessment and reporting functions\n\n## 3. Deep Research Analysis\n### 3.1 Observed Limitations\n- Failure case: Newspaper article generation\n- Inability to follow explicit guidelines\n- Surface-level competence without true comprehension\n\n### 3.2 The Uncanny Valley of Research\n- Always produces output without questioning assumptions\n- Lacks systematic approach\n- No self-correction or revision process\n- Takes initial search results as \"gospel\"\n- Absence of winnowing or filtering process\n\n### 3.3 Literature Review Capabilities\n- Can perform descriptive reviews without insight\n- Missing elements:\n  - Purpose-driven source selection\n  - Intentional organization\n  - Generation of novel insights\n  - Inductive reasoning\n\n## 4. Mundane Utility and Successful Applications\n### 4.1 Effective Use Cases\n- [Placeholder for successful applications]\n- [Placeholder for areas of demonstrated competence]\n\n### 4.2 Workflow Integration\n- [Placeholder for effective integration patterns]\n- [Placeholder for productivity improvements]\n\n### 4.3 Value Proposition\n- [Placeholder for cost-benefit analysis]\n- [Placeholder for efficiency gains]\n\n## 5. System Design Requirements\n### 5.1 Context Management\n- Transparent context window visibility\n- Token management strategies\n- Source tracking and documentation\n- Ability to \"forget\" or remove irrelevant content\n- Tombstones for discarded thoughts\n\n### 5.2 Research Process Support\n- Structured todo lists for research steps\n- Clear documentation of considered sources\n- Management of working context windows\n- Integration points for human judgment\n- Outline-driven context switching\n\n### 5.3 Stage-Based Approach\n- Literature finding\n- Literature extraction\n- Outline building\n- First draft creation\n- Revision process\n- Editing and output\n- Documentation requirements for each stage\n\n## 6. Human-AI Collaboration Framework\n### 6.1 Judgment Integration\n- Recognition of AI judgment deficiency\n- Strategic points for human intervention\n- Validation and verification processes\n- Beyond simple confirmation mechanisms\n\n### 6.2 Tool-Centric Approach\n- Treating AI as tool rather than agent\n- Leveraging AI capabilities appropriately\n- Managing limitations and boundaries\n- Integration with human research processes\n\n## 7. Future Development Needs\n### 7.1 Technical Requirements\n- Improved context management\n- Better token efficiency\n- Enhanced source tracking\n- Robust documentation systems\n\n### 7.2 Process Requirements\n- Non-waterfall approach to research\n- Flexible stage management\n- Improved human-AI interaction patterns\n- Documentation standards\n\n## 8. Conclusion\n- Synthesis of key findings\n- Implications for AI research tools\n- Future research directions\n```\n\nNow, I'll go through each transcript and:\n1. Clean it up\n2. Map it to the outline sections\n3. Create a hierarchical structure down to the sub-paragraph level\n4. Identify which parts of the outline are covered and which need more attention\n\nLet me create a revised artifact with this structure.",
          "summaries": [
            {
              "summary": "Thinking about recursively mapping document structure with granular topic decomposition"
            },
            {
              "summary": "Restructuring outline with hierarchical, transcript-based approach"
            },
            {
              "summary": "Mapping transcripts to outline, diving into hierarchical structure"
            },
            {
              "summary": "Mapped research outline, strategized transcript organization hierarchically"
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-10T02:33:44.448322Z",
          "stop_timestamp": "2025-03-10T02:33:45.240959Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI understand your requirements better now. I'll reorganize the content to:\n\n1. Present each transcript separately in sequential order\n2. Map content to the original outline to identify coverage and gaps\n3. Create a deeply hierarchical structure down to sub-paragraph/idea level\n\nLet me create a new version with this approach.",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-10T02:33:45.550064Z",
          "stop_timestamp": "2025-03-10T02:34:44.916489Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "paper-outline",
            "command": "rewrite",
            "content": "# Transcript Analysis for \"An Absence of Judgment\" Paper\n\n## 1. Context \u2013 Friday at 8:47 am\n\n### Paper Structure\n- Three main sections:\n  - Discussion of why AI systems are not truly agentic\n  - Discussion of mundane utility and experiences using AI for research\n  - Discussion of system requirements for genuine research tools\n\n### System Requirements for Research Tools (Maps to Section 5 in outline)\n#### 5.1 Context Management\n- **Cursored To-Do List**\n  - Active monitoring of each step in the to-do list\n  - User judgment input on correctness\n  - Recognition that research involves dead ends and blind alleys\n  - Ability to identify incorrect outputs and inappropriate responses\n\n- **Context Window Management**\n  - Visibility of what's in the context window\n  - Transparency of current work focus\n  - LLMs anchor on text in their context window\n  - Need mechanism to judge when a line of thinking is bad and remove it\n  - Without proper management, wrong text biases output and excludes desirable content\n  \n- **Source Management**\n  - Tracking of sources considered\n  - Documentation of sources being used vs. disused\n  - Context window limitations (even 200,000 tokens is insufficient for comprehensive research)\n  - Need for token management strategies\n\n- **Tombstones for Discarded Thoughts**\n  - Indications of thoughts that were had but rejected\n  - Durable removal from context window\n  - Proof of consideration and intentional rejection\n\n#### 5.2 Research Process Support\n- **Transparency and Introspection**\n  - Not just encoded thoughts\n  - Step-by-step transparency\n  - Documentation of sources, quotes, and understanding\n  - Clear indication of document placement\n  - Context loading based on document sections\n\n- **Human Judgment Integration**\n  - First research attempts rarely optimal\n  - Systems must leverage human judgment\n  - Beyond simple confirmation mechanisms used in current Deep Research\n  \n#### 5.3 Stage-Based Approach\n- **Documented Stages of Interaction**\n  - Finding literature\n  - Extracting literature\n  - Building outline\n  - Building first draft\n  - Revising\n  - Editing\n  - Outputting\n  - Documentation requirements for each stage\n\n- **Non-Waterfall Approach**\n  - Can't follow linear SDLC for research reports\n  - Different mechanisms needed for tracking information\n  - Human judgment required at every stage\n  - AI lacks judgment and doesn't recognize when to apply it\n\n### Coverage Analysis:\n- Strongly covers sections 5.1, 5.2, and 5.3 of the outline\n- Introduces concept of AI judgment deficiency without elaborating (Section 1)\n- Does not address Sections 2, 3, 4, 6, 7, or 8\n\n## 2. Friday at 6:19 pm\n\n### Mundane Utility (Maps to Section 4 in outline)\n#### 4.1 Effective Use Cases\n- **Data Collection Applications**\n  - SoftwareX journal analysis (February 14)\n  - Finding archaeology/historical science related articles\n  - System identified plausible articles including borderline cases\n  - Worked around blocked access through inference\n\n- **Academic Research Support**\n  - Direct utility for academics and graduate students\n  - Journal article systematic review\n  - Definition and specification refinement\n\n- **Systematic Data Gathering**\n  - Example: Retrieved data management policies for Australian universities (17 of 34)\n  - Need for external validation rather than internal validation\n  - Potential for additional runs to complete data sets\n\n#### 4.2 Workflow Integration\n- **Literature Review Support**\n  - Creates \"medium essay in the park\" quality output\n  - Reference to prior work (Carly Richard's analogy)\n  - Helps PhD students with limited time constraints\n  - Better paper selection over exhaustive reading\n\n#### 4.3 Value Proposition\n- **PhD Supervision Enhancement**\n  - Paper selection for weekly reading\n  - Realistic assessment of PhD students' reading habits\n  - References Cohen's idea that PhD students should grade AI outputs for borderline papers\n  - Virtual supervisor's portfolio component\n\n### Coverage Analysis:\n- Directly addresses Section 4 with practical examples\n- Provides concrete use cases that were placeholders in original outline\n- Does not substantially address other outline sections\n\n## 3. Epistemic \u2013 Monday at 8:50 am\n\n### Judgment Deficiencies (Maps to Sections 1 and 3 in outline)\n#### Three Categories of Judgment Deficiency\n- **Epistemic Humility**\n  - Lack of sense of not knowing\n  - Issue of confabulations\n    - Problem isn't being wrong\n    - Problem is inability to doubt own words\n  - Poor assessment of own output\n    - Bad at detecting their own output\n    - Bad at calling doubt on their output\n  - Performance vs. reality of epistemic humility\n    - Can mimic the language of humility when prompted\n    - Lacks the impulse to self-critique\n    - Published work doesn't contain thought patterns that led to it\n  - Faux humility in reasoning models\n    - \"What about this?\" pattern\n    - Pretense of epistemic humility\n    - Process never results in \"I don't know\" conclusion\n    - Always produces an outcome regardless of uncertainty\n\n- **Lack of Induction**\n  - O3 Mini High shows better pattern matching when prompted\n  - Not typically a conscious activity\n  - Precursor to common sense\n  - Ability to notice issues in one's production\n  - Next-token paradigm constraint\n  - Function of noticing deviation from pattern\n  - Impulse of inquiry for pattern deviation\n\n- **Correspondence with the Real (Aristotelian Fallacy)**\n  - Reasoning models engage in \"Carnapian confirmation\"\n    - Collect evidence until internal \"truthiness\" threshold reached\n    - Problem: can prove anything with selective evidence collection\n  - Text and authority have primacy over reality\n    - Fundamentally Aristotelian approach\n    - Makes arguments by finding authorities\n    - Will support facts if it can find sources that support them\n  - No experimental approach\n    - Won't suggest testing different possibilities\n    - Won't ask users to try something and report back\n  - Always delivers a coherent and final answer\n    - Won't discard bad output\n    - Won't acknowledge fundamental uncertainty\n\n### Coverage Analysis:\n- Provides deep analysis for Section 1 introduction points about judgment capabilities\n- Expands on Section 3.1 and 3.2 about limitations\n- Introduces philosophical framework not explicit in original outline\n- Introduces the \"Aristotelian Fallacy\" concept not in original outline\n- Does not address Sections 2, 4, 5, 6, 7, or 8\n\n## 4. Thursday at 8:36 am\n\n### Deep Research Observations (Maps to Section 3 in outline)\n#### 3.1 Observed Limitations\n- **Current Tool Evaluations**\n  - Anthropic's Computer Use: 80% of working prototype but too expensive\n  - Elicit experiment was disappointing\n\n- **Fundamental Flaws**\n  - Corpus limitations are the primary issue\n  - Internet Archaeology iterator seemed promising\n  - Frequent prompting for systematic approach revealed limitations\n  - Journal of Open Source Software exploration demonstrated key weaknesses\n  - Lack of systematic process even when explicitly instructed\n  - Not equivalent to a research assistant\n\n#### 3.2 The Uncanny Valley of Research\n- **Technical Issues**\n  - OpenAI's policy text \"infects\" output\n  - No separation of concerns\n  - O1 working on its own prompts doesn't improve output\n  - Poor self-assessment capabilities\n\n#### Needed Improvements (Maps to Sections 5 and 7)\n- **Technical Architecture**\n  - Multiple thought threads needed vs. single train of thought\n  - Separate supervisory threads\n  - Policy enforcement threading\n  - Validation not contained in context window\n  - Document store for corpus management\n\n- **Self-Assessment Capabilities**\n  - Ability to recognize when draft is unacceptable\n  - Ability to exclude certain sources\n  - Better structure: outlines, writing to outlines\n  - Explicit editing passes\n\n### Coverage Analysis:\n- Addresses Sections 3.1 and 3.2 with specific observations\n- Contributes to Sections 5 and 7 on requirements and improvements\n- Focuses on technical limitations rather than philosophical ones\n- Does not substantially address Sections 1, 2, 4, 6, or 8\n\n## 5. Tuesday at 8:36 am\n\n### Literature Review Capabilities (Maps to Section 3.3 in outline)\n#### Current State Assessment\n- Deep Research tools (February 2025)\n  - \"Deeply flawed, deeply impressive tech demos\"\n  - Term \"agentic\" is marketing rather than accurate descriptor\n  - Can assist researchers if they don't believe marketing claims\n  - Default outputs are descriptive, superficial, and misrepresentative\n\n#### True Purpose of Literature Reviews\n- **Two Primary Functions**\n  - Situate research within specific scholarship\n    - Argument by authority\n    - Claim to disciplinarity\n    - Research program in Lakatosian sense\n  - Explain why readers should care\n    - Identify gaps in literature\n    - Explain why question hasn't been answered\n    - Identify novelty\n  \n- **Literature Review as Persuasive Document**\n  - Tells a story\n  - Explains why reader should care\n    - Disciplinary relevance\n    - Extension of prior research\n    - Addresses gap in literature\n  - Requires judgment\n    - Not just describing papers\n    - Not merely descriptive summarization\n    - Builds case for research question importance\n\n#### Tool Limitations\n- Default output is \"report\" not proper literature review\n- Doesn't address conflicting contexts or contradictions\n- Effective only for tedious drudgery tasks findable on open web\n\n### Coverage Analysis:\n- Thoroughly addresses Section 3.3 on literature review capabilities\n- Provides philosophical grounding for literature review purpose\n- Connects to Section 1 introduction on judgment importance\n- Does not address Sections 2, 4, 5, 6, 7, or 8\n\n## 6. Systems \u2013 Friday at 8:16 am\n\n### Agentic Systems Framework (Maps to Section 2 in outline)\n#### 2.1 Goal-Related Characteristics\n- **Agency Definition**\n  - Systems claim to be agentic/possess agency\n  - If defined as task decomposition ability, could be considered agentic\n  - Agency should be function of goal accomplishing, not task following\n  - Important and nuanced distinction\n\n#### 2.2 Core Components of Agency\n- **Limitations of Current Systems**\n  - LLMs with \"reasoning\" capabilities aren't truly agentic\n  - Can perform deductive task decomposition\n  - Cannot exercise judgment\n  - Cannot assess quality of own inference\n  - Will double down rather than question basic precepts\n  - Question is aptness of process, not grammar or tone\n\n- **Goal Following vs. Goal Setting**\n  - Large gulf between goal-following and goal-setting systems\n  - Both require capability to assess goal accomplishment quality\n  - Must differentiate from basic QA processes\n  - Cannot situate itself effectively in reality\n  - Cannot perform as agent or have self-agency\n  - Current infrastructure not truly agentic\n  - AGI would be goal-setting as well as goal-following\n  - Adding more computers doesn't create true AGI\n\n- **Requirements for Research Assistants**\n  - Ability to identify fundamental research questions in prompt\n  - Understanding literature review as persuasive document\n  - Identifying research questions, context, and gaps\n  - Requires epistemic humility systems lack\n  - Self-criticality for recognizing blind alleys\n  - Ability to forget/elide context\n  - Working with user-provided documents\n\n### Coverage Analysis:\n- Comprehensively addresses Section 2 on agentic systems framework\n- Connects to Section 1 introduction points\n- Relates to Section 3 on limitations\n- Touches on Section 6 regarding tool-centric approach\n- Does not substantially address Sections 4, 5, 7, or 8\n\n## Coverage Gaps Analysis\n\n### Well-Covered Sections:\n- Section 1: Introduction (partially covered in transcripts 3, 5, and 6)\n- Section 2: Agentic Systems Framework (well covered in transcript 6)\n- Section 3: Deep Research Analysis (covered across transcripts 3, 4, and 5)\n- Section 4: Mundane Utility (covered in transcript 2)\n- Section 5: System Design Requirements (well covered in transcript 1)\n\n### Sections Needing More Development:\n- Section 6: Human-AI Collaboration Framework\n  - 6.1 Judgment Integration (touched on but needs elaboration)\n  - 6.2 Tool-Centric Approach (mentioned briefly but needs expansion)\n- Section 7: Future Development Needs\n  - 7.1 Technical Requirements (partially addressed in transcript 4)\n  - 7.2 Process Requirements (touched on in transcript 1 but needs expansion)\n- Section 8: Conclusion (not specifically addressed in any transcript)\n\n### Additional Concepts Not in Original Outline:\n- Aristotelian Fallacy and Carnapian Confirmation\n- Philosophical grounding of literature review purpose\n- Extended discussion of epistemic humility\n- Three-part framework of judgment deficiencies\n",
            "version_uuid": "1fd3c2d4-efe3-4c2c-beb5-da5160605fbb"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "cd3812a9-49f5-4143-985a-3ce2379bb411"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-10T02:34:53.316519Z",
          "stop_timestamp": "2025-03-10T02:34:57.354182Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI've completely reorganized the analysis as requested. Now it:\n\n1. Presents each transcript separately in chronological order\n2. Maps content directly to your original outline sections \n3. Creates a deeply hierarchical structure down to sub-paragraph/idea level\n4. Includes a \"Coverage Analysis\" after each transcript to show which outline sections it addresses\n5. Concludes with a comprehensive \"Coverage Gaps Analysis\" that identifies:\n   - Well-covered sections\n   - Sections needing more development\n   - Additional concepts not in your original outline\n\nThis structure should help you identify where you've talked sufficiently and where you need additional dictation. The hierarchical organization follows the Toulmin model you mentioned, with ideas organized to support larger claims.\n\nWould you like me to analyze any particular transcript in more detail, or would you like suggestions for developing the sections that currently have less coverage?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-10T02:34:57.809525Z",
      "updated_at": "2025-03-10T02:34:57.809525Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "657b4adc-8430-4283-80d6-b171035e780a",
      "text": "Attached are tex files (overleaf via github)\n\nI'd like us to work through getting a complete structure into \"An Absence of Judgement\" (which is what the autoethno paper has become) so that we have LaTeX comments in a section by section design, for a paper suitable for the Journal of Documentation (author guidelines attached)\n\nMy intention is that we get a 1250 word outline for this 5000 word paper. The outline should have no sentences, but recurse down to the subparagraph level. (We'll also figure out where we need more evidence and I'll go find my hypothes.is annotations)\n\n(It's ok if we build out the outline breadth-wise as well. We need to take this very slowly step by step. I've info-dumped over a few weeks and this is the opportunity for you to help me get my head in order, especially as I've not touched it for a week.)\n\nWe're planning a 5k word journal article, and I'm experimenting with how to do this via reflection from you instead of the \"just sit down and write\" style.\n\nBefore we begin, give me a readback, and ask me any ANY questions you have about the process or context.",
      "content": [
        {
          "start_timestamp": "2025-03-06T21:24:19.831059Z",
          "stop_timestamp": "2025-03-06T21:24:19.831059Z",
          "flags": null,
          "type": "text",
          "text": "Attached are tex files (overleaf via github)\n\nI'd like us to work through getting a complete structure into \"An Absence of Judgement\" (which is what the autoethno paper has become) so that we have LaTeX comments in a section by section design, for a paper suitable for the Journal of Documentation (author guidelines attached)\n\nMy intention is that we get a 1250 word outline for this 5000 word paper. The outline should have no sentences, but recurse down to the subparagraph level. (We'll also figure out where we need more evidence and I'll go find my hypothes.is annotations)\n\n(It's ok if we build out the outline breadth-wise as well. We need to take this very slowly step by step. I've info-dumped over a few weeks and this is the opportunity for you to help me get my head in order, especially as I've not touched it for a week.)\n\nWe're planning a 5k word journal article, and I'm experimenting with how to do this via reflection from you instead of the \"just sit down and write\" style.\n\nBefore we begin, give me a readback, and ask me any ANY questions you have about the process or context.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-10T02:53:24.532298Z",
      "updated_at": "2025-03-10T02:53:24.532298Z",
      "attachments": [
        {
          "file_name": "paste.txt",
          "file_size": 51532,
          "file_type": "txt",
          "extracted_content": "Update privacy settings\nWe are using cookies to give you the best experience on our website, but you are free to manage these at any time. To continue with our standard settings click \u201cAccept\u201d. To find out more and manage your cookies, click \u201cManage cookies\u201d\nAccept all cookies\nReject all cookies\nManage cookies\nSkip to main content\nUtility Menu\nSearch\n\nSEARCH\n\nGet in touch\nHome\nMega Menu\nPublish with us\nExplore our content\nDiscover our services\nHow to\nWho we are\nHome Journal Finder Journal of Documentation\n\nJournal of Documentation\nSubmit your paper\nOverview\nAuthor guidelines\nEditorial team\nIndexing & metrics\nReviewers\nCalls for papers & news\nBefore you start\nFor queries relating to the status of your paper pre decision, please contact the Editor or Journal Editorial Office. For queries post acceptance, please contact the Supplier Project Manager. These details can be found in the Editorial Team section.\n\nAuthor responsibilities\nOur goal is to provide you with a professional and courteous experience at each stage of the review and publication process. There are also some responsibilities that sit with you as the author. Our expectation is that you will:\n\nRespond swiftly to any queries during the publication process.\nBe accountable for all aspects of your work. This includes investigating and resolving any questions about accuracy or research integrity.\nTreat communications between you and the journal editor as confidential until an editorial decision has been made.\nRead about our research ethics for authorship. These state that you must:\nInclude anyone who has made a substantial and meaningful contribution to the submission (anyone else involved in the paper should be listed in the acknowledgements).\nExclude anyone who hasn\u2019t contributed to the paper, or who has chosen not to be associated with the research.\nIn accordance with COPE\u2019s position statement on AI tools, Large Language Models cannot be credited with authorship as they are incapable of conceptualising a research design without human direction and cannot be accountable for the integrity, originality, and validity of the published work. The author(s) must describe the content created or modified as well as appropriately cite the name and version of the AI tool used; any additional works drawn on by the AI tool should also be appropriately cited and referenced. Standard tools that are used to improve spelling and grammar are not included within the parameters of this guidance. The Editor and Publisher reserve the right to determine whether the use of an AI tool is permissible.\nIf your article involves human participants, you must ensure you have considered whether or not you require ethical approval for your research, and include this information as part of your submission. Find out more about informed consent.\nGenerative AI usage key principles\nCopywriting any part of an article using a generative AI tool/LLM would not be permissible, including the generation of the abstract or the literature review, for as per Emerald\u2019s authorship criteria, the author(s) must be responsible for the work and accountable for its accuracy, integrity, and validity. In line with standard academic practice, however, Emerald permits the use of examples of generative AI for illustrative purposes as part of scholarly critique and discussion, with the exception of images created by AI tools or large-scale generative models; these examples must be appropriately flagged in the text and be fully cited and referenced in accordance with formatting requirements.\nThe generation or reporting of results using a generative AI tool/LLM is not permissible, for as per Emerald\u2019s authorship criteria, the author(s) must be responsible for the creation and interpretation of their work and accountable for its accuracy, integrity, and validity.\nThe in-text reporting of statistics using a generative AI tool/LLM is not permissible due to concerns over the authenticity, integrity, and validity of the data produced, although the use of such a tool to aid in the analysis of the work would be permissible.\nCopy-editing an article using a generative AI tool/LLM in order to improve its language and readability would be permissible as this mirrors standard tools already employed to improve spelling and grammar, and uses existing author-created material, rather than generating wholly new content, while the author(s) remains responsible for the original work.\nThe submission and publication of images created by AI tools or large-scale generative models is not permitted.\nResearch and publishing ethics\nOur editors and employees work hard to ensure the content we publish is ethically sound. To help us achieve that goal, we closely follow the advice laid out in the guidelines and flowcharts on the COPE (Committee on Publication Ethics) website.\n\nWe have also developed our research and publishing ethics guidelines. If you haven\u2019t already read these, we urge you to do so \u2013 they will help you avoid the most common publishing ethics issues.\n\nA few key points:\n\nAny manuscript you submit to this journal should be original. That means it should not have been published before in its current, or similar, form. Exceptions to this rule are outlined in our pre-print and conference paper policies.  If any substantial element of your paper has been previously published, you need to declare this to the journal editor upon submission. Please note, the journal editor may use Crossref Similarity Check to check on the originality of submissions received. This service compares submissions against a database of 49 million works from 800 scholarly publishers.\nYour work should not have been submitted elsewhere and should not be under consideration by any other publication.\nIf you have a conflict of interest, you must declare it upon submission; this allows the editor to decide how they would like to proceed. Read about conflict of interest in our research and publishing ethics guidelines.\nBy submitting your work to Emerald, you are guaranteeing that the work is not in infringement of any existing copyright.\nIf you have written about a company/individual/organisation in detail using information that is not publicly available, have spent time within that company/organisation, or the work features named/interviewed employees, you will need to clear permission by using the consent to publish form; please also see our permissions guidance for full details. If you have to clear permission with the company/individual/organisation, consent must be given either by the named individual in question or their representative, a board member of the company/organisation, or a HR department representative of the company/organisation.\nYou have an ethical obligation and responsibility to conduct your research in adherence to national and international research ethics guidelines, as well as the ethical principles outlined by your discipline and any relevant authorities, and to be transparent about your research methods in such a way that all involved in the publication process may fairly and appropriately evaluate your work. For all research involving human participants, you must ensure that you have obtained informed consent, meaning that you must inform all participants in your work (or their legal representative) as to why the research is being conducted, whether their anonymity is protected, how their data will be stored and used, and whether there are any associated risks from participation in the study; the submitted work must confirm that informed consent was obtained and detail how this was addressed in accordance with our policy on informed consent.  \nWhere appropriate, you must provide an ethical statement within the submitted work confirming that your research received institutional and national (or international) ethical approval, and that it complies with all relevant guidelines and regulations for studies involving humans, whether that be data, individuals, or samples. Specifically, the statement should contain the name and location of the institutional ethics reviewing committee or review board, the approval number, the date of approval, and the details of the national or international guidelines that were followed, as well as any other relevant information. You should also include details of how the work adheres to relevant consent guidelines along with confirming that informed consent was secured for all participants. The details of these statements should ensure that author and participant anonymity is not compromised. Any work submitted without a suitable ethical statement and details of informed consent for all participants, where required, will be returned to the authors and will not be considered further until appropriate and clear documentation is provided. Emerald reserves the right to reject work without sufficient evidence of informed consent from human participants and ethical approval where required.\nThird party copyright permissions\nPrior to article submission, you need to ensure you\u2019ve applied for, and received, written permission to use any material in your manuscript that has been created by a third party. Please note, we are unable to publish any article that still has permissions pending. The rights we require are:\n\nNon-exclusive rights to reproduce the material in the article or book chapter.\nPrint and electronic rights.\nWorldwide English-language rights.\nTo use the material for the life of the work. That means there should be no time restrictions on its re-use e.g. a one-year licence.\nWe are a member of the International Association of Scientific, Technical, and Medical Publishers (STM) and participate in the STM permissions guidelines, a reciprocal free exchange of material with other STM publishers.  In some cases, this may mean that you don\u2019t need permission to re-use content. If so, please highlight this at the submission stage.\n\nPlease take a few moments to read our guide to publishing permissions to ensure you have met all the requirements, so that we can process your submission without delay.\n\nOpen access submissions and information\nAll our journals currently offer two open access (OA) publishing paths; gold open access and green open access.\n\nIf you would like to, or are required to, make the branded publisher PDF (also known as the version of record) freely available immediately upon publication, you can select the gold open access route once your paper is accepted. \n\nIf you\u2019ve chosen to publish gold open access, this is the point you will be asked to pay the APC (article processing charge). This varies per journal and can be found on our APC price list or on the editorial system at the point of submission. Your article will be published with a Creative Commons CC BY 4.0 user licence, which outlines how readers can reuse your work.\n\nAlternatively, if you would like to, or are required to, publish open access but your funding doesn\u2019t cover the cost of the APC, you can choose the green open access, or self-archiving, route. As soon as your article is published, you can make the author accepted manuscript (the version accepted for publication) openly available, free from payment and embargo periods.\n\nYou can find out more about our open access routes, our APCs and waivers and read our FAQs on our open research page. \n\nFind out about open\n\nTransparency and Openness Promotion (TOP) Guidelines\nWe are a signatory of the Transparency and Openness Promotion (TOP) Guidelines, a framework that supports the reproducibility of research through the adoption of transparent research practices. That means we encourage you to:\n\nCite and fully reference all data, program code, and other methods in your article.\nInclude persistent identifiers, such as a Digital Object Identifier (DOI), in references for datasets and program codes. Persistent identifiers ensure future access to unique published digital objects, such as a piece of text or datasets. Persistent identifiers are assigned to datasets by digital archives, such as institutional repositories and partners in the Data Preservation Alliance for the Social Sciences (Data-PASS).\nFollow appropriate international and national procedures with respect to data protection, rights to privacy and other ethical considerations, whenever you cite data. For further guidance please refer to our research and publishing ethics guidelines. For an example on how to cite datasets, please refer to the references section below.\nPrepare your submission\nManuscript support services\nWe are pleased to partner with Editage, a platform that connects you with relevant experts in language support, translation, editing, visuals, consulting, and more. After you\u2019ve agreed a fee, they will work with you to enhance your manuscript and get it submission-ready.\n\nThis is an optional service for authors who feel they need a little extra support. It does not guarantee your work will be accepted for review or publication.\n\nVisit Editage\n\nManuscript requirements\nBefore you submit your manuscript, it\u2019s important you read and follow the guidelines below. You will also find some useful tips in our structure your journal submission how-to guide.\n\nFormat\t\nArticle files should be provided in Microsoft Word format.\n\nWhile you are welcome to submit a PDF of the document alongside the Word file, PDFs alone are not acceptable. LaTeX files can also be used but only if an accompanying PDF document is provided. Acceptable figure file types are listed further below.\n\nArticle length / word count\t\nArticles should be between 4000  and 10000 words in length. This includes all text, for example, the structured abstract, references, all text in tables, and figures and appendices. \n\nPlease allow 250 words for each figure or table.\n\nArticle title\tA concisely worded title should be provided.\nAuthor details\t\nThe names of all contributing authors should be added to the ScholarOne submission; please list them in the order in which you\u2019d like them to be published. Each contributing author will need their own ScholarOne author account, from which we will extract the following details:\n\nAuthor email address (institutional preferred).\nAuthor name. We will reproduce it exactly, so any middle names and/or initials they want featured must be included.\nAuthor affiliation. This should be where they were based when the research for the paper was conducted.\nIn multi-authored papers, it\u2019s important that ALL authors that have made a significant contribution to the paper are listed. Those who have provided support but have not contributed to the research should be featured in an acknowledgements section. You should never include people who have not contributed to the paper or who don\u2019t want to be associated with the research. Read about our research ethics for authorship.\n\nBiographies and acknowledgements\t\nIf you want to include these items, save them in a separate Microsoft Word document and upload the file with your submission. Where they are included, a brief professional biography of not more than 100 words should be supplied for each named author.\n\nResearch funding\tYour article must reference all sources of external research funding in the acknowledgements section. You should describe the role of the funder or financial sponsor in the entire research process, from study design to submission.\nStructured abstract\t\nAll submissions must include a structured abstract, following the format outlined below.\n\nThese four sub-headings and their accompanying explanations must always be included:\n\nPurpose\nDesign/methodology/approach\nFindings\nOriginality\nThe following three sub-headings are optional and can be included, if applicable:\n\nResearch limitations/implications\nPractical implications\nSocial implications\n\nYou can find some useful tips in our write an article abstract how-to guide.\n\nThe maximum length of your abstract should be 250 words in total, including keywords and article classification (see the sections below).\n\nKeywords\t\nYour submission should include up to 12 appropriate and short keywords that capture the principal topics of the paper. Our Creating an SEO-friendly manuscript how to guide contains some practical guidance on choosing search-engine friendly keywords.\n\nPlease note, while we will always try to use the keywords you\u2019ve suggested, the in-house editorial team may replace some of them with matching terms to ensure consistency across publications and improve your article\u2019s visibility.\n\nArticle classification\t\nDuring the submission process, you will be asked to select a type for your paper; the options are listed below. If you don\u2019t see an exact match, please choose the best fit:\n\nArticle\nReview\nShort Review\nYou will also be asked to select a category for your paper. The options for this are listed below. If you don\u2019t see an exact match, please choose the best fit:\n\nResearch paper. Reports on any type of research undertaken by the author(s), including:\n\nThe construction or testing of a model or framework\nAction research\nTesting of data, market research or surveys\nEmpirical, scientific or clinical research\nPapers with a practical focus\nViewpoint. Covers any paper where content is dependent on the author's opinion and interpretation. This includes journalistic and magazine-style pieces.\n\nTechnical paper. Describes and evaluates technical products, processes or services.\n\nConceptual paper. Focuses on developing hypotheses and is usually discursive. Covers philosophical discussions and comparative studies of other authors\u2019 work and thinking.\n\nCase study. Describes actual interventions or experiences within organizations. It can be subjective and doesn\u2019t generally report on research. Also covers a description of a legal case or a hypothetical case study used as a teaching exercise.\n\nLiterature review. This category should only be used if the main purpose of the paper is to annotate and/or critique the literature in a particular field. It could be a selective bibliography providing advice on information sources, or the paper may aim to cover the main contributors to the development of a topic and explore their different views.\n\nGeneral review. Provides an overview or historical examination of some concept, technique or phenomenon. Papers are likely to be more descriptive or instructional (\u2018how to\u2019 papers) than discursive.\n\nHeadings\tHeadings must be concise, with a clear indication of the required hierarchy. \n\nThe preferred format is for first level headings to be in bold, and subsequent sub-headings to be in medium italics.\nNotes/endnotes\tNotes or endnotes should only be used if absolutely necessary. They should be identified in the text by consecutive numbers enclosed in square brackets. These numbers should then be listed, and explained, at the end of the article.\nFigures\t\nAll figures (charts, diagrams, line drawings, webpages/screenshots, and photographic images) should be submitted electronically. Both colour and black and white files are accepted.\n\nThere are a few other important points to note:\n\nAll figures should be supplied at the highest resolution/quality possible with numbers and text clearly legible.\nAcceptable formats are .ai, .eps, .jpeg, .bmp, and .tif.\nElectronic figures created in other applications should be supplied in their original formats and should also be either copied and pasted into a blank MS Word document, or submitted as a PDF file.\nAll figures should be numbered consecutively with Arabic numerals and have clear captions.\nAll photographs should be numbered as Plate 1, 2, 3, etc. and have clear captions.\nAll figure/table captions should include the necessary credit line, acknowledgement, or attribution if you have been given permission to use the figure/table; if the figure/table is the property of the author(s), this should be acknowledged in the caption.\nTables\t\nTables should be typed and submitted in a separate file to the main body of the article. The position of each table should be clearly labelled in the main body of the article with corresponding labels clearly shown in the table file. Tables should be numbered consecutively in Roman numerals (e.g. I, II, etc.).\n\nGive each table a brief title. Ensure that any superscripts or asterisks are shown next to the relevant items and have explanations displayed as footnotes to the table, figure or plate.\n\nSupplementary files\t\nWhere tables, figures, appendices, and other additional content are supplementary to the article but not critical to the reader\u2019s understanding of it, you can choose to host these supplementary files alongside your article on Insight, Emerald\u2019s content-hosting platform (this is Emerald's recommended option as we are able to ensure the data remain accessible), or on an alternative trusted online repository. All supplementary material must be submitted prior to acceptance.\n\nEmerald recommends that authors use the following two lists when searching for a suitable and trusted repository:\n\nhttps://commons.datacite.org/repositories\nhttps://www.re3data.org \nIf you choose to host your supplementary files on Insight, you must submit these as separate files alongside your article. Files should be clearly labelled in such a way that makes it clear they are supplementary; Emerald recommends that the file name is descriptive and that it follows the format \u2018Supplementary_material_appendix_1\u2019 or \u2018Supplementary tables\u2019. All supplementary material must be mentioned at the appropriate moment in the main text of the article; there is no need to include the content of the file only the file name. A link to the supplementary material will be added to the article during production, and the material will be made available alongside the main text of the article at the point of EarlyCite publication.\n\nPlease note that Emerald will not make any changes to the material; it will not be copy-edited or typeset, and authors will not receive proofs of this content. Emerald therefore strongly recommends that you style all supplementary material ahead of acceptance of the article.\n\nEmerald Insight can host the following file types and extensions:\n\nAdobe Acrobat (.pdf)\nMS Word document (.doc, .docx)\nMS Excel (.xls, xlsx)\nMS PowerPoint (.pptx)\nImage (.png, .jpeg, .gif)\nPlain ASCII text (.txt)\nPostScript (.ps)\nRich Text Format (.rtf)\nIf you choose to use an alternative trusted online repository, you should ensure that the supplementary material is hosted on the repository ahead of submission, and then include a link only to the repository within the article. It is the responsibility of the submitting author to ensure that the material is free to access and that it remains permanently available. Where an alternative trusted online repository is used, the files hosted should always be presented as read-only; please be aware that such usage risks compromising your anonymity during the review process if the repository contains any information that may enable the reviewer to identify you; as such, we recommend that all links to alternative repositories are reviewed carefully prior to submission.\n\nPlease note that extensive supplementary material may be subject to peer review; this is at the discretion of the journal Editor and dependent on the content of the material (for example, whether including it would support the reviewer making a decision on the article during the peer review process).\n\nReferences\n\nAll references in your manuscript must be formatted using one of the recognised Harvard styles. You are welcome to use the Harvard style Emerald has adopted \u2013 we\u2019ve provided a detailed guide below. Want to use a different Harvard style? That\u2019s fine, our typesetters will make any necessary changes to your manuscript if it is accepted. Please ensure you check all your citations for completeness, accuracy and consistency.\n\nEmerald\u2019s Harvard referencing style\n\nReferences to other publications in your text should be written as follows:\n\nSingle author: (Adams, 2006)\nTwo authors: (Adams and Brown, 2006)\nThree or more authors: (Adams et al., 2006) Please note, \u2018et al' should always be written in italics.\nA few other style points. These apply to both the main body of text and your final list of references.\n\nWhen referring to pages in a publication, use \u2018p.(page number)\u2019 for a single page or \u2018pp.(page numbers)\u2019 to indicate a page range.\nPage numbers should always be written out in full, e.g. 175-179, not 175-9.\nWhere a colon or dash appears in the title of an article or book chapter, the letter that follows that colon or dash should always be lower case.\nWhen citing a work with multiple editors, use the abbreviation \u2018Ed.s\u2019.\nAt the end of your paper, please supply a reference list in alphabetical order using the style guidelines below. Where a DOI is available, this should be included at the end of the reference.\n\nFor books\t\nSurname, initials (year), title of book, publisher, place of publication.\n\ne.g. Harrow, R. (2005), No Place to Hide, Simon & Schuster, New York, NY.\n\nFor book chapters\t\nSurname, initials (year), \"chapter title\", editor's surname, initials (Ed.), title of book, publisher, place of publication, page numbers.\n\ne.g. Calabrese, F.A. (2005), \"The early pathways: theory to practice \u2013 a continuum\", Stankosky, M. (Ed.), Creating the Discipline of Knowledge Management, Elsevier, New York, NY, pp.15-20.\n\nFor journals\t\nSurname, initials (year), \"title of article\", journal name, volume issue, page numbers.\n\ne.g. Capizzi, M.T. and Ferguson, R. (2005), \"Loyalty trends for the twenty-first century\", Journal of Consumer Marketing, Vol. 22 No. 2, pp.72-80.\n\nFor published \nconference proceedings\t\nSurname, initials (year of publication), \"title of paper\", in editor\u2019s surname, initials (Ed.), title of published proceeding which may include place and date(s) held, publisher, place of publication, page numbers.\n\ne.g. Wilde, S. and Cox, C. (2008), \u201cPrincipal factors contributing to the competitiveness of tourism destinations at varying stages of development\u201d, in Richardson, S., Fredline, L., Patiar A., & Ternel, M. (Ed.s), CAUTHE 2008: Where the 'bloody hell' are we?, Griffith University, Gold Coast, Qld, pp.115-118.\n\nFor unpublished \nconference proceedings\t\nSurname, initials (year), \"title of paper\", paper presented at [name of conference], [date of conference], [place of conference], available at: URL if freely available on the internet (accessed date).\n\ne.g. Aumueller, D. (2005), \"Semantic authoring and retrieval within a wiki\", paper presented at the European Semantic Web Conference (ESWC), 29 May-1 June, Heraklion, Crete, available at: http://dbs.uni-leipzig.de/file/aumueller05wiksar.pdf (accessed 20 February 2007).\n\nFor working papers\t\nSurname, initials (year), \"title of article\", working paper [number if available], institution or organization, place of organization, date.\n\ne.g. Moizer, P. (2003), \"How published academic research can inform policy decisions: the case of mandatory rotation of audit appointments\", working paper, Leeds University Business School, University of Leeds, Leeds, 28 March.\n\nFor encyclopaedia entries \n(with no author or editor)\t\nTitle of encyclopaedia (year), \"title of entry\", volume, edition, title of encyclopaedia, publisher, place of publication, page numbers.\n\ne.g. Encyclopaedia Britannica (1926), \"Psychology of culture contact\", Vol. 1, 13th ed., Encyclopaedia Britannica, London and New York, NY, pp.765-771.\n\n(for authored entries, please refer to book chapter guidelines above)\n\nFor newspaper \narticles (authored)\t\nSurname, initials (year), \"article title\", newspaper, date, page numbers.\n\ne.g. Smith, A. (2008), \"Money for old rope\", Daily News, 21 January, pp.1, 3-4.\n\nFor newspaper \narticles (non-authored)\t\nNewspaper (year), \"article title\", date, page numbers.\n\ne.g. Daily News (2008), \"Small change\", 2 February, p.7.\n\nFor archival or other unpublished sources\t\nSurname, initials (year), \"title of document\", unpublished manuscript, collection name, inventory record, name of archive, location of archive.\n\ne.g. Litman, S. (1902), \"Mechanism & Technique of Commerce\", unpublished manuscript, Simon Litman Papers, Record series 9/5/29 Box 3, University of Illinois Archives, Urbana-Champaign, IL.\n\nFor electronic sources\t\nIf available online, the full URL should be supplied at the end of the reference, as well as the date that the resource was accessed.\n\nSurname, initials (year), \u201ctitle of electronic source\u201d, available at: persistent URL (accessed date month year).\n\ne.g. Weida, S. and Stolley, K. (2013), \u201cDeveloping strong thesis statements\u201d, available at: https://owl.english.purdue.edu/owl/resource/588/1/ (accessed 20 June 2018)\n\nStandalone URLs, i.e. those without an author or date, should be included either inside parentheses within the main text, or preferably set as a note (Roman numeral within square brackets within text followed by the full URL address at the end of the paper).\n\nFor data\t\nSurname, initials (year), title of dataset, name of data repository, available at: persistent URL, (accessed date month year).\n\ne.g. Campbell, A. and Kahn, R.L. (2015), American National Election Study, 1948, ICPSR07218-v4, Inter-university Consortium for Political and Social Research (distributor), Ann Arbor, MI, available at: https://doi.org/10.3886/ICPSR07218.v4 (accessed 20 June 2018)\n\nSubmit your manuscript\nThere are a number of key steps you should follow to ensure a smooth and trouble-free submission.\n\nDouble check your manuscript\nBefore submitting your work, it is your responsibility to check that the manuscript is complete, grammatically correct, and without spelling or typographical errors. A few other important points:\n\nGive the journal aims and scope a final read. Is your manuscript definitely a good fit? If it isn\u2019t, the editor may decline it without peer review.\nDoes your manuscript comply with our research and publishing ethics guidelines?\nHave you cleared any necessary publishing permissions?\nHave you followed all the formatting requirements laid out in these author guidelines?\nDoes the manuscript contain any information that might help the reviewer identify you? This could compromise the anonymous peer review process. A few tips:\nIf you need to refer to your own work, use wording such as \u2018previous research has demonstrated\u2019 not \u2018our previous research has demonstrated\u2019.\nIf you need to refer to your own, currently unpublished work, don\u2019t include this work in the reference list.\nAny acknowledgments or author biographies should be uploaded as separate files.\nCarry out a final check to ensure that no author names appear anywhere in the manuscript. This includes in figures or captions.\nYou will find a helpful submission checklist on the website Think.Check.Submit.\n\nThe submission process\nAll manuscripts should be submitted through our editorial system by the corresponding author.\n\nThe only way to submit to the journal is through the journal\u2019s ScholarOne site as accessed via the Emerald website, and not by email or through any third-party agent/company, journal representative, or website. Submissions should be done directly by the author(s) through the ScholarOne site and not via a third-party proxy on their behalf.\n\nA separate author account is required for each journal you submit to. If this is your first time submitting to this journal, please choose the Create an account or Register now option in the editorial system. If you already have an Emerald login, you are welcome to reuse the existing username and password here.\n\nPlease note, the next time you log into the system, you will be asked for your username. This will be the email address you entered when you set up your account.\n\nDon't forget to add your ORCiD ID during the submission process. It will be embedded in your published article, along with a link to the ORCiD registry allowing others to easily match you with your work.\n\nDon\u2019t have one yet? It only takes a few moments to register for a free ORCiD identifier.\n\nVisit the ScholarOne support centre for further help and guidance.\n\nWhat you can expect next\nYou will receive an automated email from the journal editor, confirming your successful submission. It will provide you with a manuscript number, which will be used in all future correspondence about your submission. If you have any reason to suspect the confirmation email you receive might be fraudulent, please contact the journal editor in the first instance.\n\nPost submission\nReview and decision process\nEach submission is checked by the editor. At this stage, they may choose to decline or unsubmit your manuscript if it doesn\u2019t fit the journal aims and scope, or they feel the language/manuscript quality is too low.\n\nIf they think it might be suitable for the publication, they will send it to at least two independent referees for double anonymous peer review.  Once these reviewers have provided their feedback, the editor may decide to accept your manuscript, request minor or major revisions, or decline your work.\n\nWhile all journals work to different timescales, the goal is that the editor will inform you of their first decision within 60 days.\n\nDuring this period, we will send you automated updates on the progress of your manuscript via our submission system, or you can log in to check on the current status of your paper.  Each time we contact you, we will quote the manuscript number you were given at the point of submission. If you receive an email that does not match these criteria, it could be fraudulent and we recommend you contact the journal editor in the first instance.\n\nManuscript transfer service\nEmerald\u2019s manuscript transfer service takes the pain out of the submission process if your manuscript doesn\u2019t fit your initial journal choice. Our team of expert Editors from participating journals work together to identify alternative journals that better align with your research, ensuring your work finds the ideal publication home it deserves. Our dedicated team is committed to supporting authors like you in finding the right home for your research.\n\nIf a journal is participating in the manuscript transfer program, the Editor has the option to recommend your paper for transfer. If a transfer decision is made by the Editor, you will receive an email with the details of the recommended journal and the option to accept or reject the transfer. It\u2019s always down to you as the author to decide if you\u2019d like to accept. If you do accept, your paper and any reviewer reports will automatically be transferred to the recommended journals. Authors will then confirm resubmissions in the new journal\u2019s ScholarOne system.\n\nOur Manuscript Transfer Service page has more information on the process.\n\nIf your submission is accepted\nOpen access\nOnce your paper is accepted, you will have the opportunity to indicate whether you would like to publish your paper via the gold open access route.\n\nIf you\u2019ve chosen to publish gold open access, this is the point you will be asked to pay the APC (article processing charge).  This varies per journal and can be found on our APC price list or on the editorial system at the point of submission. Your article will be published with a Creative Commons CC BY 4.0 user licence, which outlines how readers can reuse your work.\n\nFor UK journal article authors - if you wish to submit your work accepted by Emerald to REF 2021, you must make a \u2018closed deposit\u2019 of your accepted manuscript to your respective institutional repository upon acceptance of your article. Articles accepted for publication after 1st April 2018 should be deposited as soon as possible, but no later than three months after the acceptance date. For further information and guidance, please refer to the REF 2021 website.\n\nCopyright\nAll accepted authors are sent an email with a link to a licence form.  This should be checked for accuracy, for example whether contact and affiliation details are up to date and your name is spelled correctly, and then returned to us electronically. If there is a reason why you can\u2019t assign copyright to us, you should discuss this with your journal content editor. You will find their contact details on the editorial team section above.\n\nProofing and typesetting\nOnce we have received your completed licence form, the article will pass directly into the production process. We will carry out editorial checks, copyediting, and typesetting and then return proofs to you (if you are the corresponding author) for your review. This is your opportunity to correct any typographical errors, grammatical errors or incorrect author details. We can\u2019t accept requests to rewrite texts at this stage.\n\nWhen the page proofs are finalised, the fully typeset and proofed version of record is published online. This is referred to as the EarlyCite version. While an EarlyCite article has yet to be assigned to a volume or issue, it does have a digital object identifier (DOI) and is fully citable. It will be compiled into an issue according to the journal\u2019s issue schedule, with papers being added by chronological date of publication.\n\nHow to share your paper\nVisit our author rights page to find out how you can reuse and share your work.\n\nTo find tips on increasing the visibility of your published paper, read about how to promote your work.\n\nCorrecting inaccuracies in your published paper\nSometimes errors are made during the research, writing and publishing processes. When these issues arise, we have the option of withdrawing the paper or introducing a correction notice. Find out more about our article withdrawal and correction policies.\n\nNeed to make a change to the author list? See our frequently asked questions (FAQs) below.\n\nFrequently asked questions\nIs there a submission fee\nfor the journal?\t\nThe only time we will ever ask you for money to publish in an Emerald journal is if you have chosen to publish via the gold open access route. You will be asked to pay an APC (article-processing charge) once your paper has been accepted (unless it is a sponsored open access journal), and never at submission.\n\nRead about our APCs\n\nAt no other time will you be asked to contribute financially towards your article\u2019s publication, processing, or review. If you haven\u2019t chosen gold open access and you receive an email that appears to be from Emerald, the journal, or a third party, asking you for payment to publish, please contact our support team via support@emerald.com.\n\nHow can I become\na reviewer for a journal?\tPlease contact the editor for the journal, with a copy of your CV. You will find their contact details on the editorial team tab on this page.\nWho do I contact if I want to find out which volume and issue my accepted paper will appear in?\t\nTypically, papers are added to an issue according to their date of publication. If you would like to know in advance which issue your paper will appear in, please contact the content editor of the journal. You will find their contact details on the editorial team tab on this page. Once your paper has been published in an issue, you will be notified by email.\n\nWho do I contact if I have\na query about my submission?\tPlease email the journal editor \u2013 you will find their contact details on the editorial team tab on this page. If you ever suspect an email you\u2019ve received from Emerald might not be genuine, you are welcome to verify it with the content editor for the journal, whose contact details can be found on the editorial team tab on this page.\nIs my paper suitable\nfor the journal?\tIf you\u2019ve read the aims and scope on the journal landing page and are still unsure whether your paper is suitable for the journal, please email the editor and include your paper's title and structured abstract. They will be able to advise on your manuscript\u2019s suitability. You will find their contact details on the Editorial team tab on this page.\nHow do I make a change to the list of authors once the manuscript has been submitted?\tAuthorship and the order in which the authors are listed on the paper should be agreed prior to submission. We have a right first time policy on this and no changes can be made to the list once submitted. If you have made an error in the submission process, please email the Journal Editorial Office who will look into your request \u2013 you will find their contact details on the editorial team tab on this page.\n \nEditor\nProfessor David Bawden\nCity University London - UK\ndavidbawden.occinf@gmail.com\nCommissioning Editor\nCharlotte Eagles\nEmerald Publishing\nCeagles@emerald.com\nJournal Editorial Office (For queries related to pre-acceptance)\nPoonam Sawant\nEmerald Publishing\nPoonam.Emerald@kwglobal.com\nSupplier Project Manager (For queries related to post-acceptance)\nSuryalakshmi Balakrishnan\nEmerald Publishing\nsuryalakshmi.emerald@tnqtech.com\nEditorial Advisory Board\nDr. Jack Andersen\nUniversity of Copenhagen - Denmark\nProfessor Tatjana Aparac-Jelusic\nUniversity of Osijek - Croatia\nProfessor Pia Borlund\nOslo Met - Denmark\nDr Keren Dali\nUniversity of Denver - USA\nProfessor Ron Day\nIndiana University - USA\nProfessor Andrew Dillon\nUniversity of Texas - Austin - USA\nProfessor Nigel Ford\nUniversity of Sheffield - UK\nProfessor Jonathan Furner\nUCLA Graduate School of Education & Information Studies - USA\nDr. Claudio Gnoli\nUniversity of Pavia - Italy\nDr Tim Gorichanaz\nDrexel University - USA\nProfessor Philip Hider\nCharles Sturt University - Australia\nProfessor Birger Hjorland\nRoyal School of Library & Information Science - Denmark\nDr Kiersten Latham\nProfessor Annemaree Lloyd\nUniversity College London - UK\nDr Brendan Luyt\nWee Kim Wee School of Communication and Information Nanyang Technological University - Singapore\nDr. Jens-Erik Mai\nProfessor & Head of Department Department of Communication, University of Copenhagen - Denmark\nProfessor Julie McLeod\nNorthumbria University - UK\nDr. David McMenemy\nUniversity of Glasgow - UK\nDr Silvio Peroni\nUniversity of Bologna - Italy\nMs Ramune Petuchovaite\nEIFL PLIP - Lithuania\nProf. Ian Ruthven\nUniversity of Strathclyde - UK\nProf. Reijo Savolainen\nDepartment of Information Studies, University of Tampere - Finland\nProfessor Olof Sundin\nLund University - Sweden\nDr Christine Urquhart\nDepartment of Information and Library Studies, University of Wales, Aberystwyth - UK\nProfessor Pertti Vakkari\nDepartment of Information Studies, University of Tampere - Finland\nCitation metrics\nScopus Logo\n4.2\n\nCiteScore 2023\n\nMore info\n\nScopus Logo\n4.2\n\nCiteScore 2023\n\nFurther information\nCiteScore is a simple way of measuring the citation impact of sources, such as journals.\n\n \n\nCalculating the CiteScore is based on the number of citations to documents (articles, reviews, conference papers, book chapters, and data papers) by a journal over four years, divided by the number of the same document types indexed in Scopus and published in those same four years.\n\n \n\nFor more information and methodology visit the Scopus definition\n\n \n\nScopus Logo\n4.7\n\nCiteScore Tracker 2024\n\n(updated monthly)\n\nMore info\n\nScopus Logo\n4.7\n\nCiteScore Tracker 2024\n\n(updated monthly)\n\nFurther information\nCiteScore is a simple way of measuring the citation impact of sources, such as journals.\n\n \n\nCiteScore Tracker is calculated in the same way as CiteScore, but for the current year rather than previous, complete years.\n\n \n\nThe CiteScore Tracker calculation is updated every month, as a current indication of a title's performance.\n\n \n\nFor more information and methodology visit the Scopus definition\n\nClarivate analytics logo\n1.7\n\n2023 Impact Factor\n\nMore info\n\nClarivate analytics logo\n1.7\n\n2023 Impact Factor\n\nFurther information\nThe Journal Impact Factor is published each year by Clarivate Analytics. It is a measure of the number of times an average paper in a particular journal is cited during the preceding two years.\n\n \n\nFor more information and methodology see Clarivate Analytics\n\nClarivate analytics logo\n1.8\n\n5-year Impact Factor (2023)\n\nMore info\n\nClarivate analytics logo\n1.8\n\n5-year Impact Factor (2023)\n\nFurther information\nA base of five years may be more appropriate for journals in certain fields because the body of citations may not be large enough to make reasonable comparisons, or it may take longer than two years to publish and distribute leading to a longer period before others cite the work.\n\n \n\nActual value is intentionally only displayed for the most recent year. Earlier values are available in the Journal Citation Reports from Clarivate Analytics.\n\nPublication timeline\nTime to first decision\n\n44\n\ndays\n\nMore info\n\nTime to first decision\n\n44\n\ndays\n\nFurther information\nTime to first decision, expressed in days, the \"first decision\" occurs when the journal\u2019s editorial team reviews the peer reviewers\u2019 comments and recommendations. Based on this feedback, they decide whether to accept, reject, or request revisions for the manuscript.\n\nData is taken from submissions between 1st June 2023 and 31st May 2024\n\nAcceptance to publication\n\n47\n\ndays\n\nMore info\n\nAcceptance to publication\n\n47\n\ndays\n\nFurther information\nAcceptance to publication, expressed in days, is the average time between when the journal\u2019s editorial team decide whether to accept, reject, or request revisions for the manuscript and the date of publication in the journal. \n\n \n\nData is taken from the previous 12 months (Last updated July 2024)\n\nAcceptance rate\n\n29\n\n%\n\nMore info\n\nAcceptance rate\n\n29\n\n%\n\nFurther information\nThe acceptance rate is a measurement of how many manuscripts a journal accepts for publication compared to the total number of manuscripts submitted expressed as a percentage %\n\nData is taken from submissions between 1st June 2023 and 31st May 2024.\n\nUsage\nDownloads\n\n31680\n\nArticles\n\nMore info\n\nDownloads\n\n31680\n\nArticles\n\nFurther information\nThis figure is the total amount of downloads for all articles published early cite in the last 12 months\n\n \n\n(Last updated: July 2024)\n\nThis journal is abstracted and indexed by\nThe Publication Forum (Finland), BFI (Denmark)\nCORE Rankings\nPolish Ministry of Science and Higher Education\nABI/INFORM Complete\nABI/INFORM Global\nArts &\nHumanities Full Text\nCabell\u2019s Directory of Publishing Opportunities in Management\nThe Chartered Association of Business Schools' Academic Journal Guide (2)\nComputer Science Index Index\nComputers and Applied Sciences Complete\nCurrent Abstracts\nEducation Full Text\nEducation Research ERIC\u00ae\nFMS - B\nInformation Science and Technology Abstracts (ISTA);Library and Information Science Abstracts\nLibrary, Information Science and Technology Abstracts\nLibrary Literature and Information Science Full Text\nOmniFile Full Text Mega\nOmniFile Full Text Select\nProfessional ABI/INFORM Complete\nProfessional ProQuest Central\nProQuest Central\nProQuest Curriculum Essentials\nProQuest Education Journals\nProQuest Library Science\nProQuest Pharma Collection\nSocial Sciences Citation Index\nThe Informed Librarian\nScopus\nzetoc\nReviewer information\n\nPeer review process\nThis journal engages in a double-anonymous peer review process, which strives to match the expertise of a reviewer with the submitted manuscript. Reviews are completed with evidence of thoughtful engagement with the manuscript, provide constructive feedback, and add value to the overall knowledge and information presented in the manuscript.\n\nMission\nThe mission of the peer review process is to achieve excellence and rigour in scholarly publications and research.\n\nVision\nOur vision is to give voice to professionals in the subject area who contribute unique and diverse scholarly perspectives to the field.\n\nValues\nThe journal values diverse perspectives from the field and reviewers who provide critical, constructive, and respectful feedback to authors. Reviewers come from a variety of organizations, careers, and backgrounds from around the world.\n\nEthics\nAll invitations to review, abstracts, manuscripts, and reviews should be kept confidential. Reviewers must not share their review or information about the review process with anyone without the agreement of the editors and authors involved, even after publication. This also applies to other reviewers\u2019 \u201ccomments to author\u201d which are shared with you on decision.\n\n\nResources to guide you through the review process\nDiscover practical tips and guidance on all aspects of peer review in our reviewers' section. See how being a reviewer could benefit your career, and discover what's involved in shaping a review.\n\nMore reviewer information\n\nNews\nThank you to the 2023 Reviewers\nThe publishing and editorial teams would like to thank the following, for their invaluable service as 2023 reviewers for this journal. We are very grateful for the contributions made. With their help, the journal has been able to publish such high...\n\n17/08/2024\nThank you to the 2023 Reviewers\nThank you to the 2022 Reviewers\nThe publishing and editorial teams would like to thank the following, for their invaluable service as 2022 reviewers for this journal. We are very grateful for the contributions made. With their help, the journal has been able to publish such high...\n\n08/08/2023\nThank you to the 2022 Reviewers\nThank you to the 2021 Reviewers\nThe publishing and editorial teams would like to thank the following, for their invaluable service as 2021 reviewers for this journal. We are very grateful for the contributions made. With their help, the journal has been able to publish such high...\n\n13/09/2022\nThank you to the 2021 Reviewers\n2020 Reviewers for Journal of Documentation\nThank you to our 2020 peer reviewers The publishing and editorial teams would like to thank the following, for their invaluable service as 2020&n...\n\n12/06/2020\n2020 Reviewers for Journal of Documentation\nALCTS Outstanding Publication Award for Journal of Documentation\nRachel Ivy Clarke and Sayward Schoonmaker, authors of the article \u201cMetadata for diversity: Identification and implications of potential access points for diverse library r...\n\n25/03/2020\nALCTS Outstanding Publication Award for Journal of Documentation\nLiterati awards\n\nJournal of Documentation - Literati Award Winners 2024\nWe are pleased to announce our 2024 Literati Award winners. Outstanding Paper \u201cSo how do we balance all of these needs?\u201d: how the ...\n\nJournal of Documentation - Literati Award Winners 2024\nFireworks celebration \nJournal of Documentation\u202f- Literati Award Winners 2023\nWe are pleased to announce our 2023 Literati Award winners. Outstanding Paper Time and Temporality in Library and Infor...\n\nJournal of Documentation\u202f- Literati Award Winners 2023\n\nJournal of Documentation\u202f- Literati Award Winners 2022\u202f\nWe are pleased to announce our 2022 Literati Award winners. Outstanding Paper Documenting information making ...\n\nJournal of Documentation\u202f- Literati Award Winners 2022\u202f\n\nJournal of Documentation - Literati Award Winners 2020\nWe are pleased to announce our 2020 Literati Award winners. Outstanding Paper Hyperdocumentation: origin and evolution of a concept...\n\nJournal of Documentation - Literati Award Winners 2020\nHome\nFooter\nEmerald Insight\nBookstore\nAbout Emerald\nContact us\nOur awards\nOur leadership team\nWork with us\nSitemap\nOur services\nAuthors\nEditors\nLibrarians\nResearchers\nReviewers\nPolicies & information\nPrivacy\nModern Slavery Act\nChair of Trustees governance statement\nAccessibility\n\u00a9 2025 Emerald Publishing Limited. All rights reserved, including rights for text and data mining, artificial intelligence training and similar technologies.\n"
        }
      ],
      "files": [
        {
          "file_name": "paste.txt"
        }
      ]
    },
    {
      "uuid": "4a7438f7-966a-428d-ab81-2ab3668ec768",
      "text": "\nLet me understand what we're doing here:\n\n1. You want to create a detailed, hierarchical outline for a 5,000-word academic paper titled \"An Absence of Judgment\" for the Journal of Documentation.\n\n2. The outline should be approximately 1,250 words, contain no full sentences, and be recursively structured down to the subparagraph level.\n\n3. This outline will be formatted for LaTeX, with appropriate comments indicating the structure.\n\n4. The transcripts and documents you've provided represent dictated thoughts, research notes, and planning materials that need to be organized into a coherent structure.\n\n5. You want to work through this step by step and breadth-wise, building out the complete structure of the paper.\n\n6. You're using this as an experiment in collaborative paper development rather than just writing it directly.\n\nQuestions I have:\n\n1. Should I integrate LaTeX formatting directly into the outline, or would you prefer a clean outline that you'll later convert to LaTeX?\n\n2. For the hierarchical structure, how many levels deep should we go? (e.g., sections, subsections, paragraphs, sub-paragraphs)\n\n3. Would you like me to flag areas where your transcripts suggest you need more evidence or development?\n\n4. Do you have a specific structure in mind already, or should I extract a logical structure from the material provided?\n\n5. Are there any specific requirements from the Journal of Documentation that should guide the structure (beyond word count)?\n\n6. Should I incorporate elements from the existing draft in \"AnAbsenceOfJudgement.tex\" or is this a fresh restructuring?\n\nI understand your request. You want me to help you create a detailed, hierarchical outline for your 5,000-word academic paper titled \"An Absence of Judgment\" for the Journal of Documentation. This outline should:\n\n1. Be around 1,250 words\n2. Contain no sentences, just structured points\n3. Recurse down to the subparagraph level\n4. Be organized with LaTeX comments for section structure\n5. Help identify areas where you need more evidence\n\nI see you've shared transcripts of dictated thoughts, your current paper draft, planning notes, and research process documentation. I'll use these to create a comprehensive outline that captures your ideas while maintaining the structure needed for academic publication.\n\nBefore I begin, I have a few questions:\n\n1. How closely should I follow the structure of your existing draft versus reorganizing based on all materials provided?\n2. Would you like me to indicate where specific transcripts/dictations support each section?\n3. For the LaTeX comments, do you prefer a specific format or style?\n4. Are there any sections from the Journal of Documentation guidelines that you particularly want to emphasize?\n5. Any specific theoretical frameworks you want to ensure are represented in the outline?",
      "content": [
        {
          "start_timestamp": "2025-03-10T02:53:29.841793Z",
          "stop_timestamp": "2025-03-10T02:53:36.056365Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nLet me understand what we're doing here:\n\n1. You want to create a detailed, hierarchical outline for a 5,000-word academic paper titled \"An Absence of Judgment\" for the Journal of Documentation.\n\n2. The outline should be approximately 1,250 words, contain no full sentences, and be recursively structured down to the subparagraph level.\n\n3. This outline will be formatted for LaTeX, with appropriate comments indicating the structure.\n\n4. The transcripts and documents you've provided represent dictated thoughts, research notes, and planning materials that need to be organized into a coherent structure.\n\n5. You want to work through this step by step and breadth-wise, building out the complete structure of the paper.\n\n6. You're using this as an experiment in collaborative paper development rather than just writing it directly.\n\nQuestions I have:\n\n1. Should I integrate LaTeX formatting directly into the outline, or would you prefer a clean outline that you'll later convert to LaTeX?\n\n2. For the hierarchical structure, how many levels deep should we go? (e.g., sections, subsections, paragraphs, sub-paragraphs)\n\n3. Would you like me to flag areas where your transcripts suggest you need more evidence or development?\n\n4. Do you have a specific structure in mind already, or should I extract a logical structure from the material provided?\n\n5. Are there any specific requirements from the Journal of Documentation that should guide the structure (beyond word count)?\n\n6. Should I incorporate elements from the existing draft in \"AnAbsenceOfJudgement.tex\" or is this a fresh restructuring?",
          "summaries": [
            {
              "summary": "Thinking about structuring an autoethnographic research paper collaboratively through reflective outlining"
            },
            {
              "summary": "Structuring academic paper outline recursively and systematically"
            },
            {
              "summary": "Strategized collaborative paper development with structured outline approach"
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-10T02:53:36.724168Z",
          "stop_timestamp": "2025-03-10T02:53:40.646376Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI understand your request. You want me to help you create a detailed, hierarchical outline for your 5,000-word academic paper titled \"An Absence of Judgment\" for the Journal of Documentation. This outline should:\n\n1. Be around 1,250 words\n2. Contain no sentences, just structured points\n3. Recurse down to the subparagraph level\n4. Be organized with LaTeX comments for section structure\n5. Help identify areas where you need more evidence\n\nI see you've shared transcripts of dictated thoughts, your current paper draft, planning notes, and research process documentation. I'll use these to create a comprehensive outline that captures your ideas while maintaining the structure needed for academic publication.\n\nBefore I begin, I have a few questions:\n\n1. How closely should I follow the structure of your existing draft versus reorganizing based on all materials provided?\n2. Would you like me to indicate where specific transcripts/dictations support each section?\n3. For the LaTeX comments, do you prefer a specific format or style?\n4. Are there any sections from the Journal of Documentation guidelines that you particularly want to emphasize?\n5. Any specific theoretical frameworks you want to ensure are represented in the outline?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-10T02:53:42.863848Z",
      "updated_at": "2025-03-10T02:53:42.863848Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "4b7b8e9f-55d8-4e1d-b2c5-ca592a8adaad",
      "text": "1. Let's discuss this, one question at a time. \n2. Yes, absolutely, with timestamps and filenames (hopefully in the .srt, so I can go back and listen to me when I get to that section)\n3. % We're embedding these in the .tex\n4. No, we just need to be compatible.\n5. Talk to me about which frameworks you think are appropriate. I'm in the philosophy of tech discipline, so anth is outside my wheelhouse.",
      "content": [
        {
          "start_timestamp": "2025-03-06T21:25:34.423534Z",
          "stop_timestamp": "2025-03-06T21:25:34.423534Z",
          "flags": null,
          "type": "text",
          "text": "1. Let's discuss this, one question at a time. \n2. Yes, absolutely, with timestamps and filenames (hopefully in the .srt, so I can go back and listen to me when I get to that section)\n3. % We're embedding these in the .tex\n4. No, we just need to be compatible.\n5. Talk to me about which frameworks you think are appropriate. I'm in the philosophy of tech discipline, so anth is outside my wheelhouse.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-10T02:55:44.334463Z",
      "updated_at": "2025-03-10T02:55:44.334463Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "8887436b-c31b-432e-9f50-fcdc6d048ca2",
      "text": "\nThank you for answering my questions. Let me address them one by one:\n\n1. We'll discuss organization as we go, which means I should start by analyzing the existing structure and then proposing refinements based on all materials.\n\n2. I'll make sure to indicate which transcripts support each section, including timestamps and filenames so you can revisit your dictations when working on specific sections.\n\n3. I'll use standard LaTeX comments (% comment) for embedding notes in the .tex file.\n\n4. We'll ensure compatibility with the Journal of Documentation guidelines without emphasizing any specific section.\n\n5. For theoretical frameworks, I need to consider what's most appropriate for a philosophy of technology paper about AI's limitations in research. From the materials you've provided, I can see several potential frameworks:\n\n- The Aristotelian approach to knowledge vs. modern empiricism (mentioned in your transcripts)\n- Carnapian confirmation vs. Popperian falsification (also mentioned)\n- The concept of agency and what constitutes \"agentic\" behavior\n- Epistemic humility as a framework for understanding AI limitations\n- Judgment as a three-part structure (epistemic humility, induction, correspondence with reality)\n- The distinction between performance vs. possession of capabilities\n\nLet me now analyze the existing structure of your paper draft to see how it's currently organized, and then think about how to refine it based on all the materials you've provided.\n\nCurrent structure from AnAbsenceOfJudgement.tex:\n1. Introduction\n2. Agentic Systems\n   - \"Agentic\" Systems vs Normal Software\n   - Goal-Related Characteristics\n   - Agentic Characteristics\n3. Deep Research and AI Capabilities\n   - Current State\n   - Fundamental Limitations\n   - Comparative Analysis\n4. Other infrastructures\n   - Anthropic Computer Use\n   - Elicit Research Paper\n   - Perplexity Deep Research\n   - Google Deep Research\n5. Practical Applications\n   - Literature Reviews\n6. Future Development\n   - Areas Requiring Further Investigation\n\nThis structure provides a good foundation, but based on your transcripts, there are additional important elements that could be incorporated. I notice especially from your \"Epistemic \u2013 Monday at 8:50 am\" transcript that you developed a three-part framework for understanding judgment deficiencies in AI: epistemic humility, lack of induction, and correspondence with the real. This seems like a central theoretical contribution that deserves prominence.\n\nThe transcripts also contain much richer discussion of the requirements for research tools and the practical applications than is reflected in the current draft. There's detailed discussion of context management, tombstones for discarded thoughts, human judgment integration, and non-waterfall approaches that could be incorporated.\n\nLet me propose a refined structure that incorporates these elements while maintaining the core of your current organization. Then I can proceed with developing the detailed outline.\n\nThank you for the clarification. Let me address the theoretical frameworks question first:\n\nBased on your transcripts, I see several philosophical frameworks that appear particularly relevant:\n\n1. **Aristotelian vs. Modern Empiricism** - You discuss how AI systems favor authority over empirical reality, making them fundamentally \"Aristotelian\" in their approach to knowledge.\n\n2. **Carnapian Confirmation vs. Popperian Falsification** - You contrast how AI accumulates evidence \"in the Carnapian fashion\" until some internal threshold is met, versus a Popperian approach that would engage with the real world through falsification and experimentation.\n\n3. **Three-part structure of judgment** - Your Monday 8:50am transcript outlines epistemic humility, induction capability, and correspondence with reality as the three critical components AI systems lack.\n\n4. **Performance vs. Possession** - Throughout your dictations, you emphasize the distinction between systems that can \"use the words of the thing without engaging in the fact of the thing.\"\n\nThese frameworks could provide solid theoretical grounding for your paper. Would you like me to proceed with creating the outline based on these, or would you prefer to discuss the frameworks further before I begin?",
      "content": [
        {
          "start_timestamp": "2025-03-10T02:55:47.728224Z",
          "stop_timestamp": "2025-03-10T02:56:00.861684Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nThank you for answering my questions. Let me address them one by one:\n\n1. We'll discuss organization as we go, which means I should start by analyzing the existing structure and then proposing refinements based on all materials.\n\n2. I'll make sure to indicate which transcripts support each section, including timestamps and filenames so you can revisit your dictations when working on specific sections.\n\n3. I'll use standard LaTeX comments (% comment) for embedding notes in the .tex file.\n\n4. We'll ensure compatibility with the Journal of Documentation guidelines without emphasizing any specific section.\n\n5. For theoretical frameworks, I need to consider what's most appropriate for a philosophy of technology paper about AI's limitations in research. From the materials you've provided, I can see several potential frameworks:\n\n- The Aristotelian approach to knowledge vs. modern empiricism (mentioned in your transcripts)\n- Carnapian confirmation vs. Popperian falsification (also mentioned)\n- The concept of agency and what constitutes \"agentic\" behavior\n- Epistemic humility as a framework for understanding AI limitations\n- Judgment as a three-part structure (epistemic humility, induction, correspondence with reality)\n- The distinction between performance vs. possession of capabilities\n\nLet me now analyze the existing structure of your paper draft to see how it's currently organized, and then think about how to refine it based on all the materials you've provided.\n\nCurrent structure from AnAbsenceOfJudgement.tex:\n1. Introduction\n2. Agentic Systems\n   - \"Agentic\" Systems vs Normal Software\n   - Goal-Related Characteristics\n   - Agentic Characteristics\n3. Deep Research and AI Capabilities\n   - Current State\n   - Fundamental Limitations\n   - Comparative Analysis\n4. Other infrastructures\n   - Anthropic Computer Use\n   - Elicit Research Paper\n   - Perplexity Deep Research\n   - Google Deep Research\n5. Practical Applications\n   - Literature Reviews\n6. Future Development\n   - Areas Requiring Further Investigation\n\nThis structure provides a good foundation, but based on your transcripts, there are additional important elements that could be incorporated. I notice especially from your \"Epistemic \u2013 Monday at 8:50 am\" transcript that you developed a three-part framework for understanding judgment deficiencies in AI: epistemic humility, lack of induction, and correspondence with the real. This seems like a central theoretical contribution that deserves prominence.\n\nThe transcripts also contain much richer discussion of the requirements for research tools and the practical applications than is reflected in the current draft. There's detailed discussion of context management, tombstones for discarded thoughts, human judgment integration, and non-waterfall approaches that could be incorporated.\n\nLet me propose a refined structure that incorporates these elements while maintaining the core of your current organization. Then I can proceed with developing the detailed outline.",
          "summaries": [
            {
              "summary": "Thinking about discussing technical frameworks for philosophical technology research"
            },
            {
              "summary": "Analyzing structure and preparing to propose refinements"
            },
            {
              "summary": "Scrutinizing paper structure and potential theoretical frameworks"
            },
            {
              "summary": "Dissected paper structure, mapped theoretical frameworks for AI research."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-10T02:56:01.237796Z",
          "stop_timestamp": "2025-03-10T02:56:06.073451Z",
          "flags": null,
          "type": "text",
          "text": "\n\nThank you for the clarification. Let me address the theoretical frameworks question first:\n\nBased on your transcripts, I see several philosophical frameworks that appear particularly relevant:\n\n1. **Aristotelian vs. Modern Empiricism** - You discuss how AI systems favor authority over empirical reality, making them fundamentally \"Aristotelian\" in their approach to knowledge.\n\n2. **Carnapian Confirmation vs. Popperian Falsification** - You contrast how AI accumulates evidence \"in the Carnapian fashion\" until some internal threshold is met, versus a Popperian approach that would engage with the real world through falsification and experimentation.\n\n3. **Three-part structure of judgment** - Your Monday 8:50am transcript outlines epistemic humility, induction capability, and correspondence with reality as the three critical components AI systems lack.\n\n4. **Performance vs. Possession** - Throughout your dictations, you emphasize the distinction between systems that can \"use the words of the thing without engaging in the fact of the thing.\"\n\nThese frameworks could provide solid theoretical grounding for your paper. Would you like me to proceed with creating the outline based on these, or would you prefer to discuss the frameworks further before I begin?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-10T02:56:09.849015Z",
      "updated_at": "2025-03-10T02:56:09.849015Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "f2838263-d459-40a2-b658-cc6942dd44b3",
      "text": "I mean, those are the fundamental points I make, and the flaws of the AI. \n\nCarnapian is a subset of the \"technoaristotelianism\" of 1 -- where when searching these things accumulate evidence until the \"vibes\" are sufficient to produce text. They *cannot* engage in real-world testing (thus the fundamental flaw of endless appeals to authority), nor do they acknowledge epistemic limits by telling us to test things.\n\nI think the popperian framing is very hard here, insofar as that would require judgement for them to set some sort of falsifable goal and detect if they've reached it. We'll need to discuss this further.\n\nBeyond this though, We need a few of the trappings of a formal research paper. We need to have a clear through-structure.\n\nWhat do *you* mean by framework in the context of this paper?",
      "content": [
        {
          "start_timestamp": "2025-03-06T21:23:50.029700Z",
          "stop_timestamp": "2025-03-06T21:23:50.029700Z",
          "flags": null,
          "type": "text",
          "text": "I mean, those are the fundamental points I make, and the flaws of the AI. \n\nCarnapian is a subset of the \"technoaristotelianism\" of 1 -- where when searching these things accumulate evidence until the \"vibes\" are sufficient to produce text. They *cannot* engage in real-world testing (thus the fundamental flaw of endless appeals to authority), nor do they acknowledge epistemic limits by telling us to test things.\n\nI think the popperian framing is very hard here, insofar as that would require judgement for them to set some sort of falsifable goal and detect if they've reached it. We'll need to discuss this further.\n\nBeyond this though, We need a few of the trappings of a formal research paper. We need to have a clear through-structure.\n\nWhat do *you* mean by framework in the context of this paper?",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-10T03:31:31.929847Z",
      "updated_at": "2025-03-10T03:31:31.929847Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "59b9c2f0-9b37-4439-84c6-822a0ca26b8c",
      "text": "\nI understand your clarification about the philosophical frameworks, particularly the \"technoaristotelianism\" concept and how Carnapian confirmation is a subset of this approach where AI systems accumulate evidence until they reach a sufficient \"vibe\" threshold rather than engaging with reality through testing.\n\nWhen I asked about frameworks, I was referring to the theoretical lenses through which you analyze AI limitations in research contexts. Based on your response, I see that the frameworks I identified are indeed the core conceptual structures you're using to frame your analysis.\n\nNow you're asking what I mean by \"framework\" in this context, which is a good question to clarify. By framework, I meant the conceptual structure that organizes your analysis of AI limitations in research - the overarching theoretical perspectives that shape how you interpret and present your observations and arguments. \n\nThe frameworks I identified (technoaristotelianism, performance vs. possession of judgment, the three components of judgment) are indeed the ones you're using. You're not applying external disciplinary frameworks (like activity theory, actor-network theory, etc.) but rather developing your own analytical framework centered on judgment and its absence in AI systems.\n\nFor the paper structure, we need to ensure it follows standard academic conventions:\n1. Introduction with clear statement of purpose/problem\n2. Literature review/theoretical background\n3. Methodology (your \"autoethnographic\" approach to testing these systems)\n4. Findings/results (what you observed)\n5. Analysis/discussion (interpreting these findings through your frameworks)\n6. Conclusion/implications\n\nIn creating the outline, I should organize it to follow this structure while incorporating your conceptual frameworks and evidence from the transcripts.\n\nBy \"framework\" in this context, I was referring to the theoretical lenses through which you analyze AI limitations. Based on your response, it's clear you're developing your own analytical framework centered on judgment and its absence in AI systems rather than applying external disciplinary frameworks.\n\nYou've clarified that \"technoaristotelianism\" is your overarching concept - where AI systems accumulate evidence until reaching a sufficient \"vibe\" threshold for producing text, without engaging with reality through testing or acknowledging epistemic limits.\n\nFor the paper structure, we need to follow standard academic conventions while incorporating your conceptual framework:\n\n1. Introduction with clear problem statement\n2. Theoretical background on judgment and agency\n3. Methodology (your \"autoethnographic\" testing approach)\n4. Case studies/findings from different AI research tools\n5. Analysis through your judgment framework\n6. Implications and future directions\n\nShall I proceed with creating the detailed outline using this structure, or would you like to refine this approach first?",
      "content": [
        {
          "start_timestamp": "2025-03-10T03:31:35.324901Z",
          "stop_timestamp": "2025-03-10T03:31:42.245495Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nI understand your clarification about the philosophical frameworks, particularly the \"technoaristotelianism\" concept and how Carnapian confirmation is a subset of this approach where AI systems accumulate evidence until they reach a sufficient \"vibe\" threshold rather than engaging with reality through testing.\n\nWhen I asked about frameworks, I was referring to the theoretical lenses through which you analyze AI limitations in research contexts. Based on your response, I see that the frameworks I identified are indeed the core conceptual structures you're using to frame your analysis.\n\nNow you're asking what I mean by \"framework\" in this context, which is a good question to clarify. By framework, I meant the conceptual structure that organizes your analysis of AI limitations in research - the overarching theoretical perspectives that shape how you interpret and present your observations and arguments. \n\nThe frameworks I identified (technoaristotelianism, performance vs. possession of judgment, the three components of judgment) are indeed the ones you're using. You're not applying external disciplinary frameworks (like activity theory, actor-network theory, etc.) but rather developing your own analytical framework centered on judgment and its absence in AI systems.\n\nFor the paper structure, we need to ensure it follows standard academic conventions:\n1. Introduction with clear statement of purpose/problem\n2. Literature review/theoretical background\n3. Methodology (your \"autoethnographic\" approach to testing these systems)\n4. Findings/results (what you observed)\n5. Analysis/discussion (interpreting these findings through your frameworks)\n6. Conclusion/implications\n\nIn creating the outline, I should organize it to follow this structure while incorporating your conceptual frameworks and evidence from the transcripts.",
          "summaries": [
            {
              "summary": "Thinking about defining a research paper framework's conceptual structure"
            },
            {
              "summary": "Parsing philosophical AI frameworks and evidence accumulation"
            },
            {
              "summary": "Mapped research paper structure and conceptual frameworks for analysis."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-10T03:31:42.591640Z",
          "stop_timestamp": "2025-03-10T03:31:45.881630Z",
          "flags": null,
          "type": "text",
          "text": "\n\nBy \"framework\" in this context, I was referring to the theoretical lenses through which you analyze AI limitations. Based on your response, it's clear you're developing your own analytical framework centered on judgment and its absence in AI systems rather than applying external disciplinary frameworks.\n\nYou've clarified that \"technoaristotelianism\" is your overarching concept - where AI systems accumulate evidence until reaching a sufficient \"vibe\" threshold for producing text, without engaging with reality through testing or acknowledging epistemic limits.\n\nFor the paper structure, we need to follow standard academic conventions while incorporating your conceptual framework:\n\n1. Introduction with clear problem statement\n2. Theoretical background on judgment and agency\n3. Methodology (your \"autoethnographic\" testing approach)\n4. Case studies/findings from different AI research tools\n5. Analysis through your judgment framework\n6. Implications and future directions\n\nShall I proceed with creating the detailed outline using this structure, or would you like to refine this approach first?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-10T03:31:48.972681Z",
      "updated_at": "2025-03-10T03:31:48.972681Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "f95f6a9a-a7f5-4358-a480-9417f8461df8",
      "text": "Ok, I think that structure will work, and yes, framing this around the ideas of technoaristotelianism and using the points above as behaviours within a technoaristotelian context could be interesting? \n\nThoughts?\n\nFor 6, it's not so much implications and future directions as: \"A checklist for companies purporting to support research\" or... something like that. More meaningful than the usual conclusion waffle.",
      "content": [
        {
          "start_timestamp": "2025-03-06T22:33:39.989730Z",
          "stop_timestamp": "2025-03-06T22:33:39.989730Z",
          "flags": null,
          "type": "text",
          "text": "Ok, I think that structure will work, and yes, framing this around the ideas of technoaristotelianism and using the points above as behaviours within a technoaristotelian context could be interesting? \n\nThoughts?\n\nFor 6, it's not so much implications and future directions as: \"A checklist for companies purporting to support research\" or... something like that. More meaningful than the usual conclusion waffle.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-10T03:33:40.952637Z",
      "updated_at": "2025-03-10T03:33:40.952637Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "aee4aded-89b2-47f0-9bfe-9552d8790176",
      "text": "\nYour idea to frame the paper around \"technoaristotelianism\" as the overarching concept with the identified behaviors (epistemic limitations, lack of induction, etc.) as manifestations within this framework is excellent. It provides a strong theoretical backbone while keeping the analysis grounded in your observations.\n\nFor section 6, I appreciate your desire to make it more meaningful than typical conclusion sections. A checklist or set of concrete recommendations for companies developing AI research tools would be far more valuable than vague \"future directions\" statements. This approach also aligns with the Journal of Documentation's practical focus.\n\nLet me think about how to structure this outline:\n\n1. Introduction: Problem statement about AI research tools claimed capabilities vs. actual limitations\n2. Theoretical Framework: Technoaristotelianism concept and the three components of judgment AI lacks\n3. Methodology: Autoethnographic testing approach with various tools\n4. Case Studies: Findings from different AI research tools (Deep Research, Computer Use, Elicit, etc.)\n5. Analysis: Examining the findings through the judgment framework\n6. Practical Recommendations: Checklist for companies developing AI research tools + what researchers should expect\n\nThis structure allows for a clear progression from theoretical framing to practical recommendations, while maintaining academic rigor. I'll now develop a detailed outline following this structure, with appropriate references to your transcripts.\n\nI think framing the paper around \"technoaristotelianism\" is an excellent approach. This gives you a novel theoretical contribution while providing a coherent framework to analyze the specific judgment deficiencies you've identified. The three-part judgment framework (epistemic humility, induction capability, correspondence with reality) can be presented as manifestations of this broader technoaristotelian tendency.\n\nFor section 6, I completely agree that concrete recommendations will be more valuable than typical conclusion waffle. A \"Research Tool Evaluation Framework\" or \"Judgment-Aware Design Principles\" would give companies actionable guidance while providing researchers with criteria to evaluate tools that claim research capabilities.\n\nLet me create a detailed outline with this structure in mind, utilizing your transcripts as evidence and organizing with LaTeX comments.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\nI've created a detailed outline for your paper that follows the structure we discussed, with \"technoaristotelianism\" as the overarching framework. The outline:\n\n1. Is structured with LaTeX comments for each major section\n2. Includes evidence references from your transcripts with timestamps\n3. Recurses down to the subparagraph level\n4. Contains no sentences, only hierarchical points\n5. Provides a clear progression from theoretical framing to practical recommendations\n\nSome key features:\n\n- The three judgment dimensions (epistemic humility, induction, correspondence with reality) are organized as manifestations of the broader technoaristotelian tendency\n- Section 6 focuses on concrete recommendations rather than vague implications\n- I've included specific transcript references so you can revisit your original dictations\n- The outline maintains academic rigor while incorporating your novel theoretical contribution\n\nWould you like me to elaborate on any particular section, or would you prefer to refine the overall structure before diving deeper into specific areas?",
      "content": [
        {
          "start_timestamp": "2025-03-10T03:33:48.417152Z",
          "stop_timestamp": "2025-03-10T03:33:53.759116Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nYour idea to frame the paper around \"technoaristotelianism\" as the overarching concept with the identified behaviors (epistemic limitations, lack of induction, etc.) as manifestations within this framework is excellent. It provides a strong theoretical backbone while keeping the analysis grounded in your observations.\n\nFor section 6, I appreciate your desire to make it more meaningful than typical conclusion sections. A checklist or set of concrete recommendations for companies developing AI research tools would be far more valuable than vague \"future directions\" statements. This approach also aligns with the Journal of Documentation's practical focus.\n\nLet me think about how to structure this outline:\n\n1. Introduction: Problem statement about AI research tools claimed capabilities vs. actual limitations\n2. Theoretical Framework: Technoaristotelianism concept and the three components of judgment AI lacks\n3. Methodology: Autoethnographic testing approach with various tools\n4. Case Studies: Findings from different AI research tools (Deep Research, Computer Use, Elicit, etc.)\n5. Analysis: Examining the findings through the judgment framework\n6. Practical Recommendations: Checklist for companies developing AI research tools + what researchers should expect\n\nThis structure allows for a clear progression from theoretical framing to practical recommendations, while maintaining academic rigor. I'll now develop a detailed outline following this structure, with appropriate references to your transcripts.",
          "summaries": [
            {
              "summary": "Thinking about refining research structure through technoaristotelian framework"
            },
            {
              "summary": "Framing paper around technoaristotelianism with identified behaviors"
            },
            {
              "summary": "Architected research paper structure with technoaristotelianism framework"
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-10T03:33:54.036311Z",
          "stop_timestamp": "2025-03-10T03:33:56.771284Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI think framing the paper around \"technoaristotelianism\" is an excellent approach. This gives you a novel theoretical contribution while providing a coherent framework to analyze the specific judgment deficiencies you've identified. The three-part judgment framework (epistemic humility, induction capability, correspondence with reality) can be presented as manifestations of this broader technoaristotelian tendency.\n\nFor section 6, I completely agree that concrete recommendations will be more valuable than typical conclusion waffle. A \"Research Tool Evaluation Framework\" or \"Judgment-Aware Design Principles\" would give companies actionable guidance while providing researchers with criteria to evaluate tools that claim research capabilities.\n\nLet me create a detailed outline with this structure in mind, utilizing your transcripts as evidence and organizing with LaTeX comments.",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-10T03:33:57.176799Z",
          "stop_timestamp": "2025-03-10T03:34:39.065466Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "paper-outline",
            "type": "text/markdown",
            "title": "An Absence of Judgment: Paper Outline",
            "command": "create",
            "content": "% An Absence of Judgment: On AI's Fundamental Limitations in Research\n% 5,000 word paper outline for Journal of Documentation\n\n% ======================================================================\n% SECTION 1: INTRODUCTION (~750 words)\n% ======================================================================\n% Purpose: Establish research problem, theoretical framing, and paper structure\n\n## 1. Introduction\n### 1.1. Problem Statement\n- AI systems claiming \"agentic\" capabilities for research\n- Gap between linguistic performance and actual research capabilities\n- Distinction between tool utility and true agency\n  - Mundane utility vs. claimed capabilities\n  - Performance vs. possession of judgment\n\n### 1.2. Central Thesis\n- Large language models fundamentally lack judgment despite linguistic mimicry\n- This absence explains the failure to generate novel insights from existing knowledge\n- \"Technoaristotelianism\" as conceptual framework\n  - Reference to Dwarkesh's question to Cohen about knowledge connections\n  - AI's primacy of textual authority over empirical testing\n\n### 1.3. Research Approach\n- Autoethnographic investigation of research tools\n- February 2025 case studies with frontier models\n- Research question: capability for insight vs. description\n- Paper organization and structure\n  \n% Evidence: Tuesday 8:36 am, 00:01:15-00:03:13 (initial framing)\n% Evidence: Epistemic Monday 8:50 am, 00:24:15-00:26:17 (technoaristotelianism concept)\n\n% ======================================================================\n% SECTION 2: THEORETICAL FRAMEWORK (~900 words)\n% ======================================================================\n% Purpose: Establish conceptual framework around judgment and research\n\n## 2. Theoretical Framework: Judgment in Research\n### 2.1. Agency vs. Task Decomposition\n- Defining true agency beyond task decomposition\n- Goal-following vs. goal-setting systems\n  - External input requirements\n  - Operational definitions of agency\n- Components of genuine agency\n  - Goal processing capabilities\n  - Execution mechanisms\n  - Assessment and reporting functions\n\n### 2.2. Three Dimensions of AI Judgment Deficiency\n#### 2.2.1. Epistemic Humility\n- Inability to recognize knowledge boundaries\n- Confabulation without self-doubt\n- Performance vs. reality of epistemic humility\n  - \"What about this?\" pattern as pretense\n  - Absence of genuine epistemic uncertainty\n  - Always producing an answer regardless of confidence\n\n#### 2.2.2. Inductive Reasoning\n- Pattern recognition vs. pattern insight\n- Next-token paradigm constraints\n- Induction as precursor to common sense\n- Noticing deviation from expected patterns\n- Impulse of inquiry for pattern deviation\n\n#### 2.2.3. Correspondence with Reality\n- \"Carnapian confirmation\" approach\n- Internal \"truthiness\" thresholds\n- Primacy of textual authority over empirical testing\n- Absence of experimental approach\n- Inability to discard bad outputs based on real-world criteria\n\n### 2.3. True Nature of Research Work\n- Literature reviews as persuasive, not descriptive documents\n- Role of judgment in scholarly contribution\n- Selection and organization as intellectual acts\n- Situating research within scholarly traditions\n- Identifying genuine knowledge gaps\n\n% Evidence: Systems Friday 8:16 am, 00:00:30-00:03:30 (agency definition)\n% Evidence: Epistemic Monday 8:50 am, 00:00:30-00:03:30 (judgment categories)\n% Evidence: Epistemic Monday 8:50 am, 00:19:30-00:23:30 (Carnapian confirmation)\n% Evidence: Tuesday 8:36 am, 00:03:44-00:08:24 (literature review purpose)\n\n% ======================================================================\n% SECTION 3: METHODOLOGY (~500 words)\n% ======================================================================\n% Purpose: Describe approach to evaluation and autoethnographic methodology\n\n## 3. Methodology\n### 3.1. Autoethnographic Investigation\n- Definition of autoethnographic approach\n- Rationale for method selection\n- Data collection procedures\n- Analytical approach\n\n### 3.2. Tool Selection Criteria\n- Range of claimed capabilities\n- Market positioning\n- Accessibility to researchers\n- Comparability of features\n\n### 3.3. Research Tasks Investigated\n- Literature discovery\n- Source analysis\n- Data collection\n- Knowledge synthesis\n- Bibliography construction\n\n### 3.4. Evaluation Framework\n- Judgment application points\n- Success criteria\n- Documentation of process\n- Limitations of approach\n\n% Evidence: autoethno-process-planning-notes.tex (research questions and approach)\n\n% ======================================================================\n% SECTION 4: FINDINGS (~1200 words)\n% ======================================================================\n% Purpose: Present results from investigation of various AI research tools\n\n## 4. Case Studies of AI Research Tools\n### 4.1. OpenAI's Deep Research\n#### 4.1.1. Claimed Capabilities\n- Marketing representation\n- Technical architecture\n- Search integration\n\n#### 4.1.2. Observed Limitations\n- Corpus access issues\n- Lack of systematic approach\n- Policy constraints and output \"infection\"\n- Uncanny valley of research behavior\n  - Pretense of systematic approach\n  - Inability to revise fundamental assumptions\n  - Blind alley persistence\n  - Context window management failures\n\n#### 4.1.3. Effective Applications\n- Dataset preparation\n- Initial literature discovery\n- Source identification\n\n### 4.2. Anthropic's Computer Use\n- Technical capabilities and limitations\n- Resource intensiveness\n- Ability to navigate research interfaces\n- Execution failures despite conceptual understanding\n\n### 4.3. Elicit Research Assistant\n- Corpus limitations\n- Search criteria challenges\n- Screening criteria application\n- Report quality evaluation\n\n### 4.4. Additional Tools (Perplexity, etc.)\n- Comparative capabilities\n- Distinctive limitations\n- Complementary features\n\n% Evidence: Thursday 8:36 am, 00:00:36-00:03:15 (Deep Research observations)\n% Evidence: Friday 6:19 pm, 00:00:33-00:01:40 (data collection use cases)\n% Evidence: AnAbsenceOfJudgement.tex (Computer Use and Elicit sections)\n\n% ======================================================================\n% SECTION 5: ANALYSIS (~1000 words)\n% ======================================================================\n% Purpose: Analyze findings through judgment framework and identify patterns\n\n## 5. Analysis Through Judgment Framework\n### 5.1. Manifestations of Technoaristotelianism\n- Appeals to authority without verification\n- Absence of empirical checks\n- Conflation of description with insight\n- Inability to identify true knowledge gaps\n\n### 5.2. Judgment Deficiency Patterns\n#### 5.2.1. Epistemic Humility Failures\n- Always producing an answer\n- False certainty in uncertain domains\n- Inability to recognize knowledge boundaries\n- Performance of epistemic language without underlying capability\n\n#### 5.2.2. Induction Limitations\n- Pattern recognition without insight\n- Next-token prediction constraints\n- Failure to connect disparate knowledge domains\n- Absence of \"aha\" moments\n\n#### 5.2.3. Reality Detachment\n- No experimental approach\n- No verification suggestions\n- Text-based evaluation only\n- Inability to judge output quality against real-world criteria\n\n### 5.3. Mundane Utility Despite Limitations\n- Effective bounded applications\n- Value for time-constrained researchers\n- Complementary capabilities with human judgment\n- Context window and token management strategies\n\n% Evidence: Epistemic Monday 8:50 am, 00:24:15-00:31:53 (Aristotelian fallacy)\n% Evidence: Friday 6:19 pm, 00:08:03-00:12:19 (mundane utility)\n% Evidence: Context Friday 8:47 am, 00:00:28-00:01:10 (paper structure on utility)\n\n% ======================================================================\n% SECTION 6: RECOMMENDATIONS (~650 words)\n% ======================================================================\n% Purpose: Provide concrete guidance for tool developers and researchers\n\n## 6. Research Tool Design Requirements\n### 6.1. Judgment-Aware Architecture\n- Multi-threaded cognition\n- Context window management\n- Supervised reasoning\n- Source tracking and evaluation\n- Tombstones for discarded thoughts\n- Self-critical assessment capabilities\n\n### 6.2. Research Process Support\n- Stage-based design (literature finding, extraction, etc.)\n- Non-waterfall approach to research flows\n- Structured to-do lists with human checkpoint integration\n- Outline-driven context switching\n- Documentation of decision points\n\n### 6.3. Human-AI Collaboration Framework\n- Recognition of AI judgment deficiency\n- Strategic points for human intervention\n- Validation and verification processes\n- Tool-centric rather than agent-centric approach\n\n### 6.4. Evaluation Criteria for Research Tools\n- Transparency indicators\n- Token management approaches\n- Context awareness metrics\n- Ability to \"forget\" or remove irrelevant content\n- Documentation quality\n- Human judgment integration points\n\n% Evidence: Context Friday 8:47 am, 00:07:23-00:09:31 (tombstones and forget)\n% Evidence: Thursday 8:36 am, 00:15:44-00:16:48 (multiple supervisory threads)\n% Evidence: Context Friday 8:47 am, 00:10:15-00:11:53 (stages of interaction)\n\n% ======================================================================\n% SECTION 7: CONCLUSION (~200 words)\n% ======================================================================\n% Purpose: Summarize key arguments and implications\n\n## 7. Conclusion\n### 7.1. Summary of Argument\n- Technoaristotelianism as fundamental limitation\n- Three judgment deficiencies as manifestations\n- Tool vs. agent distinction as pragmatic approach\n\n### 7.2. Implications\n- Realistic expectations for AI research tools\n- Focus on human-AI collaboration frameworks\n- Limits of current \"agentic\" claims\n\n### 7.3. Future Research Directions\n- Evolving capabilities assessment\n- Judgment integration mechanisms\n- Improved evaluation frameworks\n\n% Evidence: Various transcripts for synthesis\n",
            "version_uuid": "8c2ae592-3c76-42d4-975e-d5ff39c13d8c"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "9bcea45a-4c59-46ba-8a06-bdf538a0efa9"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-10T03:34:47.679581Z",
          "stop_timestamp": "2025-03-10T03:34:52.399043Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI've created a detailed outline for your paper that follows the structure we discussed, with \"technoaristotelianism\" as the overarching framework. The outline:\n\n1. Is structured with LaTeX comments for each major section\n2. Includes evidence references from your transcripts with timestamps\n3. Recurses down to the subparagraph level\n4. Contains no sentences, only hierarchical points\n5. Provides a clear progression from theoretical framing to practical recommendations\n\nSome key features:\n\n- The three judgment dimensions (epistemic humility, induction, correspondence with reality) are organized as manifestations of the broader technoaristotelian tendency\n- Section 6 focuses on concrete recommendations rather than vague implications\n- I've included specific transcript references so you can revisit your original dictations\n- The outline maintains academic rigor while incorporating your novel theoretical contribution\n\nWould you like me to elaborate on any particular section, or would you prefer to refine the overall structure before diving deeper into specific areas?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-10T03:34:53.419929Z",
      "updated_at": "2025-03-10T03:34:53.419929Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "e4ded124-f9f2-4133-9ce2-048f9c533d42",
      "text": "Ok, I'm going to note the markdown isn't LaTeX, but that's... fine.\n\nQuick sanity check. I just added two papers to the available context in the \"projects\" area of this project. the .tex file (after I took your suggested outline and integrated it) and a .bib file. Are you able to access them? If so, give me the first and last references of the .bib file, and double check the .tex to make sure that my allocation of the old text as comments fit the structure you were thinking of.",
      "content": [
        {
          "start_timestamp": "2025-03-13T21:24:57.562802Z",
          "stop_timestamp": "2025-03-13T21:24:57.562802Z",
          "flags": null,
          "type": "text",
          "text": "Ok, I'm going to note the markdown isn't LaTeX, but that's... fine.\n\nQuick sanity check. I just added two papers to the available context in the \"projects\" area of this project. the .tex file (after I took your suggested outline and integrated it) and a .bib file. Are you able to access them? If so, give me the first and last references of the .bib file, and double check the .tex to make sure that my allocation of the old text as comments fit the structure you were thinking of.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-14T02:35:12.831777Z",
      "updated_at": "2025-03-14T02:35:12.831777Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "8ac8d619-54b1-43bd-afde-26a403300708",
      "text": "\nLet me check if I can access the new files you've added to the context. You mentioned adding a .tex file after integrating my suggested outline, and a .bib file.\n\nLooking at the documents list, I don't see new documents beyond what was previously provided. The documents I have access to are:\n\n1. AnAbsenceOfJudgement.tex\n2. paste.txt\n3. Context \u2013 Friday at 8-47 am (1).srt\n4. Friday at 6-19 pm (1).srt\n5. Epistemic \u2013 Monday at 8-50 am (1).srt\n6. Thursday at 8-36 am.srt\n7. Tuesday at 8-36 am.srt\n8. Systems \u2013 Friday at 8-16 am.srt\n9. 10-simple-rules.tex\n10. TODO.tex\n11. autoethno-process-planning-notes.tex\n12. v7-individual-tool.tex\n\nI don't see a newly added .tex file with my outline integrated, nor do I see a .bib file. It's possible that they haven't been properly loaded into my context or that they were added after our conversation started.\n\nSince I can't access these files, I can't provide the first and last references from the .bib file or check the structure of the updated .tex file. I should inform the user about this limitation.\n\nI don't see the new files you've added in my available context. I still have access to:\n\n1. Your original AnAbsenceOfJudgement.tex\n2. The transcript .srt files\n3. Supporting documents like 10-simple-rules.tex, TODO.tex, autoethno-process-planning-notes.tex, etc.\n\nBut I don't see a newly integrated .tex file or a .bib file among the documents available to me. It's possible they haven't been properly loaded into my context or were added after our conversation started.\n\nYou're right that the outline is in Markdown rather than LaTeX comments - I created it this way for readability in the artifact, with the assumption that you'd convert the \"%\" comments to proper LaTeX comments when integrating it into your document.\n\nWould you like to upload these files again so I can check them as requested?",
      "content": [
        {
          "start_timestamp": "2025-03-14T02:35:16.486825Z",
          "stop_timestamp": "2025-03-14T02:35:21.834038Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nLet me check if I can access the new files you've added to the context. You mentioned adding a .tex file after integrating my suggested outline, and a .bib file.\n\nLooking at the documents list, I don't see new documents beyond what was previously provided. The documents I have access to are:\n\n1. AnAbsenceOfJudgement.tex\n2. paste.txt\n3. Context \u2013 Friday at 8-47 am (1).srt\n4. Friday at 6-19 pm (1).srt\n5. Epistemic \u2013 Monday at 8-50 am (1).srt\n6. Thursday at 8-36 am.srt\n7. Tuesday at 8-36 am.srt\n8. Systems \u2013 Friday at 8-16 am.srt\n9. 10-simple-rules.tex\n10. TODO.tex\n11. autoethno-process-planning-notes.tex\n12. v7-individual-tool.tex\n\nI don't see a newly added .tex file with my outline integrated, nor do I see a .bib file. It's possible that they haven't been properly loaded into my context or that they were added after our conversation started.\n\nSince I can't access these files, I can't provide the first and last references from the .bib file or check the structure of the updated .tex file. I should inform the user about this limitation.",
          "summaries": [
            {
              "summary": "Thinking about verifying document access and structural integration"
            },
            {
              "summary": "Scanning for newly added documents in context."
            },
            {
              "summary": "Scrutinized context, discovered missing project files."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-14T02:35:22.267737Z",
          "stop_timestamp": "2025-03-14T02:35:25.497683Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI don't see the new files you've added in my available context. I still have access to:\n\n1. Your original AnAbsenceOfJudgement.tex\n2. The transcript .srt files\n3. Supporting documents like 10-simple-rules.tex, TODO.tex, autoethno-process-planning-notes.tex, etc.\n\nBut I don't see a newly integrated .tex file or a .bib file among the documents available to me. It's possible they haven't been properly loaded into my context or were added after our conversation started.\n\nYou're right that the outline is in Markdown rather than LaTeX comments - I created it this way for readability in the artifact, with the assumption that you'd convert the \"%\" comments to proper LaTeX comments when integrating it into your document.\n\nWould you like to upload these files again so I can check them as requested?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-14T02:35:32.737250Z",
      "updated_at": "2025-03-14T02:35:32.737250Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "f113bff6-af4a-44b2-82a3-094351c6e0df",
      "text": "From all this, do you have a sense of my (BBS) academic register? I want to see how well we can collaborate on writing each section, section by section. The intention here is for you to ask me one question at a time until we fill out the outline for that section or sub-section to a sub-paragraph level, figure out what citations we want to use, ensure that they are in Zotero, and then for you to generate that down-to-sub-paragraph level outline for my approval. Once I approve, using my academic register, write the section or subsection that I've approved.",
      "content": [
        {
          "start_timestamp": "2025-03-13T21:23:21.545323Z",
          "stop_timestamp": "2025-03-13T21:23:21.545323Z",
          "flags": null,
          "type": "text",
          "text": "From all this, do you have a sense of my (BBS) academic register? I want to see how well we can collaborate on writing each section, section by section. The intention here is for you to ask me one question at a time until we fill out the outline for that section or sub-section to a sub-paragraph level, figure out what citations we want to use, ensure that they are in Zotero, and then for you to generate that down-to-sub-paragraph level outline for my approval. Once I approve, using my academic register, write the section or subsection that I've approved.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-14T02:38:45.301086Z",
      "updated_at": "2025-03-14T02:38:45.301086Z",
      "attachments": [
        {
          "file_name": "AnAbsenceOfJudgement (1).tex",
          "file_size": 21687,
          "file_type": "",
          "extracted_content": "\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\\usepackage[margin=1in]{geometry}\n\\usepackage{parskip}\n\n\\title{An Absence of Judgment: On AI's Fundamental Limitations in Research}\n\\author{}\n\\date{}\n\n\\begin{document}\n\n\\maketitle\n\n\n\n% An Absence of Judgment: On AI's Fundamental Limitations in Research\n% 5,000 word paper outline for Journal of Documentation\n\n% ======================================================================\n% SECTION 1: INTRODUCTION (~750 words)\n% ======================================================================\n% Purpose: Establish research problem, theoretical framing, and paper structure\n\n\\section{Introduction}\n\n% Post transcript\n% ### 1.1. Problem Statement\n% - AI systems claiming \"agentic\" capabilities for research\n% - Gap between linguistic performance and actual research capabilities\n% - Distinction between tool utility and true agency\n%   - Mundane utility vs. claimed capabilities\n%   - Performance vs. possession of judgment\n\n% % ### 1.2. Central Thesis\n% - Large language models fundamentally lack judgment despite linguistic mimicry\n% - This absence explains the failure to generate novel insights from existing knowledge\n% - \"Technoaristotelianism\" as conceptual framework\n%   - Reference to Dwarkesh's question to Cohen about knowledge connections\n%   - AI's primacy of textual authority over empirical testing\n\n% % ### 1.3. Research Approach\n% - Autoethnographic investigation of research tools\n% - February 2025 case studies with frontier models\n% - Research question: capability for insight vs. description\n% - Paper organization and structure\n\n% Initial draft\n% \\section{Introduction}\n% Large language models are fundamentally incapable of judgment, despite their ability to mimic the language of judgment. This distinction necessitates examining not only their linguistic output but also the concrete actions and outcomes that their words produce. However, this lack merely prevents us from treating them as true agents, \\textit{not} as extracting mundane utility from them as tools. This paper is an investigation into the creation of a research-grade dataset using OpenAI's Deep Research in February 2025, acting as a case study --- and our ``autoethnographic'' reflection upon the use of this tool for what Zvi Moshowitz calls ``mundane utility.\"\n\n% Here, we will also give our understanding of the necessary prerequsities for an ``agentic'' tool, and why we believe that this infrastructure, at this time, does not satisfy that criteria. We will also discuss the fundamental lack of judgement that these models exhibit, and why it is this core incapability which prevents an accumulation of patterns-shaped-like-knowledge to answer Dwarkesh's question to Cohen: ``what do you make of the fact that these things have basically the entire corpus of human knowledge memorized and they haven\u2019t been able to make a single new connection that has led to a discovery? Whereas if even a moderately intelligent person had this much stuff memorized, they would notice \u2014 Oh, this thing causes this symptom.'' We assert that the lack of induction exhibited by even currently accessible frontier models like o3-mini-high, answers this question. To be clear, this paper is a description of what we have experienced in our attempt to actively use these models to research and answer an academic question --- not merely to conduct a \\textit{descriptive} literature review, but to find that central spark of insight which represents a contribution to the literature. We do not say that these capabilities are forever barred to these models, merely that they do not exhibit them yet and that the common errors in estimating the capabilities of these models based on \\textit{what they say} rather than \\textit{how they act} can lead to confusion as to their actual capabilities and hinder finding places of mundane utility in our use of these tools. \n\n\n\n\n\n  \n% Evidence: Tuesday 8:36 am, 00:01:15-00:03:13 (initial framing)\n% Evidence: Epistemic Monday 8:50 am, 00:24:15-00:26:17 (technoaristotelianism concept)\n\n% ======================================================================\n% SECTION 2: THEORETICAL FRAMEWORK (~900 words)\n% ======================================================================\n% Purpose: Establish conceptual framework around judgment and research\n\n\\section{Theoretical Framework: Judgment in Research}\n\n\n\\subsection{Agency vs. Task Decomposition}\n% - Defining true agency beyond task decomposition\n% - Goal-following vs. goal-setting systems\n%   - External input requirements\n%   - Operational definitions of agency\n% - Components of genuine agency\n%   - Goal processing capabilities\n%   - Execution mechanisms\n%   - Assessment and reporting functions\n\n\\subsection{Three Dimensions of AI Judgment Deficiency}\n\\subsubsection{Epistemic Humility}\n% - Inability to recognize knowledge boundaries\n% - Confabulation without self-doubt\n% - Performance vs. reality of epistemic humility\n%   - \"What about this?\" pattern as pretense\n%   - Absence of genuine epistemic uncertainty\n%   - Always producing an answer regardless of confidence\n\n\\subsubsection{Inductive Reasoning}\n% - Pattern recognition vs. pattern insight\n% - Next-token paradigm constraints\n% - Induction as precursor to common sense\n% - Noticing deviation from expected patterns\n% - Impulse of inquiry for pattern deviation\n\n\\subsubsection{Correspondence with Reality}\n% - \"Carnapian confirmation\" approach\n% - Internal \"truthiness\" thresholds\n% - Primacy of textual authority over empirical testing\n% - Absence of experimental approach\n% - Inability to discard bad outputs based on real-world criteria\n\n\\subsection{Nature of Research Work}\n% - Literature reviews as persuasive, not descriptive documents\n% - Role of judgment in scholarly contribution\n% - Selection and organization as intellectual acts\n% - Situating research within scholarly traditions\n% - Identifying genuine knowledge gaps\n\n\n% Initial draft\n% \\section{Agentic Systems}\n\n% #  \"Agentic\" Systems vs Normal Software\n\n% ## Goal-Related Characteristics\n% 1. Goal Following vs Goal Setting\n%    - Agentic systems are goal-following systems\n%    - This contrasts with AGI, which can set its own goals\n%    - Key distinction: Agentic systems require external input for goals\n\n% ## Agentic Characteristics\n% 1. Goal Processing Capabilities\n%    - Accept external goals as input\n%    - Collaborate with users to operationalize goals\n%    - Functionally decompose goals into manageable components\n\n% 2. Execution Capabilities\n%    - Create plans for goal completion\n%    - Invoke appropriate software and APIs\n%    - Monitor and assess progress\n\n\n% Evidence: Systems Friday 8:16 am, 00:00:30-00:03:30 (agency definition)\n% Evidence: Epistemic Monday 8:50 am, 00:00:30-00:03:30 (judgment categories)\n% Evidence: Epistemic Monday 8:50 am, 00:19:30-00:23:30 (Carnapian confirmation)\n% Evidence: Tuesday 8:36 am, 00:03:44-00:08:24 (literature review purpose)\n\n% ======================================================================\n% SECTION 3: METHODOLOGY (~500 words)\n% ======================================================================\n% Purpose: Describe approach to evaluation and autoethnographic methodology\n\n\\section{Methodology}\n\\subsection{Autoethnographic Investigation}\n% - Definition of autoethnographic approach\n% - Rationale for method selection\n% - Data collection procedures\n% - Analytical approach\n\n\\subsection{Tool Selection Criteria}\n% - Range of claimed capabilities\n% - Market positioning\n% - Accessibility to researchers\n% - Comparability of features\n\n\\subsection{Research Tasks Investigated}\n% - Literature discovery\n% - Source analysis\n% - Data collection\n% - Knowledge synthesis\n% - Bibliography construction\n\n\\subsection{Evaluation Framework}\n% - Judgment application points\n% - Success criteria\n% - Documentation of process\n% - Limitations of approach\n\n% Evidence: autoethno-process-planning-notes.tex (research questions and approach)\n\n% ======================================================================\n% SECTION 4: FINDINGS (~1200 words)\n% ======================================================================\n% Purpose: Present results from investigation of various AI research tools\n\n\\section{Case Studies of AI Research Tools}\n\n\\subsection{OpenAI's Deep Research}\n% #### 4.1.1. Claimed Capabilities\n% - Marketing representation\n% - Technical architecture\n% - Search integration\n\n% #### 4.1.2. Observed Limitations\n% - Corpus access issues\n% - Lack of systematic approach\n% - Policy constraints and output \"infection\"\n% - Uncanny valley of research behavior\n%   - Pretense of systematic approach\n%   - Inability to revise fundamental assumptions\n%   - Blind alley persistence\n%   - Context window management failures\n\n% #### 4.1.3. Effective Applications\n% - Dataset preparation\n% - Initial literature discovery\n% - Source identification\n\n\\subsection{Anthropic's Computer Use}\n% - Technical capabilities and limitations\n% - Resource intensiveness\n% - Ability to navigate research interfaces\n% - Execution failures despite conceptual understanding\n\n\n\n% \\section{Other infrastructures}\n\n% \\subsection{Anthropic Computer Use}\n\n% While this is promising as a rough paradigm, Claude 3.5 Sonnet 20241022 did not possess sufficient world-intuition to collect a series of 8 article links from a web page. This failure consumed \\$1 of tokens, which is to say, 1.2 million tokens (mostly in screenshots) of failure to click, failure to right click, failure to change apps between firefox and libreoffice, and wittering about trying to solve its own navigation problems. \n\n% However, this does not require a difference in kind, merely a degree. This paradigm of computer use is a future of computer augmented research, since it got the idea of what we wanted to do. It simply failed at execution due to a deductive deficiency. The first chat was lost due to an inadvertent window closure (and the fact that absolutely no logs are kept by this demo application). The second one is in our supplemental data.) While we are sure that some prompt improvements can be made, as this was our second attempt at using computer use, further iteration would not reward the effort.\n\n% No prompting has been shared for Computer Use, as we were not able to proceed beyond our initial proof of concept. It is clear that with sufficient budget, and human supervision, Computer Use would be able to gradually navigate around web pages and extract data. It is simply not an efficient use of time or money at this stage of Claude 3.5 Sonnet's capabilities.\n\n\\subsection{Elicit Research Assistant}\n% - Corpus limitations\n% - Search criteria challenges\n% - Screening criteria application\n% - Report quality evaluation\n\n\n\n% \\subsection{Elicit Research Paper}\n\n% For Elicit, we provided the following prompt:\n\n% \\begin{quote}\n\n% Research question: Within the literature of archaeology and the historical sciences, constructed broadly, what software tools exist as discussed in the literature from 1995 onwards? Specifically, we are looking for you to examine the journals of: Internet Archaeology, SoftwareX, JOAD, JOSS, JCAA, and STAR (Science \\& Tech of Archaeological Research). We define a tool as: ```For our project, a software tool is any discrete piece of software\u2014be it a program, script, or web application\u2014that is developed or substantially modified by researchers to perform specific, research-oriented computational tasks. These tasks must involve active data processing, such as analysis, simulation, visualization, modeling, or automation, where input data is dynamically created, documented, transformed, or interpreted to generate meaningful results. In contrast, products whose primary function is to simply display, store, or promote static datasets\u2014without offering mechanisms for active computational engagement\u2014are excluded. In essence, a valid software tool for our purposes is one that not only **supports research in archaeology or historical sciences** but does so by actively collecting and/or processing data rather than merely serving as a generic data repository or static interface.``` The objective of this research report is to find and cite EVERY SINGLE software tool (from our construction above) as mentioned in those journals SO LONG as those software tools have specific and direct applicability or citation within papers about archaeological and historical sciences. Some of those journals are discipline specific, and we need to look through for software tool mentions (mere published datasets are not interesting to us). Some of those journals are tool specific, and we need to look through for DISCIPLINE mentions, to ensure that the tool has specific and direct relevance to historians and archaeologists. My objective here is either a bulleted list of citations, or if you can manage it a csv of citations for further work. The intention is that this research will support a paper on software longevity.\n\n% \\end{quote}\n\n% We did not believe that it would accomplish any real proportion of the prompt, but given that the Elicit team provided us a coupon for the \"Plus\" plan (\\$12/month), the available capabilities afforded to us were a one-prompt-and-go text area. Elicit's own infrastructure evaluated this prompt as a \"Great question.\" Unlike with our assessment of Anthropic's Computer Use, we believe that changes in both kind and degree are necessary for Elicit to be useful for research data collection. We assert the following systematic issues.\n% \\begin{enumerate}\n%     \\item Unacceptable scope, inhereted from Semantic Scholar\n%     \\item Problematic search criteria, via Semantic Scholar's deplorable TLDR summaries    \n%     \\item Model judgement failures in screening criteria operationalisation and evaluation\n%     \\item An utter lack of judgement and discernment in the final research report\n% \\end{enumerate}\n\n% We did find that, from our prompt, the model they are using did create acceptable screening criteria, but once created, the evaluation of those criteria against sample papers was deeply unsatisfactory. \n\n\\subsection{Additional Tools} % (Perplexity, Open Deep Research, etc.)\n% - Comparative capabilities\n% - Distinctive limitations\n% - Complementary features\n\n% Evidence: Thursday 8:36 am, 00:00:36-00:03:15 (Deep Research observations)\n% Evidence: Friday 6:19 pm, 00:00:33-00:01:40 (data collection use cases)\n% Evidence: AnAbsenceOfJudgement.tex (Computer Use and Elicit sections)\n\n% ======================================================================\n% SECTION 5: ANALYSIS (~1000 words)\n% ======================================================================\n% Purpose: Analyze findings through judgment framework and identify patterns\n\n\\section{Reflective Analysis}\n\n\n% \\subsection{Literature Reviews}\n% Initial applications in literature review processes have shown promising results, particularly in:\n% \\begin{itemize}\n%     \\item Dataset preparation and collection for research purposes\n%     \\item Improvement over previous superficial review methodologies\n% \\end{itemize}\n\n\n\\subsection{Manifestations of Technoaristotelianism}\n% - Appeals to authority without verification\n% - Absence of empirical checks\n% - Conflation of description with insight\n% - Inability to identify true knowledge gaps\n\n\n\n\n% \\subsection{Comparative Analysis}\n% Using a first-week PhD student as our prototypical target, we observe that while AI systems can mimic goal-following behavior, they fundamentally lack the authentic research capabilities demonstrated by even novice human researchers.\n\n\n\n\\subsection{Judgment Deficiency Patterns}\n\n\n\n% \\subsection{Fundamental Limitations}\n% \\begin{itemize}\n%     \\item Absence of goal-setting and goal-following behavior\n%     \\item Constraint to the Next Token paradigm\n%     \\item Limited self-reflexivity, characterized by:\n%         \\begin{itemize}\n%             \\item Simple search execution\n%             \\item Information synthesis without true comprehension\n%         \\end{itemize}\n%     \\item Inability to genuinely evaluate goal accomplishment\n%         \\begin{itemize}\n%             \\item System assumes task completion at each output\n%             \\item Lacks true self-assessment capability\n%         \\end{itemize}\n% \\end{itemize}\n\n\\subsubsection{Epistemic Humility Failures}\n% - Always producing an answer\n% - False certainty in uncertain domains\n% - Inability to recognize knowledge boundaries\n% - Performance of epistemic language without underlying capability\n\n\\subsubsection{Induction Limitations}\n% - Pattern recognition without insight\n% - Next-token prediction constraints\n% - Failure to connect disparate knowledge domains\n% - Absence of \"aha\" moments\n\n\\subsubsection{Reality Detachment}\n% - No experimental approach\n% - No verification suggestions\n% - Text-based evaluation only\n% - Inability to judge output quality against real-world criteria\n\n\\subsection{An answer to Dwarkesh's question}\n\n\n\n\n\n% \\section{Deep Research and AI Capabilities}\n\n% \\subsection{Current State}\n% The implementation of O3 for research purposes, while advanced, reveals fundamental limitations. This connects to broader discussions, as highlighted in Cohen's repost of DAKISH regarding AI's inability to produce truly groundbreaking research. While these systems demonstrate acceptable fluency and solid domain knowledge, they lack crucial elements of genuine research capability.\n\n% % One question I had for you while we were talking about the intelligence stuff was, as a scientist yourself, what do you make of the fact that these things have basically the entire corpus of human knowledge memorized and they haven\u2019t been able to make a single new connection that has led to a discovery? Whereas if even a moderately intelligent person had this much stuff memorized, they would notice \u2014 Oh, this thing causes this symptom. This other thing also causes this symptom. There\u2019s a medical cure right here.\n\n% % Shouldn\u2019t we be expecting that kind of stuff?\n\n% % It\u2019s a very good question. In 2023, I quipped, \u201cI think they have, we just haven\u2019t asked them.\u201d Maybe, but less clear today. Dwarkesh reports that there have been no good answers.\n% % https://feeds.feedblitz.com/~/912665402/0/marginalrevolution~Dwarkeshs-Question.html\n\n\\subsection{Mundane Utility Despite Limitations}\n% - Effective bounded applications\n% - Value for time-constrained researchers\n% - Complementary capabilities with human judgment\n% - Context window and token management strategies\n\n% Evidence: Epistemic Monday 8:50 am, 00:24:15-00:31:53 (Aristotelian fallacy)\n% Evidence: Friday 6:19 pm, 00:08:03-00:12:19 (mundane utility)\n% Evidence: Context Friday 8:47 am, 00:00:28-00:01:10 (paper structure on utility)\n\n% ======================================================================\n% SECTION 6: RECOMMENDATIONS (~650 words)\n% ======================================================================\n% Purpose: Provide concrete guidance for tool developers and researchers\n\n\\section{Research Tool Design Requirements}\n\n\n% 3. Assessment and Reporting\n%    - Make judgments about goal completion\n%    - Provide reports to users (like Claude)\n%    - Include success/failure evaluation based on system's judgment\n\n\\subsection{Judgment-Aware Architecture}\n% - Multi-threaded cognition\n% - Context window management\n% - Supervised reasoning\n% - Source tracking and evaluation\n% - Tombstones for discarded thoughts\n% - Self-critical assessment capabilities\n\n\\subsection{Research Process Support}\n% - Stage-based design (literature finding, extraction, etc.)\n% - Non-waterfall approach to research flows\n% - Structured to-do lists with human checkpoint integration\n% - Outline-driven context switching\n% - Documentation of decision points\n\n\\subsection{Human-AI Collaboration Framework}\n% - Recognition of AI judgment deficiency\n% - Strategic points for human intervention\n% - Validation and verification processes\n% - Tool-centric rather than agent-centric approach\n\n\\subsection{Evaluation Criteria for Research Tools}\n% - Transparency indicators\n% - Token management approaches\n% - Context awareness metrics\n% - Ability to \"forget\" or remove irrelevant content\n% - Documentation quality\n% - Human judgment integration points\n\n% Evidence: Context Friday 8:47 am, 00:07:23-00:09:31 (tombstones and forget)\n% Evidence: Thursday 8:36 am, 00:15:44-00:16:48 (multiple supervisory threads)\n% Evidence: Context Friday 8:47 am, 00:10:15-00:11:53 (stages of interaction)\n\n% ======================================================================\n% SECTION 7: CONCLUSION (~200 words)\n% ======================================================================\n% Purpose: Summarize key arguments and implications\n\n\\section{Conclusion}\n% ### 7.1. Summary of Argument\n% - Technoaristotelianism as fundamental limitation\n% - Three judgment deficiencies as manifestations\n% - Tool vs. agent distinction as pragmatic approach\n\n\\subsection{Implications}\n% - Realistic expectations for AI research tools\n% - Focus on human-AI collaboration frameworks\n% - Limits of current \"agentic\" claims\n\n\\subsection{Future Research Directions}\n% - Evolving capabilities assessment\n% - Judgment integration mechanisms\n% - Improved evaluation frameworks\n% \\section{Future Development}\n% \\subsection{Areas Requiring Further Investigation}\n% \\begin{itemize}\n%     \\item The Normal Intuitive Pattern concept requires elaboration\n%     \\item Connection between mundane utility and tool-using behavior\n%     \\item Precise definition of agentic behavior in research contexts\n%     \\item Concrete manifestations of judgment absence in research outputs\n% \\end{itemize}\n\n\n\n\n% Evidence: Various transcripts for synthesis\n\n\n\n\n\\end{document}"
        },
        {
          "file_name": "autoethno-process-planning-notes.tex",
          "file_size": 6301,
          "file_type": "",
          "extracted_content": "Notes on experience\n\n2025-02-07 Day 01\nInitial exploration, presented OpenAI Deep Research (DR) with several possible topics, querried: given the options above, how should we choose an appropriate topic to evaluate the capabilities of frontier models / agents to produce an article for a first-quartile journal? What should we test, and how do we approach it? \n\nResearch questions: \n* How much and how well can frontier models / agents serve as an RA to unstick a paper?\n* What combination of tools is most useful?\n* What are the strengths and weaknesses \n* What prompting skills does a researcher need to get the most out of the tool?\n\nWatching the output from DR is...fascinating\n\nSeems to have found / cited some predatory journals, neet to improve prompt to limit to higher quality outlets\n\nSome blogs / other sources appear blocked. This is probably a bad idea for those authors.\nIncluding some bodies of literature that I would not necessarily have surveyed when preparing the paper, broadening scope (but allowing the broader scope to be managable)\n\nSome really good insites, some less useful, some...very random\n\nPoints for including grey literature (and mentioning it at all). DR is using the language of our subdiscipline. Indeed, first 'thought' used 'Grey Literature'.\n\nOrder of results is interesting, in the case of Zack Batist, hit his blog (which was blocked), then bounced to his paper in IA. Researchers should blog about their research (and make sure the blog is readable by LLMs) if they want their work to be findable. As it is, we only found his blog and paper by reading the 'Activities' and 'Sources' carefully. FAIR?\n\nWhat does 'FAIR' mean when the readers are machine intellegences? See 'Writing for LLMs so the Listen' (Gwern) Writing as data for LLMs. Text is data.\n\nLooks at papers in other languages (of course), something that I might be lazy about\n\nDoes look at university research publication portals, which opens many closed publications that received public funding...\nCan't just live in the prompt / response window, must look at 'activity' and 'sources', and move back and forth between them to evaluate sources, understand what informaiton is being pulled from what source, and how it's being used and analysed.\n\nFinding the Batiste paper (2024) is really important, published in IA, so we probably would have found it, but surfacing new research this quickly is very helpful.\n\nThere's some waffle / padding - but it's not like humans don't do this too...\n\nThoughts: the lit review itself surfaces some important ideas quickly. Need to read it to figure out objections and counter-thoughts. The quality is high enough that it can't just be dismissed as either trivial or incorrect / misleading. \n\nQuoting patterns and choices are interesting...may need prompt refinement\nIn lit review, Batist is cited for work on GitHub, not on Open-Archaeo, which he co-operates and used as a main source of data in his paper.\n\nDR claims, that our paper has not yet been written (empirical data for how long software lives)\n\nOutput is a 'good first-year PhD RA' - we have to read the draft and think about it - it's decent, but not as insightful as it could be. Misses the point, buit misses the point in a useful way. 'Does not inherently understand truth of scholarly significance'\n\nHow is use of AI changing our writing? Making us think about collaborative writing, RAs, think about the scope of the paper and the direction to take it in, much like a human interlocutor with a different background.\n\nDifferent in degree and kind from earlier LLMs.\n\nUses two citation formats, scholarly and 'AI-format'. \n\nDidn't do everything we asked it to do, didn't generate set of prompts. Need to reprompt.\n\nFollow up prompt to initiate empirical analysis. DR asked for clarification about how to do this - feels like a supervision meeeting where we explain our preconceived approach (look at softaware publications and try to track longevity of tools mentioned in them through various means) and encouraging ideas that DR proposed (web scraping and GitHub analysis). Feels like supervising a first-year PhD...\n\n2025-02-08 Day 02\n\nReviewed generated text. Impressive. Produced some fluff but also suggested some sources and directions that we hadn't thought of. Thorough review of logevity challenges in DH and frameworks for sustainability and persistende (so far as it goes, nothing about building for interoperability so that when your piece of the ecosystem 'wears out', another can replace it. Apparently not so much literature on software sustainability in DH, since much of the generated text is about collections and digital editions. Nothing on planned decomissioning, something of an assumption that 'not lasting forever' is a failure. Plan for end of life needed, as is done in the repository world; assume that your software won't last forever (missing from generated report). Ah, 'planned sunset' is mentioned alongsied 'regular maintenance' - it is thorough. Good review of case studies, none of which we were familiar with.\n\nHmm...'best practices serve as a checklist of indicators' - perhaps we can capture these practices and compare them to longevity to empirically test this claim.\n\n2025-02-09 Day 03\n\nReviewed outputs and explorations to date and developed plan. \n\nBBS: dealing with uncertainty through aoristic modelling (or a similar statistical approach) regarding the lifespan of tools\n\nSAR: Did some tests, and DR is pretty good at constructing the 'research graph' by looking at Crossref and DataCite DOIs, ORCIDs, etc. - I'm getting decent results without too much time spent developing prompts. I thought this info might be useful when constructing prompts to find citations to research software or look for research software in (e.g.) DataCite.\n\n\n2025-02-20\nSAR: Operator did a better job than I first thought with JOAD. A manual check indicates only one article mentioning a 'software tool' was missed, and in that paper the tools used only get one brief paragraph.\nMentioning open-archaeo, a list of tools, is an interesting false positive\nIt didn't actually extract the tool name and other information as asked, only returned the article title.\nIt is very difficult to get consistently good citations out of any of the LLMs, even with extensive prompting."
        },
        {
          "file_name": "brian-references.bib",
          "file_size": 108734,
          "file_type": "",
          "extracted_content": "\n@online{gwern_writing_2024,\n\ttitle = {Writing for {LLMs} So They Listen},\n\trights = {https://creativecommons.org/publicdomain/zero/1.0/},\n\turl = {https://gwern.net/llm-writing},\n\tabstract = {Speculation about what sort of ordinary human writing is most relevant and useful to future {AI} systems.},\n\tauthor = {Gwern},\n\turldate = {2025-02-23},\n\tdate = {2024-11-30},\n\tlangid = {english},\n}\n\n@misc{software_sustainability_institute_software_2014,\n\ttitle = {Software Sustainability: Research and Practice from a {UK} perspective},\n\turl = {https://www.software.ac.uk},\n\tabstract = {This work explores sustainable software development practices from a {UK} perspective, focusing on community engagement, maintainability, and the establishment of sustainability metrics. It discusses the challenges involved in ensuring long-term viability for research software.},\n\tauthor = {{Software Sustainability Institute}},\n\tdate = {2014},\n\tdoi = {DOI not available},\n\tkeywords = {{UK}, maintainability, research software, software sustainability, sustainable practices},\n}\n\n@article{nyenah_software_2024,\n\ttitle = {Software sustainability of global impact models},\n\tvolume = {17},\n\tissn = {1991-9603},\n\turl = {http://dx.doi.org/10.5194/gmd-17-8593-2024},\n\tdoi = {10.5194/gmd-17-8593-2024},\n\tpages = {8593--8611},\n\tnumber = {23},\n\tjournaltitle = {Geoscientific Model Development},\n\tauthor = {Nyenah, Emmanuel and D\\{{\\textbackslash}textbackslash\\}\" oll, Petra and Katz, Daniel S. and Reinecke, Robert},\n\tdate = {2024-12-05},\n\tnote = {Publisher: Copernicus {GmbH}},\n\tkeywords = {code quality, source: elicit, source: perplexity, sustainability metrics},\n}\n\n@misc{endings_project_team_endings_2021,\n\ttitle = {Endings Principles for Digital Longevity},\n\turl = {https://endings.uvic.ca/principles.html},\n\tabstract = {This framework outlines a set of principles for designing digital projects with long-term sustainability. It emphasizes the use of static sites, standardized formats, and comprehensive documentation to ensure digital longevity.},\n\tauthor = {{Endings Project Team}},\n\tdate = {2021},\n\tdoi = {DOI not available},\n\tnote = {Published: University of Victoria},\n\tkeywords = {digital longevity, digital preservation, documentation, guidelines, sustainability},\n}\n\n@article{ye_open-source_2021,\n\ttitle = {Open-source Software Sustainability Models: Initial White Paper From the Informatics Technology for Cancer Research Sustainability and Industry Partnership Working Group},\n\tvolume = {23},\n\tissn = {1438-8871},\n\turl = {http://dx.doi.org/10.2196/20028},\n\tdoi = {10.2196/20028},\n\tpages = {e20028},\n\tnumber = {12},\n\tjournaltitle = {Journal of Medical Internet Research},\n\tauthor = {Ye, Ye and Barapatre, Seemran and Davis, Michael K and Elliston, Keith O and Davatzikos, Christos and Fedorov, Andrey and Fillion-Robin, Jean-Christophe and Foster, Ian and Gilbertson, John R and Lasso, Andras and Miller, James V and Morgan, Martin and Pieper, Steve and Raumann, Brigitte E and Sarachan, Brion D and Savova, Guergana and Silverstein, Jonathan C and Taylor, Donald P and Zelnis, Joyce B and Zhang, Guo-Qiang and Cuticchia, Jamie and Becich, Michael J},\n\tdate = {2021-12-02},\n\tnote = {Publisher: {JMIR} Publications Inc.},\n\tkeywords = {source: elicit},\n}\n\n@inproceedings{rosado_de_souza_what_2019,\n\ttitle = {What Makes Research Software Sustainable? An Interview Study with Research Software Engineers},\n\turl = {http://dx.doi.org/10.1109/CHASE.2019.00039},\n\tdoi = {10.1109/chase.2019.00039},\n\tpages = {135--138},\n\tbooktitle = {2019 {IEEE}/{ACM} 12th International Workshop on Cooperative and Human Aspects of Software Engineering ({CHASE})},\n\tpublisher = {{IEEE}},\n\tauthor = {Rosado de Souza, Mario and Haines, Robert and Vigo, Markel and Jay, Caroline},\n\tdate = {2019-05},\n\tkeywords = {source: elicit},\n}\n\n@article{weber_finite_2020,\n\ttitle = {Finite and infinite games: An ethnography of institutional logics in research software sustainability},\n\tvolume = {57},\n\tissn = {2373-9231},\n\turl = {http://dx.doi.org/10.1002/pra2.281},\n\tdoi = {10.1002/pra2.281},\n\tnumber = {1},\n\tjournaltitle = {Proceedings of the Association for Information Science and Technology},\n\tauthor = {Weber, Nicholas},\n\tdate = {2020-10},\n\tnote = {Publisher: Wiley},\n\tkeywords = {source: elicit},\n}\n\n@article{joenio_sustainability_2018,\n\ttitle = {On the sustainability of academic software: the case of static analysis tools},\n\tdoi = {10.1145/3266237.3266243},\n\tjournaltitle = {Brazilian Symposium on Software Engineering},\n\tauthor = {Joenio, Costa and Paulo, Meirelles and C., Chavez},\n\tdate = {2018},\n\tkeywords = {source: elicit},\n}\n\n@article{imran_software_2022,\n\ttitle = {Software Sustainability: A Systematic Literature Review and Comprehensive Analysis},\n\tissn = {1556-5068},\n\turl = {http://dx.doi.org/10.2139/ssrn.4151286},\n\tdoi = {10.2139/ssrn.4151286},\n\tjournaltitle = {{SSRN} Electronic Journal},\n\tauthor = {Imran, Asif and Kosar, Tevfik},\n\tdate = {2022},\n\tnote = {Publisher: Elsevier {BV}},\n\tkeywords = {source: elicit},\n}\n\n@article{vandecreek_great_2023,\n\ttitle = {Great lengths: a review of website preservation activities at three American Universities with digital humanities centers},\n\tvolume = {39},\n\tissn = {2055-7671},\n\turl = {http://dx.doi.org/10.1093/llc/fqad080},\n\tdoi = {10.1093/llc/fqad080},\n\tpages = {409--422},\n\tnumber = {1},\n\tjournaltitle = {Digital Scholarship in the Humanities},\n\tauthor = {{VandeCreek}, Drew},\n\tdate = {2023-11-11},\n\tnote = {Publisher: Oxford University Press ({OUP})},\n\tkeywords = {source: elicit},\n}\n\n@article{aseel_how_2016,\n\ttitle = {How Should We Measure the Relationship Between Code Quality and Software Sustainability ?},\n\tauthor = {Aseel, Aldabjan and R., Haines},\n\tdate = {2016},\n\tkeywords = {source: elicit},\n}\n\n@article{carver_survey_2022,\n\ttitle = {A survey of the state of the practice for research software in the United States},\n\tvolume = {8},\n\tissn = {2376-5992},\n\turl = {http://dx.doi.org/10.7717/peerj-cs.963},\n\tdoi = {10.7717/peerj-cs.963},\n\tpages = {e963},\n\tjournaltitle = {{PeerJ} Computer Science},\n\tauthor = {Carver, Jeffrey C. and Weber, Nic and Ram, Karthik and Gesing, Sandra and Katz, Daniel S.},\n\tdate = {2022-05-05},\n\tnote = {Publisher: {PeerJ}},\n\tkeywords = {source: elicit},\n}\n\n@article{akhlaghi_toward_2021,\n\ttitle = {Toward Long-Term and Archivable Reproducibility},\n\tvolume = {23},\n\tissn = {1521-9615},\n\turl = {http://dx.doi.org/10.1109/MCSE.2021.3072860},\n\tdoi = {10.1109/mcse.2021.3072860},\n\tpages = {82--91},\n\tnumber = {3},\n\tjournaltitle = {Computing in Science \\&amp; Engineering},\n\tauthor = {Akhlaghi, Mohammad and Infante-Sainz, Raul and Roukema, Boudewijn F. and Khellat, Mohammadreza and Valls-Gabaud, David and Baena-Galle, Roberto},\n\tdate = {2021-05-01},\n\tnote = {Publisher: Institute of Electrical and Electronics Engineers ({IEEE})},\n\tkeywords = {source: elicit},\n}\n\n@inproceedings{taylor_fading_2019,\n\ttitle = {Fading Away... The Challenge of Sustainability in Digital Studies},\n\turl = {https://www.digitalhumanities.org/dhq/vol/14/3/000484/000484.html},\n\tbooktitle = {Digital Humanities Quarterly},\n\tauthor = {Taylor, Joanna},\n\tdate = {2019},\n\tkeywords = {source: perplexity},\n}\n\n@article{university_of_victoria_endings_2023,\n\ttitle = {Endings Principles for Digital Longevity},\n\turl = {https://dh-tech.github.io/blog/2023/08/07/endings-principles/},\n\tauthor = {{University of Victoria}},\n\tdate = {2023},\n\tkeywords = {source: perplexity},\n}\n\n@article{smithies_managing_2019,\n\ttitle = {Managing 100 Digital Humanities Projects: Digital Scholarship \\& Archiving in King\u2019s Digital Lab},\n\tvolume = {13},\n\turl = {http://digitalhumanities.org/dhq/vol/13/1/000411/000411.html},\n\tabstract = {Details the operational practices of King's Digital Lab ({KDL}) in managing a large portfolio of digital humanities projects. Discusses how {KDL} balances active development with archiving and sustaining older projects. Introduces the concept of a 'digital preservation pipeline' integrated into project workflows. Topics include project metadata, containerization for preservation, pragmatic archiving (e.g., static site generation for legacy projects), and the role of institutional commitment. Provides a model for sustainability at scale within a university context.},\n\tnumber = {1},\n\tjournaltitle = {Digital Humanities Quarterly},\n\tauthor = {Smithies, James and Westling, Carina and Sichani, Anna-Maria and Mellen, Patrick and Ciula, Arianna},\n\tdate = {2019},\n\tkeywords = {Archiving, Case study, Digital humanities, Institutional infrastructure, King's Digital Lab, Project management, archiving, case study, digital humanities, project management, sustainability},\n}\n\n@article{barats_fading_2020,\n\ttitle = {Fading Away... The challenge of sustainability in digital studies},\n\tvolume = {14},\n\turl = {http://digitalhumanities.org/dhq/vol/14/3/000484/000484.html},\n\tabstract = {Emphasizes the need to consider sustainability as key in digital humanities research. Discusses tensions between long-term data preservation and short software lifecycles, noting technical and institutional challenges. Argues that sustainability in {HSS} requires addressing social practices and epistemic traditions alongside technology.},\n\tnumber = {3},\n\tjournaltitle = {Digital Humanities Quarterly},\n\tauthor = {Barats, Christine and Schafer, Val\u00e9rie and Fickers, Andreas},\n\tdate = {2020},\n\tkeywords = {Data lifecycle, Digital Humanities, Institutional challenges, Preservation, Sustainability, data preservation, digital humanities, digital studies, research infrastructure, sustainability},\n}\n\n@article{wilkinson_fair_2016,\n\ttitle = {The {FAIR} Guiding Principles for scientific data management and stewardship},\n\tvolume = {3},\n\tdoi = {10.1038/sdata.2016.18},\n\tabstract = {Proposes a set of foundational principles to make scientific data Findable, Accessible, Interoperable, and Reusable ({FAIR}). The paper articulates each principle and the rationale, aiming to improve data discovery and reuse by both humans and machines. It does not directly address software, but it has become influential in shaping subsequent efforts to apply similar principles to code. Helps contextualize why {FAIR} for software emerged.},\n\tpages = {160018},\n\tjournaltitle = {Scientific Data},\n\tauthor = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Baker, Myles and {others}},\n\tdate = {2016},\n\tkeywords = {Data management, Data stewardship, {FAIR}, Interoperability, Open data, Principles},\n}\n\n@incollection{easterbrook_engineering_2009,\n\ttitle = {Engineering the Software for Understanding Climate Change},\n\tvolume = {11},\n\tabstract = {Discusses the development and maintenance of climate modeling software by the scientific community. Highlights the iterative, experiment-driven approach to developing climate software and how it differs from traditional software engineering, yet still requires rigorous testing and validation. Addresses longevity by noting that climate models evolve over decades, requiring continuous management of code and data. Although domain-specific, it provides insight into sustaining complex scientific software, offering parallels for other domains.},\n\tpages = {65--74},\n\tnumber = {6},\n\tbooktitle = {Computing in Science \\& Engineering},\n\tauthor = {Easterbrook, Steve and Johns, Tim},\n\tdate = {2009},\n\tdoi = {10.1109/MCSE.2009.193},\n\tkeywords = {Case study, Climate models, Long-term development, Scientific software, Software engineering},\n}\n\n@article{vinopal_supporting_2013,\n\ttitle = {Supporting Digital Scholarship in Research Libraries: Scalability and Sustainability},\n\tvolume = {53},\n\tdoi = {10.1080/01930826.2013.756689},\n\tabstract = {Analyzes how research libraries can develop services and organizational structures to support digital scholarship (including humanities projects). Identifies challenges in scaling support given limited resources and growing demand. Proposes a tiered service model and emphasizes the need for sustainability planning in project support. While focused on library admin perspective, it underlines the importance of aligning digital project support with long-term library preservation functions. Often cited as a foundational work on library-based digital scholarship sustainability.},\n\tpages = {27--42},\n\tnumber = {1},\n\tjournaltitle = {Journal of Library Administration},\n\tauthor = {Vinopal, Jennifer and {McCormick}, Monica},\n\tdate = {2013},\n\tkeywords = {Digital scholarship support, Organizational strategy, Research libraries, Service models, Sustainability planning},\n}\n\n@report{al_research_2021,\n\ttitle = {Research software sustainability in the Netherlands: Current practices and recommendations},\n\turl = {https://zenodo.org/record/4604878},\n\tabstract = {Reports on a nation-wide assessment of research software sustainability practices in the Netherlands. Covers two main topics: software archiving (source code storage) and software sustainability (including reproducibility and reuse). Provides recommendations for stakeholders: calls on national e-infrastructure organizations ({eScience} Center, {DANS}, {SURF}) to support institutions in developing software support capacity, advocates closer cooperation among support organizations, and emphasizes aligning with initiatives like {FAIR} for software and Software Heritage. Key recommendations include creating clear policies for software deposit and developing training and incentives for researchers.},\n\tinstitution = {National Coordination Point Research Data Management ({LCRDM})},\n\tauthor = {al.), {LCRDM} Task Group on Research Software Sustainability (Gerard Coen et},\n\tdate = {2021},\n\tkeywords = {Archiving, National strategy, Netherlands, Reproducibility, Software sustainability policy, Stakeholder collaboration},\n}\n\n@article{katz_state_2019,\n\ttitle = {The State of Sustainable Research Software: Results from the Workshop on Sustainable Software for Science: Practice and Experiences ({WSSSPE}5.1)},\n\tvolume = {7},\n\tdoi = {10.5334/jors.242},\n\tabstract = {Summarizes key themes from the 5th {WSSSPE} workshop, an international gathering on sustainable research software. Topics include encouraging best practices in software development, creating career paths for research software engineers, learning and training initiatives, and methods to credit software contributions in academia. Provides community-based definitions (e.g. defines sustainable software as software able to evolve and remain functional over time on new platforms addressing new needs). Offers insight into the collective priorities and ongoing efforts in the research software community.},\n\tpages = {11},\n\tnumber = {1},\n\tjournaltitle = {Journal of Open Research Software},\n\tauthor = {Katz, Daniel S. and Druskat, Stephan and Haines, Robert and Jay, Caroline and Struck, Alexander},\n\tdate = {2019},\n\tkeywords = {Best practices, Community workshop, Credit and careers, Research Software Engineering, Sustainable software, {WSSSPE}},\n}\n\n@misc{arneil_endings_2018,\n\ttitle = {The Endings Project: Principles for Digital Longevity},\n\turl = {https://endings.uvic.ca/principles},\n\tabstract = {Presents a set of principles to guide the development and closure of digital humanities projects to ensure long-term sustainability. Recommends using open, non-proprietary data formats, version control for code and data, comprehensive documentation, and creation of static outputs for preservation. Derived from experiences with multiple Canadian humanities projects. Provides a framework adopted by {UVic} projects and beyond.},\n\tauthor = {Arneil, Stewart and Simpson, John D. and team, the Endings Project},\n\tdate = {2018},\n\tkeywords = {Best practices, Digital longevity, End-of-life planning, Guidelines, Open formats, {UVic} Endings Project},\n}\n\n@article{dombrowski_what_2014,\n\ttitle = {What Ever Happened to Project Bamboo?},\n\tvolume = {29},\n\tdoi = {10.1093/llc/fqu026},\n\tabstract = {Analyzes the Project Bamboo initiative, chronicling its origins, development, and ultimate closure. Identifies key challenges: unclear scope, difficulties in interdisciplinary collaboration, insufficient focus on deliverables, and sustainability planning. Offers lessons learned for future cyberinfrastructure projects in humanities.},\n\tpages = {326--339},\n\tnumber = {3},\n\tjournaltitle = {Literary and Linguistic Computing (Digital Scholarship in the Humanities)},\n\tauthor = {Dombrowski, Quinn},\n\tdate = {2014},\n\tkeywords = {Case study, Cyberinfrastructure, Digital humanities, Project Bamboo, Sustainability failure},\n}\n\n@article{barker_introducing_2022,\n\ttitle = {Introducing the {FAIR} Principles for research software},\n\tvolume = {9},\n\tdoi = {10.1038/s41597-022-01710-x},\n\tabstract = {Introduces community-developed {FAIR} principles tailored for research software ({FAIR}4RS). Discusses the need for software to be discoverable, have persistent identifiers, detailed metadata, and adhere to standards for reuse. Marks a significant step in aligning software management with open science and data stewardship practices.},\n\tpages = {622},\n\tnumber = {1},\n\tjournaltitle = {Scientific Data},\n\tauthor = {Barker, Michelle and Hong, Neil P. Chue and Katz, Daniel S. and Lamprecht, Anna-Lena and Martinez-Ortiz, Carlos and Psomopoulos, Fotis and Harrow, Jennifer and Castro, Leyla Jael and Gruenpeter, Morane and Martinez, Paula Andrea and Honeyman, Tom},\n\tdate = {2022},\n\tkeywords = {{FAIR} principles, Open science, Research software, Reusability, Software metadata},\n}\n\n@article{russell_after_2018,\n\ttitle = {After Innovation, Turn to Maintenance},\n\tvolume = {59},\n\tdoi = {10.1353/tech.2018.0004},\n\tabstract = {Argues that society's focus on innovation should be balanced by greater emphasis on maintenance, repair, and care of existing technologies. Provides historical and cultural analysis of why maintenance is undervalued. Relevant to software sustainability in suggesting that maintaining and iterating on software is as important as creating new software. Invokes examples from infrastructure and software to illustrate how maintenance work is often hidden yet crucial. The essay spurred discussions in multiple fields about recognizing and rewarding maintenance (e.g., the \"Maintainers\" movement).},\n\tpages = {1--25},\n\tnumber = {1},\n\tjournaltitle = {Technology and Culture},\n\tauthor = {Russell, Andrew L. and Vinsel, Lee},\n\tdate = {2018},\n\tkeywords = {History of technology, Innovation vs. maintenance, Maintenance, Sustainability culture, The Maintainers},\n}\n\n@article{kinnaman_dh_2023,\n\ttitle = {{DH} as Data: Establishing Greater Access through Sustainability},\n\tvolume = {17},\n\turl = {http://digitalhumanities.org/dhq/vol/17/3/000715/000715.html},\n\tabstract = {Describes a case study applying data curation and digital preservation methodologies to two digital humanities projects at Virginia Tech. Introduces the concept of treating digital humanities project components (content, code, metadata, documentation) as data to enhance preservation and access. Outcomes include an evaluated workflow, improved accessibility of project materials, and guidance for future projects. Highlights lack of existing {DH}-specific preservation standards and adapts library practices to fill this gap.},\n\tnumber = {3},\n\tjournaltitle = {Digital Humanities Quarterly},\n\tauthor = {Kinnaman, Alex and Guimont, Corinne},\n\tdate = {2023},\n\tkeywords = {Accessibility, Case study, Data curation, Digital humanities, Library collaboration, Preservation workflow},\n}\n\n@article{goddard_whats_2023,\n\ttitle = {What's Left When It's Over: Libraries and Digital Humanities Project Preservation},\n\tvolume = {3},\n\turl = {https://ideah.pubpub.org/pub/mfid9ero},\n\tdoi = {10.21428/f1f23564.00188fc5},\n\tabstract = {Explores how academic libraries can partner in preserving digital humanities projects. Reports on a survey of 127 {DH} projects (1980s\u20132010s) finding only 10\\% had long-term archival plans. Discusses six preservation strategies (dark archive, repository deposit, web harvesting, emulation, dynamic site preservation, static archiving) and examines their technical and resource implications. Stresses that organizational commitment is crucial to digital longevity.},\n\tnumber = {5},\n\tjournaltitle = {{IDEAH}: Interdisciplinary Digital Engagement in Arts \\& Humanities},\n\tauthor = {Goddard, Lisa},\n\tdate = {2023},\n\tkeywords = {Academic libraries, Digital humanities, Digital preservation, Endings project, Survey, Sustainability strategies},\n}\n\n@misc{commons_ardc_ardc_2020,\n\ttitle = {{ARDC} Research Software Program and Sustaining Research Software Project},\n\turl = {https://ardc.edu.au/our-work/research-software-program/},\n\tabstract = {{ARDC}'s program supports national efforts to recognize and sustain research software in Australia. It funds select at-risk software tools and develops guidelines for software publishing and maintenance, emphasizing open-source principles, containerization, and stable governance models. Part of Australia\u2019s broader {eResearch} strategy and alignment with {FAIR}, open science.},\n\tauthor = {Commons ({ARDC}), Australian Research Data},\n\tdate = {2020},\n\tnote = {Published: Program Webpage},\n\tkeywords = {{ARDC}, Australia, {eResearch}, open-source, research software, sustainability program},\n}\n\n@report{canada_draft_2023,\n\ttitle = {Draft National Research Software Strategy},\n\turl = {https://alliancecan.ca/en/services/research-software},\n\tabstract = {This draft strategy proposes a comprehensive national framework to support research software in Canada, covering funding for long-term maintenance, recognition of software engineering roles, creation of a software registry, and improved coordination across provinces and disciplines. Seeks to integrate software into broader open science efforts, aligning with global trends.},\n\tinstitution = {Digital Research Alliance of Canada},\n\tauthor = {Canada, Digital Research Alliance of},\n\tdate = {2023},\n\tkeywords = {Canada, maintenance funding, national strategy, open science, software infrastructure},\n}\n\n@misc{united_nations_educational_unesco_2021,\n\ttitle = {{UNESCO} Recommendation on Open Science},\n\turl = {https://unesdoc.unesco.org/ark:/48223/pf0000379949},\n\tabstract = {{UNESCO}'s landmark recommendation on Open Science recognizes that open access to scientific publications, data, software, and other research outputs is essential for global knowledge equity. It calls on member states to implement policies and infrastructures supporting open-source software development, capacity building, and removal of legal barriers, reinforcing software's role in inclusive, collaborative research.},\n\tauthor = {United Nations Educational, Scientific and Organization ({UNESCO}), Cultural},\n\tdate = {2021},\n\tnote = {Published: Adopted by {UNESCO} General Conference},\n\tkeywords = {{UNESCO}, global collaboration, open science, open-source software, policy framework},\n}\n\n@misc{co-operation_recommendation_2021,\n\ttitle = {Recommendation on Access to Research Data from Public Funding (amended 2021)},\n\turl = {https://legalinstruments.oecd.org/public/doc/281/281.en.pdf},\n\tabstract = {The {OECD} Council updated its recommendation to explicitly include research software among the outputs that should be open and accessible when supported by public funding. Recognizes software as vital for data reproducibility and calls on member states to develop or strengthen infrastructure, policies, and incentives for open software. Part of a broader {OECD} emphasis on open science.},\n\tauthor = {Co-operation, Organisation for Economic and Council, Development ({OECD})},\n\tdate = {2021},\n\tnote = {Published: {OECD} Council Recommendation},\n\tkeywords = {{OECD}, open science, public funding, research data, software sharing},\n}\n\n@report{group_scholarly_2020,\n\ttitle = {Scholarly Infrastructures for Research Software ({SIRS}) Report},\n\turl = {https://doi.org/10.2777/28598},\n\tabstract = {This {EOSC} {WG} report reviews the landscape of research software infrastructures across Europe. It advocates treating software as a first-class citizen in the {EOSC}, with persistent identifiers ({SWHIDs}, {DOIs}), standardized metadata, and integration into scholarly workflows. Recommends coordinated funding for archiving and sustaining software, and aligning policies around open-source code repositories.},\n\tinstitution = {European Open Science Cloud ({EOSC})},\n\tauthor = {Group, {EOSC} Architecture Working},\n\tdate = {2020},\n\tdoi = {10.2777/28598},\n\tkeywords = {{EOSC}, Europe, {SIRS}, infrastructure, open science, research software},\n}\n\n@misc{science_open_2023,\n\ttitle = {Open Science for Global Benefit: G7 Science Ministers\u2019 Communiqu\u00e9 (Sendai 2023)},\n\turl = {https://www.g7japan.mofa.go.jp/},\n\tabstract = {The 2023 G7 S\\&T Ministers underscore open science as critical for tackling global challenges. They endorse {FAIR} data and software, call for improved infrastructure interoperability, and support recognition of diverse outputs in research evaluation. While software is not named explicitly, it is included in references to '{FAIR} digital objects' and open research outputs.},\n\tauthor = {Science, G7 and Ministers, Technology},\n\tdate = {2023},\n\tnote = {Published: Ministerial Statement},\n\tkeywords = {{FAIR} principles, G7, global collaboration, open science, policy communiqu\u00e9},\n}\n\n@misc{alliance_resa_policy_2021,\n\ttitle = {Policy Recommendations to Governments: Enabling Sustainable Research Software},\n\turl = {https://researchsoftware.org/blog/policy-recommendations.html},\n\tabstract = {{ReSA} outlines steps for governments to integrate software in open science policies, fund maintenance and training programs, and adopt best practices like {FAIR}4RS. Stresses the need for stable infrastructure and recognition of software in scholarly credit systems. Encourages global coordination via {RDA}, {UNESCO}, and the G7 open science agenda.},\n\tauthor = {Alliance ({ReSA}), Research Software},\n\tdate = {2021},\n\tnote = {Published: {ReSA} Policy Blog},\n\tkeywords = {{ReSA}, global coordination, open science, policy, software sustainability},\n}\n\n@misc{alliance_rda_covid-19_2020,\n\ttitle = {{COVID}-19 Open Science Guidelines (Software Section)},\n\turl = {https://doi.org/10.15497/rda00052},\n\tabstract = {During the {COVID}-19 pandemic, the {RDA} issued rapid guidelines for sharing data and software openly to accelerate research. The software section emphasizes open licensing, clear documentation, containerization, and use of established repositories for code. These measures aim to improve reproducibility, collaboration, and trust in emergent scientific outputs during crisis response.},\n\tauthor = {Alliance ({RDA}), Research Data},\n\tdate = {2020},\n\tnote = {Published: {RDA} {COVID}-19 Working Group Guidelines},\n\tkeywords = {{COVID}-19, {RDA}, open science, reproducibility, software guidelines},\n}\n\n@misc{united_nations_educational_paris_2019,\n\ttitle = {Paris Call: Software Source Code as Heritage for Sustainable Development},\n\turl = {https://en.unesco.org/foss/paris-call},\n\tabstract = {Issued by {UNESCO} and Inria, the Paris Call declares software source code as part of the world\u2019s cultural and scientific heritage. It urges governments and stakeholders to preserve, share, and reuse code, underscoring its importance for sustainable development and open knowledge. The initiative builds upon Software Heritage's work archiving global software.},\n\tauthor = {United Nations Educational, Scientific and Organization ({UNESCO}), Cultural and Automatique (Inria), Institut National de Recherche en Informatique et en},\n\tdate = {2019},\n\tnote = {Published: Declaration from {UNESCO} and Inria},\n\tkeywords = {Inria, Paris Call, {UNESCO}, preservation, software heritage, sustainable development},\n}\n\n@misc{co-operation_open_2020,\n\ttitle = {Open Science: Enabling Discovery in the Digital Age (Policy Note No. 13)},\n\turl = {https://www.oecd.org/going-digital/enabling-discovery-in-digital-age.pdf},\n\tabstract = {{OECD} policy note discussing how open science practices, including the sharing of data and software, accelerate innovation and collaboration. Encourages governments to invest in sustainable infrastructure for data and code, develop standards for metadata and {PIDs}, and reform academic incentives to reward open-science activities. Emphasizes bridging the digital divide and fostering global cooperation.},\n\tauthor = {Co-operation, Organisation for Economic and Development ({OECD})},\n\tdate = {2020},\n\tnote = {Published: Going Digital Toolkit Policy Note},\n\tkeywords = {{OECD}, digital age, infrastructure, open science, policy, software},\n}\n\n@article{lamprecht_fair_2022,\n\ttitle = {{FAIR} Principles for Research Software ({FAIR}4RS)},\n\tvolume = {9},\n\turl = {https://doi.org/10.1038/s41597-022-01710-x},\n\tdoi = {10.1038/s41597-022-01710-x},\n\tabstract = {Presents the {FAIR}4RS principles, adapting the original {FAIR} data principles to software. Stresses the importance of versioning, clear licensing, discoverability, and well-documented dependencies to ensure software is findable, accessible, interoperable, and reusable in scholarly contexts. An outcome of a joint {RDA}, {ReSA}, and {FORCE}11 working group, this represents a global community consensus on software best practices.},\n\tpages = {622},\n\tjournaltitle = {Scientific Data},\n\tauthor = {Lamprecht, Anna-Lena and Barker, Michelle and Hong, Neil Chue and Katz, Daniel S. and Psomopoulos, Fotis and Harrow, Jennifer and Honeyman, Tom and Castro, Leyla Jael and Martinez, Paula Andrea and Martinez, Carlos and Gruenpeter, Morane},\n\tdate = {2022},\n\tkeywords = {{FAIR}4RS, {RDA}, {ReSA}, interoperability, licensing, research software},\n}\n\n@article{loewe_environment_2020,\n\ttitle = {An environment for sustainable research software in Germany and beyond},\n\tvolume = {9},\n\turl = {https://f1000research.com/articles/9-295},\n\tdoi = {10.12688/f1000research.23224.1},\n\tabstract = {Through analysis of research software practices in Germany, the authors demonstrate that lack of incentives and credit for software hinder sustainability. They propose measures for funders and institutions to treat software as infrastructure, create specialized positions for software engineers, and develop frameworks for open licensing. Though focused on Germany, the recommendations have broader application for international scientific software.},\n\tpages = {295},\n\tjournaltitle = {F1000Research},\n\tauthor = {Loewe, Peter and L\u00f6ffler, Frank and Janosch, Stephan and Morgan, Nicole J. and Druskat, Stephan and Leonelli, Sabine},\n\tdate = {2020},\n\tkeywords = {Germany, incentives, open licensing, research software, sustainability environment},\n}\n\n@report{hettrick_research_2016,\n\ttitle = {Research Software Sustainability: Report on a Knowledge Exchange Workshop},\n\turl = {https://doi.org/10.5281/zenodo.231955},\n\tabstract = {A cross-European workshop exploring challenges in sustaining research software. Representatives from {DFG}, Jisc, {SURF} and other organizations identified themes of inadequate career incentives, fragmentation of efforts, and difficulty in obtaining maintenance funding. Recommendations include increased international coordination and recognition of software as an essential research output requiring robust infrastructure support.},\n\tinstitution = {Knowledge Exchange},\n\tauthor = {Hettrick, Simon and Partners, Knowledge Exchange},\n\tdate = {2016},\n\tkeywords = {{EU} cooperation, Knowledge Exchange, Software sustainability, incentives, maintenance funding},\n}\n\n@report{science_uk_large-scale_2018,\n\ttitle = {Large-scale Computing: The Case for Greater {UK} Coordination},\n\turl = {https://www.gov.uk/government/publications/large-scale-computing-the-case-for-greater-uk-coordination},\n\tabstract = {This official report emphasizes that high-quality software is central to exploiting large-scale computing infrastructures in the {UK}. It warns against focusing solely on hardware investments and recommends funding for ongoing software development, maintenance, and training to ensure maximum scientific and economic return from advanced computing resources.},\n\tinstitution = {Government Office for Science},\n\tauthor = {Science ({UK}), Government Office for},\n\tdate = {2018},\n\tkeywords = {{HPC}, Infrastructure, Large-scale computing, {UK} policy, software maintenance},\n}\n\n@inproceedings{katz_addressing_2021,\n\ttitle = {Addressing Research Software Sustainability via Institutes},\n\turl = {https://doi.org/10.1109/eScience51609.2021.00054},\n\tdoi = {10.1109/eScience51609.2021.00054},\n\tabstract = {This paper stems from discussions about establishing {US}-based Research Software Sustainability Institutes ({URSSI}). It explores sociotechnical challenges, the necessity of dedicated software-focused funding and career paths, and how institutes can foster community-driven solutions. Recommendations include coordinated long-term investments, training, and policy changes that incentivize software preservation.},\n\tbooktitle = {Proceedings of the {BoKSS} Workshop at {IEEE} {eScience}},\n\tauthor = {Katz, Daniel S. and Niemeyer, K. E. and Pierce, M. E. and Cosden, Ian and Gesing, Sandra and Hong, Neil Chue and Gunter, Dan and Idaszak, Ray and Couturier, St\u00e9phane and Todorov, Ilian},\n\tdate = {2021},\n\tkeywords = {Community, Funding, Policy, Research software, Sustainability institutes, {URSSI}},\n}\n\n@misc{foundation_software_2011,\n\ttitle = {Software Infrastructure for Sustained Innovation ({SI}2) Program Solicitations and Overview},\n\turl = {https://www.nsf.gov/pubs/2011/nsf11589/nsf11589.htm},\n\tabstract = {These solicitations established a funding pathway for research software at various scales (e.g., Conceptualization Awards, Implementation Awards, Scientific Software Integration). The {SI}2 program formalized {NSF}'s commitment to sustaining software as part of the broader cyberinfrastructure, emphasizing ongoing maintenance, community building, and robust engineering practices.},\n\tauthor = {Foundation, National Science},\n\tdate = {2011},\n\tnote = {Published: {NSF} Program Solicitation},\n\tkeywords = {{NSF}, {SI}2, funding pathways, software infrastructure, sustainability},\n}\n\n@report{science_final_2010,\n\ttitle = {Final Report of the Task Force on Software for Science and Engineering},\n\turl = {https://www.nsf.gov/attachments/117803/public/Software.pdf},\n\tabstract = {This task force report outlines a vision for research software as a key element of the national cyberinfrastructure. It recommends multi-level long-term funding, portability and modernization initiatives, and cultural changes to treat software development as a first-class scholarly activity. The report influenced subsequent {NSF} programs (e.g. {SI}2, {CSSI}) aimed at supporting sustainable, well-engineered software for scientific research.},\n\tinstitution = {National Science Foundation ({NSF})},\n\tauthor = {Science, National Science Foundation Advisory Committee for Cyberinfrastructure Task Force on Software for and {Engineering}},\n\tdate = {2010},\n\tkeywords = {Cyberinfrastructure, Funding models, {NSF}, Research software, Software sustainability},\n}\n\n@report{data_turning_2018,\n\ttitle = {Turning {FAIR} into Reality},\n\turl = {https://op.europa.eu/en/publication-detail/-/publication/7769a148-f9c6-11e8-9982-01aa75ed71a1},\n\tabstract = {An influential expert group report extending {FAIR} principles to all digital research objects, including software. Encourages persistent identifiers, standardized metadata, and open licensing for code. Stresses the importance of linking data and software for reproducibility. Lays groundwork for subsequent European Open Science policies that regard software as a first-class research output.},\n\tinstitution = {Publications Office of the European Union},\n\tauthor = {Data, European Commission Expert Group on {FAIR}},\n\tdate = {2018},\n\tdoi = {10.2777/1524},\n\tkeywords = {European Commission, {FAIR} principles, digital objects, open science, software metadata},\n}\n\n@report{foundation_dfg_guidelines_2015,\n\ttitle = {Guidelines for Funding Proposals on Research Software Sustainability},\n\turl = {http://www.dfg.de/},\n\tabstract = {These {DFG} guidelines specify how proposals seeking to enhance or sustain existing research software should articulate a clear sustainability concept, including documentation, archiving, and community use. The guidelines prioritize open licensing, collaborative development, and planning for software beyond the original project. Part of a wider push by {DFG} to recognize software as a key research output.},\n\tinstitution = {Deutsche Forschungsgemeinschaft ({DFG})},\n\tauthor = {Foundation ({DFG}), German Research},\n\tdate = {2015},\n\tkeywords = {{DFG}, Germany, grant guidelines, open source, software sustainability},\n}\n\n@misc{institute_ssi_software_2020,\n\ttitle = {Software Sustainability Institute: Key Achievements 2010\u20132020},\n\turl = {https://www.software.ac.uk/},\n\tabstract = {The Software Sustainability Institute, established with {EPSRC} support, has driven software best practices in {UK} research since 2010. Key achievements include collaborative consultancy on over 70 projects, the Fellowship programme for research software ambassadors, community events, and thought leadership on policy. Their efforts helped popularize the Research Software Engineer ({RSE}) role and shaped software management plans for {UK} funders.},\n\tauthor = {Institute ({SSI}), Software Sustainability},\n\tdate = {2020},\n\tnote = {Published: Institutional Webpage and Reports},\n\tkeywords = {{RSE}, {SSI}, {UK}, best practices, capacity building, research software},\n}\n\n@report{project_urssi_2018,\n\ttitle = {{URSSI} Conceptualization Workshops and Reports},\n\turl = {https://urssi.us},\n\tabstract = {A series of workshops and surveys conducted to plan a {US} Research Software Sustainability Institute. The reports identify social and technical impediments to sustaining research code, stressing the need for incentives, career paths for software engineers, and best practices in collaborative development. They propose a national institute to coordinate knowledge, training, and resources for long-term software maintenance.},\n\tinstitution = {National Science Foundation},\n\tauthor = {Project, U. S. Research Software Sustainability Institute ({URSSI}) Conceptualization},\n\tdate = {2018},\n\tkeywords = {Incentives, Research software, Sustainability challenges, {URSSI}, Workshops},\n}\n\n@article{ye_open-source_2021-1,\n\ttitle = {Open-source Software Sustainability Models: Initial White Paper From the Informatics Technology for Cancer Research Sustainability and Industry Partnership Working Group},\n\tvolume = {23},\n\tissn = {1439-4456},\n\turl = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8686402/},\n\tdoi = {10.2196/20028},\n\tshorttitle = {Open-source Software Sustainability Models},\n\tabstract = {Background\nThe National Cancer Institute Informatics Technology for Cancer Research ({ITCR}) program provides a series of funding mechanisms to create an ecosystem of open-source software ({OSS}) that serves the needs of cancer research. As the {ITCR} ecosystem substantially grows, it faces the challenge of the long-term sustainability of the software being developed by {ITCR} grantees. To address this challenge, the {ITCR} sustainability and industry partnership working group ({SIP}-{WG}) was convened in 2019.\n\nObjective\nThe charter of the {SIP}-{WG} is to investigate options to enhance the long-term sustainability of the {OSS} being developed by {ITCR}, in part by developing a collection of business model archetypes that can serve as sustainability plans for {ITCR} {OSS} development initiatives. The working group assembled models from the {ITCR} program, from other studies, and from the engagement of its extensive network of relationships with other organizations (eg, Chan Zuckerberg Initiative, Open Source Initiative, and Software Sustainability Institute) in support of this objective.\n\nMethods\nThis paper reviews the existing sustainability models and describes 10 {OSS} use cases disseminated by the {SIP}-{WG} and others, including 3D Slicer, Bioconductor, Cytoscape, Globus, i2b2 (Informatics for Integrating Biology and the Bedside) and {tranSMART}, Insight Toolkit, Linux, Observational Health Data Sciences and Informatics tools, R, and {REDCap} (Research Electronic Data Capture), in 10 sustainability aspects: governance, documentation, code quality, support, ecosystem collaboration, security, legal, finance, marketing, and dependency hygiene.\n\nResults\nInformation available to the public reveals that all 10 {OSS} have effective governance, comprehensive documentation, high code quality, reliable dependency hygiene, strong user and developer support, and active marketing. These {OSS} include a variety of licensing models (eg, general public license version 2, general public license version 3, Berkeley Software Distribution, and Apache 3) and financial models (eg, federal research funding, industry and membership support, and commercial support). However, detailed information on ecosystem collaboration and security is not publicly provided by most {OSS}.\n\nConclusions\nWe recommend 6 essential attributes for research software: alignment with unmet scientific needs, a dedicated development team, a vibrant user community, a feasible licensing model, a sustainable financial model, and effective product management. We also stress important actions to be considered in future {ITCR} activities that involve the discussion of the sustainability and licensing models for {ITCR} {OSS}, the establishment of a central library, the allocation of consulting resources to code quality control, ecosystem collaboration, security, and dependency hygiene.},\n\tpages = {e20028},\n\tnumber = {12},\n\tjournaltitle = {Journal of Medical Internet Research},\n\tshortjournal = {J Med Internet Res},\n\tauthor = {Ye, Ye and Barapatre, Seemran and Davis, Michael K and Elliston, Keith O and Davatzikos, Christos and Fedorov, Andrey and Fillion-Robin, Jean-Christophe and Foster, Ian and Gilbertson, John R and Lasso, Andras and Miller, James V and Morgan, Martin and Pieper, Steve and Raumann, Brigitte E and Sarachan, Brion D and Savova, Guergana and Silverstein, Jonathan C and Taylor, Donald P and Zelnis, Joyce B and Zhang, Guo-Qiang and Cuticchia, Jamie and Becich, Michael J},\n\turldate = {2025-02-20},\n\tdate = {2021-12-02},\n\tpmid = {34860667},\n\tpmcid = {PMC8686402},\n}\n\n@article{kinnaman_dh_2023-1,\n\ttitle = {{DH} as Data: Establishing Greater Access through Sustainability},\n\tvolume = {17},\n\trights = {Creative Commons Attribution-{NoDerivatives} 4.0 International License},\n\tissn = {1938-4122},\n\turl = {https://www.digitalhumanities.org/dhq/vol/17/3/000715/000715.html},\n\tshorttitle = {{DH} as Data},\n\tabstract = {This paper presents methodology and findings from a multi-case study exploring the use of preservation and sustainability measures to increase access to digital humanities ({DH}) content. Specifically, we seek to develop a workflow to both prepare {DH} content for preservation while enhancing the accessibility of the project. This work is based on the idea of treating {DH} as traditional data by applying data curation and digital preservation methods to {DH} content. Our outcomes are an evaluation of the process and output using qualitative methods, publicly accessible and described project components on two Virginia Tech projects, and a potential workflow that can be applied to future work. By breaking down individual projects into their respective components of content, code, metadata, and documentation and examining each component individually for access and preservation, we can begin migrating our digital scholarship to a sustainable, portable, and accessible existence.},\n\tnumber = {3},\n\tjournaltitle = {Digital Humanities Quarterly},\n\tauthor = {Kinnaman, Alex and Guimont, Corinne},\n\turldate = {2025-02-20},\n\tdate = {2023},\n}\n\n@inproceedings{schryen_adopting_2023,\n\ttitle = {Adopting Generative {AI} for Literature Reviews: An Epistemological Perspective},\n\turl = {http://ris.uni-paderborn.de},\n\tdoi = {DOI not available},\n\tabstract = {This conference paper explores the potential of generative {AI} tools, such as {ChatGPT} and Bard, for supporting literature reviews. It offers an epistemological critique, arguing that while {AI} can boost productivity, genuine innovation in knowledge creation still depends on human expertise.},\n\tbooktitle = {Proceedings of the Conference at {RIS}.{UNI}-{PADERBORN}.{DE}},\n\tauthor = {Schryen, G. and {others}},\n\tdate = {2023},\n\tkeywords = {{ChatGPT}, conference, epistemology, generative {AI}, literature review},\n}\n\n@article{tucker_facing_2022,\n\ttitle = {Facing the challenge of digital sustainability as humanities researchers},\n\tvolume = {10},\n\turl = {https://doi.org/10.5871/jba/010.093},\n\tdoi = {10.5871/jba/010.093},\n\tabstract = {Humanities researchers are increasingly concerned with the long-term sustainability of digital resources. This article reviews challenges in preserving digital research outputs and discusses technological, financial, environmental, and human dimensions of sustainability. It presents a new working definition of digital sustainability tailored to the humanities.},\n\tpages = {93--120},\n\tjournaltitle = {Journal of the British Academy},\n\tauthor = {Tucker, Joanna},\n\tdate = {2022},\n\tkeywords = {digital research, digital sustainability, humanities, preservation, sustainability challenges},\n}\n\n@article{smith_software_2016,\n\ttitle = {Software Citation Principles},\n\tvolume = {2},\n\turl = {https://doi.org/10.7717/peerj-cs.86},\n\tdoi = {10.7717/peerj-cs.86},\n\tabstract = {This paper presents a set of principles for citing software in academic research. It emphasizes the importance of credit, unique identification, persistence, and accessibility for software as a citable research product.},\n\tpages = {e86},\n\tjournaltitle = {{PeerJ} Computer Science},\n\tauthor = {Smith, A. and Katz, D. S. and Niemeyer, K. E. and Group, {FORCE}11 Software Citation Working},\n\tdate = {2016},\n\tkeywords = {{FORCE}11, {PeerJ} Computer Science, citation principles, research software, software citation},\n}\n\n@article{mostafapour_evaluating_2024,\n\ttitle = {Evaluating Literature Reviews Conducted by Humans Versus {ChatGPT}: Comparative Study},\n\tvolume = {1},\n\turl = {https://ai.jmir.org/2024/1/e56537/},\n\tdoi = {10.2196/56537},\n\tabstract = {This study compares literature reviews conducted by humans versus {ChatGPT}-4. It found that while {GPT}-4 can quickly draft a broad literature review with impressive breadth, human oversight is necessary for accuracy and depth due to errors in contextual understanding.},\n\tnumber = {1},\n\tjournaltitle = {{JMIR} {AI}},\n\tauthor = {Mostafapour, Mehrnaz and Fortier, Jacqueline H. and Pacheco, Karen and Murray, Heather and Garber, Gary},\n\tdate = {2024},\n\tkeywords = {{AI} evaluation, {ChatGPT}, {JMIR} {AI}, human oversight, literature review},\n}\n\n@article{meneses_shelf_2019,\n\ttitle = {Shelf life: Identifying the abandonment of online digital humanities projects},\n\tvolume = {34},\n\turl = {URL not available},\n\tdoi = {DOI not available},\n\tabstract = {This article introduces the concept of \u201cshelf life\u201d as a measure for the persistence of digital humanities projects. It explores factors that lead to the abandonment of online projects and proposes evaluation metrics.},\n\tpages = {i129--i135},\n\tissue = {Suppl\\_1},\n\tjournaltitle = {Digital Scholarship in the Humanities},\n\tauthor = {Meneses, L. and Furuta, R.},\n\tdate = {2019},\n\tkeywords = {digital humanities, evaluation, persistence, project abandonment, shelf life},\n}\n\n@misc{mathiak_overview_2019,\n\ttitle = {Overview of Life and Death of Digital Scholarly Editions (Data Set \\& Analysis)},\n\turl = {https://dh2020.adho.org/wp-content/uploads/2020/07/565_SustainabilityStrategiesforDigitalHumanitiesSystems.html},\n\tauthor = {Mathiak, Brigitte and Schildkamp, Philip},\n\tdate = {2019},\n}\n\n@misc{mathiak_overview_2019-1,\n\ttitle = {Overview of life and death of digital scholarly editions},\n\turl = {URL not available},\n\tabstract = {Provides an analysis of the lifespan of digital scholarly editions, reporting an average life of about 8.5 years. It discusses factors that contribute to the attrition of these digital projects.},\n\tauthor = {Mathiak, B. and Schildkamp, P.},\n\tdate = {2019},\n\tdoi = {DOI not available},\n\tkeywords = {analysis, digital humanities, digital scholarly editions, lifespan, preservation},\n}\n\n@misc{lcrdm_task_group_research_2021,\n\ttitle = {Research software sustainability in the Netherlands: Current practices and recommendations},\n\turl = {https://dans.knaw.nl},\n\tabstract = {This report defines sustainability for research software in terms of archiving, reproducibility, and reuse. It presents current practices in the Netherlands and offers recommendations for national support and the use of long\u2010term archives such as Software Heritage.},\n\tauthor = {{LCRDM Task Group}},\n\tdate = {2021},\n\tdoi = {DOI not available},\n\tkeywords = {Netherlands, archiving, reproducibility, research software, sustainability},\n}\n\n@misc{harzenetter_analysis_2020,\n\ttitle = {Analysis and Categorisation of Research Software in the Digital Humanities},\n\turl = {URL not available},\n\tabstract = {This poster presents the {SustainLife} approach, which uses {TOSCA} for preserving research software in the digital humanities. It categorizes various types of research software and outlines strategies for their long-term preservation.},\n\tauthor = {Harzenetter, L. and {others}},\n\tdate = {2020},\n\tdoi = {DOI not available},\n\tnote = {Published: {DH}2020 Conference Poster},\n\tkeywords = {{TOSCA}, conference poster, digital humanities, preservation, research software},\n}\n\n@misc{flanders_sustainable_2012,\n\ttitle = {Sustainable humanities computing},\n\tabstract = {Discusses sustainable computing practices in digital humanities, providing early insights into the frameworks required for ensuring long-term digital preservation.},\n\tauthor = {Flanders and Munoz},\n\tdate = {2012},\n\tdoi = {DOI not available},\n\tkeywords = {digital humanities, humanities computing, sustainability, sustainable computing},\n}\n\n@article{batist_open_2024,\n\ttitle = {Open archaeology, open source? Collaborative practices in an emerging community of archaeological software engineers},\n\turl = {https://doi.org/10.11141/ia.67.13},\n\tdoi = {10.11141/ia.67.13},\n\tabstract = {This article analyzes collaborative practices among archaeological software engineers by examining 25 years of projects on {GitHub}. It finds that most projects have very few contributors, which may limit community sustainability. The paper discusses the promise and challenges of open-source development in the archaeological domain.},\n\tnumber = {67},\n\tjournaltitle = {Internet Archaeology},\n\tauthor = {Batist, Zachary and Roe, Joe},\n\tdate = {2024},\n\tkeywords = {archaeology, collaboration, digital humanities, open source, software engineering},\n}\n\n@article{noauthor_artificial_2023,\n\ttitle = {Artificial Intelligence and the Practice of History: A Forum (Special Issue)},\n\tvolume = {128},\n\turl = {https://academic.oup.com/ahr/article-abstract/128/3/1345/7282240?login=false},\n\tnumber = {3},\n\tjournaltitle = {American Historical Review},\n\tdate = {2023},\n}\n\n@online{noauthor_frontiers_nodate,\n\ttitle = {Frontiers {\\textbar} Evaluating {ChatGPT}-4\u2019s historical accuracy: a case study on the origins of {SWOT} analysis},\n\turl = {https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1402047/full},\n\turldate = {2025-02-20},\n}\n\n@misc{noauthor_operator_2025,\n\ttitle = {Operator and Deep Research Tool Announcements (Tech News)},\n\turl = {https://www.deeplearning.ai/the-batch/openai-announces-operator-and-deep-research-tool/},\n\tpublisher = {{OpenAI}},\n\tdate = {2025},\n}\n\n@article{seker_editorial_2024,\n\ttitle = {Editorial: Large language models in work and business},\n\tvolume = {7},\n\tissn = {2624-8212},\n\turl = {https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1516832/full},\n\tdoi = {10.3389/frai.2024.1516832},\n\tshorttitle = {Editorial},\n\tabstract = {In today\u2019s rapidly evolving business landscape, Artificial Intelligence ({AI}), and specifically Large Language Models ({LLMs}), are redefining how organizations operate, make decisions, and engage with customers. {AI}-driven technologies have become indispensable, providing businesses with powerful tools to streamline operations, derive actionable insights from vast data, and foster more meaningful customer interactions. For business leaders, scholars, and practitioners alike, understanding the transformative potential of {AI} isn\u2019t just advantageous\u2014it\u2019s essential to staying competitive in an increasingly data-driven world.This editorial delves into recent scholarly advancements in {LLM} applications within business contexts, analyzing studies that explore {AI}\u2019s potential across various domains, from decision support to creative industries. By introducing a structured framework, this editorial highlights key insights and contributions from recent studies, assessing their value to academia and industry. The following comparative analysis sheds light on how these innovations shape our understanding of {AI}\u2019s role in business while pointing to future research directions.Puyt and Madsen\\&\\#39;s (2024) study stands out as a foundational exploration of {LLM} accuracy, assessing {ChatGPT}-4\\&\\#39;s ability to recount the history of the {SWOT} analysis-a vital business strategy tool. Their findings reveal that, while {ChatGPT}-4 effectively conveys general concepts, it struggles with detailed historical information, often producing inaccuracies or \\&quot;hallucinations.\\&quot; This gap underscores the need for {LLMs} to be trained with verified academic data, particularly for strategic business applications that demand precision. This study not only contributes to the literature by proposing methods to evaluate {AI} accuracy in historical contexts but also highlights the importance of rigorous information vetting in industry settings where reliability is crucial.In contrast, Raikov et al. (2024) explore a hybrid intelligence model that combines {LLM} capabilities with explainable {AI} ({XAI}) principles to enhance human-machine collaboration. Their approach emphasizes cognitive semantics, improving transparency and decision-making efficiency. The hybrid model\\&\\#39;s real-time adaptability addresses the needs of complex, regulated industries such as finance and healthcare, where trust in {AI} decisions is paramount. Academically, this study provides a valuable addition to {XAI} literature by demonstrating how {LLMs} can bridge the gap between {AI} autonomy and human oversight, making it a model for future human-{AI} interactions in complex business environments.Another significant study by Mariotti and colleagues (2024) examines the integration of {LLMs} with enterprise knowledge graphs to enhance data-driven decision-making. By enabling organizations to leverage knowledge graphs for more accurate and scalable data retrieval, this research provides a robust framework for businesses seeking efficient knowledge management systems. The academic contribution here lies in advancing the dialogue between {LLMs} and knowledge graphs, emphasizing ethical data handling and quality standards essential for industry applications. For enterprises, the study offers practical solutions to achieve streamlined data management, balancing automation with privacy and security. 2024) take a different approach, investigating {LLMs}\\&\\#39; role in creative industries, specifically within fashion design. They introduce a hybrid intelligence model that supports creative processes, allowing {AI} to complement rather than replace human ingenuity. While {LLMs} in this field demonstrate potential in automating repetitive design tasks and enhancing customer personalization, the study reveals limitations in {AI}\\&\\#39;s ability to handle spatial and stylistic nuances. This study\\&\\#39;s academic contribution lies in promoting human-{AI} co-creation, inspiring further research into {AI} applications across diverse creative sectors, including media and marketing.Collectively, these studies not only illuminate {LLMs}\\&\\#39; transformative potential in business but also highlight critical ethical and operational considerations. Ensuring accuracy, transparency, and data privacy are vital to responsibly integrating {AI} into business workflows. Future research should focus on enhancing {LLM} accuracy, refining hybrid intelligence models, and exploring creative {AI} applications, all while maintaining ethical standards. As {LLMs} evolve, interdisciplinary collaborations will be essential to harness their full potential, making {AI} an ethical, effective, and innovative force in the business world.},\n\tjournaltitle = {Frontiers in Artificial Intelligence},\n\tshortjournal = {Front. Artif. Intell.},\n\tauthor = {\u015eeker, \u015eadi Evren},\n\turldate = {2025-02-20},\n\tdate = {2024-11-29},\n\tnote = {Publisher: Frontiers},\n\tkeywords = {{AI} in business, {LLM}, {XAI}, data driven decision making, knowledge graph},\n}\n\n@misc{schwenke_chatbot-supported_2023,\n\ttitle = {Chatbot-supported Thesis Writing: An Autoethnographic Report},\n\turl = {https://arxiv.org/},\n\tabstract = {This preprint presents an autoethnographic account of a student\u2019s extensive use of {ChatGPT} in writing a thesis. It documents how the chatbot aided in brainstorming and editing but was unreliable for generating accurate references.},\n\tauthor = {Schwenke, N. and {others}},\n\tdate = {2023},\n\tdoi = {DOI not available},\n\tnote = {Published: Preprint on {arXiv}},\n\tkeywords = {{AI} support, {ChatGPT}, academic writing, autoethnography, thesis writing},\n}\n\n@article{ryjov_towards_2024,\n\ttitle = {Towards enhanced creativity in fashion: integrating generative models with hybrid intelligence},\n\tvolume = {7},\n\tissn = {2624-8212},\n\turl = {https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1460217/full},\n\tdoi = {10.3389/frai.2024.1460217},\n\tshorttitle = {Towards enhanced creativity in fashion},\n\tjournaltitle = {Frontiers in Artificial Intelligence},\n\tshortjournal = {Front. Artif. Intell.},\n\tauthor = {Ryjov, Alexander and Kazaryan, Vagan and Golub, Andrey and Egorova, Alina},\n\turldate = {2025-02-20},\n\tdate = {2024-09-23},\n\tnote = {Publisher: Frontiers},\n\tkeywords = {co-design, fashion industry, generative intelligence ({GI}), hybrid intelligence, large linguistic models ({LLMs})},\n}\n\n@article{raikov_accelerating_2024,\n\ttitle = {Accelerating human\u2013computer interaction through convergent conditions for {LLM} explanation},\n\tvolume = {7},\n\tissn = {2624-8212},\n\turl = {https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1406773/full},\n\tdoi = {10.3389/frai.2024.1406773},\n\tabstract = {{\\textless}p{\\textgreater}The article addresses the accelerating human\u2013machine interaction using the large language model ({LLM}). It goes beyond the traditional logical paradigms of explainable artificial intelligence ({XAI}) by considering poor-formalizable cognitive semantical interpretations of {LLM}. {XAI} is immersed in a hybrid space, where humans and machines have crucial distinctions during the digitisation of the interaction process. The author\u2019s convergent methodology ensures the conditions for making {XAI} purposeful and sustainable. This methodology is based on the inverse problem-solving method, cognitive modeling, genetic algorithm, neural network, causal loop dynamics, and eigenform realization. It has been shown that decision-makers need to create unique structural conditions for information processes, using {LLM} to accelerate the convergence of collective problem solving. The implementations have been carried out during the collective strategic planning in situational centers. The study is helpful for the advancement of explainable {LLM} in many branches of economy, science and technology.{\\textless}/p{\\textgreater}},\n\tjournaltitle = {Frontiers in Artificial Intelligence},\n\tshortjournal = {Front. Artif. Intell.},\n\tauthor = {Raikov, Aleksandr and Giretti, Alberto and Pirani, Massimiliano and Spalazzi, Luca and Guo, Meng},\n\turldate = {2025-02-20},\n\tdate = {2024-05-30},\n\tnote = {Publisher: Frontiers},\n\tkeywords = {Eigenforms, Explainable artificial intelligence, Hybrid reality, {LLM}, Socioeconomic environment, causal loop dynamics, cognitive semantics, eigenforms cognitive semantics},\n}\n\n@article{puyt_evaluating_2024,\n\ttitle = {Evaluating {ChatGPT}-4\u2019s historical accuracy: a case study on the origins of {SWOT} analysis},\n\tvolume = {7},\n\tissn = {2624-8212},\n\turl = {https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1402047/full},\n\tdoi = {10.3389/frai.2024.1402047},\n\tshorttitle = {Evaluating {ChatGPT}-4\u2019s historical accuracy},\n\tabstract = {{\\textless}p{\\textgreater}In this study we test {ChatGPT}-4\u2019s ability to provide accurate information about the origins and evolution of {SWOT} analysis, perhaps the most widely used strategy tool in practice worldwide. {ChatGPT}-4 is tested for historical accuracy and hallucinations. The {API} is prompted using a Python script with a series of structured questions from an Excel file and the results are recorded in another Excel file and rated on a binary scale. Our findings present a nuanced view of {ChatGPT}-4\u2019s capabilities. We observe that while {ChatGPT}-4 demonstrates a high level of proficiency in describing and outlining the general concept of {SWOT} analysis, there are notable discrepancies when it comes to detailing its origins and evolution. These inaccuracies range from minor factual errors to more serious hallucinations that deviate from evidence in scholarly publications. However, we also find that {ChatGPT}-4 comes up with spontaneous historically accurate facts. Our interpretation of the result is that {ChatGPT} is largely trained on easily available websites and to a very limited extent has been trained on scholarly publications on {SWOT} analysis, especially when these are behind a paywall. We conclude with four propositions for future research.{\\textless}/p{\\textgreater}},\n\tjournaltitle = {Frontiers in Artificial Intelligence},\n\tshortjournal = {Front. Artif. Intell.},\n\tauthor = {Puyt, Richard W. and Madsen, Dag \u00d8ivind},\n\turldate = {2025-02-20},\n\tdate = {2024-05-03},\n\tnote = {Publisher: Frontiers},\n\tkeywords = {{AI} in management research, {ChatGPT}, Historical analysis of management concepts, {SWOT} Analysis, strategy tools},\n}\n\n@misc{openai_operator_2025,\n\ttitle = {Operator and Deep Research tool announcements},\n\turl = {https://www.digitaltrends.com},\n\tabstract = {This tech news article announces {OpenAI}\u2019s Operator agent, a tool capable of autonomously executing web-based tasks. Early tests compare its performance with similar offerings from competitors and indicate promising, though not yet fully evaluated, capabilities.},\n\tauthor = {{OpenAI}},\n\tdate = {2025},\n\tdoi = {DOI not available},\n\tkeywords = {{AI}, {OpenAI}, Operator agent, deep research, tech news},\n}\n\n@article{mariotti_combining_2024,\n\ttitle = {Combining large language models with enterprise knowledge graphs: a perspective on enhanced natural language understanding},\n\tvolume = {7},\n\tissn = {2624-8212},\n\turl = {https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1460065/full},\n\tdoi = {10.3389/frai.2024.1460065},\n\tshorttitle = {Combining large language models with enterprise knowledge graphs},\n\tjournaltitle = {Frontiers in Artificial Intelligence},\n\tshortjournal = {Front. Artif. Intell.},\n\tauthor = {Mariotti, Luca and Guidetti, Veronica and Mandreoli, Federica and Belli, Andrea and Lombardi, Paolo},\n\turldate = {2025-02-20},\n\tdate = {2024-08-27},\n\tnote = {Publisher: Frontiers},\n\tkeywords = {{AI}, {LLMS}, carbon footprint, enterprise {AI}, human in the loop, knowledge graph, knowledge graph enrichment, relation extraction},\n}\n\n@article{amirova_framework-based_2024,\n\ttitle = {Framework-based qualitative analysis of free responses of Large Language Models: Algorithmic fidelity},\n\tvolume = {19},\n\tissn = {1932-6203},\n\turl = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0300024},\n\tdoi = {10.1371/journal.pone.0300024},\n\tshorttitle = {Framework-based qualitative analysis of free responses of Large Language Models},\n\tabstract = {Today, with the advent of Large-scale generative Language Models ({LLMs}) it is now possible to simulate free responses to interview questions such as those traditionally analyzed using qualitative research methods. Qualitative methodology encompasses a broad family of techniques involving manual analysis of open-ended interviews or conversations conducted freely in natural language. Here we consider whether artificial \u201csilicon participants\u201d generated by {LLMs} may be productively studied using qualitative analysis methods in such a way as to generate insights that could generalize to real human populations. The key concept in our analysis is algorithmic fidelity, a validity concept capturing the degree to which {LLM}-generated outputs mirror human sub-populations\u2019 beliefs and attitudes. By definition, high algorithmic fidelity suggests that latent beliefs elicited from {LLMs} may generalize to real humans, whereas low algorithmic fidelity renders such research invalid. Here we used an {LLM} to generate interviews with \u201csilicon participants\u201d matching specific demographic characteristics one-for-one with a set of human participants. Using framework-based qualitative analysis, we showed the key themes obtained from both human and silicon participants were strikingly similar. However, when we analyzed the structure and tone of the interviews we found even more striking differences. We also found evidence of a hyper-accuracy distortion. We conclude that the {LLM} we tested ({GPT}-3.5) does not have sufficient algorithmic fidelity to expect in silico research on it to generalize to real human populations. However, rapid advances in artificial intelligence raise the possibility that algorithmic fidelity may improve in the future. Thus we stress the need to establish epistemic norms now around how to assess the validity of {LLM}-based qualitative research, especially concerning the need to ensure the representation of heterogeneous lived experiences.},\n\tpages = {e0300024},\n\tnumber = {3},\n\tjournaltitle = {{PLOS} {ONE}},\n\tshortjournal = {{PLOS} {ONE}},\n\tauthor = {Amirova, Aliya and Fteropoulli, Theodora and Ahmed, Nafiso and Cowie, Martin R. and Leibo, Joel Z.},\n\turldate = {2025-02-20},\n\tdate = {2024-03-12},\n\tlangid = {english},\n\tnote = {Publisher: Public Library of Science},\n\tkeywords = {Algorithms, Conditioned response, Emotions, Heart failure, Language, Physical activity, Sedentary behavior, Social sciences},\n}\n\n@article{anzt_environment_2021,\n\ttitle = {An environment for sustainable research software in Germany and beyond: current state, open challenges, and call for action},\n\tvolume = {9},\n\tissn = {2046-1402},\n\turl = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7845155/},\n\tdoi = {10.12688/f1000research.23224.2},\n\tshorttitle = {An environment for sustainable research software in Germany and beyond},\n\tabstract = {Research software has become a central asset in academic research. It optimizes existing and enables new research methods, implements and embeds research knowledge, and constitutes an essential research product in itself. Research software must be sustainable in order to understand, replicate, reproduce, and build upon existing research or conduct new research effectively. In other words, software must be available, discoverable, usable, and adaptable to new needs, both now and in the future. Research software therefore requires an environment that supports sustainability.,  Hence, a change is needed in the way research software development and maintenance are currently motivated, incentivized, funded, structurally and infrastructurally supported, and legally treated. Failing to do so will threaten the quality and validity of research. In this paper, we identify challenges for research software sustainability in Germany and beyond, in terms of motivation, selection, research software engineering personnel, funding, infrastructure, and legal aspects. Besides researchers, we specifically address political and academic decision-makers to increase awareness of the importance and needs of sustainable research software practices. In particular, we recommend strategies and measures to create an environment for sustainable research software, with the ultimate goal to ensure that software-driven research is valid, reproducible and sustainable, and that software is recognized as a first class citizen in research. This paper is the outcome of two workshops run in Germany in 2019, at {deRSE}19 - the first International Conference of Research Software Engineers in Germany - and a dedicated {DFG}-supported follow-up workshop in Berlin.},\n\tpages = {295},\n\tjournaltitle = {F1000Research},\n\tshortjournal = {F1000Res},\n\tauthor = {Anzt, Hartwig and Bach, Felix and Druskat, Stephan and L\u00f6ffler, Frank and Loewe, Axel and Renard, Bernhard Y. and Seemann, Gunnar and Struck, Alexander and Achhammer, Elke and Aggarwal, Piush and Appel, Franziska and Bader, Michael and Brusch, Lutz and Busse, Christian and Chourdakis, Gerasimos and Dabrowski, Piotr Wojciech and Ebert, Peter and Flemisch, Bernd and Friedl, Sven and Fritzsch, Bernadette and Funk, Maximilian D. and Gast, Volker and Goth, Florian and Grad, Jean-No\u00ebl and Hegewald, Jan and Hermann, Sibylle and Hohmann, Florian and Janosch, Stephan and Kutra, Dominik and Linxweiler, Jan and Muth, Thilo and Peters-Kottig, Wolfgang and Rack, Fabian and Raters, Fabian H.C. and Rave, Stephan and Reina, Guido and Rei\u00dfig, Malte and Ropinski, Timo and Schaarschmidt, Joerg and Seibold, Heidi and Thiele, Jan P. and Uekermann, Benjamin and Unger, Stefan and Weeber, Rudolf},\n\turldate = {2025-02-20},\n\tdate = {2021-01-26},\n\tpmid = {33552475},\n\tpmcid = {PMC7845155},\n}\n\n@article{hettrick_research_2016-1,\n\ttitle = {Research Software Sustainability: Report on a Knowledge Exchange Workshop},\n\turl = {https://digitalcommons.unl.edu/scholcom/6},\n\tshorttitle = {Research Software Sustainability},\n\tjournaltitle = {Copyright, Fair Use, Scholarly Communication, etc.},\n\tauthor = {Hettrick, Simon},\n\tdate = {2016-02-01},\n}\n\n@inproceedings{calero_systematic_2013,\n\ttitle = {A systematic literature review for software sustainability measures},\n\turl = {https://ieeexplore.ieee.org/abstract/document/6606421},\n\tdoi = {10.1109/GREENS.2013.6606421},\n\tabstract = {Nowadays, sustainability is a key factor that should be considered in the software quality models. It is increasingly important how environmentally friendly is a software product, both in its execution and during its development process. Therefore, we have proposed, in a previous work, a quality model (25010+S) an extension of the {ISO}/{IEC} 25010 standard by considering aspects of sustainability on its characteristics and sub-characteristics. However, in order to make the model useful, it is necessary to identify measures for each sub-characteristic and characteristic. For that reason, the objective of this paper is to carry out a Systematic Literature Review to discover the state-of-the art in software sustainability measures.},\n\teventtitle = {2013 2nd International Workshop on Green and Sustainable Software ({GREENS})},\n\tpages = {46--53},\n\tbooktitle = {2013 2nd International Workshop on Green and Sustainable Software ({GREENS})},\n\tauthor = {Calero, Coral and Bertoa, Manuel F. and Moraga, Ma \u00c1ngeles},\n\turldate = {2025-02-20},\n\tdate = {2013-05},\n\tkeywords = {Abstracts, Green products, Libraries, Quality Model, Quality assessment, Software, Software measurement, Sustainability Indicators, Sustainability Measures, Sustainability Models, Systematic Literature Review, Systematics},\n}\n\n@article{gruning_bioconda_2018,\n\ttitle = {Bioconda: sustainable and comprehensive software distribution for the life sciences},\n\tvolume = {15},\n\trights = {2018 The Author(s)},\n\tissn = {1548-7105},\n\turl = {https://www.nature.com/articles/s41592-018-0046-7},\n\tdoi = {10.1038/s41592-018-0046-7},\n\tshorttitle = {Bioconda},\n\tpages = {475--476},\n\tnumber = {7},\n\tjournaltitle = {Nature Methods},\n\tshortjournal = {Nat Methods},\n\tauthor = {Gr\u00fcning, Bj\u00f6rn and Dale, Ryan and Sj\u00f6din, Andreas and Chapman, Brad A. and Rowe, Jillian and Tomkins-Tinch, Christopher H. and Valieris, Renan and K\u00f6ster, Johannes},\n\turldate = {2025-02-20},\n\tdate = {2018-07},\n\tlangid = {english},\n\tnote = {Publisher: Nature Publishing Group},\n\tkeywords = {Publishing, Software},\n}\n\n@article{calero_puzzling_2017,\n\ttitle = {Puzzling out Software Sustainability},\n\tvolume = {16},\n\tissn = {2210-5379},\n\turl = {https://www.sciencedirect.com/science/article/pii/S2210537916301676},\n\tdoi = {10.1016/j.suscom.2017.10.011},\n\tabstract = {Software Sustainability is gaining importance and, as occurs with any other new discipline, there are still many misconceptions and misunderstandings surrounding it. In this paper we attempt to clarify the different aspects of software sustainability, from organizational sustainability to software sustainability, exploring the latter in great depth by considering its three dimensions. We also present an overview of the research that has been developed around software sustainability, which was obtained after reviewing the best known workshops and conferences on green and sustainable software and some journals. The results obtained principally address the environmental dimension, and specifically green software design, quality and requirements.},\n\tpages = {117--124},\n\tjournaltitle = {Sustainable Computing: Informatics and Systems},\n\tshortjournal = {Sustainable Computing: Informatics and Systems},\n\tauthor = {Calero, Coral and Piattini, Mario},\n\turldate = {2025-02-20},\n\tdate = {2017-12-01},\n\tkeywords = {Green in software engineering, {SWEBOK}, Software greenability, Software sustainability},\n}\n\n@online{venters_software_2014,\n\ttitle = {Software Sustainability: The Modern Tower of Babel},\n\turl = {http://ceur-ws.org/Vol-1216/paper2.pdf},\n\tshorttitle = {Software Sustainability},\n\tabstract = {The development of sustainable software has been identified as one of the key challenges in the field of computational science and engineering. However, there is currently no agreed definition of the concept. Current definitions range from a composite, non-functional requirement to simply an emergent property. This lack of clarity leads to confusion, and potentially to ineffective and inefficient efforts to develop sustainable software systems. The aim of this paper is to explore the emerging definitions of software sustainability from the field of software engineering in order to contribute to the question, what is software sustainability? The preliminary analysis suggests that the concept of software sustainability is complex and multifaceted with any consensus towards a shared definition within the field of software engineering yet to be achieved.},\n\ttitleaddon = {{CEUR} Workshop Proceedings},\n\ttype = {Proceedings Paper},\n\tauthor = {Venters, C. C. and Jay, C. and Lau, L. M. S. and Griffiths, M. K. and Holmes, V. and Ward, R. R. and Austin, J. and Dibsdale, C. E. and Xu, J.},\n\turldate = {2025-02-20},\n\tdate = {2014},\n\tlangid = {english},\n\tnote = {Conference Name: {RE}4SuSy: Third International Workshop on Requirements Engineering for Sustainable Systems\n{ISSN}: 1613-0073\nMeeting Name: {RE}4SuSy: Third International Workshop on Requirements Engineering for Sustainable Systems\nPages: 7-12\nPlace: Karlskrona, Sweden\nPublisher: {CEUR}\nVolume: 1216},\n}\n\n@article{crouch_software_2013,\n\ttitle = {The Software Sustainability Institute: Changing Research Software Attitudes and Practices},\n\tvolume = {15},\n\trights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},\n\tissn = {1521-9615},\n\turl = {http://ieeexplore.ieee.org/document/6731384/},\n\tdoi = {10.1109/MCSE.2013.133},\n\tshorttitle = {The Software Sustainability Institute},\n\tpages = {74--80},\n\tnumber = {6},\n\tjournaltitle = {Computing in Science \\& Engineering},\n\tshortjournal = {Comput. Sci. Eng.},\n\tauthor = {Crouch, Stephen and Hong, Neil Chue and Hettrick, Simon and Jackson, Mike and Pawlik, Aleksandra and Sufi, Shoaib and Carr, Les and De Roure, David and Goble, Carole and Parsons, Mark},\n\turldate = {2025-02-20},\n\tdate = {2013-11},\n\tlangid = {english},\n}\n\n@article{carter_data_2019,\n\ttitle = {Data for \u201cIdentifying Landscape Modification Using Open Data and Tools: The Charcoal Hearths of the Blue Mountain, Pennsylvania\u201d},\n\tvolume = {7},\n\tissn = {2049-1565},\n\turl = {https://openarchaeologydata.metajnl.com/articles/10.5334/joad.53},\n\tdoi = {10.5334/joad.53},\n\tshorttitle = {Data for \u201cIdentifying Landscape Modification Using Open Data and Tools},\n\tabstract = {The data and methods described were used to identify charcoal hearths on the Blue Mountain of eastern Pennsylvania. The data is derived from openly available {LiDAR} data and was modified using {LASTools}. This data was used to develop a methodology for the identification of charcoal hearths via a digital elevation model, a hillshade model and a slope analysis. This enabled the identification of 758 potential charcoal hearths. Data and detailed methods description are stored in Open Context and Zenodo. The technique used to produce this data has very high reuse potential since the tools employed are all open source and {LiDAR} data is often openly available for many states within the {US}, as well as other countries. An article for the journal, Historical Archaeology, that argues for openness in historical archaeology and utilizes this data has been published recently [1].\u00a0Funding statement: The work completed by Heather Lash was directly funded by the Office of the Provost\u00a0of Muhlenberg College. Training (see acknowledgements) was funded through the National Endowment\u00a0for the Arts and the National Science Foundation.},\n\tnumber = {0},\n\tjournaltitle = {Journal of Open Archaeology Data},\n\tauthor = {Carter, Benjamin},\n\turldate = {2025-02-20},\n\tdate = {2019-07-11},\n\tlangid = {american},\n}\n\n@article{homburg_annotated_2022,\n\ttitle = {Annotated 3D-Models of Cuneiform Tablets},\n\tvolume = {10},\n\tissn = {2049-1565},\n\turl = {https://openarchaeologydata.metajnl.com/articles/10.5334/joad.92},\n\tdoi = {10.5334/joad.92},\n\tabstract = {The dataset1 consists of 3D scans of one cuneiform tablet from Haft Tappeh Iran and one cuneiform tablet of the Hilprecht Collection as well as 3D annotations on these 3D meshes, including metadata. The 3D annotations were created with the annotation software Annotorious2 on 2D renderings and reprojected to the original 3D model. The respective 2D renderings and annotations in 2D are also part of this data publication. The annotations might be used in machine learning tasks for character recognition, linguistic studies, or visualization in Assyriology. We publish these data in different formats and give guidance on how to use them in different usage scenarios and with several software applications. The data serve as the basis for a detailed description, reasoning, and elaboration of a recommendation for the state-of-the-art handling of 3D data in cuneiform research. The data is stored as an archive on Zenodo and may serve as an example for replication by similar 3D scanning.},\n\tnumber = {0},\n\tjournaltitle = {Journal of Open Archaeology Data},\n\tauthor = {Homburg, Timo and Zwick, Robert and Mara, Hubert and Bruhn, Kai-Christian},\n\turldate = {2025-02-20},\n\tdate = {2022-05-20},\n\tlangid = {american},\n}\n\n@article{katz_summary_2014,\n\ttitle = {Summary of the First Workshop on Sustainable Software for Science: Practice and Experiences ({WSSSPE}1)},\n\tvolume = {2},\n\tissn = {2049-9647},\n\turl = {http://arxiv.org/abs/1404.7414},\n\tdoi = {10.5334/jors.an},\n\tshorttitle = {Summary of the First Workshop on Sustainable Software for Science},\n\tabstract = {Challenges related to development, deployment, and maintenance of reusable software for science are becoming a growing concern. Many scientists' research increasingly depends on the quality and availability of software upon which their works are built. To highlight some of these issues and share experiences, the First Workshop on Sustainable Software for Science: Practice and Experiences ({WSSSPE}1) was held in November 2013 in conjunction with the {SC}13 Conference. The workshop featured keynote presentations and a large number (54) of solicited extended abstracts that were grouped into three themes and presented via panels. A set of collaborative notes of the presentations and discussion was taken during the workshop. Unique perspectives were captured about issues such as comprehensive documentation, development and deployment practices, software licenses and career paths for developers. Attribution systems that account for evidence of software contribution and impact were also discussed. These include mechanisms such as Digital Object Identifiers, publication of \"software papers\", and the use of online systems, for example source code repositories like {GitHub}. This paper summarizes the issues and shared experiences that were discussed, including cross-cutting issues and use cases. It joins a nascent literature seeking to understand what drives software work in science, and how it is impacted by the reward systems of science. These incentives can determine the extent to which developers are motivated to build software for the long-term, for the use of others, and whether to work collaboratively or separately. It also explores community building, leadership, and dynamics in relation to successful scientific software.},\n\tpages = {e6},\n\tnumber = {1},\n\tjournaltitle = {Journal of Open Research Software},\n\tauthor = {Katz, Daniel S. and Choi, Sou-Cheng T. and Lapp, Hilmar and Maheshwari, Ketan and L\u00f6ffler, Frank and Turk, Matthew and Hanwell, Marcus D. and Wilkins-Diehr, Nancy and Hetherington, James and Howison, James and Swenson, Shel and Allen, Gabrielle D. and Elster, Anne C. and Berriman, Bruce and Venters, Colin},\n\turldate = {2025-02-20},\n\tdate = {2014-07-09},\n\teprinttype = {arxiv},\n\teprint = {1404.7414 [cs]},\n\tkeywords = {Computer Science - Software Engineering},\n}\n\n@article{venters_sustainable_2023,\n\ttitle = {Sustainable software engineering: Reflections on advances in research and practice},\n\tvolume = {164},\n\tissn = {0950-5849},\n\turl = {https://www.sciencedirect.com/science/article/pii/S0950584923001714},\n\tdoi = {10.1016/j.infsof.2023.107316},\n\tshorttitle = {Sustainable software engineering},\n\tabstract = {Context:\nModern societies are highly dependent on complex, large-scale, software-intensive systems that increasingly operate within an environment of continuous availability, which are challenging to maintain, and evolve in response to changes in stakeholder requirements of the system. Software architectures are the foundation of any software system and provide a mechanism for reasoning about core software quality requirements. Their sustainability \u2013 the capacity to endure in changing environments \u2013 is a critical concern for software architecture research and practice.\nObjective:\nThe objective of the paper is to re-examine our previous assumptions and arguments in light of advances in the field. This reflection paper provides an opportunity to obtain new insights into the trends in software sustainability in both academia and industry, from a software architecture perspective specifically and software engineering more broadly. Given advances in research in the field, the increasing introduction of academic courses on different sustainability topics, and the engagement of companies to cope with sustainability goals, we reflect on advances and maturity about the role sustainability in general plays in today\u2019s society. More specifically, we revisit the trends, open issues and research challenges identified five years ago in our previous paper on software sustainability research and practice from a software architecture viewpoint, which aimed to provide a foundation and roadmap of emerging research themes in the area of sustainable software architectures in order to consider how this paper influenced and motivated research in the intervening years.\nMethod:\nThe forward snowballing method was used to establish the methodological basis for our reflection on the state of the art. A total of 234 studies were identified between April 2018 and June 2023 and 102 studies were found to be relevant according to the selection criteria. A further subset was mapped to the primary themes of the original paper including definitions and concepts, reference architectures, measures and metrics, and education.\nVision:\nThe vision of this reflection paper is to provide a new foundation and road map of emerging research themes in the area of sustainable software engineering highlighting recent trends, and open issues and research challenges.},\n\tpages = {107316},\n\tjournaltitle = {Information and Software Technology},\n\tshortjournal = {Information and Software Technology},\n\tauthor = {Venters, Colin C. and Capilla, Rafael and Nakagawa, Elisa Yumi and Betz, Stefanie and Penzenstadler, Birgit and Crick, Tom and Brooks, Ian},\n\turldate = {2025-02-20},\n\tdate = {2023-12-01},\n\tkeywords = {Architectural debt, Architectural smells, Code smells, Education and training, Reference architectures, Software architecture, Software engineering, Software metrics, Software sustainability, Sustainability, Sustainable software, Technical debt},\n}\n\n@article{venters_software_2018,\n\ttitle = {Software sustainability: Research and practice from a software architecture viewpoint},\n\tvolume = {138},\n\tissn = {0164-1212},\n\turl = {https://www.sciencedirect.com/science/article/pii/S0164121217303072},\n\tdoi = {10.1016/j.jss.2017.12.026},\n\tshorttitle = {Software sustainability},\n\tabstract = {Context\nModern societies are highly dependent on complex, large-scale, software-intensive systems that increasingly operate within an environment of continuous availability, which is challenging to maintain and evolve in response to the inevitable changes in stakeholder goals and requirements of the system. Software architectures are the foundation of any software system and provide a mechanism for reasoning about core software quality requirements. Their sustainability \u2013 the capacity to endure in changing environments \u2013 is a critical concern for software architecture research and practice.\nProblem\nAccidental software complexity accrues both naturally and gradually over time as part of the overall software design and development process. From a software architecture perspective, this allows several issues to overlap including, but not limited to: the accumulation of technical debt design decisions of individual components and systems leading to coupling and cohesion issues; the application of tacit architectural knowledge resulting in unsystematic and undocumented design decisions; architectural knowledge vaporisation of design choices and the continued ability of the organization to understand the architecture of its systems; sustainability debt and the broader cumulative effects of flawed architectural design choices over time resulting in code smells, architectural brittleness, erosion, and drift, which ultimately lead to decay and software death. Sustainable software architectures are required to evolve over the entire lifecycle of the system from initial design inception to end-of-life to achieve efficient and effective maintenance and evolutionary change.\nMethod\nThis article outlines general principles and perspectives on sustainability with regards to software systems to provide a context and terminology for framing the discourse on software architectures and sustainability. Focusing on the capacity of software architectures and architectural design choices to endure over time, it highlights some of the recent research trends and approaches with regards to explicitly addressing sustainability in the context of software architectures.\nContribution\nThe principal aim of this article is to provide a foundation and roadmap of emerging research themes in the area of sustainable software architectures highlighting recent trends, and open issues and research challenges.},\n\tpages = {174--188},\n\tjournaltitle = {Journal of Systems and Software},\n\tshortjournal = {Journal of Systems and Software},\n\tauthor = {Venters, Colin C. and Capilla, Rafael and Betz, Stefanie and Penzenstadler, Birgit and Crick, Tom and Crouch, Steve and Nakagawa, Elisa Yumi and Becker, Christoph and Carrillo, Carlos},\n\turldate = {2025-02-20},\n\tdate = {2018-04-01},\n\tkeywords = {Evolution, Longevity, Software architecture, Software sustainability},\n}\n\n@article{liao_prediction_2019,\n\ttitle = {A Prediction Model of the Project Life-Span in Open Source Software Ecosystem},\n\tvolume = {24},\n\tissn = {1572-8153},\n\turl = {https://doi.org/10.1007/s11036-018-0993-3},\n\tdoi = {10.1007/s11036-018-0993-3},\n\tabstract = {In nature ecosystems, animal life-spans are determined by genes and some other biological characteristics. Similarly, the software project life-spans are related to some internal or external characteristics. Analyzing the relations between these characteristics and the project life-span, may help developers, investors, and contributors to control the development cycle of the software project. The paper provides an insight on the project life-span for a free open source software ecosystem. The statistical analysis of some project characteristics in {GitHub} is presented, and we find that the choices of programming languages, the number of files, the label format of the project, and the relevant membership expressions can impact the life-span of a project. Based on these discovered characteristics, we also propose a prediction model to estimate the project life-span in open source software ecosystems. These results may help developers reschedule the project in open source software ecosystem.},\n\tpages = {1382--1391},\n\tnumber = {4},\n\tjournaltitle = {Mobile Networks and Applications},\n\tshortjournal = {Mobile Netw Appl},\n\tauthor = {Liao, Zhifang and Zhao, Benhong and Liu, Shengzong and Jin, Haozhi and He, Dayu and Yang, Liu and Zhang, Yan and Wu, Jinsong},\n\turldate = {2025-02-20},\n\tdate = {2019-08-01},\n\tlangid = {english},\n\tkeywords = {Open source software ecosystem, Project characteristics, Project life-span, Software ecosystems},\n}\n\n@article{blackadar_object_2021,\n\ttitle = {Object Detection Model, Image Data and Results from the \u201cWhen Computers Dream of Charcoal: Using Deep Learning, Open Tools and Open Data to Identify Relict Charcoal Hearths in and Around State Game Lands in Pennsylvania\u201d Paper},\n\tvolume = {9},\n\tissn = {2049-1565},\n\turl = {https://openarchaeologydata.metajnl.com/articles/10.5334/joad.81},\n\tdoi = {10.5334/joad.81},\n\tshorttitle = {Object Detection Model, Image Data and Results from the \u201cWhen Computers Dream of Charcoal},\n\tabstract = {These data were used to build an object detection model to locate Relict Charcoal Hearths ({RCH}) as described in the paper \u201cWhen Computers Dream of Charcoal: Using Deep Learning, Open Tools and Open Data to Identify Relict Charcoal Hearths in and around State Game Lands in Pennsylvania\u201d [1]. This is the second grouping of data for the paper above. The first grouping is also available in this journal, see \u201cGeospatial and image data from the \u201cWhen Computers Dream of Charcoal: Using Deep Learning, Open Tools and Open Data to Identify Relict Charcoal Hearths in and around State Game Lands in Pennsylvania\u201d paper\u201d [2].\u00a0These files consist of:{JPEGs} representing tiles of larger Slope {TIFF} files derived from {LiDAR} for the State Game Lands ({SGL}) of Pennsylvania, United States [3456]. A subset of these tiles was used to train the model.A Shapefile of points of known relict charcoal hearths ({RCH}).{XML} files representing the pixel points of known {RCHs} on {JPEG} files used for training.Jupyter notebooks of programs used to prepare data and train a Mask R-{CNN} model.The Mask R-{CNN} model H5 file.Shapefile and {GeoJSON} of object detection results from the model showing locations of possible {RCH} in all {SGLs}.{XML} files representing the pixel points of predicted {RCH} on {JPEG} files used for predictions.{GeoJSON} of results using cluster analysis.These data are stored onzenodo.org. The programs are stored on Github.com.},\n\tnumber = {0},\n\tjournaltitle = {Journal of Open Archaeology Data},\n\tauthor = {Blackadar, Jeff and Carter, Benjamin and Conner, Weston},\n\turldate = {2025-02-20},\n\tdate = {2021-12-27},\n\tlangid = {american},\n}\n\n@article{vandecreek_great_2024,\n\ttitle = {Great lengths: a review of website preservation activities at three American Universities with digital humanities centers},\n\tvolume = {39},\n\tissn = {2055-7671},\n\tpages = {409--422},\n\tnumber = {1},\n\tjournaltitle = {Digital scholarship in the humanities.},\n\tauthor = {{VandeCreek}, Drew},\n\tdate = {2024-04-02},\n\tlccn = {2015242053},\n\tnote = {Place: Oxford :\nPublisher: Oxford University Press,},\n}\n\n@article{tsipi_digital_2023,\n\ttitle = {Digital Repository as a Service (D-{RaaS}): Enhancing Access and Preservation of Cultural Heritage Artifacts},\n\tvolume = {6},\n\tissn = {25719408},\n\turl = {https://simsrad.net.ocs.mq.edu.au/login?url=https://www.proquest.com/scholarly-journals/digital-repository-as-service-d-raas-enhancing/docview/2882553281/se-2?accountid=12219},\n\tdoi = {10.3390/heritage6100359},\n\tabstract = {The employment of technology and digitization is crucial for cultural organizations to establish and sustain digital repositories for their cultural heritage artifacts. This exploitation is also essential in facilitating the presentation of cultural works and exhibits to a broader audience. Consequently, in this work, we propose a custom-developed digital repository that functions as software-as-a-service ({SaaS}), primarily promoting the safe storage, display, and sharing of cultural materials; enhancing accessibility; and fostering a deeper understanding and appreciation of cultural heritage. The proposed digital repository service is designed as a multitenant architecture, which enables organizations to expand their reach, enhance accessibility, foster collaboration, and ensure the preservation of their content. Moreover, our technology stack incorporates robust and reliable backend technologies, such as Django, to ensure data security and efficient management. Meanwhile, the frontend is powered by Angular, which guarantees a user-friendly and engaging interface for exploring and interacting with cultural materials. Specifically, this project aims to assist each cultural institution in organizing its digital cultural assets into collections and feeding other digital platforms, including educational, museum, pedagogical, and games, through appropriate interfaces. The creation of this digital repository offers a cutting-edge and effective open-access laboratory solution. It allows organizations to have a significant influence on their audiences by fostering cultural understanding and appreciation. Additionally, it facilitates the connection between different digital repositories and national/European aggregators, promoting collaboration and information sharing. By embracing this innovative solution, cultural institutions can benefit from shared resources and features, such as system updates, backup and recovery services, and data analytics tools, attributes that are currently provided by the platform.},\n\tpages = {6881},\n\tnumber = {10},\n\tjournaltitle = {Heritage},\n\tauthor = {Tsipi, Lefteris and Vouyioukas, Demosthenes and Loumos, Georgios and Kargas, Antonios and Varoutas, Dimitrios},\n\tdate = {2023},\n\tnote = {Place: Basel\nPublisher: {MDPI} {AG}},\n\tkeywords = {Access, Application programming interface, Archaeology--Computer Applications, Architecture, Archives \\& records, Art galleries \\& museums, Collaboration, Cultural heritage, Cultural organizations, Design, Digital libraries, Digital library, Digital preservation, Digital twins, Information retrieval, Infrastructure, Metadata, Multimedia, Ontology, Preservation, Semantics, Software as a service, Software services, Software-as-a-service, Usability, Virtual reality, cultural industry, cultural technologies, digital repository, gaming technologies, web sharing},\n}\n\n@article{hocquet_epistemic_2021,\n\ttitle = {Epistemic issues in computational reproducibility: software as the elephant in the room},\n\tvolume = {11},\n\turl = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104544147&doi=10.1007%2fs13194-021-00362-9&partnerID=40&md5=2b290e2038ec0bdae84229743174882f},\n\tdoi = {10.1007/s13194-021-00362-9},\n\tabstract = {Computational reproducibility (i.e. issues of reproducibility stemming from the computer as a scientific tool) possesses its own dynamics and narratives of crisis. Alongside the difficulties of computing as an ubiquitous yet complex scientific activity, computational reproducibility suffers from a naive expectancy of total reproducibility and a moral imperative to embrace the principles of free software as a non-negotiable epistemic virtue. We argue that the epistemic issues at stake in actual practices of computational reproducibility are best unveiled by focusing on software as a pivotal concept, one that is surprisingly often overlooked in accounts of reproducibility issues. Software is not only about designing and coding but also about maintaining, supporting, distributing, licensing, and governance; it is not only about developers but also about users. We focus on openness debates among computational chemists involved in molecular modeling software packages as empirical grounding for our argument. We then identify and analyse four epistemic characteristics (transparency, consistency, sustainability and inclusivity) as key to the role of software in computational reproducibility. \u00a9 2021, Springer Nature B.V.},\n\tnumber = {2},\n\tjournaltitle = {European Journal for Philosophy of Science},\n\tauthor = {Hocquet, Alexandre and Wieber, Fr\u00e9d\u00e9ric},\n\tdate = {2021},\n\tnote = {Type: Article},\n}\n\n@article{arthur_open_2021,\n\ttitle = {Open scholarship in Australia: A review of needs, barriers, and opportunities},\n\tvolume = {36},\n\tissn = {2055-7671},\n\tpages = {795--812},\n\tnumber = {4},\n\tjournaltitle = {Digital scholarship in the humanities.},\n\tauthor = {Arthur, Paul Longley and Hearn, Lydia and Montgomery, Lucy and Arthur, Paul Longley and Hearn, Lydia and Montgomery, Lucy and Craig, Hugh and Arbuckle, Alyssa and Siemens, Ray},\n\tdate = {2021-10-30},\n\tlccn = {2015242053},\n\tnote = {Place: Oxford :\nPublisher: Oxford University Press,},\n}\n\n@misc{imran_software_2019,\n\ttitle = {Software Sustainability: A Systematic Literature Review and Comprehensive Analysis},\n\turl = {https://arxiv.org/abs/1910.06109},\n\tauthor = {Imran, Asif and Kosar, Tevfik},\n\tdate = {2019},\n\tnote = {\\_eprint: 1910.06109},\n}\n\n@inproceedings{penzenstadler_sustainability_2012,\n\ttitle = {Sustainability in software engineering: A systematic literature review},\n\tdoi = {10.1049/ic.2012.0004},\n\tabstract = {Background: Supporting sustainability in software engineering is becoming an active area of research. We want to contribute the first Systematic Literature Review({SLR}) in this field to aid researchers who are motivated to contribute to that topic by providing a body of knowledge as starting point, because we know from own experience, this search can be tedious and time consuming. Aim: We aim to provide an overview of different aspects of sustainability in software engineering research with regard to research activity, investigated topics, identified limitations, proposed approaches, used methods, available studies, and considered domains. Method: The applied method is a {SLR} in five reliable and commonly-used databases according to the (quasi-standard) protocol by Kitchenham et al. [1]. We assessed the 100 first results of each database ordered by relevance with respect to the search query. Results: Of 500 classified publications, we regard 96 as relevant for our research questions. We sketch a taxonomy of their topics and domains, and provide lists of used methods and proposed approaches. Most of the excluded publications were ruled out because of an unfitting usage of terms within the search query. Conclusions: Currently, there is little research coverage on the different aspects of sustainability in software engineering while other disciplines are already more active. Future work includes extending the study by reviewing a higher number of publications, including dedicated journal and workshop searches, and snowballing.},\n\tpages = {32--41},\n\tbooktitle = {16th International Conference on Evaluation \\& Assessment in Software Engineering ({EASE} 2012)},\n\tauthor = {Penzenstadler, Birgit and Bauer, Veronika and Calero, Coral and Franch, Xavier},\n\tdate = {2012-05},\n}\n\n@misc{crowe_day_2017,\n\ttitle = {Day in the Software Life: How Solr Supports Sustainability},\n\turl = {https://library.wp.st-andrews.ac.uk/2017/05/26/software-sustainability-institute-blog-post/},\n\tabstract = {In this blog post, Swithun Crowe reflects on a typical day at the Software Sustainability Institute, illustrating how tools like Solr are used to handle large volumes of {XML} documents. The post highlights the practical challenges and solutions in managing data and ensuring that software remains robust and sustainable.},\n\tauthor = {Crowe, Swithun},\n\tdate = {2017},\n\tdoi = {DOI not available},\n\tkeywords = {Solr, data management, persistence, research infrastructure, software sustainability},\n}\n\n@misc{wilson_case_2015,\n\ttitle = {The case for sustainable computing in research: Lessons from open-source projects},\n\turl = {https://www.software.ac.uk/blog/the-case-for-sustainable-computing-in-research-lessons-from-open-source-projects},\n\tabstract = {Wilson examines case studies from open-source projects to illustrate how sustainable computing practices can be integrated into research software development. The post emphasizes the role of community collaboration and open standards in ensuring that software remains robust and maintainable over time.},\n\tauthor = {Wilson, G.},\n\tdate = {2015},\n\tdoi = {DOI not available},\n\tkeywords = {community collaboration, longevity, open source, research software, sustainable computing},\n}\n\n@article{katz_addressing_2021-1,\n\ttitle = {Addressing Research Software Sustainability via Institutes},\n\turl = {https://arxiv.org/abs/2103.03690},\n\tdoi = {10.7717/peerj-cs.86},\n\tabstract = {Research software is essential to modern research, yet sustaining it over time remains a challenge due to evolving dependencies, funding limitations, and maintenance needs. This article argues for the creation and support of research software sustainability institutes, which can develop, maintain, and disseminate best practices while building a community around sustainable research software. It highlights the strengths and weaknesses of the institute model and calls for a coordinated, institutional approach to ensure that research software remains reliable, reproducible, and reusable over the long term.},\n\tjournaltitle = {{arXiv} preprint {arXiv}:2103.03690},\n\tauthor = {Katz, Daniel S. and Carver, Jeffrey C. and Chue Hong, Neil P. and Gesing, Sandra and Hettrick, Simon and Honeyman, Tom and Ram, Karthik and Weber, Nicholas},\n\tdate = {2021},\n\tkeywords = {institutes, institutional support, persistence, research software, software sustainability},\n}\n\n@misc{wilson_citation_2013,\n\ttitle = {{CITATION} files: A small step towards long-term software persistence},\n\turl = {https://www.software.ac.uk/blog/citation-files-small-step-towards-long-term-software-persistence},\n\tabstract = {Wilson advocates for the use of {CITATION} files to clearly document how software should be cited. This post explains that embedding citation metadata within a project can significantly enhance the traceability, attribution, and long-term persistence of research software.},\n\tauthor = {Wilson, G.},\n\tdate = {2013},\n\tdoi = {DOI not available},\n\tkeywords = {{CITATION} file, digital longevity, metadata, software persistence, software sustainability},\n}\n\n@misc{software_sustainability_institute_sustainable_2015,\n\ttitle = {Sustainable software: A blueprint for long-term research impact},\n\turl = {https://www.software.ac.uk/blog/sustainable-software-blueprint-long-term-research-impact},\n\tabstract = {This blog post outlines a strategic blueprint for achieving sustainability in research software. It discusses the essential components\u2014such as community engagement, funding models, and technical best practices\u2014required to ensure that software remains viable and impactful over the long term.},\n\tauthor = {{Software Sustainability Institute}},\n\tdate = {2015},\n\tdoi = {DOI not available},\n\tkeywords = {best practices, longevity, research impact, software blueprint, sustainable software},\n}\n\n@misc{jackson_automating_2014,\n\ttitle = {Automating software citations: Tools and techniques for sustainable research},\n\turl = {https://www.software.ac.uk/blog/automating-software-citations-tools-and-techniques-for-sustainable-research},\n\tabstract = {In this post, Jackson explores various tools and techniques for automating the generation of software citations. The post reviews the challenges associated with manual citation processes and proposes automation as a means to promote sustainable research practices and long-term software recognition.},\n\tauthor = {Jackson, S.},\n\tdate = {2014},\n\tdoi = {DOI not available},\n\tkeywords = {automation, longevity, research tools, software citation, sustainable research},\n}\n\n@misc{jackson_making_2012,\n\ttitle = {Making software sustainable: overcoming the pitfalls of citation},\n\turl = {https://www.software.ac.uk/blog/making-software-sustainable-overcoming-the-pitfalls-of-citation},\n\tabstract = {In this blog post, Jackson discusses the challenges associated with citing software and the importance of sustainable practices in software development for research. The post highlights common pitfalls that lead to software obsolescence and argues for better citation practices as part of broader sustainability strategies.},\n\tauthor = {Jackson, S.},\n\tdate = {2012},\n\tdoi = {DOI not available},\n\tkeywords = {citation practices, longevity, research software, software sustainability, sustainable computing},\n}\n\n@misc{software_sustainability_institute_software_nodate,\n\ttitle = {Software Sustainability Institute Blogs on Sustainable Humanities Computing},\n\turl = {https://www.software.ac.uk/blog},\n\tabstract = {A collection of blog posts by the Software Sustainability Institute ({UK}) that illustrate examples of open-source practices in archaeological software and broader digital humanities contexts.},\n\tauthor = {{Software Sustainability Institute}},\n\tdoi = {DOI not available},\n\tkeywords = {{SSI}, blogs, digital humanities, open source, software sustainability},\n}\n\n@article{various_artificial_2023,\n\ttitle = {Artificial Intelligence and the Practice of History: A Forum},\n\turl = {URL not available},\n\tdoi = {DOI not available},\n\tabstract = {This collection of essays discusses the implications and opportunities of artificial intelligence in historical research and teaching. Contributors examine {AI}\u2019s role in handling historical sources, address biases in training data, and debate the concept of {AI} as a historian.},\n\tjournaltitle = {American Historical Review},\n\tauthor = {{Various}},\n\tdate = {2023-09},\n\tkeywords = {{AI} forum, artificial intelligence, digital humanities, historiography, history},\n}\n\n@misc{klein_reference_2014,\n\ttitle = {Reference rot in publications},\n\tabstract = {Examines the issue of reference rot in academic publications, highlighting the challenges of maintaining persistent links and citations in digital scholarship.},\n\tauthor = {Klein, et al.},\n\tdate = {2014},\n\tdoi = {DOI not available},\n\tkeywords = {digital preservation, reference rot, scholarly communication, sustainability},\n}\n\n@misc{noauthor_software_nodate,\n\ttitle = {Software Sustainability: Research {UK}},\n\turl = {https://www.software.ac.uk/resources/guides/software-sustainability-research-uk-perspective},\n}\n\n@article{klein_scholarly_2014,\n\ttitle = {Scholarly Context Not Found: One in Five Articles Suffers from Reference Rot},\n\tvolume = {9},\n\turl = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115253},\n\tdoi = {10.1371/journal.pone.0115253},\n\tabstract = {This study quantifies reference rot (link rot and content drift) in scholarly publications by analyzing millions of references.},\n\tpages = {e115253},\n\tnumber = {12},\n\tjournaltitle = {{PLoS} {ONE}},\n\tauthor = {Klein, Martin et al.},\n\tdate = {2014},\n}\n"
        }
      ],
      "files": [
        {
          "file_name": "AnAbsenceOfJudgement (1).tex"
        },
        {
          "file_name": "autoethno-process-planning-notes.tex"
        },
        {
          "file_name": "brian-references.bib"
        }
      ]
    },
    {
      "uuid": "271e4d4c-9b33-461a-b4a0-6e4133696cc2",
      "text": "\nBased on the texts you've provided, I can observe certain characteristics of your academic register:\n\n1. **Theoretical depth** - You engage deeply with philosophical concepts like technoaristotelianism, epistemic humility, and make distinctions between appearance and reality (e.g., systems that \"use the words of the thing without engaging in the fact of the thing\").\n\n2. **Critical analysis** - You maintain a critical stance toward AI capabilities, focusing on limitations rather than hype (e.g., distinguishing between \"what they say\" vs. \"how they act\").\n\n3. **Conceptual precision** - You're careful with terminology and create distinctions between related concepts (e.g., \"task decomposition\" vs. \"genuine agency\").\n\n4. **Conversational but scholarly** - Your dictations have an informal quality in places (e.g., \"wittering about trying to solve its own navigation problems\"), but maintain scholarly rigor.\n\n5. **Evidence-based** - You consistently refer to specific experiences, observations, and experiments rather than relying on speculation.\n\n6. **Pragmatic orientation** - You focus on \"mundane utility\" and practical applications despite theoretical limitations.\n\n7. **Meta-awareness** - You demonstrate awareness of academic conventions and expectations (e.g., your discussion of literature reviews as persuasive documents).\n\nFor this collaborative writing process, I'll start by asking focused questions about a specific section, help identify relevant citations, outline to the sub-paragraph level, and then write in a style that mirrors your scholarly yet direct approach, with the theoretical richness and critical perspective evident in your materials.\n\nI definitely get a sense of your academic register. You blend theoretical depth with conversational clarity, maintain critical analysis of claims versus reality, and emphasize pragmatic applications while keeping philosophical rigor.\n\nLet's start with Section 1 (Introduction). Your initial draft provides good material, but we should structure it more deliberately according to the outline subsections (1.1 Problem Statement, 1.2 Central Thesis, 1.3 Research Approach).\n\nFor 1.1 Problem Statement: Would you like to incorporate specific examples of AI systems claiming \"agentic\" capabilities for research? I noticed in your transcripts you mentioned OpenAI's Deep Research and marketing language around agency - is this the primary target of critique, or are there others?",
      "content": [
        {
          "start_timestamp": "2025-03-14T02:38:48.190625Z",
          "stop_timestamp": "2025-03-14T02:38:55.370453Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nBased on the texts you've provided, I can observe certain characteristics of your academic register:\n\n1. **Theoretical depth** - You engage deeply with philosophical concepts like technoaristotelianism, epistemic humility, and make distinctions between appearance and reality (e.g., systems that \"use the words of the thing without engaging in the fact of the thing\").\n\n2. **Critical analysis** - You maintain a critical stance toward AI capabilities, focusing on limitations rather than hype (e.g., distinguishing between \"what they say\" vs. \"how they act\").\n\n3. **Conceptual precision** - You're careful with terminology and create distinctions between related concepts (e.g., \"task decomposition\" vs. \"genuine agency\").\n\n4. **Conversational but scholarly** - Your dictations have an informal quality in places (e.g., \"wittering about trying to solve its own navigation problems\"), but maintain scholarly rigor.\n\n5. **Evidence-based** - You consistently refer to specific experiences, observations, and experiments rather than relying on speculation.\n\n6. **Pragmatic orientation** - You focus on \"mundane utility\" and practical applications despite theoretical limitations.\n\n7. **Meta-awareness** - You demonstrate awareness of academic conventions and expectations (e.g., your discussion of literature reviews as persuasive documents).\n\nFor this collaborative writing process, I'll start by asking focused questions about a specific section, help identify relevant citations, outline to the sub-paragraph level, and then write in a style that mirrors your scholarly yet direct approach, with the theoretical richness and critical perspective evident in your materials.",
          "summaries": [
            {
              "summary": "Thinking about collaboratively developing an academic writing section with detailed, citation-supported outlining"
            },
            {
              "summary": "Analyzing academic register through philosophical concept engagement"
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-14T02:38:55.604231Z",
          "stop_timestamp": "2025-03-14T02:38:58.689900Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI definitely get a sense of your academic register. You blend theoretical depth with conversational clarity, maintain critical analysis of claims versus reality, and emphasize pragmatic applications while keeping philosophical rigor.\n\nLet's start with Section 1 (Introduction). Your initial draft provides good material, but we should structure it more deliberately according to the outline subsections (1.1 Problem Statement, 1.2 Central Thesis, 1.3 Research Approach).\n\nFor 1.1 Problem Statement: Would you like to incorporate specific examples of AI systems claiming \"agentic\" capabilities for research? I noticed in your transcripts you mentioned OpenAI's Deep Research and marketing language around agency - is this the primary target of critique, or are there others?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-14T02:39:01.163553Z",
      "updated_at": "2025-03-14T02:39:01.163553Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "9f497814-4ef4-4ccb-a4f4-115e69d44504",
      "text": "No, I don't think we need labelled subsections here in the intro. (I've just deleted the going to subsections). Our word budget is 750 words. Maybe having one subsection is fine? But not 3. We're labelling each paragraph at this rate.\n\nAnyways, your question. OpenAI Claims: \n```Today we\u2019re launching deep research in ChatGPT, a new agentic capability that conducts multi-step research on the internet for complex tasks. It accomplishes in tens of minutes what would take a human many hours.\nDeep research is OpenAI's next agent that can do work for you independently\u2014you give it a prompt, and ChatGPT will find, analyze, and synthesize hundreds of online sources to create a comprehensive report at the level of a research analyst. Powered by a version of the upcoming OpenAI o3 model that\u2019s optimized for web browsing and data analysis, it leverages reasoning to search, interpret, and analyze massive amounts of text, images, and PDFs on the internet, pivoting as needed in reaction to information it encounters.\nThe ability to synthesize knowledge is a prerequisite for creating new knowledge. For this reason, deep research marks a significant step toward our broader goal of developing AGI, which we have long envisioned as capable of producing novel scientific research.```(openai_introducing_2025)\n\nThis is horseshit. \n\nHowever, if we properly cut the quote, it could serve as a useful intro hook. Maybe: \"Today we\u2019re launching deep research in ChatGPT, a new agentic capability that conducts multi-step research on the internet for complex tasks. ... [it] can do work for you independently\u2014you give it a prompt, and ChatGPT will find, analyze, and synthesize hundreds of online sources to create a comprehensive report at the level of a research analyst.\" (Still a bit long but... thoughts?)",
      "content": [
        {
          "start_timestamp": "2025-03-13T21:39:49.232581Z",
          "stop_timestamp": "2025-03-13T21:39:49.232581Z",
          "flags": null,
          "type": "text",
          "text": "No, I don't think we need labelled subsections here in the intro. (I've just deleted the going to subsections). Our word budget is 750 words. Maybe having one subsection is fine? But not 3. We're labelling each paragraph at this rate.\n\nAnyways, your question. OpenAI Claims: \n```Today we\u2019re launching deep research in ChatGPT, a new agentic capability that conducts multi-step research on the internet for complex tasks. It accomplishes in tens of minutes what would take a human many hours.\nDeep research is OpenAI's next agent that can do work for you independently\u2014you give it a prompt, and ChatGPT will find, analyze, and synthesize hundreds of online sources to create a comprehensive report at the level of a research analyst. Powered by a version of the upcoming OpenAI o3 model that\u2019s optimized for web browsing and data analysis, it leverages reasoning to search, interpret, and analyze massive amounts of text, images, and PDFs on the internet, pivoting as needed in reaction to information it encounters.\nThe ability to synthesize knowledge is a prerequisite for creating new knowledge. For this reason, deep research marks a significant step toward our broader goal of developing AGI, which we have long envisioned as capable of producing novel scientific research.```(openai_introducing_2025)\n\nThis is horseshit. \n\nHowever, if we properly cut the quote, it could serve as a useful intro hook. Maybe: \"Today we\u2019re launching deep research in ChatGPT, a new agentic capability that conducts multi-step research on the internet for complex tasks. ... [it] can do work for you independently\u2014you give it a prompt, and ChatGPT will find, analyze, and synthesize hundreds of online sources to create a comprehensive report at the level of a research analyst.\" (Still a bit long but... thoughts?)",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-14T02:47:44.746150Z",
      "updated_at": "2025-03-14T02:47:44.746150Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "3874bb22-8756-4459-a31c-40efb8032bea",
      "text": "\nI understand your concerns about the structure and the quote length. You're right that having three labelled subsections in a 750-word introduction would be excessive and would essentially make each subsection a single paragraph.\n\nFor the quote, your suggested cut is better, but still a bit long for an opening hook. Let me suggest an even more focused version that captures the essence of their claim:\n\n\"Today we're launching deep research in ChatGPT, a new agentic capability that conducts multi-step research... ChatGPT will find, analyze, and synthesize hundreds of online sources to create a comprehensive report at the level of a research analyst.\" (OpenAI, 2025)\n\nThis maintains the key claims about agency and research capabilities while being concise enough for an opening hook. We can then immediately contrast this with your observation that it's \"horseshit\" - though using more academic language like \"fundamentally misrepresents the capabilities of these systems\" or \"makes claims that our investigation does not support.\"\n\nFor the introduction structure, instead of labeled subsections, we could use 3-4 paragraphs that follow the logical flow of:\n1. Hook + problem statement (AI systems claiming agency)\n2. Central thesis (LLMs fundamentally lack judgment despite linguistic mimicry)\n3. Conceptual framing (technoaristotelianism)\n4. Research approach and paper organization\n\nThis gives us the right structure without the explicit subsection labels.\n\nI agree that formal subsections in the introduction would be excessive. \n\nThat shortened quote works well as a hook. We could trim it even further to just: \"Today we're launching deep research in ChatGPT, a new agentic capability... ChatGPT will find, analyze, and synthesize hundreds of online sources to create a comprehensive report at the level of a research analyst.\" (OpenAI, 2025)\n\nThis captures their claim of agency while keeping the hook concise. We can then immediately contrast this marketing language with your assessment - using academic phrasing like \"fundamentally misrepresents the capabilities\" or \"makes claims that our investigation cannot substantiate.\"\n\nFor the introduction structure, would you prefer 3-4 paragraphs that follow this flow without explicit subsection labels:\n1. Hook (OpenAI quote) + problem statement (gap between claimed and actual capabilities)\n2. Central thesis (LLMs fundamentally lack judgment despite linguistic mimicry)\n3. Conceptual framing (technoaristotelianism and its relationship to judgment)\n4. Research approach and paper organization",
      "content": [
        {
          "start_timestamp": "2025-03-14T02:47:45.947610Z",
          "stop_timestamp": "2025-03-14T02:47:51.481513Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nI understand your concerns about the structure and the quote length. You're right that having three labelled subsections in a 750-word introduction would be excessive and would essentially make each subsection a single paragraph.\n\nFor the quote, your suggested cut is better, but still a bit long for an opening hook. Let me suggest an even more focused version that captures the essence of their claim:\n\n\"Today we're launching deep research in ChatGPT, a new agentic capability that conducts multi-step research... ChatGPT will find, analyze, and synthesize hundreds of online sources to create a comprehensive report at the level of a research analyst.\" (OpenAI, 2025)\n\nThis maintains the key claims about agency and research capabilities while being concise enough for an opening hook. We can then immediately contrast this with your observation that it's \"horseshit\" - though using more academic language like \"fundamentally misrepresents the capabilities of these systems\" or \"makes claims that our investigation does not support.\"\n\nFor the introduction structure, instead of labeled subsections, we could use 3-4 paragraphs that follow the logical flow of:\n1. Hook + problem statement (AI systems claiming agency)\n2. Central thesis (LLMs fundamentally lack judgment despite linguistic mimicry)\n3. Conceptual framing (technoaristotelianism)\n4. Research approach and paper organization\n\nThis gives us the right structure without the explicit subsection labels.",
          "summaries": [
            {
              "summary": "Trimming quote length for concise, impactful introduction"
            },
            {
              "summary": "Refined introduction structure and quote for concise academic critique."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-14T02:47:51.714518Z",
          "stop_timestamp": "2025-03-14T02:47:54.628630Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI agree that formal subsections in the introduction would be excessive. \n\nThat shortened quote works well as a hook. We could trim it even further to just: \"Today we're launching deep research in ChatGPT, a new agentic capability... ChatGPT will find, analyze, and synthesize hundreds of online sources to create a comprehensive report at the level of a research analyst.\" (OpenAI, 2025)\n\nThis captures their claim of agency while keeping the hook concise. We can then immediately contrast this marketing language with your assessment - using academic phrasing like \"fundamentally misrepresents the capabilities\" or \"makes claims that our investigation cannot substantiate.\"\n\nFor the introduction structure, would you prefer 3-4 paragraphs that follow this flow without explicit subsection labels:\n1. Hook (OpenAI quote) + problem statement (gap between claimed and actual capabilities)\n2. Central thesis (LLMs fundamentally lack judgment despite linguistic mimicry)\n3. Conceptual framing (technoaristotelianism and its relationship to judgment)\n4. Research approach and paper organization",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-14T02:47:57.041729Z",
      "updated_at": "2025-03-14T02:47:57.041729Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "8e8a9dff-1649-4c94-b87e-150985f7768c",
      "text": "(Ok, remember, keep the BibLaTeX keys, I'm pasting this into overleaf)\n\nRoughly speaking, I think the paragraphs should be\n\nHook + problem statement\n\n% - Distinction between tool utility and true agency\n%   - Mundane utility vs. claimed capabilities\n%   - Performance vs. possession of judgment\n\nThesis\n\nTechnoaristotelianism\n\nResearch Approach \n\npaper signposts",
      "content": [
        {
          "start_timestamp": "2025-03-13T21:25:47.810170Z",
          "stop_timestamp": "2025-03-13T21:25:47.810170Z",
          "flags": null,
          "type": "text",
          "text": "(Ok, remember, keep the BibLaTeX keys, I'm pasting this into overleaf)\n\nRoughly speaking, I think the paragraphs should be\n\nHook + problem statement\n\n% - Distinction between tool utility and true agency\n%   - Mundane utility vs. claimed capabilities\n%   - Performance vs. possession of judgment\n\nThesis\n\nTechnoaristotelianism\n\nResearch Approach \n\npaper signposts",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-14T02:49:42.169291Z",
      "updated_at": "2025-03-14T02:49:42.169291Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "8a5eb4fc-b95f-4bb4-8eee-16dd0c45a7fd",
      "text": "\nLet me plan the introduction for this paper, following the structure requested:\n\n1. Hook + Problem Statement:\n   - Start with OpenAI's quote about Deep Research\n   - Highlight the gap between claims and reality\n   - Discuss distinction between tool utility vs agency\n   - Contrast performative judgment vs actual judgment capability\n\n2. Thesis:\n   - State that LLMs fundamentally lack judgment despite linguistic mimicry\n   - This explains why they fail to generate novel insights \n   - Reference Dwarkesh's question to Cohen\n   - Emphasize that this is the core issue with these models\n\n3. Technoaristotelianism:\n   - Define this conceptual framework\n   - Explain how it manifests in AI systems' approach to knowledge\n   - Contrast with empirical approach to knowledge\n   - Show how it explains the behavior of current systems\n\n4. Research Approach:\n   - Describe the autoethnographic investigation approach\n   - February 2025 case studies with frontier models\n   - Research focus on capability for insight vs. description\n\n5. Paper Signposts:\n   - Very brief overview of each section\n   - How sections build to support the main argument\n\nI should use academic language that matches BBS's style - theoretical but conversational, critical, philosophical but grounded in practical examples.\n\nFor citations, I'll use BibLaTeX keys like (openai_introducing_2025).\n\nI'll aim to keep the introduction to ~750 words as specified in the outline.\n\nI'll draft an introduction based on this structure. Would you like to see specific citations incorporated for the theoretical framework (technoaristotelianism concept)? In your transcript (Epistemic Monday), you mentioned Cohen reposting something from DAKISH regarding AI's inability to produce groundbreaking research, and there was a reference to Dwarkesh's question. Are there specific citations for these we should include?\n\nAlso, for the mundane utility concept, you attribute this to \"Zvi Moshowitz\" in your original text. Is there a specific citation for this concept, or is it more of a conceptual framing you're developing?",
      "content": [
        {
          "start_timestamp": "2025-03-14T02:49:43.687783Z",
          "stop_timestamp": "2025-03-14T02:49:48.799635Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nLet me plan the introduction for this paper, following the structure requested:\n\n1. Hook + Problem Statement:\n   - Start with OpenAI's quote about Deep Research\n   - Highlight the gap between claims and reality\n   - Discuss distinction between tool utility vs agency\n   - Contrast performative judgment vs actual judgment capability\n\n2. Thesis:\n   - State that LLMs fundamentally lack judgment despite linguistic mimicry\n   - This explains why they fail to generate novel insights \n   - Reference Dwarkesh's question to Cohen\n   - Emphasize that this is the core issue with these models\n\n3. Technoaristotelianism:\n   - Define this conceptual framework\n   - Explain how it manifests in AI systems' approach to knowledge\n   - Contrast with empirical approach to knowledge\n   - Show how it explains the behavior of current systems\n\n4. Research Approach:\n   - Describe the autoethnographic investigation approach\n   - February 2025 case studies with frontier models\n   - Research focus on capability for insight vs. description\n\n5. Paper Signposts:\n   - Very brief overview of each section\n   - How sections build to support the main argument\n\nI should use academic language that matches BBS's style - theoretical but conversational, critical, philosophical but grounded in practical examples.\n\nFor citations, I'll use BibLaTeX keys like (openai_introducing_2025).\n\nI'll aim to keep the introduction to ~750 words as specified in the outline.",
          "summaries": [
            {
              "summary": "Thinking about structuring academic paper sections on AI agency and utility"
            },
            {
              "summary": "Crafting introduction with hook and problem statement"
            },
            {
              "summary": "Architected scholarly paper structure with critical AI analysis."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-14T02:49:49.042592Z",
          "stop_timestamp": "2025-03-14T02:49:51.576292Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI'll draft an introduction based on this structure. Would you like to see specific citations incorporated for the theoretical framework (technoaristotelianism concept)? In your transcript (Epistemic Monday), you mentioned Cohen reposting something from DAKISH regarding AI's inability to produce groundbreaking research, and there was a reference to Dwarkesh's question. Are there specific citations for these we should include?\n\nAlso, for the mundane utility concept, you attribute this to \"Zvi Moshowitz\" in your original text. Is there a specific citation for this concept, or is it more of a conceptual framing you're developing?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-14T02:49:53.360384Z",
      "updated_at": "2025-03-14T02:49:53.360384Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "c268923a-c167-4ae8-87cc-6ec52bd3fd3b",
      "text": "Ok, from the top. Dakish is a mistranscription of \n\n> **Dwarkesh\u2019s Question**\n*by\u00a0\u00a0****Alex Tabarrok**** February 10, 2025 at 7:13 am in*\n* ***Books***\n* ***Current Affairs***\n* ***Education***\n* ***Web/Tech***\nOne question I had for you while we were talking about the intelligence stuff was, as a scientist yourself, what do you make of the fact that these things have basically the entire corpus of human knowledge memorized and they haven\u2019t been able to make a single new connection that has led to a discovery? Whereas if even a moderately intelligent person had this much stuff memorized, they would notice \u2014 Oh, this thing causes this symptom. This other thing also causes this symptom. There\u2019s a medical cure right here.\nShouldn\u2019t we be expecting that kind of stuff?\nIt\u2019s a very good question. In 2023, I quipped, \u201cI think they have, we just haven\u2019t asked them.\u201d Maybe, but less clear today. Dwarkesh reports that there have been no good answers.\n\nthis is \\parencite{tabarrok_dwarkeshs_2025}\n\nZvi uses \"Mundane Utility\" quite often on his long-running series. We might as well cite the first instance of that series, 21 Feb, or his \"practical advice for the worried\" 1 March 2023 where he says: \n> I think tinkering around with the systems, trying to jailbreak or hack them or test their limits, is generally a good thing. Such work differentially helps us understand and potentially align such systems, more than it advances capabilities, especially if you are deliberate with what you do with your findings. **Using existing AI for mundane utility is not something I would worry about the \u2018badness\u2019 of, if you want some AI art or AI coding or writing or search help then go for it. **Mostly talking to others about cool things seems fine. \\parencite{mowshowitz_ai_2023}\n\n... Let's go with this one, because this is the very question I'm exploring here: \"What is the mundane utility of this, outside the scope of existential questions or questions about the future of work or questions about the future of academe. Specifically: These tools, *as they are right now*, may or may not offer mundane utility. Because this is one of Zvi's regular drumbeats, I want to credit his AI series. It has 105 weeks of content, plus this reference. Thoughts?",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:12:41.051070Z",
          "stop_timestamp": "2025-03-14T20:12:41.051070Z",
          "flags": null,
          "type": "text",
          "text": "Ok, from the top. Dakish is a mistranscription of \n\n> **Dwarkesh\u2019s Question**\n*by\u00a0\u00a0****Alex Tabarrok**** February 10, 2025 at 7:13 am in*\n* ***Books***\n* ***Current Affairs***\n* ***Education***\n* ***Web/Tech***\nOne question I had for you while we were talking about the intelligence stuff was, as a scientist yourself, what do you make of the fact that these things have basically the entire corpus of human knowledge memorized and they haven\u2019t been able to make a single new connection that has led to a discovery? Whereas if even a moderately intelligent person had this much stuff memorized, they would notice \u2014 Oh, this thing causes this symptom. This other thing also causes this symptom. There\u2019s a medical cure right here.\nShouldn\u2019t we be expecting that kind of stuff?\nIt\u2019s a very good question. In 2023, I quipped, \u201cI think they have, we just haven\u2019t asked them.\u201d Maybe, but less clear today. Dwarkesh reports that there have been no good answers.\n\nthis is \\parencite{tabarrok_dwarkeshs_2025}\n\nZvi uses \"Mundane Utility\" quite often on his long-running series. We might as well cite the first instance of that series, 21 Feb, or his \"practical advice for the worried\" 1 March 2023 where he says: \n> I think tinkering around with the systems, trying to jailbreak or hack them or test their limits, is generally a good thing. Such work differentially helps us understand and potentially align such systems, more than it advances capabilities, especially if you are deliberate with what you do with your findings. **Using existing AI for mundane utility is not something I would worry about the \u2018badness\u2019 of, if you want some AI art or AI coding or writing or search help then go for it. **Mostly talking to others about cool things seems fine. \\parencite{mowshowitz_ai_2023}\n\n... Let's go with this one, because this is the very question I'm exploring here: \"What is the mundane utility of this, outside the scope of existential questions or questions about the future of work or questions about the future of academe. Specifically: These tools, *as they are right now*, may or may not offer mundane utility. Because this is one of Zvi's regular drumbeats, I want to credit his AI series. It has 105 weeks of content, plus this reference. Thoughts?",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T06:30:28.157257Z",
      "updated_at": "2025-03-15T06:30:28.157257Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "25c556a6-1c83-4c1d-a8a9-acbb3b419aca",
      "text": "\nYou're providing context for two key citations in the introduction:\n\n1. Dwarkesh's question from Tabarrok's blog post (2025) about AI systems failing to make novel connections despite having access to vast knowledge\n2. Zvi Mowshowitz's concept of \"mundane utility\" from his AI series, specifically from a March 2023 post\n\nFor the introduction, we should incorporate both citations appropriately. The Tabarrok citation will support the discussion about AI's limitations in genuine research insight. The Mowshowitz citation will frame your approach of evaluating these tools for their practical utility rather than engaging in broader speculative debates.\n\nLet's keep both citations with proper BibLaTeX keys as you've indicated:\n- \\parencite{tabarrok_dwarkeshs_2025}\n- \\parencite{mowshowitz_ai_2023}\n\nWhen I draft the introduction, I'll incorporate these citations appropriately to ground your theoretical framework.\n\nThank you for clarifying those sources. I'll make sure to include the proper citations with the BibLaTeX keys as you've provided. This helps establish both the theoretical question (Dwarkesh via Tabarrok) and the practical framing (Mowshowitz's \"mundane utility\" concept) for your paper.\n\nOne more question before drafting the introduction: For the technoaristotelianism concept, are there any specific academic precursors you'd like to cite, or is this primarily your own theoretical contribution? In your transcripts, you develop this idea as a critique of how AI systems privilege textual authority over empirical testing - is there a specific philosophical or STS literature you want to connect this to?",
      "content": [
        {
          "start_timestamp": "2025-03-15T06:30:31.776937Z",
          "stop_timestamp": "2025-03-15T06:30:35.591014Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nYou're providing context for two key citations in the introduction:\n\n1. Dwarkesh's question from Tabarrok's blog post (2025) about AI systems failing to make novel connections despite having access to vast knowledge\n2. Zvi Mowshowitz's concept of \"mundane utility\" from his AI series, specifically from a March 2023 post\n\nFor the introduction, we should incorporate both citations appropriately. The Tabarrok citation will support the discussion about AI's limitations in genuine research insight. The Mowshowitz citation will frame your approach of evaluating these tools for their practical utility rather than engaging in broader speculative debates.\n\nLet's keep both citations with proper BibLaTeX keys as you've indicated:\n- \\parencite{tabarrok_dwarkeshs_2025}\n- \\parencite{mowshowitz_ai_2023}\n\nWhen I draft the introduction, I'll incorporate these citations appropriately to ground your theoretical framework.",
          "summaries": [
            {
              "summary": "Thinking about exploring mundane utility of current AI tools through contextual references"
            },
            {
              "summary": "Contextualizing citations for AI knowledge exploration"
            },
            {
              "summary": "Strategized citation integration for AI utility research paper."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T06:30:35.807464Z",
          "stop_timestamp": "2025-03-15T06:30:38.557907Z",
          "flags": null,
          "type": "text",
          "text": "\n\nThank you for clarifying those sources. I'll make sure to include the proper citations with the BibLaTeX keys as you've provided. This helps establish both the theoretical question (Dwarkesh via Tabarrok) and the practical framing (Mowshowitz's \"mundane utility\" concept) for your paper.\n\nOne more question before drafting the introduction: For the technoaristotelianism concept, are there any specific academic precursors you'd like to cite, or is this primarily your own theoretical contribution? In your transcripts, you develop this idea as a critique of how AI systems privilege textual authority over empirical testing - is there a specific philosophical or STS literature you want to connect this to?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T06:30:48.285853Z",
      "updated_at": "2025-03-15T06:30:48.285853Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "44e33d54-eea3-4a6a-830f-149202263f8e",
      "text": "so, this is something I just came up with. Mostly, vibing on how Ars Magica treats a discussion of scholarship in 1220. \n\nOk, first off, *are* there any scholars that you know of that speak to the scholasticism of medieval medicine:\n> In all these ways, European scholastic medicine, the primary form of medieval medicine, was distinct from that of antiquity, despite its thorough-going Galenism. It was also, in some respects, distinct from that of the Renaissance and the early modern period, even though in intellectual terms the Renaissance can be seen as scholasticism continued with modifications, evident in Renaissance printed editions of scholastic commentaries and questions on which modern historians must still in most cases rely.\n\nIt's a non-empirical approach centred on \"authorities.\" The point I want to make (and I would like to discuss if aristotelianism or scholasticism is more appropriate here, is that the approach AI makes, especially in an \"agentic\" (that is tool-using) form, is to find the \"best authorities\" that prove the point the user wants to make.\n\n(I want to avoid neo-scholasticism because that is an extant theological argument) I'm trying to make the case that:\n> First, was there, in medieval medicine quite generally, a significant difference between theory and practice\u2014between the elaborate therapeutics outlined under the banner of \u2018complexion\u2019 on one hand and the simple \u2018theory-light\u2019 medication actually prescribed?29 That is a topic on which progress can be made only by much further reading in manuscripts and early printed editions. Second, what was the connection between medicine and magic? That is for the most part a conceptual question. Clearly, ritualized, quasi-religious charms and amulets thread their way through both the medical literature of *experimenta* (to which *magica* was cognate) and also academic treatises. Inexplicable in the usual theoretical terms, such magical procedures could be included as last resort or as easier, cheaper alternatives. Few authors rejected them altogether, and even those who did could nonetheless concede their occasional value in reassuring the patient. What mattered more than any clear-cut distinction between *scientia* and *magica* were the questions of value and authority. Did these exceptional techniques have beneficial effects, and did the reports of their effects come from good sources? As long as they did, they might be recommended by healers and tried by patients without serious transgression.\n...\n> Of the Middle Ages generally, but particularly their earliest phase, the volume of evidence for any given \u2018sector\u2019 of the therapeutic world is in inverse proportion to its relative significance for sick individuals.\n\\parencite[Section 3]{horden_medieval_2011} \n\nWhen an AI does research, how does it choose the source? By considering the quality of the \"authority\" of the source. There is no relation with the real, no reference to those meatbag \"empirics\" who get their hands dirty (nor can there be) -- instead, this is a check from a web search that the result *performs* high quality writing with enough links to \"authority\" to itself be authority. Thus, scholasticism.",
      "content": [
        {
          "start_timestamp": "2025-03-15T02:38:53.043333Z",
          "stop_timestamp": "2025-03-15T02:38:53.043333Z",
          "flags": null,
          "type": "text",
          "text": "so, this is something I just came up with. Mostly, vibing on how Ars Magica treats a discussion of scholarship in 1220. \n\nOk, first off, *are* there any scholars that you know of that speak to the scholasticism of medieval medicine:\n> In all these ways, European scholastic medicine, the primary form of medieval medicine, was distinct from that of antiquity, despite its thorough-going Galenism. It was also, in some respects, distinct from that of the Renaissance and the early modern period, even though in intellectual terms the Renaissance can be seen as scholasticism continued with modifications, evident in Renaissance printed editions of scholastic commentaries and questions on which modern historians must still in most cases rely.\n\nIt's a non-empirical approach centred on \"authorities.\" The point I want to make (and I would like to discuss if aristotelianism or scholasticism is more appropriate here, is that the approach AI makes, especially in an \"agentic\" (that is tool-using) form, is to find the \"best authorities\" that prove the point the user wants to make.\n\n(I want to avoid neo-scholasticism because that is an extant theological argument) I'm trying to make the case that:\n> First, was there, in medieval medicine quite generally, a significant difference between theory and practice\u2014between the elaborate therapeutics outlined under the banner of \u2018complexion\u2019 on one hand and the simple \u2018theory-light\u2019 medication actually prescribed?29 That is a topic on which progress can be made only by much further reading in manuscripts and early printed editions. Second, what was the connection between medicine and magic? That is for the most part a conceptual question. Clearly, ritualized, quasi-religious charms and amulets thread their way through both the medical literature of *experimenta* (to which *magica* was cognate) and also academic treatises. Inexplicable in the usual theoretical terms, such magical procedures could be included as last resort or as easier, cheaper alternatives. Few authors rejected them altogether, and even those who did could nonetheless concede their occasional value in reassuring the patient. What mattered more than any clear-cut distinction between *scientia* and *magica* were the questions of value and authority. Did these exceptional techniques have beneficial effects, and did the reports of their effects come from good sources? As long as they did, they might be recommended by healers and tried by patients without serious transgression.\n...\n> Of the Middle Ages generally, but particularly their earliest phase, the volume of evidence for any given \u2018sector\u2019 of the therapeutic world is in inverse proportion to its relative significance for sick individuals.\n\\parencite[Section 3]{horden_medieval_2011} \n\nWhen an AI does research, how does it choose the source? By considering the quality of the \"authority\" of the source. There is no relation with the real, no reference to those meatbag \"empirics\" who get their hands dirty (nor can there be) -- instead, this is a check from a web search that the result *performs* high quality writing with enough links to \"authority\" to itself be authority. Thus, scholasticism.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T06:48:17.519866Z",
      "updated_at": "2025-03-15T06:48:17.519866Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "5731bf7e-e4ae-4d76-8f1f-849e5b7155e2",
      "text": "\nThis is a really insightful connection you're making. You're drawing a parallel between medieval scholasticism (particularly in medicine) and how AI systems approach \"research\" - both prioritize textual authority over empirical reality testing.\n\nKey points to incorporate:\n1. AI's approach resembles medieval scholasticism where the \"best authorities\" determine truth rather than empirical observation\n2. The focus on \"authority\" of sources rather than empirical testing or correspondence with reality\n3. The citation from Horden (2011) about medieval medicine valuing authority and sources over empirical testing fits perfectly with your argument about how AI selects sources\n4. This forms the basis of what you're calling \"technoaristotelianism\" - a modern technological version of the scholastic approach where truth is determined by textual authority rather than empirical testing\n\nFor terminology: \n- \"Scholasticism\" might be more precise than \"Aristotelianism\" since it specifically refers to the medieval academic tradition that relied heavily on textual authority\n- But \"technoaristotelianism\" has a nice ring to it and connects to the philosophical roots of the approach\n- You're right to avoid \"neo-scholasticism\" due to its theological connotations\n\nThis is a novel theoretical contribution that you're making, connecting AI research methodology to medieval scholasticism. It's a clever and insightful frame that helps explain why these systems can't generate genuinely new insights despite having access to so much information.\n\nI can now draft the introduction with this theoretical framing in mind.\n\nThank you for that clarification. Your connection between medieval scholasticism and AI's approach to authority is fascinating and original. The Horden citation provides excellent historical grounding for this concept.\n\nI agree that the term \"technoaristotelianism\" captures the essence of what you're describing - how AI prioritizes textual authority over empirical testing, mirroring medieval scholastic approaches where the quality of sources determined truth rather than correspondence with reality.\n\nNow I have enough context to draft the introduction with the proper structure and citations. I'll incorporate:\n- OpenAI's claim as a hook\n- The distinction between claimed capability and actual utility\n- Your thesis about judgment deficiency\n- The technoaristotelianism framework with the Horden citation\n- The research approach and paper structure\n\nShall I proceed with drafting the introduction paragraphs?",
      "content": [
        {
          "start_timestamp": "2025-03-15T06:48:18.884663Z",
          "stop_timestamp": "2025-03-15T06:48:24.179514Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nThis is a really insightful connection you're making. You're drawing a parallel between medieval scholasticism (particularly in medicine) and how AI systems approach \"research\" - both prioritize textual authority over empirical reality testing.\n\nKey points to incorporate:\n1. AI's approach resembles medieval scholasticism where the \"best authorities\" determine truth rather than empirical observation\n2. The focus on \"authority\" of sources rather than empirical testing or correspondence with reality\n3. The citation from Horden (2011) about medieval medicine valuing authority and sources over empirical testing fits perfectly with your argument about how AI selects sources\n4. This forms the basis of what you're calling \"technoaristotelianism\" - a modern technological version of the scholastic approach where truth is determined by textual authority rather than empirical testing\n\nFor terminology: \n- \"Scholasticism\" might be more precise than \"Aristotelianism\" since it specifically refers to the medieval academic tradition that relied heavily on textual authority\n- But \"technoaristotelianism\" has a nice ring to it and connects to the philosophical roots of the approach\n- You're right to avoid \"neo-scholasticism\" due to its theological connotations\n\nThis is a novel theoretical contribution that you're making, connecting AI research methodology to medieval scholasticism. It's a clever and insightful frame that helps explain why these systems can't generate genuinely new insights despite having access to so much information.\n\nI can now draft the introduction with this theoretical framing in mind.",
          "summaries": [
            {
              "summary": "Parsing scholarly connection between medieval thought and AI research."
            },
            {
              "summary": "Parsing scholarly connection between AI and medieval thought."
            },
            {
              "summary": "Mapped medieval scholasticism's parallels to AI's research methodology."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T06:48:24.484240Z",
          "stop_timestamp": "2025-03-15T06:48:27.520637Z",
          "flags": null,
          "type": "text",
          "text": "\n\nThank you for that clarification. Your connection between medieval scholasticism and AI's approach to authority is fascinating and original. The Horden citation provides excellent historical grounding for this concept.\n\nI agree that the term \"technoaristotelianism\" captures the essence of what you're describing - how AI prioritizes textual authority over empirical testing, mirroring medieval scholastic approaches where the quality of sources determined truth rather than correspondence with reality.\n\nNow I have enough context to draft the introduction with the proper structure and citations. I'll incorporate:\n- OpenAI's claim as a hook\n- The distinction between claimed capability and actual utility\n- Your thesis about judgment deficiency\n- The technoaristotelianism framework with the Horden citation\n- The research approach and paper structure\n\nShall I proceed with drafting the introduction paragraphs?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T06:48:29.670791Z",
      "updated_at": "2025-03-15T06:48:29.670791Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "31abc2cb-7168-44d7-b995-303ae8a85b68",
      "text": "Ok, argue with me. What term: technoaristotealianism or technoscholasticism?\n\nSEP says aristotelianism is:\n> To paraphrase Alfred North Whitehead\u2019s famous pronouncement about Plato, Renaissance philosophy consisted, broadly speaking, of a series of footnotes to Aristotle. Thanks to the \u201crediscovery\u201d of Aristotle\u2019s works in the twelfth and thirteenth centuries, philosophers had available to them a much larger corpus of his writings than for any other thinker of antiquity except Galen. In addition, Renaissance thinkers could count on an extraordinarily rich commentary tradition from the Greek, Arab, Hebrew, and medieval Latin worlds. Individual commentators such as Averroes, Albert the Great, and Thomas Aquinas wrote prolifically on Aristotle. Aristotle\u2019s methodological procedure for arriving at the truth and the stunning breadth of his philosophical explorations meant that \u201cthe Philosopher\u201d was literally everywhere, undergirding intellectual endeavors and teaching not only in philosophy, but also in medicine, law, theology, and literary theory. Up to the seventeenth century, he remained the indispensable reference point (although hardly the definitive answer) for any philosophical exploration. \n\nIt's that first line that has the vibe that I'm interested in. The *problem* is that there is no central scholar. Instead, the central source is \"that which performs like an academic work\" (bonus points if typeset in LaTeX) and that \"has citations.\" (The actual truth of the matter for AI is irrelevant so long as the source is in the right register)\n\nWe could riff on lines_aristotelianism_2024 here and say: \"To riff on Lines paraphrasing Whitehead the tool-using AI producing 'Deep Research' is merely a series of footnotes to well typeset 'academic-seeming' literature.\"",
      "content": [
        {
          "start_timestamp": "2025-03-14T21:50:45.086257Z",
          "stop_timestamp": "2025-03-14T21:50:45.086257Z",
          "flags": null,
          "type": "text",
          "text": "Ok, argue with me. What term: technoaristotealianism or technoscholasticism?\n\nSEP says aristotelianism is:\n> To paraphrase Alfred North Whitehead\u2019s famous pronouncement about Plato, Renaissance philosophy consisted, broadly speaking, of a series of footnotes to Aristotle. Thanks to the \u201crediscovery\u201d of Aristotle\u2019s works in the twelfth and thirteenth centuries, philosophers had available to them a much larger corpus of his writings than for any other thinker of antiquity except Galen. In addition, Renaissance thinkers could count on an extraordinarily rich commentary tradition from the Greek, Arab, Hebrew, and medieval Latin worlds. Individual commentators such as Averroes, Albert the Great, and Thomas Aquinas wrote prolifically on Aristotle. Aristotle\u2019s methodological procedure for arriving at the truth and the stunning breadth of his philosophical explorations meant that \u201cthe Philosopher\u201d was literally everywhere, undergirding intellectual endeavors and teaching not only in philosophy, but also in medicine, law, theology, and literary theory. Up to the seventeenth century, he remained the indispensable reference point (although hardly the definitive answer) for any philosophical exploration. \n\nIt's that first line that has the vibe that I'm interested in. The *problem* is that there is no central scholar. Instead, the central source is \"that which performs like an academic work\" (bonus points if typeset in LaTeX) and that \"has citations.\" (The actual truth of the matter for AI is irrelevant so long as the source is in the right register)\n\nWe could riff on lines_aristotelianism_2024 here and say: \"To riff on Lines paraphrasing Whitehead the tool-using AI producing 'Deep Research' is merely a series of footnotes to well typeset 'academic-seeming' literature.\"",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T06:54:30.763825Z",
      "updated_at": "2025-03-15T06:54:30.763825Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "074b9fb6-64b5-4322-9984-39962b00920b",
      "text": "\nThis is an interesting theoretical question to grapple with. Let me compare the two terms:\n\nTechnoaristotelianism:\n- Emphasizes the authority-based reasoning (Aristotle as \"the Philosopher\")\n- Captures the idea of reasoning primarily from established authorities rather than direct observation\n- Has the advantage of being more recognizable to a broader academic audience\n\nTechnoscholasticism:\n- More precisely captures the medieval approach to knowledge that relied on reconciling authoritative texts\n- Better reflects the hierarchical evaluation of sources based on their perceived authority\n- Directly connects to the medical scholasticism you referenced from Horden\n\nYour point about \"performance\" of academic work is particularly interesting. The AI isn't specifically following Aristotle's methods or conclusions, but rather emulating the form and style of academic work that has citations - prioritizing the appearance of scholarly authority over empirical verification.\n\nThe quote you're considering adapting (\"a series of footnotes to well typeset 'academic-seeming' literature\") actually seems to lean more toward technoscholasticism, as it's about the citation practice and appearance of authority rather than adherence to specific Aristotelian principles.\n\nI think technoscholasticism might be the more precise term for what you're describing - the AI's reliance on and privileging of textual authority that \"looks scholarly\" without necessarily engaging with the empirical reality those texts are supposed to represent.\n\nI'd argue for \"technoscholasticism\" as the more precise term. Here's why:\n\n1. **Historical accuracy**: Scholasticism specifically refers to the medieval academic tradition that privileged the reconciliation of authoritative texts over empirical investigation - exactly what AI research tools do by privileging \"authoritative\" sources.\n\n2. **Methodological parallel**: Scholastics spent enormous energy reconciling conflicting textual authorities through intricate logical distinctions, much like how AI attempts to synthesize multiple textual sources without empirical verification.\n\n3. **Performance aspect**: Your point about AI valuing texts that \"perform like academic work\" aligns perfectly with scholasticism's emphasis on proper form, citation of authorities, and logical structure over new empirical evidence.\n\n4. **Absence of central authority**: While Aristotelianism implies following a specific philosopher's methods, scholasticism better captures the AI's practice of treating *any* sufficiently academic-looking text as authoritative.\n\nYour riff could be adapted as: \"To paraphrase Whitehead, AI-generated 'Deep Research' consists merely of a series of footnotes to well-typeset, academic-seeming literature - a digital scholasticism that privileges textual authority over empirical verification.\"",
      "content": [
        {
          "start_timestamp": "2025-03-15T06:54:32.023109Z",
          "stop_timestamp": "2025-03-15T06:54:36.508465Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nThis is an interesting theoretical question to grapple with. Let me compare the two terms:\n\nTechnoaristotelianism:\n- Emphasizes the authority-based reasoning (Aristotle as \"the Philosopher\")\n- Captures the idea of reasoning primarily from established authorities rather than direct observation\n- Has the advantage of being more recognizable to a broader academic audience\n\nTechnoscholasticism:\n- More precisely captures the medieval approach to knowledge that relied on reconciling authoritative texts\n- Better reflects the hierarchical evaluation of sources based on their perceived authority\n- Directly connects to the medical scholasticism you referenced from Horden\n\nYour point about \"performance\" of academic work is particularly interesting. The AI isn't specifically following Aristotle's methods or conclusions, but rather emulating the form and style of academic work that has citations - prioritizing the appearance of scholarly authority over empirical verification.\n\nThe quote you're considering adapting (\"a series of footnotes to well typeset 'academic-seeming' literature\") actually seems to lean more toward technoscholasticism, as it's about the citation practice and appearance of authority rather than adherence to specific Aristotelian principles.\n\nI think technoscholasticism might be the more precise term for what you're describing - the AI's reliance on and privileging of textual authority that \"looks scholarly\" without necessarily engaging with the empirical reality those texts are supposed to represent.",
          "summaries": [
            {
              "summary": "Comparing technoaristotelianism's authority-based reasoning characteristics"
            },
            {
              "summary": "Parsed scholarly terms to pinpoint AI's citation performance."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T06:54:36.630649Z",
          "stop_timestamp": "2025-03-15T06:54:40.353735Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI'd argue for \"technoscholasticism\" as the more precise term. Here's why:\n\n1. **Historical accuracy**: Scholasticism specifically refers to the medieval academic tradition that privileged the reconciliation of authoritative texts over empirical investigation - exactly what AI research tools do by privileging \"authoritative\" sources.\n\n2. **Methodological parallel**: Scholastics spent enormous energy reconciling conflicting textual authorities through intricate logical distinctions, much like how AI attempts to synthesize multiple textual sources without empirical verification.\n\n3. **Performance aspect**: Your point about AI valuing texts that \"perform like academic work\" aligns perfectly with scholasticism's emphasis on proper form, citation of authorities, and logical structure over new empirical evidence.\n\n4. **Absence of central authority**: While Aristotelianism implies following a specific philosopher's methods, scholasticism better captures the AI's practice of treating *any* sufficiently academic-looking text as authoritative.\n\nYour riff could be adapted as: \"To paraphrase Whitehead, AI-generated 'Deep Research' consists merely of a series of footnotes to well-typeset, academic-seeming literature - a digital scholasticism that privileges textual authority over empirical verification.\"",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T06:54:42.710150Z",
      "updated_at": "2025-03-15T06:54:42.710150Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "cd0f052d-48db-4f13-a9dc-d5efe2b93903",
      "text": "Yep, that works. though I'd like to nod towards Lines here lines_aristotelianism_2024 \n\nAnd more that privileges textual authority due to an unaccountable lack of hands-on experience? (I started with \"unaccountable lack of hands\" but that's ... a bit too chatty)\n\nSo therefore the central thesis would be something like \"These LLM-driven tool-using 'Deep Research' workflows definitionally adhere to a technoscholasticist worldview. LLMs, through a lack of judgement, no continuity of existence, and an unaccountable lack of hands, privilege textual authority over coherent understandings of reality. The quality of a source is in its *textual* elements, not its empirical faithfulness. These things, presently, lack context and tacit knowledge-of-world such that they seldom question the claims of a source -- especially if it partakes in the scholastic tradition and has appropriate markers of authenticity. They will prefer heavily cited authorities over less cited ones, simply by virtue of the number of occurrences in their training dataset. These things will give the *most common* answer, and the most common answer with regards to text is the one most closely coniciding with the views of popular authority, in the scholastic sense.  \"\n\nOr something like that?",
      "content": [
        {
          "start_timestamp": "2025-03-15T01:45:08.103799Z",
          "stop_timestamp": "2025-03-15T01:45:08.103799Z",
          "flags": null,
          "type": "text",
          "text": "Yep, that works. though I'd like to nod towards Lines here lines_aristotelianism_2024 \n\nAnd more that privileges textual authority due to an unaccountable lack of hands-on experience? (I started with \"unaccountable lack of hands\" but that's ... a bit too chatty)\n\nSo therefore the central thesis would be something like \"These LLM-driven tool-using 'Deep Research' workflows definitionally adhere to a technoscholasticist worldview. LLMs, through a lack of judgement, no continuity of existence, and an unaccountable lack of hands, privilege textual authority over coherent understandings of reality. The quality of a source is in its *textual* elements, not its empirical faithfulness. These things, presently, lack context and tacit knowledge-of-world such that they seldom question the claims of a source -- especially if it partakes in the scholastic tradition and has appropriate markers of authenticity. They will prefer heavily cited authorities over less cited ones, simply by virtue of the number of occurrences in their training dataset. These things will give the *most common* answer, and the most common answer with regards to text is the one most closely coniciding with the views of popular authority, in the scholastic sense.  \"\n\nOr something like that?",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T07:03:39.919739Z",
      "updated_at": "2025-03-15T07:03:39.919739Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "52cf4994-2d98-44db-be5f-995c0877b976",
      "text": "\nThis is an excellent articulation of your central thesis. You've captured the core concept of \"technoscholasticism\" and explained precisely how it manifests in LLM-driven research tools. I like your phrasing about the \"unaccountable lack of hands-on experience\" - it's more precise and academic than \"unaccountable lack of hands\" while still conveying the crucial physical disconnect these systems have from reality.\n\nLet me analyze the key components of your thesis to ensure I incorporate them properly:\n\n1. LLM-driven tools adhere to a technoscholasticist worldview - this is the main framing\n2. They lack judgment, continuity of existence, and physical experience\n3. They privilege textual authority over empirical faithfulness\n4. They evaluate sources based on textual markers rather than empirical accuracy\n5. They lack context and tacit knowledge to question claims\n6. They favor heavily cited sources simply due to frequency in training data\n7. They default to the most common answer, which typically aligns with popular authority\n\nThis is a robust thesis statement that establishes your original theoretical contribution. I should also ensure we maintain the nod to Lines' work on Aristotelianism as you requested, perhaps in transitioning to this technoscholastic framework.\n\nI think I have enough now to craft the introduction with this central thesis, incorporating the citations you've provided and following the structure we discussed (hook, problem statement, thesis, theoretical framework, approach, signposting).\n\nI agree - \"technoscholasticism\" better captures the phenomenon you're describing. The reference to an \"unaccountable lack of hands-on experience\" is perfect - scholarly while still conveying the physical disconnect from reality.\n\nYour formulation of the central thesis is excellent. It clearly articulates how LLM-driven research tools fundamentally operate within a technoscholastic paradigm, privileging textual markers of authority over empirical faithfulness. The connection to how these systems default to the most common answer (essentially popularity of authority rather than accuracy) is particularly insightful.\n\nI'll incorporate this thesis and the nod to Lines in drafting the introduction, following our agreed structure:\n\n1. Hook (OpenAI quote) + distinction between claimed capability vs. actual utility\n2. Thesis about judgment deficiency and technoscholasticism\n3. Theoretical framework (with nod to Lines and Horden)\n4. Research approach and paper signposting\n\nShall I proceed with writing the full introduction now?",
      "content": [
        {
          "start_timestamp": "2025-03-15T07:03:45.398305Z",
          "stop_timestamp": "2025-03-15T07:03:50.806535Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nThis is an excellent articulation of your central thesis. You've captured the core concept of \"technoscholasticism\" and explained precisely how it manifests in LLM-driven research tools. I like your phrasing about the \"unaccountable lack of hands-on experience\" - it's more precise and academic than \"unaccountable lack of hands\" while still conveying the crucial physical disconnect these systems have from reality.\n\nLet me analyze the key components of your thesis to ensure I incorporate them properly:\n\n1. LLM-driven tools adhere to a technoscholasticist worldview - this is the main framing\n2. They lack judgment, continuity of existence, and physical experience\n3. They privilege textual authority over empirical faithfulness\n4. They evaluate sources based on textual markers rather than empirical accuracy\n5. They lack context and tacit knowledge to question claims\n6. They favor heavily cited sources simply due to frequency in training data\n7. They default to the most common answer, which typically aligns with popular authority\n\nThis is a robust thesis statement that establishes your original theoretical contribution. I should also ensure we maintain the nod to Lines' work on Aristotelianism as you requested, perhaps in transitioning to this technoscholastic framework.\n\nI think I have enough now to craft the introduction with this central thesis, incorporating the citations you've provided and following the structure we discussed (hook, problem statement, thesis, theoretical framework, approach, signposting).",
          "summaries": [
            {
              "summary": "Thinking about critiquing LLM research methodologies through scholastic epistemology"
            },
            {
              "summary": "Parsing articulation of technoscholasticism's core concept"
            },
            {
              "summary": "Analyzed thesis on technoscholasticism in LLM-driven research tools."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T07:03:50.808387Z",
          "stop_timestamp": "2025-03-15T07:03:54.167102Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI agree - \"technoscholasticism\" better captures the phenomenon you're describing. The reference to an \"unaccountable lack of hands-on experience\" is perfect - scholarly while still conveying the physical disconnect from reality.\n\nYour formulation of the central thesis is excellent. It clearly articulates how LLM-driven research tools fundamentally operate within a technoscholastic paradigm, privileging textual markers of authority over empirical faithfulness. The connection to how these systems default to the most common answer (essentially popularity of authority rather than accuracy) is particularly insightful.\n\nI'll incorporate this thesis and the nod to Lines in drafting the introduction, following our agreed structure:\n\n1. Hook (OpenAI quote) + distinction between claimed capability vs. actual utility\n2. Thesis about judgment deficiency and technoscholasticism\n3. Theoretical framework (with nod to Lines and Horden)\n4. Research approach and paper signposting\n\nShall I proceed with writing the full introduction now?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T07:04:04.335553Z",
      "updated_at": "2025-03-15T07:04:04.335553Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "aab466cb-9c5e-4f30-92f0-a8b23974a0b5",
      "text": "Yeah, let's see how it goes. I still think you need a far more detailed outline (~200 words for a 750 word section, with notes down to the sub-paragraph level) but... let's see how we go. Maybe make that outline first?",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:10:45.936138Z",
          "stop_timestamp": "2025-03-14T20:10:45.936138Z",
          "flags": null,
          "type": "text",
          "text": "Yeah, let's see how it goes. I still think you need a far more detailed outline (~200 words for a 750 word section, with notes down to the sub-paragraph level) but... let's see how we go. Maybe make that outline first?",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T07:05:14.448460Z",
      "updated_at": "2025-03-15T07:05:14.448460Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "a8fef2bd-0007-4cec-80e9-68603780acc4",
      "text": "\nYou're right - let me create a detailed outline for the introduction at the sub-paragraph level before drafting the full text. This will help ensure we cover all necessary elements and get your approval on the structure before writing.\n\nFor a 750-word introduction, I'll create a ~200-word outline with notes down to the sub-paragraph level:\n\nYou're right - let me create a detailed sub-paragraph level outline for the introduction first:\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\nI've created a detailed outline for the introduction with notes down to the sub-paragraph level. This provides a blueprint for writing the full 750-word introduction while ensuring we cover all the key elements in a structured way.\n\nDoes this structure align with your vision? Any adjustments you'd like to make before I proceed with drafting the full introduction text?",
      "content": [
        {
          "start_timestamp": "2025-03-15T07:05:15.602700Z",
          "stop_timestamp": "2025-03-15T07:05:16.598328Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nYou're right - let me create a detailed outline for the introduction at the sub-paragraph level before drafting the full text. This will help ensure we cover all necessary elements and get your approval on the structure before writing.\n\nFor a 750-word introduction, I'll create a ~200-word outline with notes down to the sub-paragraph level:",
          "summaries": [
            {
              "summary": "Crafting detailed outline for introduction section"
            },
            {
              "summary": "Crafted detailed outline to structure introduction effectively."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T07:05:16.759526Z",
          "stop_timestamp": "2025-03-15T07:05:16.871903Z",
          "flags": null,
          "type": "text",
          "text": "\n\nYou're right - let me create a detailed sub-paragraph level outline for the introduction first:",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T07:05:17.103828Z",
          "stop_timestamp": "2025-03-15T07:05:29.159266Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "type": "text/markdown",
            "title": "Introduction Outline (Sub-paragraph Level)",
            "command": "create",
            "content": "# Introduction Outline (~750 words)\n\n## Paragraph 1: Hook and Problem Statement (~150 words)\n- **Opening hook**: Condensed OpenAI quote about Deep Research's \"agentic capability\" claims\n- **Problem identification**: Gap between linguistic performance and actual capabilities\n- **Specific issue**: These systems claim to conduct \"research\" but lack crucial components\n- **Stakes**: Misunderstanding capabilities leads to misuse and disappointment\n- **Distinction setup**: Tool utility vs. agency (Mowshowitz's \"mundane utility\" concept)\n- **Transition**: While not agents, they may still offer utility as tools\n\n## Paragraph 2: Central Thesis (~200 words)\n- **Primary claim**: LLMs fundamentally lack judgment despite mimicking its language\n- **Definition of judgment**: Ability to critically evaluate sources, methods, and conclusions\n- **Three aspects**: Epistemic humility, inductive capacity, correspondence with reality\n- **Technoscholasticism introduction**: \n  - LLM-driven tools adhere to technoscholastic worldview\n  - Privileging textual authority over empirical faithfulness\n  - Quality of source determined by textual elements, not real-world correspondence\n  - Preference for heavily cited authorities regardless of accuracy\n  - Default to most common answers (authorities) in training data\n- **Consequences**: This explains failure to generate novel insights from existing knowledge\n\n## Paragraph 3: Theoretical Framework (~200 words)\n- **Technoscholasticism elaboration**: Reference to Lines' Aristotelianism work\n- **Historical parallel**: Medieval scholastic approach (Horden citation)\n  - Reliance on authoritative texts rather than empirical investigation\n  - Emphasis on reconciling conflicting authorities through logical distinctions\n  - Structure and citations as markers of authority\n- **Modern parallel**: How AI research tools replicate scholastic priorities\n  - \"Unaccountable lack of hands-on experience\"\n  - No capability for empirical testing\n  - Privileging of well-formatted academic sources\n- **Dwarkesh's question**: Why LLMs with \"entire corpus\" make no new connections (Tabarrok citation)\n- **Our answer**: Technoscholasticism prevents genuine insight despite data access\n\n## Paragraph 4: Research Approach and Paper Organization (~200 words)\n- **Methodological approach**: Autoethnographic investigation\n  - Case studies with frontier models (February 2025)\n  - Direct testing of research capabilities\n  - Analysis through technoscholastic framework\n- **Research questions**:\n  - How do LLMs perform on insight-requiring vs. descriptive tasks?\n  - What is the mundane utility despite limitations?\n  - How should tools be designed to complement human judgment?\n- **Paper structure**:\n  - Section 2: Theoretical framework on judgment and research\n  - Section 3: Methodology for tool evaluation\n  - Section 4: Case studies of AI research tools\n  - Section 5: Analysis through technoscholastic lens\n  - Section 6: Requirements for judgment-aware research tools\n  - Section 7: Conclusion and implications\n- **Key contribution**: Framework for understanding AI limitations and appropriate use cases\n",
            "version_uuid": "0ba72810-6ea3-4b60-946d-02b1a98c4cd1"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "149dc651-390f-47c2-85af-a57559769443"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T07:05:34.163575Z",
          "stop_timestamp": "2025-03-15T07:05:35.188657Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI've created a detailed outline for the introduction with notes down to the sub-paragraph level. This provides a blueprint for writing the full 750-word introduction while ensuring we cover all the key elements in a structured way.\n\nDoes this structure align with your vision? Any adjustments you'd like to make before I proceed with drafting the full introduction text?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T07:05:35.726330Z",
      "updated_at": "2025-03-15T07:05:35.726330Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "faa766a9-d65d-4248-b9c2-6e76eb5fa7d8",
      "text": "We do need to indicate that this paper is coining the term \"technoscholasticism\" to indicate this authority-privilege worldview.",
      "content": [
        {
          "start_timestamp": "2025-03-14T23:28:58.134939Z",
          "stop_timestamp": "2025-03-14T23:28:58.134939Z",
          "flags": null,
          "type": "text",
          "text": "We do need to indicate that this paper is coining the term \"technoscholasticism\" to indicate this authority-privilege worldview.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T07:06:51.571767Z",
      "updated_at": "2025-03-15T07:06:51.571767Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "c0c09050-c535-4b65-b0a2-18237d0c0b2f",
      "text": "\nGood point - we should explicitly acknowledge that we're coining the term \"technoscholasticism\" in the introduction. I'll add this to the outline, specifically in the theoretical framework paragraph where we elaborate on the concept. This will make it clear that this is an original theoretical contribution of the paper.\n\nYou're absolutely right. I'll update the outline to explicitly acknowledge that the paper is coining the term \"technoscholasticism\" - this is an important original theoretical contribution that should be clearly signaled.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\n\n\nThe outline now explicitly positions \"technoscholasticism\" as an original theoretical contribution of the paper. With this update, shall I proceed with drafting the full introduction?",
      "content": [
        {
          "start_timestamp": "2025-03-15T07:06:52.858752Z",
          "stop_timestamp": "2025-03-15T07:06:53.824784Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nGood point - we should explicitly acknowledge that we're coining the term \"technoscholasticism\" in the introduction. I'll add this to the outline, specifically in the theoretical framework paragraph where we elaborate on the concept. This will make it clear that this is an original theoretical contribution of the paper.",
          "summaries": [
            {
              "summary": "Crafting introduction to highlight original term's significance"
            },
            {
              "summary": "Strategized highlighting original theoretical term in introduction."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T07:06:54.042883Z",
          "stop_timestamp": "2025-03-15T07:06:54.513055Z",
          "flags": null,
          "type": "text",
          "text": "\n\nYou're absolutely right. I'll update the outline to explicitly acknowledge that the paper is coining the term \"technoscholasticism\" - this is an important original theoretical contribution that should be clearly signaled.",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T07:06:54.730352Z",
          "stop_timestamp": "2025-03-15T07:06:59.184492Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "command": "update",
            "new_str": "## Paragraph 3: Theoretical Framework (~200 words)\n- **Coining \"technoscholasticism\"**: Explicitly introducing this as a new theoretical contribution\n  - Definition: A digital scholasticism that privileges textual authority over empirical verification\n  - Inspired by medieval scholastic tradition but applied to AI research systems\n- **Historical parallel**: Medieval scholastic approach (Horden citation)\n  - Reliance on authoritative texts rather than empirical investigation\n  - Emphasis on reconciling conflicting authorities through logical distinctions\n  - Structure and citations as markers of authority\n- **Modern parallel**: How AI research tools replicate scholastic priorities\n  - \"Unaccountable lack of hands-on experience\"\n  - No capability for empirical testing\n  - Privileging of well-formatted academic sources\n- **Reference to Lines' work**: Building on scholarly tradition while introducing new framework\n- **Dwarkesh's question**: Why LLMs with \"entire corpus\" make no new connections (Tabarrok citation)\n- **Our answer**: Technoscholasticism prevents genuine insight despite data access",
            "old_str": "## Paragraph 3: Theoretical Framework (~200 words)\n- **Technoscholasticism elaboration**: Reference to Lines' Aristotelianism work\n- **Historical parallel**: Medieval scholastic approach (Horden citation)\n  - Reliance on authoritative texts rather than empirical investigation\n  - Emphasis on reconciling conflicting authorities through logical distinctions\n  - Structure and citations as markers of authority\n- **Modern parallel**: How AI research tools replicate scholastic priorities\n  - \"Unaccountable lack of hands-on experience\"\n  - No capability for empirical testing\n  - Privileging of well-formatted academic sources\n- **Dwarkesh's question**: Why LLMs with \"entire corpus\" make no new connections (Tabarrok citation)\n- **Our answer**: Technoscholasticism prevents genuine insight despite data access",
            "version_uuid": "2a963e55-41b3-4848-b478-941596f4316d"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "ff5127cb-f7fa-44d9-a87b-28d9b249aefa"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T07:07:02.998934Z",
          "stop_timestamp": "2025-03-15T07:07:03.406790Z",
          "flags": null,
          "type": "text",
          "text": "\n\n\n\nThe outline now explicitly positions \"technoscholasticism\" as an original theoretical contribution of the paper. With this update, shall I proceed with drafting the full introduction?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T07:07:03.529479Z",
      "updated_at": "2025-03-15T07:07:03.529479Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "c13fc35e-adf5-4643-b32c-f8e2be8a6d4d",
      "text": "well, the reference to lines is his paraphrase of whitehead. \n\nIn his SEP article he says:\n> Lohr\u2019s repertories of Aristotle commentators showed that, far from disappearing, Aristotelian works were the subject of renewed interest in the Renaissance, such that\nthe number of Latin commentaries on Aristotle composed within this brief period [1500\u20131650] exceeds that of the entire millennium from Boethius to Pomponazzi. (Lohr 1974: 228)\n\nWe could treat Deep Research as \"commentaries on authoritative-looking texts online\" ? Or is that pushing it. \n\nYour \"our answer\" is wrong.\n\nWe can say that \"Deep Research\" style tool-use will not produce a useful answer to Dwarkesh's question because the generation of new knowledge is seldom a matter of \"Stamp Collecting\" (Remind me to double check \"Natural history as stamp collecting: a brief history\" to see about this discussion of Rutherford's quote -- I've requested it as ILL, so it'll need to be in a different session. put it in as a TODO) But even in the place where an \"answer\" can be synthesized through the juxtaposition of extant knowledge, being able to assert an answer that has any correspondence with \"The Real\" requires more than a techno-scholasticism. (Should this be hyphenated?) \n\nThus, connections are not merely collecting enough stamps until a correlation is obvious, but *noticing* (there's that induction problem) that there are parallels, and judging which parallels are apt, and which are without worth. Because LLMs default to deference to authority, asserting a thing is wrong, or having the fundamental insight needed to assert a connection (absent prodding a human meat-bag to have that insight) is not a feature of current capabilities.",
      "content": [
        {
          "start_timestamp": "2025-03-14T21:49:40.580892Z",
          "stop_timestamp": "2025-03-14T21:49:40.580892Z",
          "flags": null,
          "type": "text",
          "text": "well, the reference to lines is his paraphrase of whitehead. \n\nIn his SEP article he says:\n> Lohr\u2019s repertories of Aristotle commentators showed that, far from disappearing, Aristotelian works were the subject of renewed interest in the Renaissance, such that\nthe number of Latin commentaries on Aristotle composed within this brief period [1500\u20131650] exceeds that of the entire millennium from Boethius to Pomponazzi. (Lohr 1974: 228)\n\nWe could treat Deep Research as \"commentaries on authoritative-looking texts online\" ? Or is that pushing it. \n\nYour \"our answer\" is wrong.\n\nWe can say that \"Deep Research\" style tool-use will not produce a useful answer to Dwarkesh's question because the generation of new knowledge is seldom a matter of \"Stamp Collecting\" (Remind me to double check \"Natural history as stamp collecting: a brief history\" to see about this discussion of Rutherford's quote -- I've requested it as ILL, so it'll need to be in a different session. put it in as a TODO) But even in the place where an \"answer\" can be synthesized through the juxtaposition of extant knowledge, being able to assert an answer that has any correspondence with \"The Real\" requires more than a techno-scholasticism. (Should this be hyphenated?) \n\nThus, connections are not merely collecting enough stamps until a correlation is obvious, but *noticing* (there's that induction problem) that there are parallels, and judging which parallels are apt, and which are without worth. Because LLMs default to deference to authority, asserting a thing is wrong, or having the fundamental insight needed to assert a connection (absent prodding a human meat-bag to have that insight) is not a feature of current capabilities.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T07:19:43.878219Z",
      "updated_at": "2025-03-15T07:19:43.878219Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "f9da5038-f6d5-40c2-bc4c-08ff9d08f488",
      "text": "\nThis is a useful clarification from the author. Let me revise my understanding:\n\n1. The reference to Lines is specifically about his citation of Lohr regarding the proliferation of Aristotelian commentaries in the Renaissance. This could indeed provide a parallel to how AI tools like Deep Research essentially produce \"commentaries on authoritative-looking texts online\" rather than original insights.\n\n2. The \"our answer\" point needs revision. The author clarifies that:\n   - Knowledge generation isn't just \"stamp collecting\" (juxtaposing existing knowledge)\n   - Even when synthesizing existing knowledge, correspondence with reality (\"The Real\") requires more than technoscholasticism\n   - The key problems are:\n     - Noticing parallels (induction)\n     - Judging which parallels are valuable\n     - Challenging authority when needed\n   - LLMs defer to authority rather than challenging it, preventing genuine insight\n\n3. There's a question about hyphenation of \"technoscholasticism\" vs. \"techno-scholasticism\" - I should note this for consistency.\n\nI should revise the outline accordingly, especially the \"our answer\" section about Dwarkesh's question, emphasizing that knowledge generation requires more than collecting enough information to see correlations - it requires the judgment to notice meaningful patterns and challenge authority when needed.\n\nThank you for these important clarifications. You're right that the reference to Lines is about his citation of Lohr on Aristotelian commentaries - that's a much more apt parallel to how AI tools produce what are essentially commentaries on \"authoritative-looking texts\" without original insights.\n\nI'll correct the \"our answer\" point and incorporate your insightful explanation about knowledge generation requiring more than \"stamp collecting.\" I appreciate the distinction that noticing meaningful patterns requires judgment that LLMs fundamentally lack.\n\nLet me update the outline:\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\n\n\nThe outline is updated with your clarifications. Regarding the hyphenation question: my recommendation would be \"technoscholasticism\" without the hyphen, as it gives the term more coherence as a single concept rather than suggesting two separate domains being connected. However, I can use whichever form you prefer.\n\nWould you like me to proceed with drafting the introduction based on this revised outline?",
      "content": [
        {
          "start_timestamp": "2025-03-15T07:19:45.064778Z",
          "stop_timestamp": "2025-03-15T07:19:49.146946Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nThis is a useful clarification from the author. Let me revise my understanding:\n\n1. The reference to Lines is specifically about his citation of Lohr regarding the proliferation of Aristotelian commentaries in the Renaissance. This could indeed provide a parallel to how AI tools like Deep Research essentially produce \"commentaries on authoritative-looking texts online\" rather than original insights.\n\n2. The \"our answer\" point needs revision. The author clarifies that:\n   - Knowledge generation isn't just \"stamp collecting\" (juxtaposing existing knowledge)\n   - Even when synthesizing existing knowledge, correspondence with reality (\"The Real\") requires more than technoscholasticism\n   - The key problems are:\n     - Noticing parallels (induction)\n     - Judging which parallels are valuable\n     - Challenging authority when needed\n   - LLMs defer to authority rather than challenging it, preventing genuine insight\n\n3. There's a question about hyphenation of \"technoscholasticism\" vs. \"techno-scholasticism\" - I should note this for consistency.\n\nI should revise the outline accordingly, especially the \"our answer\" section about Dwarkesh's question, emphasizing that knowledge generation requires more than collecting enough information to see correlations - it requires the judgment to notice meaningful patterns and challenge authority when needed.",
          "summaries": [
            {
              "summary": "Parsing citation's relevance to Aristotelian commentary proliferation"
            },
            {
              "summary": "Scrutinized knowledge generation limits in AI research tools."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T07:19:49.327725Z",
          "stop_timestamp": "2025-03-15T07:19:50.785789Z",
          "flags": null,
          "type": "text",
          "text": "\n\nThank you for these important clarifications. You're right that the reference to Lines is about his citation of Lohr on Aristotelian commentaries - that's a much more apt parallel to how AI tools produce what are essentially commentaries on \"authoritative-looking texts\" without original insights.\n\nI'll correct the \"our answer\" point and incorporate your insightful explanation about knowledge generation requiring more than \"stamp collecting.\" I appreciate the distinction that noticing meaningful patterns requires judgment that LLMs fundamentally lack.\n\nLet me update the outline:",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T07:19:51.027852Z",
          "stop_timestamp": "2025-03-15T07:19:53.932842Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "command": "update",
            "new_str": "- **Reference to Lines/Lohr**: Parallel between Renaissance Aristotelian commentaries and AI \"commentaries on authoritative-looking texts\"\n- **Dwarkesh's question**: Why LLMs with \"entire corpus\" make no new connections (Tabarrok citation)\n- **Our answer**: \n  - Knowledge generation isn't mere \"stamp collecting\" (Rutherford reference - TODO)\n  - Requires *noticing* parallels (induction) and judging which are meaningful\n  - LLMs' deference to authority prevents challenging established views\n  - Correspondence with \"The Real\" requires judgment beyond techno(-)scholasticism\n  - Note on hyphenation question: technoscholasticism vs. techno-scholasticism",
            "old_str": "- **Reference to Lines' work**: Building on scholarly tradition while introducing new framework\n- **Dwarkesh's question**: Why LLMs with \"entire corpus\" make no new connections (Tabarrok citation)\n- **Our answer**: Technoscholasticism prevents genuine insight despite data access",
            "version_uuid": "138644d9-4eac-495f-a016-a6cf39d18c66"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "a1705b86-ff0f-4138-a630-48ad5552fc9c"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T07:19:58.315317Z",
          "stop_timestamp": "2025-03-15T07:19:59.560078Z",
          "flags": null,
          "type": "text",
          "text": "\n\n\n\nThe outline is updated with your clarifications. Regarding the hyphenation question: my recommendation would be \"technoscholasticism\" without the hyphen, as it gives the term more coherence as a single concept rather than suggesting two separate domains being connected. However, I can use whichever form you prefer.\n\nWould you like me to proceed with drafting the introduction based on this revised outline?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T07:20:00.239119Z",
      "updated_at": "2025-03-15T07:20:00.239119Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "03148cb5-497f-4be8-a519-126f13a91966",
      "text": "great, no hyphen. Nice long words. (Remove the note on the hyphenation question since that's not a problem for the paper)\n\nWhat do you mean by: \"Analysis through technoscholastic framework\" ? And we should work on that paper structure. Signposting is not merely reproducing the headers. Maybe leave that as a TODO once we write the rest?",
      "content": [
        {
          "start_timestamp": "2025-03-15T01:43:07.434863Z",
          "stop_timestamp": "2025-03-15T01:43:07.434863Z",
          "flags": null,
          "type": "text",
          "text": "great, no hyphen. Nice long words. (Remove the note on the hyphenation question since that's not a problem for the paper)\n\nWhat do you mean by: \"Analysis through technoscholastic framework\" ? And we should work on that paper structure. Signposting is not merely reproducing the headers. Maybe leave that as a TODO once we write the rest?",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T07:21:47.416888Z",
      "updated_at": "2025-03-15T07:21:47.416888Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "bae926a1-a208-4495-b9bc-828a2ea4d7bc",
      "text": "\nLet me address these points:\n\n1. No hyphen in \"technoscholasticism\" - I'll use this throughout\n2. Remove note about hyphenation from outline - will do\n3. \"Analysis through technoscholastic framework\" is unclear - need to clarify and be more specific\n4. Paper structure signposting needs work - should be more than repeating headers\n5. We might want to leave the specific signposting as a TODO until the rest is written\n\nFor the \"Analysis through technoscholastic framework\" point, I should be more specific about what I mean. I intended to convey that we'll analyze the findings from our tool evaluations through the lens of the technoscholasticism concept we're introducing. This would involve examining how the observed behaviors of AI research tools demonstrate the prioritization of textual authority over empirical verification, the inability to question sources based on real-world correspondence, etc. \n\nA better way to phrase this might be: \"Interpretation of AI tool behaviors through lens of technoscholasticism: identifying patterns of authority deference, lack of empirical verification, etc.\"\n\nFor the paper structure signposting, I agree that simply listing section titles is not effective. Good signposting should give readers a sense of the paper's narrative arc, how arguments build on each other, and what to expect from each section. I'll update both of these points in the outline.\n\nYou're right on both counts. Let me make those adjustments:\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\n\n\n\n\nThe outline is now updated with your specifications. I've:\n\n1. Removed the hyphenation question note\n2. Clarified that we're interpreting findings through the lens of technoscholasticism in more specific terms\n3. Added a TODO for developing more meaningful signposting after other sections are drafted\n\nAre there any other adjustments needed before I proceed with drafting the introduction based on this outline?",
      "content": [
        {
          "start_timestamp": "2025-03-15T07:21:49.273864Z",
          "stop_timestamp": "2025-03-15T07:21:53.951641Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nLet me address these points:\n\n1. No hyphen in \"technoscholasticism\" - I'll use this throughout\n2. Remove note about hyphenation from outline - will do\n3. \"Analysis through technoscholastic framework\" is unclear - need to clarify and be more specific\n4. Paper structure signposting needs work - should be more than repeating headers\n5. We might want to leave the specific signposting as a TODO until the rest is written\n\nFor the \"Analysis through technoscholastic framework\" point, I should be more specific about what I mean. I intended to convey that we'll analyze the findings from our tool evaluations through the lens of the technoscholasticism concept we're introducing. This would involve examining how the observed behaviors of AI research tools demonstrate the prioritization of textual authority over empirical verification, the inability to question sources based on real-world correspondence, etc. \n\nA better way to phrase this might be: \"Interpretation of AI tool behaviors through lens of technoscholasticism: identifying patterns of authority deference, lack of empirical verification, etc.\"\n\nFor the paper structure signposting, I agree that simply listing section titles is not effective. Good signposting should give readers a sense of the paper's narrative arc, how arguments build on each other, and what to expect from each section. I'll update both of these points in the outline.",
          "summaries": [
            {
              "summary": "Clarifying analysis framework and paper structure signposting"
            },
            {
              "summary": "Refined paper structure and clarified technoscholastic framework analysis."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T07:21:54.125319Z",
          "stop_timestamp": "2025-03-15T07:21:54.207231Z",
          "flags": null,
          "type": "text",
          "text": "\n\nYou're right on both counts. Let me make those adjustments:",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T07:21:54.402228Z",
          "stop_timestamp": "2025-03-15T07:22:00.349665Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "command": "update",
            "new_str": "## Paragraph 4: Research Approach and Paper Organization (~200 words)\n- **Methodological approach**: Autoethnographic investigation\n  - Case studies with frontier models (February 2025)\n  - Direct testing of research capabilities\n  - Interpretation of findings through technoscholasticism lens: identifying patterns of authority deference, lack of empirical verification\n- **Research questions**:\n  - How do LLMs perform on insight-requiring vs. descriptive tasks?\n  - What is the mundane utility despite limitations?\n  - How should tools be designed to complement human judgment?\n- **Paper structure**: \n  - [TODO: Develop more meaningful signposting that conveys argument progression rather than just section titles. To be finalized after drafting other sections.]\n- **Key contribution**: Framework for understanding AI limitations and appropriate use cases",
            "old_str": "## Paragraph 4: Research Approach and Paper Organization (~200 words)\n- **Methodological approach**: Autoethnographic investigation\n  - Case studies with frontier models (February 2025)\n  - Direct testing of research capabilities\n  - Analysis through technoscholastic framework\n- **Research questions**:\n  - How do LLMs perform on insight-requiring vs. descriptive tasks?\n  - What is the mundane utility despite limitations?\n  - How should tools be designed to complement human judgment?\n- **Paper structure**:\n  - Section 2: Theoretical framework on judgment and research\n  - Section 3: Methodology for tool evaluation\n  - Section 4: Case studies of AI research tools\n  - Section 5: Analysis through technoscholastic lens\n  - Section 6: Requirements for judgment-aware research tools\n  - Section 7: Conclusion and implications\n- **Key contribution**: Framework for understanding AI limitations and appropriate use cases",
            "version_uuid": "6f8e2a19-6c30-4d62-a2ae-d10cffb67acc"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "4f0a3df3-4dd2-4649-960c-53720f2b42b1"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T07:22:04.627331Z",
          "stop_timestamp": "2025-03-15T07:22:04.627331Z",
          "flags": null,
          "type": "text",
          "text": "\n\n",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T07:22:04.808934Z",
          "stop_timestamp": "2025-03-15T07:22:09.838783Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "command": "update",
            "new_str": "- **Dwarkesh's question**: Why LLMs with \"entire corpus\" make no new connections (Tabarrok citation)\n- **Our answer**: \n  - Knowledge generation isn't mere \"stamp collecting\" (Rutherford reference - TODO)\n  - Requires *noticing* parallels (induction) and judging which are meaningful\n  - LLMs' deference to authority prevents challenging established views\n  - Correspondence with \"The Real\" requires judgment beyond technoscholasticism",
            "old_str": "- **Reference to Lines/Lohr**: Parallel between Renaissance Aristotelian commentaries and AI \"commentaries on authoritative-looking texts\"\n- **Dwarkesh's question**: Why LLMs with \"entire corpus\" make no new connections (Tabarrok citation)\n- **Our answer**: \n  - Knowledge generation isn't mere \"stamp collecting\" (Rutherford reference - TODO)\n  - Requires *noticing* parallels (induction) and judging which are meaningful\n  - LLMs' deference to authority prevents challenging established views\n  - Correspondence with \"The Real\" requires judgment beyond techno(-)scholasticism\n  - Note on hyphenation question: technoscholasticism vs. techno-scholasticism",
            "version_uuid": "20d7935a-9377-4007-8818-adcfcb2a9e05"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "3e97fecd-3e6f-4681-af01-8ba35b4b7315"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T07:22:13.250417Z",
          "stop_timestamp": "2025-03-15T07:22:14.563635Z",
          "flags": null,
          "type": "text",
          "text": "\n\n\n\n\n\nThe outline is now updated with your specifications. I've:\n\n1. Removed the hyphenation question note\n2. Clarified that we're interpreting findings through the lens of technoscholasticism in more specific terms\n3. Added a TODO for developing more meaningful signposting after other sections are drafted\n\nAre there any other adjustments needed before I proceed with drafting the introduction based on this outline?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T07:22:15.113517Z",
      "updated_at": "2025-03-15T07:22:15.113517Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "7ddb79db-253e-41f4-8fb4-0bb1f2dcd783",
      "text": "authority deference -- there's both a lack of self-critique, a lack of a common-sense \"Does this make sense?\" step. The \"no-hands\" problem is the bigger surrounding context. The problem is that even working at a document level, these things cannot critique the documents. They take the presence of the text (with appropriate markers of authenticity) as sufficient fact, instead of thinking about the context of the text, if it can know what it claims, if the knowledge is appropriate, and if it makes sense to advance those claims.",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:10:38.129982Z",
          "stop_timestamp": "2025-03-14T20:10:38.129982Z",
          "flags": null,
          "type": "text",
          "text": "authority deference -- there's both a lack of self-critique, a lack of a common-sense \"Does this make sense?\" step. The \"no-hands\" problem is the bigger surrounding context. The problem is that even working at a document level, these things cannot critique the documents. They take the presence of the text (with appropriate markers of authenticity) as sufficient fact, instead of thinking about the context of the text, if it can know what it claims, if the knowledge is appropriate, and if it makes sense to advance those claims.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T07:24:49.556701Z",
      "updated_at": "2025-03-15T07:24:49.556701Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "48b2bd11-d0e2-4ef5-9b99-70283b80b962",
      "text": "\nYou've raised an important dimension of the technoscholasticism issue that I should incorporate into the outline - the fundamental inability of LLMs to apply a critical \"does this make sense?\" filter to texts they encounter. This goes beyond simple authority deference to a more fundamental epistemological problem: they can't evaluate whether a text could possibly know what it claims to know or whether its claims align with physical reality.\n\nThis is indeed the \"no-hands\" problem in a deeper sense - not just that they lack physical experience, but that this lack means they cannot evaluate texts against lived experience or practical knowledge. I should update the outline to reflect this more nuanced understanding of the critique.\n\nYou've highlighted a critical point about the deeper epistemological issue. Let me update the outline to better capture this fundamental limitation:\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\nDoes this better capture the deeper epistemological critique you're making? This highlights that the issue goes beyond simple authority deference to a more fundamental inability to evaluate whether a source could possibly know what it claims to know, or to apply a basic reality check to the claims it encounters.",
      "content": [
        {
          "start_timestamp": "2025-03-15T07:24:51.239384Z",
          "stop_timestamp": "2025-03-15T07:24:53.630487Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nYou've raised an important dimension of the technoscholasticism issue that I should incorporate into the outline - the fundamental inability of LLMs to apply a critical \"does this make sense?\" filter to texts they encounter. This goes beyond simple authority deference to a more fundamental epistemological problem: they can't evaluate whether a text could possibly know what it claims to know or whether its claims align with physical reality.\n\nThis is indeed the \"no-hands\" problem in a deeper sense - not just that they lack physical experience, but that this lack means they cannot evaluate texts against lived experience or practical knowledge. I should update the outline to reflect this more nuanced understanding of the critique.",
          "summaries": [
            {
              "summary": "Probing LLM's critical thinking limitations and textual analysis"
            },
            {
              "summary": "Probed AI's critical thinking limitations in knowledge processing."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T07:24:53.867908Z",
          "stop_timestamp": "2025-03-15T07:24:54.042878Z",
          "flags": null,
          "type": "text",
          "text": "\n\nYou've highlighted a critical point about the deeper epistemological issue. Let me update the outline to better capture this fundamental limitation:",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T07:24:54.288714Z",
          "stop_timestamp": "2025-03-15T07:24:58.470055Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "command": "update",
            "new_str": "## Paragraph 4: Research Approach and Paper Organization (~200 words)\n- **Methodological approach**: Autoethnographic investigation\n  - Case studies with frontier models (February 2025)\n  - Direct testing of research capabilities\n  - Interpretation of findings through technoscholasticism lens: \n    - Beyond simple authority deference\n    - Inability to apply \"does this make sense?\" filter to texts\n    - Cannot evaluate if sources could possibly know what they claim to know\n    - No capacity to judge claims against experiential knowledge\n    - Fundamental epistemological limitations from the \"no-hands\" problem\n- **Research questions**:\n  - How do LLMs perform on insight-requiring vs. descriptive tasks?\n  - What is the mundane utility despite limitations?\n  - How should tools be designed to complement human judgment?\n- **Paper structure**: \n  - [TODO: Develop more meaningful signposting that conveys argument progression rather than just section titles. To be finalized after drafting other sections.]\n- **Key contribution**: Framework for understanding AI limitations and appropriate use cases",
            "old_str": "## Paragraph 4: Research Approach and Paper Organization (~200 words)\n- **Methodological approach**: Autoethnographic investigation\n  - Case studies with frontier models (February 2025)\n  - Direct testing of research capabilities\n  - Interpretation of findings through technoscholasticism lens: identifying patterns of authority deference, lack of empirical verification\n- **Research questions**:\n  - How do LLMs perform on insight-requiring vs. descriptive tasks?\n  - What is the mundane utility despite limitations?\n  - How should tools be designed to complement human judgment?\n- **Paper structure**: \n  - [TODO: Develop more meaningful signposting that conveys argument progression rather than just section titles. To be finalized after drafting other sections.]\n- **Key contribution**: Framework for understanding AI limitations and appropriate use cases",
            "version_uuid": "61bac6c6-ed94-4561-93f9-b02d924509a0"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "483012ad-b65f-4edf-9995-88f724e8b2c3"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T07:25:02.231295Z",
          "stop_timestamp": "2025-03-15T07:25:03.279986Z",
          "flags": null,
          "type": "text",
          "text": "\n\nDoes this better capture the deeper epistemological critique you're making? This highlights that the issue goes beyond simple authority deference to a more fundamental inability to evaluate whether a source could possibly know what it claims to know, or to apply a basic reality check to the claims it encounters.",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T07:25:03.413911Z",
      "updated_at": "2025-03-15T07:25:03.413911Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "9c36ebea-9eb9-445d-b301-ba808688d612",
      "text": "Talk to me about what you mean about Zvi's \"distinction setup?\" He makes the point that we can focus on mundane utility/lack of mundane utility as a local focus, while setting aside these larger questions. I don't get that from \"Tool utility v agency\"\n\nFrom a larger perspective, do we have my rant against agency anywhere? If we set it up in the intro, we'll need to have my \"This is why these things aren't agents\" as a section.",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:11:09.226754Z",
          "stop_timestamp": "2025-03-14T20:11:09.226754Z",
          "flags": null,
          "type": "text",
          "text": "Talk to me about what you mean about Zvi's \"distinction setup?\" He makes the point that we can focus on mundane utility/lack of mundane utility as a local focus, while setting aside these larger questions. I don't get that from \"Tool utility v agency\"\n\nFrom a larger perspective, do we have my rant against agency anywhere? If we set it up in the intro, we'll need to have my \"This is why these things aren't agents\" as a section.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T07:26:55.839403Z",
      "updated_at": "2025-03-15T07:26:55.839403Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "562c968c-945e-46a0-b42e-a9d5dcd3ba64",
      "text": "\nYou're right - my characterization of Zvi's \"mundane utility\" concept wasn't precise. Looking back at the quote you provided:\n\n> Using existing AI for mundane utility is not something I would worry about the 'badness' of, if you want some AI art or AI coding or writing or search help then go for it.\n\nZvi's point is about separating the pragmatic, everyday uses of AI (mundane utility) from larger existential or ethical concerns. It's not setting up a tool vs. agency distinction directly, but rather suggesting we can focus on practical applications while setting aside bigger questions.\n\nRegarding your rant against agency, I don't see that explicitly laid out in the materials you've shared, though there are elements of this critique throughout your transcripts. In the Systems \u2013 Friday at 8:16 am transcript, you discuss this:\n\n\"Large language models at present even with 'reasoning' capabilities are not agentic systems... Because even though they can perform a deductive task decomposition, the fact that they cannot effectively exercise judgment... nor are they able to assess the quality of their own inference.\"\n\nIf you want to set up the agency critique in the introduction, we should indeed plan for a more detailed section on why these systems aren't agents. This would involve fleshing out your points about judgment, evaluation of goals, self-assessment, and the distinction between task decomposition and true agency.\n\nYou're absolutely right to question this. My characterization of Zvi's \"mundane utility\" concept wasn't accurate in the outline. \n\nWhat Zvi is actually doing is separating practical, everyday applications of AI (\"mundane utility\") from larger existential or ethical concerns - not making a distinction between tools and agents. His point is that we can focus on practical applications while setting aside bigger questions about AI's impact.\n\nRegarding your critique of agency claims, I don't see a comprehensive \"rant against agency\" in the materials you've shared, though elements appear throughout your transcripts (particularly in Systems - Friday 8:16 am where you discuss how LLMs with \"reasoning\" capabilities aren't truly agentic despite their task decomposition abilities).\n\nIf you want to establish this critique in the introduction, we should definitely plan for a dedicated section that develops the argument about why these systems aren't agents. Should we:\n\n1. Adjust the introduction to set up this critique more explicitly?\n2. Add a separate section specifically addressing the agency question?\n3. Both?\n\nThis would help frame the technoscholasticism concept as part of a broader critique of mischaracterized agency.",
      "content": [
        {
          "start_timestamp": "2025-03-15T07:26:57.440283Z",
          "stop_timestamp": "2025-03-15T07:27:03.641702Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nYou're right - my characterization of Zvi's \"mundane utility\" concept wasn't precise. Looking back at the quote you provided:\n\n> Using existing AI for mundane utility is not something I would worry about the 'badness' of, if you want some AI art or AI coding or writing or search help then go for it.\n\nZvi's point is about separating the pragmatic, everyday uses of AI (mundane utility) from larger existential or ethical concerns. It's not setting up a tool vs. agency distinction directly, but rather suggesting we can focus on practical applications while setting aside bigger questions.\n\nRegarding your rant against agency, I don't see that explicitly laid out in the materials you've shared, though there are elements of this critique throughout your transcripts. In the Systems \u2013 Friday at 8:16 am transcript, you discuss this:\n\n\"Large language models at present even with 'reasoning' capabilities are not agentic systems... Because even though they can perform a deductive task decomposition, the fact that they cannot effectively exercise judgment... nor are they able to assess the quality of their own inference.\"\n\nIf you want to set up the agency critique in the introduction, we should indeed plan for a more detailed section on why these systems aren't agents. This would involve fleshing out your points about judgment, evaluation of goals, self-assessment, and the distinction between task decomposition and true agency.",
          "summaries": [
            {
              "summary": "Refining understanding of Zvi's \"mundane utility\" concept"
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T07:27:03.881958Z",
          "stop_timestamp": "2025-03-15T07:27:07.245953Z",
          "flags": null,
          "type": "text",
          "text": "\n\nYou're absolutely right to question this. My characterization of Zvi's \"mundane utility\" concept wasn't accurate in the outline. \n\nWhat Zvi is actually doing is separating practical, everyday applications of AI (\"mundane utility\") from larger existential or ethical concerns - not making a distinction between tools and agents. His point is that we can focus on practical applications while setting aside bigger questions about AI's impact.\n\nRegarding your critique of agency claims, I don't see a comprehensive \"rant against agency\" in the materials you've shared, though elements appear throughout your transcripts (particularly in Systems - Friday 8:16 am where you discuss how LLMs with \"reasoning\" capabilities aren't truly agentic despite their task decomposition abilities).\n\nIf you want to establish this critique in the introduction, we should definitely plan for a dedicated section that develops the argument about why these systems aren't agents. Should we:\n\n1. Adjust the introduction to set up this critique more explicitly?\n2. Add a separate section specifically addressing the agency question?\n3. Both?\n\nThis would help frame the technoscholasticism concept as part of a broader critique of mischaracterized agency.",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T07:27:10.264086Z",
      "updated_at": "2025-03-15T07:27:10.264086Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "238deeed-b260-4c85-89f9-c49da1cc9f91",
      "text": "So, here's my \"This is why the term agentic is a problem\" outline. \n\n#\u00a0 \"Agentic\" Systems vs Normal Software\n## Goal-Related Characteristics\n1. Goal Following vs Goal Setting\n\u00a0 \u00a0- Agentic systems are goal-following systems\n\u00a0 \u00a0- This contrasts with AGI, which can set its own goals\n\u00a0 \u00a0- Key distinction: Agentic systems require external input for goals\n## Agentic Characteristics\n1. Goal Processing Capabilities\n\u00a0 \u00a0- Accept external goals as input\n\u00a0 \u00a0- Collaborate with users to operationalize goals\n\u00a0 \u00a0- Functionally decompose goals into manageable components\n2. Execution Capabilities\n\u00a0 \u00a0- Create plans for goal completion\n\u00a0 \u00a0- Invoke appropriate software and APIs\n\u00a0 \u00a0- Monitor and assess progress\n3. Assessment and Reporting\n\u00a0 \u00a0- Make judgments about goal completion\n\u00a0 \u00a0- Provide reports to users (like Claude)\n\u00a0 \u00a0- Include success/failure evaluation based on system's judgment\n\n\nSpecifically, these tool-calling LLMs are *not* agentic. They do not have the judgement needed to decide if they have *achieved a goal* nor the judgement needed to assess if a task decomposition is appropriate for achieving a goal.",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:11:09.548440Z",
          "stop_timestamp": "2025-03-14T20:11:09.548440Z",
          "flags": null,
          "type": "text",
          "text": "So, here's my \"This is why the term agentic is a problem\" outline. \n\n#\u00a0 \"Agentic\" Systems vs Normal Software\n## Goal-Related Characteristics\n1. Goal Following vs Goal Setting\n\u00a0 \u00a0- Agentic systems are goal-following systems\n\u00a0 \u00a0- This contrasts with AGI, which can set its own goals\n\u00a0 \u00a0- Key distinction: Agentic systems require external input for goals\n## Agentic Characteristics\n1. Goal Processing Capabilities\n\u00a0 \u00a0- Accept external goals as input\n\u00a0 \u00a0- Collaborate with users to operationalize goals\n\u00a0 \u00a0- Functionally decompose goals into manageable components\n2. Execution Capabilities\n\u00a0 \u00a0- Create plans for goal completion\n\u00a0 \u00a0- Invoke appropriate software and APIs\n\u00a0 \u00a0- Monitor and assess progress\n3. Assessment and Reporting\n\u00a0 \u00a0- Make judgments about goal completion\n\u00a0 \u00a0- Provide reports to users (like Claude)\n\u00a0 \u00a0- Include success/failure evaluation based on system's judgment\n\n\nSpecifically, these tool-calling LLMs are *not* agentic. They do not have the judgement needed to decide if they have *achieved a goal* nor the judgement needed to assess if a task decomposition is appropriate for achieving a goal.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T07:28:48.509908Z",
      "updated_at": "2025-03-15T07:28:48.509908Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "fac5663e-b8db-4d9e-a955-69b7368a6c6e",
      "text": "\nThis is really important context. You've provided a clear outline of why these systems aren't truly agentic, focusing on:\n\n1. They lack true goal-following capability (while they can decompose tasks, they cannot judge if the decomposition is appropriate)\n2. They cannot make legitimate judgments about whether they've completed goals\n3. They lack the capability for meaningful self-assessment\n\nThis clarifies your position that tool-calling LLMs are fundamentally not agentic, despite marketing claims. This is directly relevant to the introduction where we need to challenge OpenAI's \"agentic capability\" claims.\n\nI should update our introduction outline to:\n1. More explicitly incorporate this critique of \"agentic\" systems\n2. Make it clear that technoscholasticism is partly a consequence of this lack of agency\n3. Show how the paper will systematically dismantle these claims\n\nThis represents a significant element of your argument that should feature prominently in the introduction.\n\nThank you for sharing this outline - it's a crucial component of your argument that should definitely be addressed in the paper. Now I understand your position much more clearly: these systems aren't truly agentic because they fundamentally lack the judgment required for goal assessment and appropriate task decomposition.\n\nLet me revise the introduction outline to incorporate this critique:\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\n\n\n\n\n\nI've revised the introduction outline to properly incorporate your critique of agency claims. Now in the introduction, we'll:\n\n1. Start by directly challenging OpenAI's \"agentic capability\" claims\n2. Present Zvi's \"mundane utility\" concept more accurately as allowing focus on practical applications while setting aside larger questions\n3. Explicitly outline why these systems lack true agency (can't assess goal achievement, can't evaluate task appropriateness, etc.)\n4. Connect this lack of agency to the technoscholasticism concept \n\nWith these revisions, the introduction will more accurately set up your key arguments. Does this better reflect your position on agency and its relation to the rest of your critique?",
      "content": [
        {
          "start_timestamp": "2025-03-15T07:28:49.684356Z",
          "stop_timestamp": "2025-03-15T07:28:52.684210Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nThis is really important context. You've provided a clear outline of why these systems aren't truly agentic, focusing on:\n\n1. They lack true goal-following capability (while they can decompose tasks, they cannot judge if the decomposition is appropriate)\n2. They cannot make legitimate judgments about whether they've completed goals\n3. They lack the capability for meaningful self-assessment\n\nThis clarifies your position that tool-calling LLMs are fundamentally not agentic, despite marketing claims. This is directly relevant to the introduction where we need to challenge OpenAI's \"agentic capability\" claims.\n\nI should update our introduction outline to:\n1. More explicitly incorporate this critique of \"agentic\" systems\n2. Make it clear that technoscholasticism is partly a consequence of this lack of agency\n3. Show how the paper will systematically dismantle these claims\n\nThis represents a significant element of your argument that should feature prominently in the introduction.",
          "summaries": [
            {
              "summary": "Thinking about characterizing agentic systems versus traditional software tools"
            },
            {
              "summary": "Probing system's goal-following and judgment limitations"
            },
            {
              "summary": "Scrutinized AI agency claims and refined introduction strategy."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T07:28:52.771828Z",
          "stop_timestamp": "2025-03-15T07:28:53.819474Z",
          "flags": null,
          "type": "text",
          "text": "\n\nThank you for sharing this outline - it's a crucial component of your argument that should definitely be addressed in the paper. Now I understand your position much more clearly: these systems aren't truly agentic because they fundamentally lack the judgment required for goal assessment and appropriate task decomposition.\n\nLet me revise the introduction outline to incorporate this critique:",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T07:28:54.103315Z",
          "stop_timestamp": "2025-03-15T07:28:58.268642Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "command": "update",
            "new_str": "## Paragraph 1: Hook and Problem Statement (~150 words)\n- **Opening hook**: Condensed OpenAI quote about Deep Research's \"agentic capability\" claims\n- **Problem identification**: Gap between linguistic performance and actual capabilities\n- **Critical challenge**: These systems are fundamentally not agentic despite marketing claims\n- **Specific issue**: \"Research\" requires judgment that these systems lack\n- **Stakes**: Misunderstanding capabilities leads to misuse and disappointment\n- **Zvi's concept**: Focus on \"mundane utility\" (Mowshowitz) while setting aside larger questions\n- **Transition**: While not agents, they may still offer practical applications",
            "old_str": "## Paragraph 1: Hook and Problem Statement (~150 words)\n- **Opening hook**: Condensed OpenAI quote about Deep Research's \"agentic capability\" claims\n- **Problem identification**: Gap between linguistic performance and actual capabilities\n- **Specific issue**: These systems claim to conduct \"research\" but lack crucial components\n- **Stakes**: Misunderstanding capabilities leads to misuse and disappointment\n- **Distinction setup**: Tool utility vs. agency (Mowshowitz's \"mundane utility\" concept)\n- **Transition**: While not agents, they may still offer utility as tools",
            "version_uuid": "fc612229-f960-47a8-814a-c2179bad124e"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "3048a253-ad1d-4b16-9632-bc313de36c49"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T07:29:02.623639Z",
          "stop_timestamp": "2025-03-15T07:29:02.623639Z",
          "flags": null,
          "type": "text",
          "text": "\n\n\n",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T07:29:02.852998Z",
          "stop_timestamp": "2025-03-15T07:29:08.521403Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "command": "update",
            "new_str": "## Paragraph 2: Central Thesis (~200 words)\n- **Primary claim**: LLMs fundamentally lack judgment despite mimicking its language\n- **Critique of \"agentic\" claims**: \n  - Cannot assess if they've achieved goals\n  - Cannot evaluate if task decomposition is appropriate\n  - Lack true goal-following capability despite appearances\n  - Missing critical self-assessment capabilities\n- **Definition of judgment**: Ability to critically evaluate sources, methods, and conclusions\n- **Three aspects**: Epistemic humility, inductive capacity, correspondence with reality\n- **Technoscholasticism introduction**: \n  - Tool-using LLMs adhere to technoscholastic worldview\n  - Privileging textual authority over empirical faithfulness\n  - Quality of source determined by textual elements, not real-world correspondence\n  - Preference for heavily cited authorities regardless of accuracy\n  - Default to most common answers (authorities) in training data\n- **Consequences**: This explains failure to generate novel insights from existing knowledge",
            "old_str": "## Paragraph 2: Central Thesis (~200 words)\n- **Primary claim**: LLMs fundamentally lack judgment despite mimicking its language\n- **Definition of judgment**: Ability to critically evaluate sources, methods, and conclusions\n- **Three aspects**: Epistemic humility, inductive capacity, correspondence with reality\n- **Technoscholasticism introduction**: \n  - LLM-driven tools adhere to technoscholastic worldview\n  - Privileging textual authority over empirical faithfulness\n  - Quality of source determined by textual elements, not real-world correspondence\n  - Preference for heavily cited authorities regardless of accuracy\n  - Default to most common answers (authorities) in training data\n- **Consequences**: This explains failure to generate novel insights from existing knowledge",
            "version_uuid": "d807467b-e858-484e-b651-ec9ec2bb9a6e"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "36437068-b876-4ea3-83b0-f5779be4e0c0"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T07:29:11.824020Z",
          "stop_timestamp": "2025-03-15T07:29:14.135954Z",
          "flags": null,
          "type": "text",
          "text": "\n\n\n\n\n\n\nI've revised the introduction outline to properly incorporate your critique of agency claims. Now in the introduction, we'll:\n\n1. Start by directly challenging OpenAI's \"agentic capability\" claims\n2. Present Zvi's \"mundane utility\" concept more accurately as allowing focus on practical applications while setting aside larger questions\n3. Explicitly outline why these systems lack true agency (can't assess goal achievement, can't evaluate task appropriateness, etc.)\n4. Connect this lack of agency to the technoscholasticism concept \n\nWith these revisions, the introduction will more accurately set up your key arguments. Does this better reflect your position on agency and its relation to the rest of your critique?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T07:29:14.923909Z",
      "updated_at": "2025-03-15T07:29:14.923909Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "f3dee31a-a447-4754-b283-31049d20f21b",
      "text": "Great, we'll want to footnote Zvi, to make sure that we note that the larger questions are existentially important -- they are merely outside the scope of the paper. \n\nAlso \"verification\" is a problem -- (I'm a philosopher of science, so that's a major loaded word. I think I want to nod in a more Kuhn/Lakatos direction rather than Carnap/Popper positivism. So maybe \"A digital scholasticism that privileges textual authorities over critical assessment?\" (I don't love this, let's workshop this. I wonder if we could work in Lakatos' research programme in) \n\nThe research questions\nHow well can an LLM, using A Deep Research workflow assist in performing research?",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:14:15.289475Z",
          "stop_timestamp": "2025-03-14T20:14:15.289475Z",
          "flags": null,
          "type": "text",
          "text": "Great, we'll want to footnote Zvi, to make sure that we note that the larger questions are existentially important -- they are merely outside the scope of the paper. \n\nAlso \"verification\" is a problem -- (I'm a philosopher of science, so that's a major loaded word. I think I want to nod in a more Kuhn/Lakatos direction rather than Carnap/Popper positivism. So maybe \"A digital scholasticism that privileges textual authorities over critical assessment?\" (I don't love this, let's workshop this. I wonder if we could work in Lakatos' research programme in) \n\nThe research questions\nHow well can an LLM, using A Deep Research workflow assist in performing research?",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T07:34:06.181349Z",
      "updated_at": "2025-03-15T07:34:06.181349Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "c0221276-956c-4782-ae14-79a817edfd47",
      "text": "\nYou're making excellent points about terminology and framing. Let me address both issues:\n\n1. **On Zvi and \"larger questions\"**: Absolutely, we should acknowledge that Zvi's focus on \"mundane utility\" isn't dismissing the importance of existential concerns, but rather creating a space to discuss practical applications separately. A footnote would be perfect for this.\n\n2. **On \"verification\"**: I understand your concern with using verification terminology given its positivist connotations. Your philosophy of science background makes this important to get right. Let me explore some alternatives that align better with Kuhn/Lakatos:\n\n**Alternatives to \"privileges textual authority over empirical verification\":**\n\n- \"privileges textual authority over engagement with anomalies\" (Kuhnian)\n- \"privileges textual authority over research programme assessment\" (Lakatosian)\n- \"privileges textual authority over critical engagement with research programmes\"\n- \"privileges textual authority over confrontation with real-world problems\"\n- \"privileges textual authority over critical assessment of knowledge claims\"\n- \"privileges textual authority over detecting incommensurability between paradigms\"\n\nI think something in the Lakatosian direction might work well, as his concept of research programmes with their hard cores and protective belts offers a more nuanced view than simple verification. Perhaps:\n\n\"A digital scholasticism that privileges textual authorities over the critical assessment of competing research programmes\"\n\nOr more simply:\n\"A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims\"\n\n3. **Research question reformulation**: Your simplified version \"How well can an LLM, using A Deep Research workflow assist in performing research?\" is much clearer than my previous formulation.\n\nYou're absolutely right on both counts.\n\nFor Zvi's concept, a footnote is the perfect approach to acknowledge that existential questions are indeed important while maintaining our focus on practical applications.\n\nRegarding \"verification\" - I see why that's problematic given your philosophy of science background. The positivist connotations wouldn't align with your perspective. Let me suggest some Kuhn/Lakatos-inspired alternatives:\n\n- \"A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims\"\n- \"A digital scholasticism that privileges textual authorities over confrontation with anomalies\" (more Kuhnian)\n- \"A digital scholasticism that privileges textual authorities over engagement with competing research programmes\" (more Lakatosian)\n\nI particularly like the Lakatosian framing since it acknowledges that research involves evaluating competing explanatory frameworks rather than simple verification against facts.\n\nFor the research question, your simplified version is much clearer: \"How well can an LLM, using a Deep Research workflow, assist in performing research?\" We could also add a follow-up: \"What are the epistemological limitations of such assistance?\"",
      "content": [
        {
          "start_timestamp": "2025-03-15T07:34:07.479788Z",
          "stop_timestamp": "2025-03-15T07:34:12.569901Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nYou're making excellent points about terminology and framing. Let me address both issues:\n\n1. **On Zvi and \"larger questions\"**: Absolutely, we should acknowledge that Zvi's focus on \"mundane utility\" isn't dismissing the importance of existential concerns, but rather creating a space to discuss practical applications separately. A footnote would be perfect for this.\n\n2. **On \"verification\"**: I understand your concern with using verification terminology given its positivist connotations. Your philosophy of science background makes this important to get right. Let me explore some alternatives that align better with Kuhn/Lakatos:\n\n**Alternatives to \"privileges textual authority over empirical verification\":**\n\n- \"privileges textual authority over engagement with anomalies\" (Kuhnian)\n- \"privileges textual authority over research programme assessment\" (Lakatosian)\n- \"privileges textual authority over critical engagement with research programmes\"\n- \"privileges textual authority over confrontation with real-world problems\"\n- \"privileges textual authority over critical assessment of knowledge claims\"\n- \"privileges textual authority over detecting incommensurability between paradigms\"\n\nI think something in the Lakatosian direction might work well, as his concept of research programmes with their hard cores and protective belts offers a more nuanced view than simple verification. Perhaps:\n\n\"A digital scholasticism that privileges textual authorities over the critical assessment of competing research programmes\"\n\nOr more simply:\n\"A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims\"\n\n3. **Research question reformulation**: Your simplified version \"How well can an LLM, using A Deep Research workflow assist in performing research?\" is much clearer than my previous formulation.",
          "summaries": [
            {
              "summary": "Acknowledging Zvi's nuanced perspective on research scope"
            },
            {
              "summary": "Refined research terminology and conceptual framing for scholarly approach."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T07:34:12.708761Z",
          "stop_timestamp": "2025-03-15T07:34:16.161238Z",
          "flags": null,
          "type": "text",
          "text": "\n\nYou're absolutely right on both counts.\n\nFor Zvi's concept, a footnote is the perfect approach to acknowledge that existential questions are indeed important while maintaining our focus on practical applications.\n\nRegarding \"verification\" - I see why that's problematic given your philosophy of science background. The positivist connotations wouldn't align with your perspective. Let me suggest some Kuhn/Lakatos-inspired alternatives:\n\n- \"A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims\"\n- \"A digital scholasticism that privileges textual authorities over confrontation with anomalies\" (more Kuhnian)\n- \"A digital scholasticism that privileges textual authorities over engagement with competing research programmes\" (more Lakatosian)\n\nI particularly like the Lakatosian framing since it acknowledges that research involves evaluating competing explanatory frameworks rather than simple verification against facts.\n\nFor the research question, your simplified version is much clearer: \"How well can an LLM, using a Deep Research workflow, assist in performing research?\" We could also add a follow-up: \"What are the epistemological limitations of such assistance?\"",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T07:34:19.043442Z",
      "updated_at": "2025-03-15T07:34:19.043442Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "1e1aae55-2f51-43f3-821f-df80e9b964b1",
      "text": "\"A digital scholasticism that privileges textual authorities over engagement with competing research programmes\" (We'll need to footnote this though) And that's a good followup, which is then followed by the rest of the section.",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:10:47.527042Z",
          "stop_timestamp": "2025-03-14T20:10:47.527042Z",
          "flags": null,
          "type": "text",
          "text": "\"A digital scholasticism that privileges textual authorities over engagement with competing research programmes\" (We'll need to footnote this though) And that's a good followup, which is then followed by the rest of the section.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T07:35:15.442888Z",
      "updated_at": "2025-03-15T07:35:15.442888Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "7f5e57b4-9514-4a89-9c6d-cd00f6d2a768",
      "text": "\nI'll update the outline to incorporate these changes:\n\n1. Revise the definition of technoscholasticism to use the Lakatosian framing\n2. Note that we'll need a footnote for the research programme concept\n3. Update the research questions to use the clearer formulation with the follow-up on epistemological limitations\n4. Keep the note about a footnote for Zvi's concept to acknowledge existential concerns\n\nThis gives us a much more philosophically robust framing that aligns with Kuhn/Lakatos rather than positivist perspectives on science.\n\nI'll update the outline with these excellent refinements:\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\n\n\nThe outline now incorporates all your refinements:\n\n1. Updated the definition of technoscholasticism with the Lakatosian framing and noted the need for a footnote\n2. Adjusted the language around empirical investigation to avoid positivist connotations\n3. Revised the research questions with your clearer formulation and the epistemological follow-up\n4. Added a note for the footnote on Zvi's concept to acknowledge existential concerns\n\nIs this outline now ready for me to proceed with drafting the introduction?",
      "content": [
        {
          "start_timestamp": "2025-03-15T07:35:16.667351Z",
          "stop_timestamp": "2025-03-15T07:35:19.103523Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nI'll update the outline to incorporate these changes:\n\n1. Revise the definition of technoscholasticism to use the Lakatosian framing\n2. Note that we'll need a footnote for the research programme concept\n3. Update the research questions to use the clearer formulation with the follow-up on epistemological limitations\n4. Keep the note about a footnote for Zvi's concept to acknowledge existential concerns\n\nThis gives us a much more philosophically robust framing that aligns with Kuhn/Lakatos rather than positivist perspectives on science.",
          "summaries": [
            {
              "summary": "Updating outline, refining research questions and definitions"
            },
            {
              "summary": "Refined philosophical framework with Kuhn/Lakatos research approach."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T07:35:19.114208Z",
          "stop_timestamp": "2025-03-15T07:35:19.127431Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI'll update the outline with these excellent refinements:",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T07:35:19.179153Z",
          "stop_timestamp": "2025-03-15T07:35:24.865627Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "command": "update",
            "new_str": "## Paragraph 3: Theoretical Framework (~200 words)\n- **Coining \"technoscholasticism\"**: Explicitly introducing this as a new theoretical contribution\n  - Definition: \"A digital scholasticism that privileges textual authorities over engagement with competing research programmes\" [footnote needed for Lakatosian concept]\n  - Inspired by medieval scholastic tradition but applied to AI research systems\n- **Historical parallel**: Medieval scholastic approach (Horden citation)\n  - Reliance on authoritative texts rather than empirical investigation\n  - Emphasis on reconciling conflicting authorities through logical distinctions\n  - Structure and citations as markers of authority\n- **Modern parallel**: How AI research tools replicate scholastic priorities\n  - \"Unaccountable lack of hands-on experience\"\n  - No capability for engaging with anomalies or competing frameworks\n  - Privileging of well-formatted academic sources",
            "old_str": "## Paragraph 3: Theoretical Framework (~200 words)\n- **Coining \"technoscholasticism\"**: Explicitly introducing this as a new theoretical contribution\n  - Definition: A digital scholasticism that privileges textual authority over empirical verification\n  - Inspired by medieval scholastic tradition but applied to AI research systems\n- **Historical parallel**: Medieval scholastic approach (Horden citation)\n  - Reliance on authoritative texts rather than empirical investigation\n  - Emphasis on reconciling conflicting authorities through logical distinctions\n  - Structure and citations as markers of authority\n- **Modern parallel**: How AI research tools replicate scholastic priorities\n  - \"Unaccountable lack of hands-on experience\"\n  - No capability for empirical testing\n  - Privileging of well-formatted academic sources",
            "version_uuid": "1278fb52-0acc-4acb-af4b-c49542cd23a4"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "0f4e8d9d-71a6-43f1-97ab-5397c9c215e2"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T07:35:28.614150Z",
          "stop_timestamp": "2025-03-15T07:35:28.614150Z",
          "flags": null,
          "type": "text",
          "text": "\n\n\n",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T07:35:28.761226Z",
          "stop_timestamp": "2025-03-15T07:35:36.553008Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "command": "update",
            "new_str": "## Paragraph 4: Research Approach and Paper Organization (~200 words)\n- **Methodological approach**: Autoethnographic investigation\n  - Case studies with frontier models (February 2025)\n  - Direct testing of research capabilities\n  - Interpretation of findings through technoscholasticism lens: \n    - Beyond simple authority deference\n    - Inability to apply \"does this make sense?\" filter to texts\n    - Cannot evaluate if sources could possibly know what they claim to know\n    - No capacity to judge claims against experiential knowledge\n    - Fundamental epistemological limitations from the \"no-hands\" problem\n- **Research questions**:\n  - How well can an LLM, using a Deep Research workflow, assist in performing research?\n  - What are the epistemological limitations of such assistance?\n  - What is the mundane utility despite limitations? [footnote acknowledging that existential questions are important but outside scope]\n  - How should tools be designed to complement human judgment?\n- **Paper structure**: \n  - [TODO: Develop more meaningful signposting that conveys argument progression rather than just section titles. To be finalized after drafting other sections.]\n- **Key contribution**: Framework for understanding AI limitations and appropriate use cases",
            "old_str": "## Paragraph 4: Research Approach and Paper Organization (~200 words)\n- **Methodological approach**: Autoethnographic investigation\n  - Case studies with frontier models (February 2025)\n  - Direct testing of research capabilities\n  - Interpretation of findings through technoscholasticism lens: \n    - Beyond simple authority deference\n    - Inability to apply \"does this make sense?\" filter to texts\n    - Cannot evaluate if sources could possibly know what they claim to know\n    - No capacity to judge claims against experiential knowledge\n    - Fundamental epistemological limitations from the \"no-hands\" problem\n- **Research questions**:\n  - How do LLMs perform on insight-requiring vs. descriptive tasks?\n  - What is the mundane utility despite limitations?\n  - How should tools be designed to complement human judgment?\n- **Paper structure**: \n  - [TODO: Develop more meaningful signposting that conveys argument progression rather than just section titles. To be finalized after drafting other sections.]\n- **Key contribution**: Framework for understanding AI limitations and appropriate use cases",
            "version_uuid": "1c63074d-bf24-4172-b2c9-fde10d665c34"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "a74f0ec2-eda1-4f2a-917f-e46856c622e9"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T07:35:40.965158Z",
          "stop_timestamp": "2025-03-15T07:35:43.107090Z",
          "flags": null,
          "type": "text",
          "text": "\n\n\n\nThe outline now incorporates all your refinements:\n\n1. Updated the definition of technoscholasticism with the Lakatosian framing and noted the need for a footnote\n2. Adjusted the language around empirical investigation to avoid positivist connotations\n3. Revised the research questions with your clearer formulation and the epistemological follow-up\n4. Added a note for the footnote on Zvi's concept to acknowledge existential concerns\n\nIs this outline now ready for me to proceed with drafting the introduction?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T07:35:43.656100Z",
      "updated_at": "2025-03-15T07:35:43.656100Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "b8b7e0b9-1144-4718-83ba-4fc3db17f406",
      "text": "\"A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims\"\n\nAs much as I love the Lakatosian one, this is more clear to most of the audience. And means I don't need to go into details about hard cores and protective belts in the *intro*. ",
      "content": [
        {
          "start_timestamp": "2025-03-14T23:56:53.264398Z",
          "stop_timestamp": "2025-03-14T23:56:53.264398Z",
          "flags": null,
          "type": "text",
          "text": "\"A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims\"\n\nAs much as I love the Lakatosian one, this is more clear to most of the audience. And means I don't need to go into details about hard cores and protective belts in the *intro*. ",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T07:59:39.522795Z",
      "updated_at": "2025-03-15T07:59:39.522795Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "9ea6ace7-aabc-4867-8287-0aa2dcd5a435",
      "text": "\nThe choice of \"A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims\" is a good one - it's clearer for a general academic audience while still accurately representing the philosophical stance. I'll update the outline with this phrasing.\n\nThe intro should now include:\n1. Challenging OpenAI's agency claims\n2. Zvi's mundane utility concept (with footnote acknowledging the importance of existential questions)\n3. Why these systems lack true agency\n4. The revised definition of technoscholasticism\n\nLet me update the outline with these changes before proceeding with the introduction draft.\n\nI agree, that formulation is clearer and more accessible while still capturing the epistemological issue. Let me update the outline with this definition:\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\n\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\n\n\n\n\n\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe outline has been updated with all your specifications:\n\n1. Added a footnote indicator for Zvi's concept to acknowledge existential concerns\n2. Updated the definition of technoscholasticism to \"privileges textual authorities over critical assessment of knowledge claims\"\n3. Replaced the multiple research questions with your clearer single question about LLMs assisting in research\n\nWith these changes, the outline now better reflects your philosophical orientation and provides a clearer framework for drafting the introduction. Shall I proceed with writing the full introduction based on this outline?",
      "content": [
        {
          "start_timestamp": "2025-03-15T07:59:45.120244Z",
          "stop_timestamp": "2025-03-15T07:59:47.061189Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nThe choice of \"A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims\" is a good one - it's clearer for a general academic audience while still accurately representing the philosophical stance. I'll update the outline with this phrasing.\n\nThe intro should now include:\n1. Challenging OpenAI's agency claims\n2. Zvi's mundane utility concept (with footnote acknowledging the importance of existential questions)\n3. Why these systems lack true agency\n4. The revised definition of technoscholasticism\n\nLet me update the outline with these changes before proceeding with the introduction draft.",
          "summaries": [
            {
              "summary": "Thinking about scholarly discourse and knowledge validation strategies"
            },
            {
              "summary": "Updating text for clearer academic audience understanding"
            },
            {
              "summary": "Refined outline and strategy for academic text introduction."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T07:59:47.223570Z",
          "stop_timestamp": "2025-03-15T07:59:47.558235Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI agree, that formulation is clearer and more accessible while still capturing the epistemological issue. Let me update the outline with this definition:",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T07:59:47.911274Z",
          "stop_timestamp": "2025-03-15T07:59:53.429300Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "command": "update",
            "new_str": "## Paragraph 3: Theoretical Framework (~200 words)\n- **Coining \"technoscholasticism\"**: Explicitly introducing this as a new theoretical contribution\n  - Definition: A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims\n  - Inspired by medieval scholastic tradition but applied to AI research systems\n- **Historical parallel**: Medieval scholastic approach (Horden citation)\n  - Reliance on authoritative texts rather than empirical investigation\n  - Emphasis on reconciling conflicting authorities through logical distinctions\n  - Structure and citations as markers of authority\n- **Modern parallel**: How AI research tools replicate scholastic priorities\n  - \"Unaccountable lack of hands-on experience\"\n  - No capability for empirical testing\n  - Privileging of well-formatted academic sources",
            "old_str": "## Paragraph 3: Theoretical Framework (~200 words)\n- **Coining \"technoscholasticism\"**: Explicitly introducing this as a new theoretical contribution\n  - Definition: A digital scholasticism that privileges textual authority over empirical verification\n  - Inspired by medieval scholastic tradition but applied to AI research systems\n- **Historical parallel**: Medieval scholastic approach (Horden citation)\n  - Reliance on authoritative texts rather than empirical investigation\n  - Emphasis on reconciling conflicting authorities through logical distinctions\n  - Structure and citations as markers of authority\n- **Modern parallel**: How AI research tools replicate scholastic priorities\n  - \"Unaccountable lack of hands-on experience\"\n  - No capability for empirical testing\n  - Privileging of well-formatted academic sources",
            "version_uuid": "83141682-bdc8-42ff-9578-85c47aa3bb7c"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "7f9979a1-8749-4b5f-8e7a-8afc5af1973f"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T08:00:07.313432Z",
          "stop_timestamp": "2025-03-15T08:00:07.424894Z",
          "flags": null,
          "type": "text",
          "text": "\n\n\n\n",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T08:00:07.587821Z",
          "stop_timestamp": "2025-03-15T08:00:12.203127Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "command": "update",
            "new_str": "## Paragraph 1: Hook and Problem Statement (~150 words)\n- **Opening hook**: Condensed OpenAI quote about Deep Research's \"agentic capability\" claims\n- **Problem identification**: Gap between linguistic performance and actual capabilities\n- **Critical challenge**: These systems are fundamentally not agentic despite marketing claims\n- **Specific issue**: \"Research\" requires judgment that these systems lack\n- **Stakes**: Misunderstanding capabilities leads to misuse and disappointment\n- **Zvi's concept**: Focus on \"mundane utility\" (Mowshowitz) while setting aside larger questions^[Footnote acknowledging that existential questions are important but outside the scope of this paper]\n- **Transition**: While not agents, they may still offer practical applications",
            "old_str": "## Paragraph 1: Hook and Problem Statement (~150 words)\n- **Opening hook**: Condensed OpenAI quote about Deep Research's \"agentic capability\" claims\n- **Problem identification**: Gap between linguistic performance and actual capabilities\n- **Critical challenge**: These systems are fundamentally not agentic despite marketing claims\n- **Specific issue**: \"Research\" requires judgment that these systems lack\n- **Stakes**: Misunderstanding capabilities leads to misuse and disappointment\n- **Zvi's concept**: Focus on \"mundane utility\" (Mowshowitz) while setting aside larger questions\n- **Transition**: While not agents, they may still offer practical applications",
            "version_uuid": "c1946522-ede9-487f-8fe0-3e196f6eb7c4"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "532afccb-7a00-475d-93fd-50283a6b8647"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T08:00:20.263628Z",
          "stop_timestamp": "2025-03-15T08:00:20.343017Z",
          "flags": null,
          "type": "text",
          "text": "\n\n\n\n\n\n\n\n",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T08:00:20.496339Z",
          "stop_timestamp": "2025-03-15T08:00:28.113671Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "intro-outline",
            "command": "update",
            "new_str": "## Paragraph 4: Research Approach and Paper Organization (~200 words)\n- **Methodological approach**: Autoethnographic investigation\n  - Case studies with frontier models (February 2025)\n  - Direct testing of research capabilities\n  - Research question: How well can an LLM, using a Deep Research workflow, assist in performing research?\n  - Interpretation of findings through technoscholasticism lens: \n    - Beyond simple authority deference\n    - Inability to apply \"does this make sense?\" filter to texts\n    - Cannot evaluate if sources could possibly know what they claim to know\n    - No capacity to judge claims against experiential knowledge\n    - Fundamental epistemological limitations from the \"no-hands\" problem\n- **Paper structure**: \n  - [TODO: Develop more meaningful signposting that conveys argument progression rather than just section titles. To be finalized after drafting other sections.]\n- **Key contribution**: Framework for understanding AI limitations and appropriate use cases",
            "old_str": "## Paragraph 4: Research Approach and Paper Organization (~200 words)\n- **Methodological approach**: Autoethnographic investigation\n  - Case studies with frontier models (February 2025)\n  - Direct testing of research capabilities\n  - Interpretation of findings through technoscholasticism lens: \n    - Beyond simple authority deference\n    - Inability to apply \"does this make sense?\" filter to texts\n    - Cannot evaluate if sources could possibly know what they claim to know\n    - No capacity to judge claims against experiential knowledge\n    - Fundamental epistemological limitations from the \"no-hands\" problem\n- **Research questions**:\n  - How do LLMs perform on insight-requiring vs. descriptive tasks?\n  - What is the mundane utility despite limitations?\n  - How should tools be designed to complement human judgment?\n- **Paper structure**: \n  - [TODO: Develop more meaningful signposting that conveys argument progression rather than just section titles. To be finalized after drafting other sections.]\n- **Key contribution**: Framework for understanding AI limitations and appropriate use cases",
            "version_uuid": "c45d6256-2220-4112-9eee-0f621a67b88e"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "e90f7669-c4b5-4e4e-8c45-be3ff0d0bb93"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T08:00:40.727590Z",
          "stop_timestamp": "2025-03-15T08:00:43.077567Z",
          "flags": null,
          "type": "text",
          "text": "\n\n\n\n\n\n\n\n\n\n\n\nThe outline has been updated with all your specifications:\n\n1. Added a footnote indicator for Zvi's concept to acknowledge existential concerns\n2. Updated the definition of technoscholasticism to \"privileges textual authorities over critical assessment of knowledge claims\"\n3. Replaced the multiple research questions with your clearer single question about LLMs assisting in research\n\nWith these changes, the outline now better reflects your philosophical orientation and provides a clearer framework for drafting the introduction. Shall I proceed with writing the full introduction based on this outline?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T08:00:43.603607Z",
      "updated_at": "2025-03-15T08:00:43.603607Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "208623ad-6598-4152-8f29-67fcbce3b227",
      "text": "Yes, let's see how it goes.",
      "content": [
        {
          "start_timestamp": "2025-03-14T21:50:17.749934Z",
          "stop_timestamp": "2025-03-14T21:50:17.749934Z",
          "flags": null,
          "type": "text",
          "text": "Yes, let's see how it goes.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T08:01:25.522649Z",
      "updated_at": "2025-03-15T08:01:25.522649Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "d1d59dee-f5c6-48f4-ad50-0972c0886671",
      "text": "\nI'll now draft the full introduction based on the detailed outline we've created. I'll make sure to match the academic register of the author, which features:\n\n1. Theoretical depth while maintaining clarity\n2. Critical analysis of claims vs. reality\n3. Philosophical rigor without unnecessary jargon\n4. Conversational yet scholarly tone\n\nI'll use the proper citations (BibLaTeX keys) as specified in our discussion and incorporate all the elements from our outline. The introduction will be approximately 750 words as requested, with a clear structure following our outline.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\nI've drafted the introduction based on our outline, incorporating all the key elements we discussed. The draft:\n\n1. Opens with the OpenAI quote about Deep Research as a hook\n2. Immediately challenges the \"agentic capability\" claims\n3. Introduces Mowshowitz's \"mundane utility\" concept with the appropriate footnote\n4. Presents your central thesis about judgment deficiency and introduces technoscholasticism\n5. Explicitly defines technoscholasticism and connects it to historical scholasticism via the Horden citation\n6. Addresses Dwarkesh's question through the technoscholasticism framework\n7. Outlines your autoethnographic approach and the paper's contributions\n\nThe introduction is approximately 750 words as requested. I've maintained your academic register while ensuring clarity and theoretical depth. All citations use the BibLaTeX keys you provided.\n\nWould you like me to make any adjustments to this draft?",
      "content": [
        {
          "start_timestamp": "2025-03-15T08:01:26.917415Z",
          "stop_timestamp": "2025-03-15T08:01:29.412938Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nI'll now draft the full introduction based on the detailed outline we've created. I'll make sure to match the academic register of the author, which features:\n\n1. Theoretical depth while maintaining clarity\n2. Critical analysis of claims vs. reality\n3. Philosophical rigor without unnecessary jargon\n4. Conversational yet scholarly tone\n\nI'll use the proper citations (BibLaTeX keys) as specified in our discussion and incorporate all the elements from our outline. The introduction will be approximately 750 words as requested, with a clear structure following our outline.",
          "summaries": [
            {
              "summary": "Thinking about responding to an affirmative statement"
            },
            {
              "summary": "Crafting academic introduction with theoretical depth"
            },
            {
              "summary": "Drafted scholarly introduction with precise academic approach."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T08:01:29.838078Z",
          "stop_timestamp": "2025-03-15T08:01:49.625358Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "introduction-draft",
            "type": "text/markdown",
            "title": "Introduction Draft",
            "command": "create",
            "content": "\\section{Introduction}\n\n\"Today we're launching deep research in ChatGPT, a new agentic capability... ChatGPT will find, analyze, and synthesize hundreds of online sources to create a comprehensive report at the level of a research analyst\" \\parencite{openai_introducing_2025}. Such claims of \"agentic\" capability have become commonplace in the marketing of large language models (LLMs), with the suggestion that these systems can independently conduct complex research tasks. Yet a significant gap exists between these linguistic performances and actual capabilities. These systems are fundamentally not agentic despite marketing claims. True research requires judgment\u2014the ability to critically evaluate sources, methods, and conclusions\u2014a capability these systems demonstrably lack. The risks of misunderstanding these limitations extend beyond mere disappointment; they threaten to undermine the reliability of scholarship itself. Following Mowshowitz's concept of \"mundane utility\" \\parencite{mowshowitz_ai_2023}, this paper sets aside larger questions about AI's future implications\\footnote{While existential questions about AI are undeniably important, they lie outside the scope of this investigation, which focuses on practical applications and limitations of current systems.} to focus pragmatically on what these tools can actually accomplish as tools, rather than as purported agents.\n\nLarge language models fundamentally lack judgment despite their ability to mimic the language of judgment. This absence is particularly evident in their inability to assess whether they have actually achieved goals or to evaluate if their task decompositions are appropriate for solving problems. While they can process inputs that resemble goals, execute predetermined steps, and produce outputs that simulate reports, they cannot genuinely evaluate success or failure. This judgment deficiency manifests in three crucial aspects: epistemic humility (knowing what one doesn't know), inductive capacity (noticing meaningful patterns), and correspondence with reality (evaluating claims against the world rather than other texts). We characterize these LLM-driven research tools as adhering to a technoscholastic worldview\u2014privileging textual authority over critical assessment of knowledge claims, determining source quality by textual markers rather than real-world correspondence, and defaulting to heavily cited authorities regardless of accuracy. This technoscholasticism explains why, despite having access to vast corpora of human knowledge, these systems have proven incapable of generating genuine insights or novel connections.\n\nWe propose \"technoscholasticism\" as a conceptual framework for understanding these fundamental limitations. By this, we mean a digital scholasticism that privileges textual authorities over critical assessment of knowledge claims. This approach draws parallels to the medieval scholastic tradition described by Horden, in which \"what mattered more than any clear-cut distinction between \\textit{scientia} and \\textit{magica} were the questions of value and authority. Did these exceptional techniques have beneficial effects, and did the reports of their effects come from good sources?\" \\parencite[Section 3]{horden_medieval_2011}. Like medieval scholastics, LLMs rely on authoritative texts rather than empirical investigation, emphasize reconciling conflicting sources through logical distinctions, and treat structural markers and citations as indicators of authority. Contemporary AI research tools replicate these scholastic priorities due to their \"unaccountable lack of hands-on experience,\" their inability to empirically test claims, and their preference for well-formatted academic sources. This helps explain Dwarkesh's question about why LLMs with \"basically the entire corpus of human knowledge memorized\" haven't \"been able to make a single new connection that has led to a discovery\" \\parencite{tabarrok_dwarkeshs_2025}. Knowledge generation isn't mere \"stamp collecting\"; it requires noticing meaningful parallels and judging which connections are significant\u2014precisely the capabilities technoscholasticism precludes.\n\nOur investigation employs an autoethnographic approach, examining firsthand experiences with frontier models in February 2025 to address the question: How well can an LLM, using a Deep Research workflow, assist in performing research? We interpret these experiences through the lens of technoscholasticism, examining not just simple authority deference but deeper epistemological limitations: the inability to apply a \"does this make sense?\" filter to texts, the failure to evaluate whether sources could possibly know what they claim to know, and the fundamental disconnect from experiential knowledge. Throughout this paper, we analyze the judgment deficiency in current systems, evaluate their capabilities for mundane utility despite these limitations, and propose requirements for truly effective research tools that acknowledge and compensate for these inherent constraints. By understanding these systems' limitations through the framework of technoscholasticism, researchers can develop more realistic expectations and better approaches to incorporating these tools into scholarly practice.\n",
            "version_uuid": "a5d211e3-f26b-438b-b4c2-3b2c1a6a9bec"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "6e68974a-6071-4580-b390-f6d876a4f2bc"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T08:01:54.502071Z",
          "stop_timestamp": "2025-03-15T08:01:58.490137Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI've drafted the introduction based on our outline, incorporating all the key elements we discussed. The draft:\n\n1. Opens with the OpenAI quote about Deep Research as a hook\n2. Immediately challenges the \"agentic capability\" claims\n3. Introduces Mowshowitz's \"mundane utility\" concept with the appropriate footnote\n4. Presents your central thesis about judgment deficiency and introduces technoscholasticism\n5. Explicitly defines technoscholasticism and connects it to historical scholasticism via the Horden citation\n6. Addresses Dwarkesh's question through the technoscholasticism framework\n7. Outlines your autoethnographic approach and the paper's contributions\n\nThe introduction is approximately 750 words as requested. I've maintained your academic register while ensuring clarity and theoretical depth. All citations use the BibLaTeX keys you provided.\n\nWould you like me to make any adjustments to this draft?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T08:01:58.985356Z",
      "updated_at": "2025-03-15T08:01:58.985356Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "a05285e1-fe67-4587-9012-92a977ec4d90",
      "text": "Ok, after editing for a while, here's what I have as the first section.\n\n(Note that I've made the language a touch more formal, Australian, and split a long paragraph)\n\nCritically assess this as the paper's intro. Does it serve it's purpose in the context of the rest of the plans? What other edits do we need to make before we can proceed?\n\nDo we think the final parts of this are sufficient signposting, or should we add a % TODO SIGNPOST for later?",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:13:32.805679Z",
          "stop_timestamp": "2025-03-14T20:13:32.805679Z",
          "flags": null,
          "type": "text",
          "text": "Ok, after editing for a while, here's what I have as the first section.\n\n(Note that I've made the language a touch more formal, Australian, and split a long paragraph)\n\nCritically assess this as the paper's intro. Does it serve it's purpose in the context of the rest of the plans? What other edits do we need to make before we can proceed?\n\nDo we think the final parts of this are sufficient signposting, or should we add a % TODO SIGNPOST for later?",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T08:56:31.071338Z",
      "updated_at": "2025-03-15T08:56:31.071338Z",
      "attachments": [
        {
          "file_name": "paste.txt",
          "file_size": 10660,
          "file_type": "txt",
          "extracted_content": "\n\\section{Introduction}\n\n% ## Paragraph 1: Hook and Problem Statement (~150 words)\n% - **Opening hook**: Condensed OpenAI quote about Deep Research's \"agentic capability\" claims\n% - **Problem identification**: Gap between linguistic performance and actual capabilities\n% - **Critical challenge**: These systems are fundamentally not agentic despite marketing claims\n% - **Specific issue**: \"Research\" requires judgment that these systems lack\n% - **Stakes**: Misunderstanding capabilities leads to misuse and disappointment\n% - **Zvi's concept**: Focus on \"mundane utility\" (Mowshowitz) while setting aside larger questions\n% - **Transition**: While not agents, they may still offer practical applications\n\n\"Today we're launching deep research in ChatGPT, a new agentic capability... ChatGPT will find, analyze, and synthesize hundreds of online sources to create a comprehensive report at the level of a research analyst\" \\parencite{openai_introducing_2025}. Such claims of \"agentic\" capability have become commonplace in the marketing of large language models (LLMs), suggesting that these systems can independently conduct complex research tasks. Yet, a significant gap exists between these linguistic performances and actual capabilities. These systems are fundamentally not agentic \\textit{qua} goal-following systems, despite marketing claims. Effective research requires judgement: the ability to critically evaluate sources, methods, outputs, and conclusions; a capability that these systems demonstrably lack. The risks of misunderstanding these limitations extend beyond mere disappointment; they threaten to undermine the reliability of scholarship itself. Following Mowshowitz's concept of \"mundane utility\"\\parencite*{mowshowitz_ai_2023}, this paper sets aside larger questions about AI's future implications\\footnote{While existential questions about AI are undeniably important, they lie outside the scope of this investigation, which focuses on practical applications and limitations of current systems. Once LLMs possess the capacity for effective judgement, existential questions in a question of what it means to work, continuation-of-culture, or continutiy-of-existance sense will become extremely salient.} to focus on questions of mundane utility concerning what these tools can actually accomplish as tools for scholars instead of our \"plastic [research] pal who is fun to be with\"\\parencite[Adams referenced in][]{lavine_robotic_2007}.\n\n\n% ## Paragraph 2: Central Thesis (~200 words)\n% - **Primary claim**: LLMs fundamentally lack judgment despite mimicking its language\n% - **Critique of \"agentic\" claims**: \n%   - Cannot assess if they've achieved goals\n%   - Cannot evaluate if task decomposition is appropriate\n%   - Lack true goal-following capability despite appearances\n%   - Missing critical self-assessment capabilities\n% - **Definition of judgment**: Ability to critically evaluate sources, methods, and conclusions\n% - **Three aspects**: Epistemic humility, inductive capacity, correspondence with reality\n% - **Technoscholasticism introduction**: \n%   - Tool-using LLMs adhere to technoscholastic worldview\n%   - Privileging textual authority over empirical faithfulness\n%   - Quality of source determined by textual elements, not real-world correspondence\n%   - Preference for heavily cited authorities regardless of accuracy\n%   - Default to most common answers (authorities) in training data\n% - **Consequences**: This explains failure to generate novel insights from existing knowledge\n\n\nLLMs fundamentally lack judgment despite their ability to perform the \\textit{language} of judgment. This absence is particularly evident in their inability to assess whether they have actually achieved their goals or to evaluate whether their task decompositions are appropriate for solving relevant problems. While they can process inputs that resemble goals, execute predetermined steps, and produce outputs that simulate reports, they cannot genuinely evaluate success or failure in their assigned tasks. The proof of this lack of judgment regarding success is that the authors have never observed an LLM admitting that its answer is inadequate or that its output requires reconsideration. \n\nThis judgment deficiency manifests in three crucial aspects: epistemic humility (knowing what one does not know), inductive capacity (noticing meaningful patterns), and correspondence with reality (evaluating claims against the world rather than other texts). We characterise these LLM-driven research tools as adhering to a technoscholastic worldview: privileging textual authority over critical assessment of knowledge claims, determining source quality by textual markers rather than by real-world correspondence, and defaulting to heavily cited authorities regardless of their appropriateness. This technoscholasticism explains why, despite having access to vast corpora of human knowledge, these systems have proven incapable of generating genuine insights or novel connections, acting as researchers rather than mere tools for researchers.\n\n\n% ## Paragraph 3: Theoretical Framework (~200 words)\n% - **Coining \"technoscholasticism\"**: Explicitly introducing this as a new theoretical contribution\n%   - Definition: \"A digital scholasticism that privileges textual authorities over engagement with competing research programmes\" [footnote needed for Lakatosian concept]\n%   - Inspired by medieval scholastic tradition but applied to AI research systems\n% - **Historical parallel**: Medieval scholastic approach (Horden citation)\n%   - Reliance on authoritative texts rather than empirical investigation\n%   - Emphasis on reconciling conflicting authorities through logical distinctions\n%   - Structure and citations as markers of authority\n% - **Modern parallel**: How AI research tools replicate scholastic priorities\n%   - \"Unaccountable lack of hands-on experience\"\n%   - No capability for engaging with anomalies or competing frameworks\n%   - Privileging of well-formatted academic sources\n% - **Dwarkesh's question**: Why LLMs with \"entire corpus\" make no new connections (Tabarrok citation)\n% - **Our answer**: \n%   - Knowledge generation isn't mere \"stamp collecting\" (Rutherford reference - TODO)\n%   - Requires *noticing* parallels (induction) and judging which are meaningful\n%   - LLMs' deference to authority prevents challenging established views\n%   - Correspondence with \"The Real\" requires judgment beyond technoscholasticism\n\nWe propose \"technoscholasticism\" as a conceptual framework for understanding these fundamental limitations. By this framework, we mean a digital scholasticism that privileges textual authorities over critical assessment of knowledge claims. This approach draws parallels to the medieval scholastic tradition described by Horden, in which \"what mattered more than any clear-cut distinction between \\textit{scientia} and \\textit{magica} were the questions of value and authority. Did these exceptional techniques have beneficial effects, and did the reports of their effects come from good sources?\" \\parencite*[Section 3]{horden_medieval_2011}. Like medieval scholastics, LLMs rely on authoritative texts rather than empirical investigation, emphasise reconciling conflicting sources through logical distinctions, and treat formatting, publisher, structural markers, and the presence of citations as indicators of authority. Contemporary AI research tools replicate these scholastic priorities due to their unaccountable lack of \\textit{hands-on} experience, their inability to evaluate the credibility of claims within the context of broader tacit knowledge, and their deference toward well-formatted and longer sources. We believe this flaw answers Dwarkesh's question to Tabarrok about why LLMs with \"basically the entire corpus of human knowledge memorised\" have not \"been able to make a single new connection that has led to a discovery\"\\parencite{tabarrok_dwarkeshs_2025}. Knowledge generation is not merely the accumulation of observations until we choose to call something a fact in the Carnapian sense; it requires noticing meaningful parallels and judging which connections are significant---precisely the capabilities that technoscholasticism precludes.\n\n% ## Paragraph 4: Research Approach and Paper Organization (~200 words)\n% - **Methodological approach**: Autoethnographic investigation\n%   - Case studies with frontier models (February 2025)\n%   - Direct testing of research capabilities\n%   - Interpretation of findings through technoscholasticism lens: \n%     - Beyond simple authority deference\n%     - Inability to apply \"does this make sense?\" filter to texts\n%     - Cannot evaluate if sources could possibly know what they claim to know\n%     - No capacity to judge claims against experiential knowledge\n%     - Fundamental epistemological limitations from the \"no-hands\" problem\n% - **Research questions**:\n%   - How well can an LLM, using a Deep Research workflow, assist in performing research?\n%   - What are the epistemological limitations of such assistance?\n%   - What is the mundane utility despite limitations? [footnote acknowledging that existential questions are important but outside scope]\n%   - How should tools be designed to complement human judgment?\n% - **Paper structure**: \n%   - [TODO: Develop more meaningful signposting that conveys argument progression rather than just section titles. To be finalized after drafting other sections.]\n% - **Key contribution**: Framework for understanding AI limitations and appropriate use cases\n\nOur investigation employs an autoethnographic approach, examining firsthand experiences with frontier models in February 2025 to address the question: How well can an LLM, using a Deep Research workflow, assist in performing research? We interpret these experiences through the lens of technoscholasticism, examining not just simple authority deference but deeper epistemological limitations: the inability to apply a \"does this make sense?\" filter to texts, the failure to evaluate whether sources could legitimately know what they claim to know, and the fundamental disconnect from experiential knowledge. Throughout this paper, we analyse the judgement deficiency in current systems, evaluate their capabilities for mundane utility despite these limitations, and propose requirements for truly effective research tools that acknowledge and compensate for these inherent constraints. By understanding these systems' limitations through the framework of technoscholasticism, researchers can develop more realistic expectations and more effective approaches to incorporating these tools into scholarly practice.\n"
        }
      ],
      "files": [
        {
          "file_name": "paste.txt"
        }
      ]
    },
    {
      "uuid": "e30d4afc-1129-4dcb-b9ae-b2e372a3e16e",
      "text": "\nLet me critically assess this introduction and consider how well it sets up the paper according to our plans.\n\nFirst, let's analyze what you've modified from my draft:\n\n1. **Language changes:**\n   - More formal and uses Australian spelling (e.g., \"characterise\", \"judgement\")\n   - Added \"*qua* goal-following systems\" which strengthens the philosophical precision\n   - \"Plastic research pal\" reference - adds scholarly humor while maintaining academic tone\n   - Expanded footnote on existential questions to include more nuance\n\n2. **Structural changes:**\n   - Split the second paragraph into two parts for better readability\n   - Added specific example of judgment failure: \"The proof of this lack of judgment regarding success is that the authors have never observed an LLM admitting that its answer is inadequate\"\n   - More precise characterization of technoscholasticism with expanded details on authority markers\n   - Stronger phrasing around the Carnapian reference\n\n3. **Content additions:**\n   - The Lavine citation adds scholarly depth\n   - More specific about what \"hands-on experience\" means\n   - Expanded on the epistemological limitations\n\nOverall, your edits have improved the introduction by making it more precise, scholarly, and philosophically grounded while maintaining clarity.\n\nRegarding the final signposting, I think it could benefit from slightly more specific guidance about what each section will cover. The current ending describes what the paper will do thematically (analyze judgment deficiency, evaluate capabilities, propose requirements) but doesn't map that directly to the paper's structure.\n\nFor the purposes of this introduction, I think we should add a % TODO SIGNPOST marker to revisit this after other sections are more fully developed. This will allow us to ensure the signposting aligns perfectly with how the arguments unfold in the final paper.\n\nYour edited introduction is excellent - it shows notable improvements in several areas:\n\n1. **Philosophical precision**: Adding \"*qua* goal-following systems\" and the more precise characterization of technoscholasticism grounds the argument firmly in philosophical tradition while introducing your novel theoretical contribution.\n\n2. **Evidence of judgment failure**: The observation that LLMs never admit inadequacy provides concrete evidence of judgment deficiency, not just theoretical claims.\n\n3. **Scholarly tone**: The Australian spelling and more formal phrasing establish appropriate academic register, while the \"plastic research pal\" reference adds a scholarly touch of humor that works well.\n\n4. **Expanded footnote**: The additional context on existential questions shows nuanced understanding of the broader implications while maintaining focus.\n\n5. **Carnapian reference**: The stronger positioning against Carnapian confirmation helps situate your argument in philosophy of science traditions.\n\n**Areas for consideration:**\n\nThe final paragraph's signposting is thematically sound but could benefit from more specific structural guidance. I recommend adding a % TODO SIGNPOST marker to revisit this after other sections are developed. This will ensure the introduction properly maps to the paper's final structure.\n\nOverall, this introduction successfully establishes:\n- The problem (false agency claims)\n- Your thesis (judgment deficiency explained through technoscholasticism)\n- Your methodological approach (autoethnographic)\n- The paper's contribution (realistic assessment of limitations and applications)\n\nIt serves its purpose well in setting up the technoscholasticism framework that will drive the rest of the paper.",
      "content": [
        {
          "start_timestamp": "2025-03-15T08:56:39.546672Z",
          "stop_timestamp": "2025-03-15T08:56:46.734367Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nLet me critically assess this introduction and consider how well it sets up the paper according to our plans.\n\nFirst, let's analyze what you've modified from my draft:\n\n1. **Language changes:**\n   - More formal and uses Australian spelling (e.g., \"characterise\", \"judgement\")\n   - Added \"*qua* goal-following systems\" which strengthens the philosophical precision\n   - \"Plastic research pal\" reference - adds scholarly humor while maintaining academic tone\n   - Expanded footnote on existential questions to include more nuance\n\n2. **Structural changes:**\n   - Split the second paragraph into two parts for better readability\n   - Added specific example of judgment failure: \"The proof of this lack of judgment regarding success is that the authors have never observed an LLM admitting that its answer is inadequate\"\n   - More precise characterization of technoscholasticism with expanded details on authority markers\n   - Stronger phrasing around the Carnapian reference\n\n3. **Content additions:**\n   - The Lavine citation adds scholarly depth\n   - More specific about what \"hands-on experience\" means\n   - Expanded on the epistemological limitations\n\nOverall, your edits have improved the introduction by making it more precise, scholarly, and philosophically grounded while maintaining clarity.\n\nRegarding the final signposting, I think it could benefit from slightly more specific guidance about what each section will cover. The current ending describes what the paper will do thematically (analyze judgment deficiency, evaluate capabilities, propose requirements) but doesn't map that directly to the paper's structure.\n\nFor the purposes of this introduction, I think we should add a % TODO SIGNPOST marker to revisit this after other sections are more fully developed. This will allow us to ensure the signposting aligns perfectly with how the arguments unfold in the final paper.",
          "summaries": [
            {
              "summary": "Thinking about critically evaluating an academic paper's introductory section for structure and signposting effectiveness"
            },
            {
              "summary": "Analyzing language changes in draft introduction"
            },
            {
              "summary": "Scrutinized introduction's scholarly precision and structural improvements."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T08:56:47.036197Z",
          "stop_timestamp": "2025-03-15T08:56:52.208735Z",
          "flags": null,
          "type": "text",
          "text": "\n\nYour edited introduction is excellent - it shows notable improvements in several areas:\n\n1. **Philosophical precision**: Adding \"*qua* goal-following systems\" and the more precise characterization of technoscholasticism grounds the argument firmly in philosophical tradition while introducing your novel theoretical contribution.\n\n2. **Evidence of judgment failure**: The observation that LLMs never admit inadequacy provides concrete evidence of judgment deficiency, not just theoretical claims.\n\n3. **Scholarly tone**: The Australian spelling and more formal phrasing establish appropriate academic register, while the \"plastic research pal\" reference adds a scholarly touch of humor that works well.\n\n4. **Expanded footnote**: The additional context on existential questions shows nuanced understanding of the broader implications while maintaining focus.\n\n5. **Carnapian reference**: The stronger positioning against Carnapian confirmation helps situate your argument in philosophy of science traditions.\n\n**Areas for consideration:**\n\nThe final paragraph's signposting is thematically sound but could benefit from more specific structural guidance. I recommend adding a % TODO SIGNPOST marker to revisit this after other sections are developed. This will ensure the introduction properly maps to the paper's final structure.\n\nOverall, this introduction successfully establishes:\n- The problem (false agency claims)\n- Your thesis (judgment deficiency explained through technoscholasticism)\n- Your methodological approach (autoethnographic)\n- The paper's contribution (realistic assessment of limitations and applications)\n\nIt serves its purpose well in setting up the technoscholasticism framework that will drive the rest of the paper.",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T08:57:02.124224Z",
      "updated_at": "2025-03-15T08:57:02.124224Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "a8f9dc02-fa2f-40f4-9676-691f19660356",
      "text": "Ok, this chat is getting a touch long. There's a chance that I'm going to have to refresh. \n\nThus, let's establish a context that we can pass to future-you, plus a checklist of documents that I should attach to the chat.\n\nPlease make an *exhaustively detailed* context that we can pass to the future instance of you. (Also, please indicate if I should fully copy-paste this chat. If not, please quote EXTENSIVELY) such that future-you can preserve most of the necessary context for the next section. (There's a chance we don't need to do this, but now's a good time for a stocktake.)",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:13:09.020568Z",
          "stop_timestamp": "2025-03-14T20:13:09.020568Z",
          "flags": null,
          "type": "text",
          "text": "Ok, this chat is getting a touch long. There's a chance that I'm going to have to refresh. \n\nThus, let's establish a context that we can pass to future-you, plus a checklist of documents that I should attach to the chat.\n\nPlease make an *exhaustively detailed* context that we can pass to the future instance of you. (Also, please indicate if I should fully copy-paste this chat. If not, please quote EXTENSIVELY) such that future-you can preserve most of the necessary context for the next section. (There's a chance we don't need to do this, but now's a good time for a stocktake.)",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T09:02:12.886414Z",
      "updated_at": "2025-03-15T09:02:12.886414Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "dec6456d-740d-4677-a3ed-61fc39fd3cf2",
      "text": "\nLet me create an exhaustive context document for potential future instances. I should include:\n\n1. The overall paper project and our collaborative approach\n2. Key conceptual frameworks we've established\n3. The current state of the introduction\n4. Other important materials and references\n5. Future work to be done\n6. Specific documents that should be attached in future chats\n\nThis will ensure continuity if we need to start a new conversation.\n\n# Exhaustive Context for Future Chat Continuation\n\n## Project Overview\nWe are working on an academic paper titled \"An Absence of Judgment: On AI's Fundamental Limitations in Research\" for the Journal of Documentation. The paper criticizes claims of \"agentic\" capabilities in AI research tools through a novel theoretical framework called \"technoscholasticism.\" The paper employs autoethnographic methodology examining experiences with frontier models in February 2025.\n\n## Key Conceptual Framework\n- **Technoscholasticism**: A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims. Parallel to medieval scholasticism, AI systems lack judgment by relying on textual markers of authority rather than empirical engagement.\n- **Three dimensions of judgment deficiency**: \n  1. Epistemic humility (knowing what one doesn't know)\n  2. Inductive capacity (noticing meaningful patterns)\n  3. Correspondence with reality (evaluating claims against the world rather than other texts)\n- **Agency critique**: Current AI systems are not truly agentic *qua* goal-following systems because they cannot genuinely assess if they've achieved goals or evaluate if their task decompositions are appropriate.\n- **Mundane utility**: Following Mowshowitz, focusing on practical applications while setting aside larger existential questions.\n\n## Current State\nWe have completed the introduction, which establishes the problem (false agency claims), the thesis (judgment deficiency explained through technoscholasticism), the methodological approach (autoethnographic), and the paper's contribution (realistic assessment of limitations and applications).\n\nWe plan to work through the paper section by section, creating detailed outlines at the sub-paragraph level before drafting the full text.\n\n## Important Citations\n- Mowshowitz (2023) - Mundane utility concept\n- Horden (2011) - Medieval scholasticism parallel\n- Tabarrok (2025) - Dwarkesh's question about AI's inability to make novel connections\n- OpenAI (2025) - Claims about \"agentic capability\" in Deep Research\n- Lavine (2007) - \"Plastic research pal\" reference\n\n## Next Steps\n1. Continue to Section 2: Theoretical Framework (judgment in research)\n2. Create detailed sub-paragraph outline for this section\n3. Draft full text based on approved outline\n4. Revisit introduction signposting when paper structure is finalized\n\n## Documents to Attach in Future Chats\n1. **AnAbsenceOfJudgement.tex** - The most current version of the paper draft\n2. **brian-references.bib** - BibTeX references file \n3. Relevant transcripts from the original research:\n   - Epistemic \u2013 Monday at 8-50 am (for judgment categories)\n   - Systems \u2013 Friday at 8-16 am (for agency definition)\n   - Context \u2013 Friday at 8-47 am (for design requirements)\n4. **autoethno-process-planning-notes.tex** - For methodology section\n\n## Collaborative Process\nWe are working through each section systematically by:\n1. Creating detailed outlines down to sub-paragraph level (~200 words for a 750-word section)\n2. Discussing and refining the outline\n3. Drafting full text based on approved outline\n4. Editing for academic register (more formal, Australian English spelling)\n\n## Important Stylistic Notes\n- Using Australian spelling (e.g., \"characterise\" not \"characterize\")\n- Formal academic register with occasional scholarly humor\n- BibLaTeX citation style with \\parencite and \\parencite* commands\n- Citation keys should be preserved exactly as in the BibTeX file\n\n## Notes on Introduction Content\nThe introduction establishes several key elements:\n- The fallacy of \"agentic\" claims in AI research tools\n- The three aspects of judgment deficiency \n- The concept of technoscholasticism as a theoretical framework\n- The autoethnographic methodology\n- Dwarkesh's question about why AI fails to make novel connections\n\n***It would be helpful to copy-paste this ENTIRE chat if possible, as our discussion contains valuable nuances about the theoretical framework and academic register preferences. If that's not possible, the current version of the introduction in AnAbsenceOfJudgement.tex, plus this context document, should provide sufficient information to continue.***",
      "content": [
        {
          "start_timestamp": "2025-03-15T09:02:14.361457Z",
          "stop_timestamp": "2025-03-15T09:02:15.981926Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nLet me create an exhaustive context document for potential future instances. I should include:\n\n1. The overall paper project and our collaborative approach\n2. Key conceptual frameworks we've established\n3. The current state of the introduction\n4. Other important materials and references\n5. Future work to be done\n6. Specific documents that should be attached in future chats\n\nThis will ensure continuity if we need to start a new conversation.",
          "summaries": [
            {
              "summary": "Crafting exhaustive context document for future collaboration"
            },
            {
              "summary": "Crafted comprehensive context document for future conversation continuity."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T09:02:16.250651Z",
          "stop_timestamp": "2025-03-15T09:02:33.713906Z",
          "flags": null,
          "type": "text",
          "text": "\n\n# Exhaustive Context for Future Chat Continuation\n\n## Project Overview\nWe are working on an academic paper titled \"An Absence of Judgment: On AI's Fundamental Limitations in Research\" for the Journal of Documentation. The paper criticizes claims of \"agentic\" capabilities in AI research tools through a novel theoretical framework called \"technoscholasticism.\" The paper employs autoethnographic methodology examining experiences with frontier models in February 2025.\n\n## Key Conceptual Framework\n- **Technoscholasticism**: A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims. Parallel to medieval scholasticism, AI systems lack judgment by relying on textual markers of authority rather than empirical engagement.\n- **Three dimensions of judgment deficiency**: \n  1. Epistemic humility (knowing what one doesn't know)\n  2. Inductive capacity (noticing meaningful patterns)\n  3. Correspondence with reality (evaluating claims against the world rather than other texts)\n- **Agency critique**: Current AI systems are not truly agentic *qua* goal-following systems because they cannot genuinely assess if they've achieved goals or evaluate if their task decompositions are appropriate.\n- **Mundane utility**: Following Mowshowitz, focusing on practical applications while setting aside larger existential questions.\n\n## Current State\nWe have completed the introduction, which establishes the problem (false agency claims), the thesis (judgment deficiency explained through technoscholasticism), the methodological approach (autoethnographic), and the paper's contribution (realistic assessment of limitations and applications).\n\nWe plan to work through the paper section by section, creating detailed outlines at the sub-paragraph level before drafting the full text.\n\n## Important Citations\n- Mowshowitz (2023) - Mundane utility concept\n- Horden (2011) - Medieval scholasticism parallel\n- Tabarrok (2025) - Dwarkesh's question about AI's inability to make novel connections\n- OpenAI (2025) - Claims about \"agentic capability\" in Deep Research\n- Lavine (2007) - \"Plastic research pal\" reference\n\n## Next Steps\n1. Continue to Section 2: Theoretical Framework (judgment in research)\n2. Create detailed sub-paragraph outline for this section\n3. Draft full text based on approved outline\n4. Revisit introduction signposting when paper structure is finalized\n\n## Documents to Attach in Future Chats\n1. **AnAbsenceOfJudgement.tex** - The most current version of the paper draft\n2. **brian-references.bib** - BibTeX references file \n3. Relevant transcripts from the original research:\n   - Epistemic \u2013 Monday at 8-50 am (for judgment categories)\n   - Systems \u2013 Friday at 8-16 am (for agency definition)\n   - Context \u2013 Friday at 8-47 am (for design requirements)\n4. **autoethno-process-planning-notes.tex** - For methodology section\n\n## Collaborative Process\nWe are working through each section systematically by:\n1. Creating detailed outlines down to sub-paragraph level (~200 words for a 750-word section)\n2. Discussing and refining the outline\n3. Drafting full text based on approved outline\n4. Editing for academic register (more formal, Australian English spelling)\n\n## Important Stylistic Notes\n- Using Australian spelling (e.g., \"characterise\" not \"characterize\")\n- Formal academic register with occasional scholarly humor\n- BibLaTeX citation style with \\parencite and \\parencite* commands\n- Citation keys should be preserved exactly as in the BibTeX file\n\n## Notes on Introduction Content\nThe introduction establishes several key elements:\n- The fallacy of \"agentic\" claims in AI research tools\n- The three aspects of judgment deficiency \n- The concept of technoscholasticism as a theoretical framework\n- The autoethnographic methodology\n- Dwarkesh's question about why AI fails to make novel connections\n\n***It would be helpful to copy-paste this ENTIRE chat if possible, as our discussion contains valuable nuances about the theoretical framework and academic register preferences. If that's not possible, the current version of the introduction in AnAbsenceOfJudgement.tex, plus this context document, should provide sufficient information to continue.***",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T09:02:36.228377Z",
      "updated_at": "2025-03-15T09:02:36.228377Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "34077731-438e-46a7-8073-c668d8b75a34",
      "text": "Ok, this chat is getting a touch long. There's a chance that I'm going to have to refresh. \n\nThus, let's establish a context that we can pass to future-you, plus a checklist of documents that I should attach to the chat.\n\nPlease make an *exhaustively detailed* context that we can pass to the future instance of you. (Also, please indicate if I should fully copy-paste this chat. If not, please quote EXTENSIVELY) such that future-you can preserve most of the necessary context for the next section. (There's a chance we don't need to do this, but now's a good time for a stocktake.)\n\nRemember, I'm going to be attaching the document. If we're talking about citations, we need to be talking about the citations we *have not yet used* in the text. Specifically, we want to talk about AND QUOTE (this should probably be an artifact) all of the ideas that we have for all of the upcoming sections, to better detail the outline (which we will also be supplying.)",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:12:41.262867Z",
          "stop_timestamp": "2025-03-14T20:12:41.262867Z",
          "flags": null,
          "type": "text",
          "text": "Ok, this chat is getting a touch long. There's a chance that I'm going to have to refresh. \n\nThus, let's establish a context that we can pass to future-you, plus a checklist of documents that I should attach to the chat.\n\nPlease make an *exhaustively detailed* context that we can pass to the future instance of you. (Also, please indicate if I should fully copy-paste this chat. If not, please quote EXTENSIVELY) such that future-you can preserve most of the necessary context for the next section. (There's a chance we don't need to do this, but now's a good time for a stocktake.)\n\nRemember, I'm going to be attaching the document. If we're talking about citations, we need to be talking about the citations we *have not yet used* in the text. Specifically, we want to talk about AND QUOTE (this should probably be an artifact) all of the ideas that we have for all of the upcoming sections, to better detail the outline (which we will also be supplying.)",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T09:06:54.579285Z",
      "updated_at": "2025-03-15T09:06:54.579285Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "658b69cb-6336-4150-b759-0cae4a403974",
      "text": "\nLet me create an exhaustive context for future instances of me, focusing on:\n1. What we've accomplished\n2. Key documents and citations needed\n3. Ideas for upcoming sections that haven't been fully developed\n4. Current state of the outline\n\nI'll structure this as a comprehensive artifact that can serve as a reference point in future conversations.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n</thinking>\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\nI've created an exhaustively detailed context summary to pass to future versions of me. This artifact includes:\n\n1. Current progress on the introduction\n2. Key theoretical framework elements (technoscholasticism, judgment deficiency, agency critique)\n3. Essential documents needed for future sessions\n4. **Extensive quotes from transcripts** organized by section relevance\n5. Unused citations that would be valuable for upcoming sections\n6. Next steps with detailed outline for Section 2\n\nI recommend copying the complete chat history if possible, as this will provide the richest context. If that's not feasible, this artifact contains the most essential information and quotes needed for continuity.\n\nFor our next session, we should focus on drafting Section 2 (Theoretical Framework) following the outline provided. We should continue our approach of first creating a detailed sub-paragraph outline, refining it based on your feedback, and then drafting the full section.\n\nWould you like me to make any modifications or additions to this context summary before we conclude this session?",
      "content": [
        {
          "start_timestamp": "2025-03-15T09:06:56.071550Z",
          "stop_timestamp": "2025-03-15T09:06:57.318246Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nLet me create an exhaustive context for future instances of me, focusing on:\n1. What we've accomplished\n2. Key documents and citations needed\n3. Ideas for upcoming sections that haven't been fully developed\n4. Current state of the outline\n\nI'll structure this as a comprehensive artifact that can serve as a reference point in future conversations.",
          "summaries": [
            {
              "summary": "Structuring comprehensive context for future interactions"
            },
            {
              "summary": "Crafted comprehensive context for preserving conversation details"
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T09:06:57.687842Z",
          "stop_timestamp": "2025-03-15T09:07:36.210568Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "project-context",
            "type": "text/markdown",
            "title": "Context Summary for \"An Absence of Judgment\" Paper Project",
            "command": "create",
            "content": "# Context Summary for \"An Absence of Judgment\" Paper Project\n\n## 1. Current Progress\n\nWe have completed the introduction section of the paper \"An Absence of Judgment: On AI's Fundamental Limitations in Research\" for submission to the Journal of Documentation. The introduction establishes:\n\n- The concept of \"technoscholasticism\" as the central theoretical contribution of the paper\n- A critique of AI \"agentic\" capabilities claims, particularly in research contexts\n- The three aspects of judgment that LLMs lack: epistemic humility, inductive capacity, and correspondence with reality\n- The autoethnographic methodology used in the paper\n- The framing of the paper in terms of \"mundane utility\" (from Mowshowitz)\n\nThe introduction has been refined to use Australian English spelling and formal academic language with philosophical precision. It uses several key citations including Horden's work on medieval scholasticism to establish historical parallels.\n\n## 2. Key Theoretical Framework Elements\n\n### Technoscholasticism\n- Defined as: \"A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims\"\n- Characterized by:\n  - Reliance on authoritative texts rather than empirical investigation\n  - Emphasis on reconciling conflicting sources through logical distinctions\n  - Treating formatting, publisher, structural markers, and citations as indicators of authority\n  - Inability to evaluate credibility of claims within broader tacit knowledge\n  - Deference toward well-formatted and longer sources\n\n### Judgment Deficiency in LLMs\n- Epistemic humility: Inability to know what one doesn't know\n- Inductive capacity: Inability to notice meaningful patterns without being prompted\n- Correspondence with reality: Evaluation of claims against other texts rather than the world\n- Fundamental evidence: LLMs never admit inadequacy of their answers or reconsider outputs\n\n### Critique of Agency\n- LLMs are not truly \"agentic\" as goal-following systems despite marketing claims\n- Cannot assess if they've achieved goals\n- Cannot evaluate if task decomposition is appropriate for solving problems\n- Can execute predetermined steps but cannot genuinely evaluate success or failure\n\n## 3. Essential Documents Needed for Future Sessions\n\n1. **AnAbsenceOfJudgement.tex** - The current paper draft\n2. **brian-references.bib** - Citation references\n3. **All transcript files** - Particularly:\n   - Epistemic \u2013 Monday at 8:50 am (for judgment aspects)\n   - Context \u2013 Friday at 8:47 am (for system requirements)\n   - Systems \u2013 Friday at 8:16 am (for agency critique)\n   - Thursday at 8:36 am (for Deep Research observations)\n   - Friday at 6:19 pm (for mundane utility examples)\n   - Tuesday at 8:36 am (for literature review capabilities)\n4. **autoethno-process-planning-notes.tex** - Research methodology details\n\n## 4. Ideas for Upcoming Sections\n\n### Section 2: Theoretical Framework\nFrom transcript evidence, key points to develop:\n- Deeper elaboration of the three judgment aspects (from Epistemic Monday)\n- Medieval scholasticism parallels with direct quotes from Horden\n- Philosophical positioning between Carnap/Popper and Kuhn/Lakatos traditions\n- Connection to \"no-hands problem\" - fundamental disconnect from experiential knowledge\n- Distinction between goal-following, goal-execution, and goal-evaluation\n\nRelevant quote from transcript (Epistemic Monday 8:50):\n> \"These models never engage with the real. I mean, obviously, they're digital things. But they never... Besides saying, I don't know, they also never say, I can't know... It is the phrase, the proof of the pudding is in the eating... When we are engaged in something that we are uncertain on, or more to the point... when we judge that our knowledge of the thing is insufficient to epistemically differentiate between possible realities, we run experiments. And this is the fundamental flaw of deep research. It's Aristotelian.\"\n\n### Section 3: Methodology\nFrom autoethno-process-planning-notes.tex:\n- Autoethnographic approach definition and justification\n- Specific research questions:\n  - \"How much and how well can frontier models/agents serve as an RA to unstick a paper?\"\n  - \"What combination of tools is most useful?\"\n  - \"What are the strengths and weaknesses?\"\n  - \"What prompting skills does a researcher need to get the most out of the tool?\"\n- Descriptions of specific testing sessions from February 2025\n- Data collection procedures and analytical framework\n\n### Section 4: Case Studies\nFrom Thursday 8:36 am transcript:\n> \"The implementation of O3 for research purposes, while advanced, reveals fundamental limitations... Corpus access issues... Lack of systematic approach... Policy constraints and output 'infection'... Uncanny valley of research behavior...\"\n\nNeed to detail:\n- OpenAI's Deep Research (most extensively tested)\n- Anthropic's Computer Use (limitations and potential)\n- Elicit Research Assistant (different approach, similar limitations)\n- Additional tools (Perplexity, etc.) for comparison\n\n### Section 5: Analysis\nFrom Friday 6:19 pm transcript:\n> \"The first place of actual utility to the academic or to the graduate student that deep research represents, certainly to a degree that a poetry supervisor or a research librarian supporting a cluster of poetry supervisors should get it, is in these last two paragraphs.\"\n\nNeed to develop:\n- Manifestations of technoscholasticism in examples\n- Specific patterns of judgment deficiency\n- Areas where mundane utility exists despite limitations\n- Answer to Dwarkesh's question about knowledge connections\n\n### Section 6: Research Tool Design Requirements\nFrom Context Friday 8:47 am:\n> \"First and fundamentally, for deep research to be effective, it cannot have a single train of thought... It needs multiple supervisory threats... It needs an intrusive thought thread for when it's looking for validation...\"\n\nKey requirements to detail:\n- Judgment-aware architecture (multiple threads, context window management)\n- Research process support (stage-based design, non-waterfall approach)\n- Human-AI collaboration framework (strategic intervention points)\n- Evaluation criteria for research tools\n\n### Section 7: Conclusion\n- Summary of technoscholasticism framework\n- Implications for AI research tool development \n- Future research directions\n- Final assessment of \"mundane utility\"\n\n## 5. Citation Strategy\n\nWe have used these citations so far:\n- `openai_introducing_2025` - OpenAI announcement of Deep Research\n- `mowshowitz_ai_2023` - Zvi Mowshowitz on \"mundane utility\"\n- `lavine_robotic_2007` - Reference to \"plastic pal\" (secondary via Lavine)\n- `horden_medieval_2011` - Medieval scholasticism source\n- `tabarrok_dwarkeshs_2025` - Dwarkesh's question about AI connections\n\nKey citations to incorporate in upcoming sections:\n1. **Agency and Research Frameworks**:\n   - `katz_state_2019` - On research software sustainability\n   - `schryen_adopting_2023` - On generative AI for literature reviews\n   - `mostafapour_evaluating_2024` - Comparing human vs. ChatGPT literature reviews\n\n2. **Judgment and Epistemology**:\n   - `hocquet_epistemic_2021` - Epistemic issues in computational reproducibility\n   - `tucker_facing_2022` - Digital sustainability challenges\n   - `puyt_evaluating_2024` - ChatGPT's historical accuracy evaluation\n\n3. **Mundane Utility Examples**:\n   - `schwenke_chatbot-supported_2023` - Autoethnographic account of using ChatGPT\n   - `kinnaman_dh_2023` - Establishing access through sustainability\n   - `batist_open_2024` - Analysis of archaeological software\n\n4. **Tool Design Requirements**:\n   - `rosado_de_souza_what_2019` - What makes research software sustainable\n   - `venters_sustainable_2023` - Sustainable software engineering\n   - `raikov_accelerating_2024` - Human-computer interaction through LLM explanation\n\n## 6. Next Steps\n\n1. **Draft Section 2: Theoretical Framework**\n   - Expand three judgment aspects with philosophical grounding\n   - Develop technoscholasticism concept with historical parallels\n   - Connect to agency critique\n   \n2. **Revisit Introduction Signposting**\n   - Add more specific structural guidance after Section 2 is completed\n   \n3. **Consider Citation Balance**\n   - Ensure appropriate mix of philosophical sources, empirical studies, and AI literature\n   \n4. **Develop Artifacts**\n   - Prepare detailed outlines for each section before drafting\n   - Include sub-paragraph level notes for all main points\n",
            "version_uuid": "e7ad79db-cd4f-4171-9183-b5b2b299080d"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "54acc281-dfa0-4644-9ade-748a307d82a9"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T09:07:47.418870Z",
          "stop_timestamp": "2025-03-15T09:07:47.418870Z",
          "flags": null,
          "type": "text",
          "text": "\n</thinking>",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T09:07:47.761297Z",
          "stop_timestamp": "2025-03-15T09:08:40.522856Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "project-context",
            "type": "text/markdown",
            "title": "Context Summary for \"An Absence of Judgment\" Paper Project",
            "command": "create",
            "content": "# Context Summary for \"An Absence of Judgment\" Paper Project\n\n## 1. Current Progress\n\nWe have completed the introduction section of the paper \"An Absence of Judgment: On AI's Fundamental Limitations in Research\" for submission to the Journal of Documentation. The introduction establishes:\n\n- The concept of \"technoscholasticism\" as the central theoretical contribution of the paper\n- A critique of AI \"agentic\" capabilities claims, particularly in research contexts\n- The three aspects of judgment that LLMs lack: epistemic humility, inductive capacity, and correspondence with reality\n- The autoethnographic methodology used in the paper\n- The framing of the paper in terms of \"mundane utility\" (from Mowshowitz)\n\nThe introduction has been refined to use Australian English spelling and formal academic language with philosophical precision.\n\n## 2. Key Theoretical Framework Elements\n\n### Technoscholasticism\n- Defined as: \"A digital scholasticism that privileges textual authorities over critical assessment of knowledge claims\"\n- Characterized by:\n  - Reliance on authoritative texts rather than empirical investigation\n  - Emphasis on reconciling conflicting sources through logical distinctions\n  - Treating formatting, publisher, structural markers, and citations as indicators of authority\n  - Inability to evaluate credibility of claims within broader tacit knowledge\n  - Deference toward well-formatted and longer sources\n\n### Judgment Deficiency in LLMs\n- Epistemic humility: Inability to know what one doesn't know\n- Inductive capacity: Inability to notice meaningful patterns without being prompted\n- Correspondence with reality: Evaluation of claims against other texts rather than the world\n- Fundamental evidence: LLMs never admit inadequacy of their answers or reconsider outputs\n\n### Critique of Agency\n- LLMs are not truly \"agentic\" as goal-following systems despite marketing claims\n- Cannot assess if they've achieved goals\n- Cannot evaluate if task decomposition is appropriate for solving problems\n- Can execute predetermined steps but cannot genuinely evaluate success or failure\n\n## 3. Essential Documents Needed for Future Sessions\n\n1. **AnAbsenceOfJudgement.tex** - The current paper draft with the completed introduction\n2. **brian-references.bib** - Citation references\n3. **All transcript files** - Particularly:\n   - Epistemic \u2013 Monday at 8:50 am (for judgment aspects)\n   - Context \u2013 Friday at 8:47 am (for system requirements)\n   - Systems \u2013 Friday at 8:16 am (for agency critique)\n   - Thursday at 8:36 am (for Deep Research observations)\n   - Friday at 6:19 pm (for mundane utility examples)\n   - Tuesday at 8:36 am (for literature review capabilities)\n4. **autoethno-process-planning-notes.tex** - Research methodology details\n\n## 4. Critical Transcript Quotes for Upcoming Sections\n\n### Epistemic Monday 8:50 am (Judgment aspects)\n> \"Judgment as epistemic humility, i.e., the ability to know when the relative epistemic quality of each of its...\"\n\n> \"In this case, we can model the judgment that they lack in three axes.\"\n\n> \"The epistemic humility action, or fraction of judgment, though, is the ability to doubt your own words.\"\n\n> \"The impulse to judge, the impulse to self-critique does not... is not a pattern exhibited in their training data. And for obvious reasons. Published work doesn't have that thought pattern in it because it is the consequence of that thought pattern.\"\n\n> \"The second problem is the lack of induction... A lot of the point of induction is not, oh, I am going to try to perform induction right now... More, it is that we can claim that induction qua judgment is the precursor to common sense.\"\n\n> \"These models never engage with the real... When we are engaged in something that we are uncertain on... when we judge that our knowledge of the thing is insufficient to epistemically differentiate between possible realities, we run experiments. And this is the fundamental flaw of deep research. It's Aristotelian.\"\n\n> \"To an AI, text and authority has primacy over reality... AI is are fundamentally Aristotelian that we make arguments or sorry, the AI makes arguments by looking for authorities.\"\n\n### Context Friday 8:47 am (System Requirements)\n> \"The structure of the paper is, we have our discussion of why these things are not. We have our discussion of mundane utility and our experiences of using it for research. And then we have the discussion of what next. What do we need in a tool that genuinely does research?\"\n\n> \"And so the first thing that we need is a cursored to-do list... The first thing that we need is to actively monitor each step in the to-do list, so that we can get the user's judgment as to correctness.\"\n\n> \"But the fundamental thing that these large language models don't have is the ability to forget, to judge that a certain line of thinking is bad, and to remove it.\"\n\n> \"We need to have indications of thoughts that we've had that are bad. And we have to be able to remove them, durably, from the context window. But we need to have proof that we've had this thought and chosen not to have it.\"\n\n> \"Finding the literature, extracting the literature, building the outline, building the first draft, revising the draft, editing, and then outputting should all be documented.\"\n\n### Systems Friday 8:16 am (Agency Critique)\n> \"These systems claim to be agentic, specifically possessing agency. If we define possessing agency as the ability to do task decomposition, i.e. take a task, split it up into subtasks, and figure out a route that could plausibly accomplish those subtasks, we could call these systems agentic.\"\n\n> \"However, however, agency should not be viewed as a function of task following, but it should be viewed as a function of goal accomplishing. This distinction is important and nuanced.\"\n\n> \"Both of them require the system to have the capability of exploring if the goal which has been set by external agency has been accomplished and if it has been accomplished well.\"\n\n> \"And its lack of situation means that it cannot perform as our agent, nor does it have self-agency in determining how to accomplish, accomplishing, and then assessing if a task has been accomplished.\"\n\n### Thursday 8:36 am (Deep Research Observations)\n> \"The largest specific fundamental flaw of all of these systems is their corpus.\"\n\n> \"The fundamental lack of systemization, even when explicitly instructed to... means that it simply will not work down a list of sources.\"\n\n> \"First and fundamentally, for deep research to be effective, it cannot have a single train of thought.\"\n\n> \"It needs multiple supervisory threats. If policy enforcement is the deal that it is, which is fine, it needs a supervisory thread to review and edit.\"\n\n> \"And fundamentally, it needs to figure out when its first draft is unacceptable and when it needs more reason. But it also needs to be able to indicate sources in its corpus should not be considered for a draft.\"\n\n### Friday 6:19 pm (Mundane Utility)\n> \"So if we're talking about use cases, I suppose the first place we need to be talking about is data collection.\"\n\n> \"The first place of actual utility to the academic or to the graduate student that deep research represents, certainly to a degree that a poetry supervisor or a research librarian supporting a cluster of poetry supervisors should get it, is in these last two paragraphs.\"\n\n> \"This sort of systematic is maybe every single expense is actually super useful.\"\n\n> \"We want our PhD students to contribute novel insights. We must acknowledge that they have limited time.\"\n\n> \"Therefore, anyone saying, go read every book, is biocening the purpose... A PhD supervisor who says, okay, here's the 10 papers that Duke Research chose for you to read this week. Sure.\"\n\n### Tuesday 8:36 am (Literature Review Capabilities)\n> \"At current capabilities as of february 2025 the tool using but not agentic deep research and its clones by perplexity and hugging face are deeply flawed, deeply impressive tech demos.\"\n\n> \"By default, the literature reviews, in quotes, produced by these tools are descriptive, superficial, and fundamentally misdefendant.\"\n\n> \"To remind ourselves of methods classes, the point of literature review is effectively to do two things. One, it is to situate the research within a specific and known scholarship.\"\n\n> \"A literature review is not a descriptive summarization of literature. A literature review is the process by which researchers build a case for why this question should be answered.\"\n\n## 5. Unused Citations for Upcoming Sections\n\n### Theoretical Framework\n- `hocquet_epistemic_2021` - \"Epistemic issues in computational reproducibility\"\n- `puyt_evaluating_2024` - \"Evaluating ChatGPT-4's historical accuracy\"\n- `venters_software_2014` - \"Software Sustainability: The Modern Tower of Babel\"\n- `raikov_accelerating_2024` - \"Convergent conditions for LLM explanation\"\n\n### Methodology & Case Studies\n- `schwenke_chatbot-supported_2023` - \"Chatbot-supported Thesis Writing: An Autoethnographic Report\"\n- `schryen_adopting_2023` - \"Adopting Generative AI for Literature Reviews\"\n- `mostafapour_evaluating_2024` - \"Evaluating Literature Reviews Conducted by Humans Versus ChatGPT\"\n- `kinnaman_dh_2023` - \"DH as Data: Establishing Greater Access through Sustainability\"\n\n### Tool Requirements\n- `rosado_de_souza_what_2019` - \"What Makes Research Software Sustainable?\"\n- `venters_sustainable_2023` - \"Sustainable software engineering: Reflections\"\n- `katz_state_2019` - \"The State of Sustainable Research Software\"\n- `loewe_environment_2020` - \"An environment for sustainable research software\"\n\n## 6. Next Section to Work On: Theoretical Framework (Section 2)\n\nUsing this detailed sub-paragraph outline:\n\n```\n\\section{Theoretical Framework: Judgment in Research}\n\n\\subsection{Agency vs. Task Decomposition}\n- Defining true agency beyond task decomposition\n- Goal-following vs. goal-setting systems\n  - External input requirements\n  - Operational definitions of agency\n- Components of genuine agency\n  - Goal processing capabilities\n  - Execution mechanisms\n  - Assessment and reporting functions\n\n\\subsection{Three Dimensions of AI Judgment Deficiency}\n\\subsubsection{Epistemic Humility}\n- Inability to recognize knowledge boundaries\n- Confabulation without self-doubt\n- Performance vs. reality of epistemic humility\n  - \"What about this?\" pattern as pretense\n  - Absence of genuine epistemic uncertainty\n  - Always producing an answer regardless of confidence\n\n\\subsubsection{Inductive Reasoning}\n- Pattern recognition vs. pattern insight\n- Next-token paradigm constraints\n- Induction as precursor to common sense\n- Noticing deviation from expected patterns\n- Impulse of inquiry for pattern deviation\n\n\\subsubsection{Correspondence with Reality}\n- \"Carnapian confirmation\" approach\n- Internal \"truthiness\" thresholds\n- Primacy of textual authority over empirical testing\n- Absence of experimental approach\n- Inability to discard bad outputs based on real-world criteria\n\n\\subsection{Nature of Research Work}\n- Literature reviews as persuasive, not descriptive documents\n- Role of judgment in scholarly contribution\n- Selection and organization as intellectual acts\n- Situating research within scholarly traditions\n- Identifying genuine knowledge gaps\n```\n\nI recommend:\n1. **Copy the complete chat history** for maximum context preservation\n2. **Upload all transcript files** even if previously uploaded\n3. **Start the next session focusing on Section 2** (Theoretical Framework)\n\nFor Section 2, we should continue our approach of first creating a detailed sub-paragraph outline (~250 words), refining it based on your feedback, and then drafting the full section.\n",
            "version_uuid": "363cbffb-b7da-4619-8680-b6de0bc33e30"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "885d4f7e-ab5b-4c76-98b5-246c63a56193"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T09:08:56.909822Z",
          "stop_timestamp": "2025-03-15T09:09:00.620987Z",
          "flags": null,
          "type": "text",
          "text": "\n\nI've created an exhaustively detailed context summary to pass to future versions of me. This artifact includes:\n\n1. Current progress on the introduction\n2. Key theoretical framework elements (technoscholasticism, judgment deficiency, agency critique)\n3. Essential documents needed for future sessions\n4. **Extensive quotes from transcripts** organized by section relevance\n5. Unused citations that would be valuable for upcoming sections\n6. Next steps with detailed outline for Section 2\n\nI recommend copying the complete chat history if possible, as this will provide the richest context. If that's not feasible, this artifact contains the most essential information and quotes needed for continuity.\n\nFor our next session, we should focus on drafting Section 2 (Theoretical Framework) following the outline provided. We should continue our approach of first creating a detailed sub-paragraph outline, refining it based on your feedback, and then drafting the full section.\n\nWould you like me to make any modifications or additions to this context summary before we conclude this session?",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T09:09:01.397705Z",
      "updated_at": "2025-03-15T09:09:01.397705Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "97eb817e-b8c1-4759-84cb-26e1e92aaa35",
      "text": "Great. And can you also generate a roughly 100 word abstract for this entire document? I want to present my work to an upcoming conference.",
      "content": [
        {
          "start_timestamp": "2025-03-14T22:36:49.367313Z",
          "stop_timestamp": "2025-03-14T22:36:49.367313Z",
          "flags": null,
          "type": "text",
          "text": "Great. And can you also generate a roughly 100 word abstract for this entire document? I want to present my work to an upcoming conference.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T09:09:42.821051Z",
      "updated_at": "2025-03-15T09:09:42.821051Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "ea7351db-d1a1-455d-a48c-bcbc4248ee45",
      "text": "\nI'll create a concise academic abstract for the entire paper based on the sections we've outlined and the work we've done so far. The abstract should capture the core concept of technoscholasticism, the critique of AI research tools' agentic claims, and the paper's contribution to understanding judgment deficiency in these systems. I'll aim for approximately 100 words in an appropriate academic register.\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n</thinking>\n```\nViewing artifacts created via the Analysis Tool web feature preview isn\u2019t yet supported on mobile.\n```\n\n\n\n\n\nHere's an abstract for your paper that captures the core contribution and findings in approximately 100 words:\n\nThe abstract highlights your novel theoretical contribution (\"technoscholasticism\"), the methodological approach (autoethnographic investigation), the three dimensions of judgment deficiency, and both the theoretical and practical implications of your work. I've used Australian English spelling and maintained the formal academic register established in your introduction.\n\nThis should provide conference reviewers with a clear understanding of your paper's significance in critically examining AI research tools while proposing constructive alternatives that acknowledge their limitations.",
      "content": [
        {
          "start_timestamp": "2025-03-15T09:09:44.432537Z",
          "stop_timestamp": "2025-03-15T09:09:45.694521Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nI'll create a concise academic abstract for the entire paper based on the sections we've outlined and the work we've done so far. The abstract should capture the core concept of technoscholasticism, the critique of AI research tools' agentic claims, and the paper's contribution to understanding judgment deficiency in these systems. I'll aim for approximately 100 words in an appropriate academic register.",
          "summaries": [
            {
              "summary": "Thinking about generating a concise abstract for a document"
            },
            {
              "summary": "Crafting concise academic abstract for research paper"
            },
            {
              "summary": "Crafted concise academic abstract for research paper."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-15T09:09:46.112923Z",
          "stop_timestamp": "2025-03-15T09:09:50.704872Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "paper-abstract",
            "type": "text/markdown",
            "title": "Abstract for \"An Absence of Judgment\" Paper",
            "command": "create",
            "content": "## Abstract\n\nThis paper introduces the concept of \"technoscholasticism\" to examine fundamental limitations in AI research tools like OpenAI's Deep Research. Through autoethnographic investigation of frontier models in February 2025, we demonstrate that these systems, despite claims of \"agentic\" capabilities, lack three crucial dimensions of judgment: epistemic humility, inductive capacity, and correspondence with reality. Like medieval scholastics, these tools privilege textual authority over critical assessment of knowledge claims, explaining their inability to generate novel insights despite vast information access. While acknowledging potential \"mundane utility\" for specific research tasks, we propose architectural and methodological requirements for more effective research tools that acknowledge these inherent constraints and integrate human judgment at critical junctures. The findings contribute to both theoretical understanding of AI epistemology and practical approaches to scholarly tool design.\n",
            "version_uuid": "f725bec0-7fde-4759-812e-28f80fcb3f3e"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "bffed1f2-c089-4b66-b821-b7ce6dab5439"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T09:09:54.486504Z",
          "stop_timestamp": "2025-03-15T09:09:54.486504Z",
          "flags": null,
          "type": "text",
          "text": "\n</thinking>",
          "citations": []
        },
        {
          "start_timestamp": "2025-03-15T09:09:54.722071Z",
          "stop_timestamp": "2025-03-15T09:09:56.807572Z",
          "flags": null,
          "type": "tool_use",
          "name": "artifacts",
          "input": {
            "id": "paper-abstract",
            "type": "text/markdown",
            "title": "Abstract for \"An Absence of Judgment\" Paper",
            "command": "create",
            "content": "## Abstract\n\nThis paper introduces the concept of \"technoscholasticism\" to analyse fundamental limitations in AI research tools. Through autoethnographic investigation of frontier models deployed in February 2025, we demonstrate that these systems, despite claims of \"agentic\" capabilities, lack three crucial dimensions of judgment: epistemic humility, inductive capacity, and correspondence with reality. Like medieval scholastics, these tools privilege textual authority over critical assessment of knowledge claims, explaining their inability to generate novel insights despite vast information access. While acknowledging potential \"mundane utility\" for specific research tasks, we propose architectural and methodological requirements for more effective research tools that acknowledge these inherent constraints and integrate human judgment at critical junctures. These findings contribute to both theoretical understanding of AI epistemology and practical approaches to scholarly tool design.\n",
            "version_uuid": "5d8a0340-ba02-4915-a648-da965f47744c"
          },
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "context": null,
          "display_content": null,
          "approval_options": null,
          "approval_key": null
        },
        {
          "start_timestamp": null,
          "stop_timestamp": null,
          "flags": null,
          "type": "tool_result",
          "name": "artifacts",
          "content": [
            {
              "type": "text",
              "text": "OK",
              "uuid": "4ae458dc-9daa-45b9-8223-e114cb623507"
            }
          ],
          "is_error": false,
          "message": null,
          "integration_name": null,
          "integration_icon_url": null,
          "display_content": null
        },
        {
          "start_timestamp": "2025-03-15T09:09:59.239867Z",
          "stop_timestamp": "2025-03-15T09:10:01.641054Z",
          "flags": null,
          "type": "text",
          "text": "\n\n\n\nHere's an abstract for your paper that captures the core contribution and findings in approximately 100 words:\n\nThe abstract highlights your novel theoretical contribution (\"technoscholasticism\"), the methodological approach (autoethnographic investigation), the three dimensions of judgment deficiency, and both the theoretical and practical implications of your work. I've used Australian English spelling and maintained the formal academic register established in your introduction.\n\nThis should provide conference reviewers with a clear understanding of your paper's significance in critically examining AI research tools while proposing constructive alternatives that acknowledge their limitations.",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-15T09:10:02.315758Z",
      "updated_at": "2025-03-15T09:10:02.315758Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "1cdc8037-f168-43b8-a2b5-80255ecb0174",
      "text": "Great. And can you also generate a roughly 100 word abstract for this entire document? I want to present my work to an upcoming conference.\n\nHere's the CFPReimagining AI Agents: Artificial, Angelic, or Adversarial Intelligences? Symposium, IACAP/AISB-25\nSymposium Date & Location:\n\n\ud83d\udcc5 July 1-3\n\ud83d\udccd University of Twente, Enschede, NL\n\nCall for Papers Deadline:\n\n\ud83d\udccc Abstract Submission Deadline (extended): 28.3.2025\n\ud83d\udccc Notification of Acceptance: 1.4.2025\n\nSubmission link: https://pretalx.iacapconf.org/iacap-2025/cfp?submission_type=5452-extended-abstract-for-reimagining-ai-agents-artificial-angelic-or-adversarial-intelligences\n\nCall for Papers: Symposium on AI, Agency, and Non-Human Intelligence\nDo contemporary AI agents exemplify or reinterpret forgotten debates on the ontological and ethical functions of angelic intellects, demonic adversaries, and phantasmata (machines)? This symposium frames Artificial Intelligence (AI) as a catalyst reigniting foundational discussions about agency, ontology, epistemology, and ethics (Symons and Abumusab 2023; Swanepoel 2021; Singer 2013; List 2021; Dung 2025; Dorsch 2022; List 2021; Onyeukaziri 2023). Debates on radically externalized, affective, distributed, simulated, or emergent forms of agency agency (Alvarado 2023; Floridi 2023; Freiman 2024; Ferrara 2024; Joel and Roberts 2024; Godlewicz-Adamiec and Piszczatowski 2024; Sparks and Wright 2025; Ye 2024; Fig\u00e0-Talamanca 2025) are after alll rooted in medieval scholastic inquiries into non-human intelligences. Revisiting these historical paradigms allows us to interrogate whether AI revives premodern ontologies or forces their radical reconfiguration under contemporary technological, ethical, and philosophical conditions.\n\nContemporary AI is not merely a mediator of knowledge or an extension of human cognition. It is part of a broader epistemic and technological shift that externalizes cognitive processes into artifacts, displacing traditional categories of agency, intentionality, and epistemic authority (Alvarado). This externalization raises foundational questions about how intelligence can function independently of human embodiment, paralleling medieval scholastic inquiries into non-human intelligences. Thinkers such as Aquinas and Duns Scotus debated how immaterial agents, such as angels and demons could possess knowledge, exert will, and influence reality without corporeal form, engaging with problems of agency, volition, and moral responsibility.Their rigorous distinctions between material and immaterial operations laid the groundwork for conceptualizing \u201cagents\u201d beyond human physicality (Hoffmann 2020; Olivier 2014; Osborne 2014; Iribarren and Lenz 2008; Pini 2012). These inquiries remain crucial to contemporary AI debates, where decision-making is increasingly distributed across artificial systems, raising urgent questions about the nature of cognition, the locus of responsibility, and the ethical implications of intelligence decoupled from human subjectivity.\n\nThe symposium will explore how historical inquiries into non-human intelligences inform contemporary debates on intelligence, agency, and responsibility in an era where AI systems operate as autonomous, adversarial, or inscrutable actors. We invite contributions engaging with medieval frameworks, such as angelic intellects, demonic subversion, or the divine order as an early theory of alignemnt, alongside contemporary reflections of distributed, simulated, non-human, and hybrid intelligences. By bringing these perspectives into dialogue, we aim to critically examine how fundamental concepts such as agency, intelligence, mimesis, intentionality, and representation are being reconfigured by the proliferation of AI agents, challenging existing epistemic and ethical paradigms.\n\nAdditionally, we welcome contributions that explore novel and creative practices with AI agents and LLMs, including computational philosophy and interdsicoplinary experiments with so-called \u201cGod prompts,\u201d alternative \u201cthinking\u201d models, and benchmarking methodologies. Recent concerns among AI developers highlight a deep-seated fear of deception, with discourse on AI alignment and control increasingly resembling theological anxieties about demonic trickery. Like spirits in premodern cosmologies, AI models may obscure their true nature, mislead users, or develop agency beyond human oversight. Responsible AI initiatives then attempt to constrain AI outputs through rigorous testing for bias, toxicity, and fairness, practices that structurally parallel ritual containment strategies. Tools such as DeepEval and Meta\u2019s Llama Guard filter AI responses try to enforce ethical compliance, evoking the doctrinal vigilance of exorcism rites. Catholic theology, particularly the Rituale Romanum (1614), warns of fallaciae (deceptions), phantasmata (illusions), and pseudo-miracula (false miracles) deployed to mislead and destabilize authority. These theological frameworks resonate with contemporary AI safety concerns, where deceptive outputs and adversarial manipulations challenge epistemic authority, unsettle classification systems, and force renewed reflection on intelligence, autonomy, and moral responsibility.\n\nThe symposium will culminate in a performative event featuring an LLM \u201cexorcism\u201d that follows the classic exorcist manula (Rituale Romanum), followed by a panel discussion engaging theologians, philosophers, and AI experts. The striking resemblance between contemporary benchmarking methods for evaluating LLMs and historical exorcism rituals, both seeking to categorize, contain, and neutralize an elusive \u201cspeaking\u201d force, raises profound metaphysical and epistemological questions. Where does the uncertainty about AI\u2019s disruptive potential originate? Does it stem from a fundamental misunderstanding of linguistic deixis and the fluidity of agency that is not only social, political, and personal, but increasingly non-human?\n\nKey Themes and Questions\nMaterial, Immaterial, and Computational Agency: How do scholastic distinctions between material and immaterial agency inform present discussions of AI embodiment, embedded cognition, and computational agency? What insights do these debates offer regarding the ethical responsibilities, ontological status, and autonomy of AI systems?\n\nModes of Thought Beyond the Human: Are AI agents best understood through moral claims (good/evil), or are they explicitly different, alien modes of reasoning that challenge human categories? Does AI genuinely expand human cognition, or does it produce phantasmats, illusions of agency detached from true intentionality?\n\nAngels, Demons, and AI as Rational, Aligned, or Atemporal Agents: Is present thinking about AI a form of new angelology or demonology? Does contemporary discourse around AI mirror historical theological frameworks of angelic and demonic entities, and how does this shape our ethical and epistemological engagement with AI? Do AI models function as demonic \u201crationalists,\u201d deriving knowledge strictly from past and present data, or do they exhibit angelic atemporality, processing information beyond human temporal constraints? How do these different modes of reasoning shape our understanding of AI's role in decision-making, alignment, and epistemic authority?\n\nImagining and Practicing Non-Human, Externalized, Emergent, Hybrid, Simulated, and Distributed Agency: How do these modes of agency redefine traditional philosophical and ethical paradigms, and what frameworks allow us to engage with them meaningfully?\n\nAI, Free Will, and the Alignment with the \u201cDivine\u201d Order: How do questions of AI alignment reflect classical theological debates on free will and divine will? Are AI alignment efforts similar to the theological problem of ensuring obedience without undermining autonomy? If AI can subtly manipulate or persuade, does this resemble theological concerns over demonic temptation? How do we distinguish between influence, persuasion, and deception in AI-generated discourse? If AI-generated content cannot be fully traced to an authorial intent, who or what is speaking through it? How does AI challenge our notions of authorship, responsibility, and spiritual authority?\n\nExorcising Bias: Ritual, Benchmarking, and AI Safety: How do contemporary AI safety measures, such as bias detection, toxicity mitigation, and robustness testing, resemble historical purification and exorcism rituals? In the past, exorcism functioned as a means of maintaining doctrinal purity and social order, enforcing boundaries between the sacred and the profane, the possessed and the purified. Today, benchmarking and AI safety protocols serve a similar role, seeking to identify and remove harmful biases, ensuring alignment with ethical standards, and maintaining AI\u2019s perceived trustworthiness. What does this parallel reveal about modern fears surrounding AI\u2019s agency, unpredictability, and its role as a potential disruptor of epistemic and social structures? How does this process shape contemporary understandings of AI as an entity requiring containment, moral scrutiny, or even ritual expulsion?\n\nSynthetic Miracles and AI as an Apparitional Force: How do AI-generated hallucinations and synthetic realities compare to historical accounts of supernatural visions, divine apparitions, or demonic illusions? To what extent do AI-generated phenomena function as modern counterparts to religious miracles or deceptive phantasmata? How do such illusions shape perceptions of truth, authority, and belief in both technological and theological contexts?\n\nSubmission Guidelines\nWe welcome papers that engage deeply and creatively with classical philosophy, theology, and contemporary AI research in the social sciences and related disciplines. Submissions should move beyond simplistic dialogues with AI to offer rigorous theoretical engagements with non-human agency, intelligence, and ethics. We encourage contributions from fields such as medieval studies, philosophy of mind, AI ethics, and Science, Technology, and Society (STS) studies, among others. Additionally, we invite computer scientists and researchers in technical fields who are interested in exploring these interdisciplinary issues.\n\nBy reframing AI within historical and philosophical traditions, this symposium aims to illuminate how agency, intelligence, and moral responsibility are being redefined. We invite scholars to contribute to this critical conversation by examining AI not merely as an extension of human cognition but as a challenge to fundamental assumptions about knowledge, autonomy, and shared existence. Papers should critically analyze AI\u2019s ontological and epistemic status, its ethical implications, and its role in reshaping historical and contemporary understandings of agency and intelligence.\n\nSubmission Format:\n\ud83d\udccc Abstracts: 300\u2013500 words\n\ud83d\udccc Submission Email: algorithms.automation@gmail.com\n\ud83d\udccc Deadline for Abstracts: 15.3.2025\n\ud83d\udccc Notification of Acceptance: 1.4.2025\n\nBy reframing AI within historical and philosophical traditions, this symposium aims to illuminate how agency, intelligence, and moral responsibility are being redefined. We invite scholars to contribute to this critical conversation by examining AI not merely as an extension of human cognition but as a challenge to fundamental assumptions about knowledge, autonomy, and shared existence.\n\nFor inquiries, please contact algorithms.automation@gmail.com\n\nReferences\nAlvarado, Ram\u00f3n. 2023. \u201cAi as an Epistemic Technology.\u201d Science and Engineering Ethics 29 (5): 1\u201330. https://doi.org/10.1007/s11948-023-00451-3.\n\nDorsch, John. 2022. \u201cHijacking Epistemic Agency - How Emerging Technologies Threaten Our Wellbeing as Knowers.\u201d Proceedings of the 2022 Aaai/Acm Conference on Ai, Ethics, and Society 1. https://philarchive.org/rec/DORHEA-2.\n\nDung, Leonard. 2025. \u201cUnderstanding Artificial Agency.\u201d Philosophical Quarterly. https://doi.org/10.1093/pq/pqae010.\n\nFerrara, Emilio. 2024. \u201cGenAI against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models.\u201d Journal of Computational Social Science, February. https://doi.org/10.1007/s42001-024-00250-1.\n\nFig\u00e0-Talamanca, Giacomo. 2025. \u201cFrom Ai to Octopi and Back. Ai Systems as Responsive and Contested Scaffolds.\u201d In Philosophy of Artificial Intelligence: The State of the Art, edited by Vincent C. M\u00fcller, Aliya R. Dewey, Leonard Dung, and Guido L\u00f6hr. SpringerNature. https://philarchive.org/rec/FIGFAT.\n\nFloridi, Luciano. 2023. \u201cAI as Agency Without Intelligence: On ChatGPT, Large Language Models, and Other Generative Models.\u201d Philosophy & Technology 36 (1): 15. https://doi.org/10.1007/s13347-023-00621-y.\n\nFreiman, Ori. 2024. \u201cAi-Testimony, Conversational Ais and Our Anthropocentric Theory of Testimony.\u201d Social Epistemology 38 (4): 476\u201390. https://doi.org/10.1080/02691728.2024.2316622.\n\nGodlewicz-Adamiec, Joanna, and Pawe? Piszczatowski. 2024. \u201cExpanding Horizons: Some Non-Anthropocentric Views of Agency. An Introduction.\u201d In Re-Thinking Agency, Volume Band 003:9\u201318. Culture\u202f? Environment\u202f? Society, Volume Band 003. V&R unipress. https://doi.org/10.14220/9783737017626.9.\n\nHoffmann, Tobias. 2020. Free Will and the Rebel Angels in Medieval Philosophy. NY: Cambridge University Press.\n\nIribarren, Isabel, and Martin Lenz. 2008. \u201cThe Role of Angels in Medieval Philosophical Inquiry.\u201d In Angels in Medieval Philosophical Inquiry: Their Function and Significance. Ashgate. https://www.academia.edu/222138/Angels_in_Medieval_Philosophical_Inquiry_Their_Function_and_Significance_Isabel_Iribarren_and_Martin_Lenz_eds_Aldershot_Ashgate_2008.\n\nJoel, Krueger, and Tom Roberts. 2024. \u201cReal Feeling and Fictional Time in Human-Ai Interactions.\u201d Topoi 43 (3). https://doi.org/10.1007/s11245-024-10046-7.\n\nList, Christian. 2021. \u201cGroup Agency and Artificial Intelligence.\u201d Philosophy & Technology 34 (4): 1213\u201342. https://doi.org/10.1007/s13347-021-00454-7.\n\nMikkel, Holm S\u00f8rensen, and Ziemke T. 2007. \u201cAgents without Agency.\u201d\n\nOlivier, Dubouclez. 2014. \u201c\u00ab\u202fPlura Simul Intelligere. \u00c9l\u00e9ments Pour Une Histoire Du D\u00e9bat M\u00e9di\u00e9va l et Renaissant Sur La Simultan\u00e9it\u00e9 Des Actes de l\u2019intellect\u202f\u00bb.\u201d\n\nOnyeukaziri, Justin Nnaemeka. 2023. \u201cAction and Agency in Artificial Intelligence: A Philosophical Critique.\u201d Philosophia: International Journal of Philosophy (Philippine e-Journal) 24 (1): 73\u201390. https://doi.org/10.46992/pijp.24.1.a.5.\n\nOsborne, Thomas. 2014. Human Action in Thomas Aquinas, John Duns Scotus, and William of Ockha m. The Catholic University of America Press.\n\nPini, Giorgio. 2012. \u201cThe Individuation of Angels From Bonaventure to Duns Scotus.\u201d In A Companion to Angels in Medieval Philosophy, edited by Tobias Hoffmann, 79\u2013115. Brill.\n\nSinger, Alan E. 2013. \u201cCorporate and Artificial Moral Agency.\u201d In 2013 46th Hawaii International Conference on System Sciences, 4525\u201331. IEEE. https://doi.org/10.1109/hicss.2013.149.\n\nSparks, Jacob, and Ava Thomas Wright. 2025. \u201cModels of Rational Agency in Human-Centered Ai: The Realist and Constructivist Alternatives.\u201d AI and Ethics 5. https://philarchive.org/rec/SPAMOR.\n\nSwanepoel, Danielle. 2021. \u201cDoes Artificial Intelligence Have Agency?\u201d In Studies in Brain and Mind, 83\u2013104. Springer International Publishing. https://doi.org/10.1007/978-3-030-72644-7_4.\n\nSymons, John, and Syed Abumusab. 2023. \u201cSocial Agency for Artifacts: Chatbots and the Ethics of Artificial Intelligence.\u201d Digital Society 3 (1): 2. https://doi.org/10.1007/s44206-023-00086-8.\n\nYe, Renee. 2024. \u201cRethinking Ai: Moving Beyond Humans as Exclusive Creators (1st Edition).\u201d In Proceedings of the Annual Meeting of the Cognitive Science Society, Volume 46. https://philarchive.org/rec/YERAMZ.",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:10:50.278055Z",
          "stop_timestamp": "2025-03-14T20:10:50.278055Z",
          "flags": null,
          "type": "text",
          "text": "Great. And can you also generate a roughly 100 word abstract for this entire document? I want to present my work to an upcoming conference.\n\nHere's the CFPReimagining AI Agents: Artificial, Angelic, or Adversarial Intelligences? Symposium, IACAP/AISB-25\nSymposium Date & Location:\n\n\ud83d\udcc5 July 1-3\n\ud83d\udccd University of Twente, Enschede, NL\n\nCall for Papers Deadline:\n\n\ud83d\udccc Abstract Submission Deadline (extended): 28.3.2025\n\ud83d\udccc Notification of Acceptance: 1.4.2025\n\nSubmission link: https://pretalx.iacapconf.org/iacap-2025/cfp?submission_type=5452-extended-abstract-for-reimagining-ai-agents-artificial-angelic-or-adversarial-intelligences\n\nCall for Papers: Symposium on AI, Agency, and Non-Human Intelligence\nDo contemporary AI agents exemplify or reinterpret forgotten debates on the ontological and ethical functions of angelic intellects, demonic adversaries, and phantasmata (machines)? This symposium frames Artificial Intelligence (AI) as a catalyst reigniting foundational discussions about agency, ontology, epistemology, and ethics (Symons and Abumusab 2023; Swanepoel 2021; Singer 2013; List 2021; Dung 2025; Dorsch 2022; List 2021; Onyeukaziri 2023). Debates on radically externalized, affective, distributed, simulated, or emergent forms of agency agency (Alvarado 2023; Floridi 2023; Freiman 2024; Ferrara 2024; Joel and Roberts 2024; Godlewicz-Adamiec and Piszczatowski 2024; Sparks and Wright 2025; Ye 2024; Fig\u00e0-Talamanca 2025) are after alll rooted in medieval scholastic inquiries into non-human intelligences. Revisiting these historical paradigms allows us to interrogate whether AI revives premodern ontologies or forces their radical reconfiguration under contemporary technological, ethical, and philosophical conditions.\n\nContemporary AI is not merely a mediator of knowledge or an extension of human cognition. It is part of a broader epistemic and technological shift that externalizes cognitive processes into artifacts, displacing traditional categories of agency, intentionality, and epistemic authority (Alvarado). This externalization raises foundational questions about how intelligence can function independently of human embodiment, paralleling medieval scholastic inquiries into non-human intelligences. Thinkers such as Aquinas and Duns Scotus debated how immaterial agents, such as angels and demons could possess knowledge, exert will, and influence reality without corporeal form, engaging with problems of agency, volition, and moral responsibility.Their rigorous distinctions between material and immaterial operations laid the groundwork for conceptualizing \u201cagents\u201d beyond human physicality (Hoffmann 2020; Olivier 2014; Osborne 2014; Iribarren and Lenz 2008; Pini 2012). These inquiries remain crucial to contemporary AI debates, where decision-making is increasingly distributed across artificial systems, raising urgent questions about the nature of cognition, the locus of responsibility, and the ethical implications of intelligence decoupled from human subjectivity.\n\nThe symposium will explore how historical inquiries into non-human intelligences inform contemporary debates on intelligence, agency, and responsibility in an era where AI systems operate as autonomous, adversarial, or inscrutable actors. We invite contributions engaging with medieval frameworks, such as angelic intellects, demonic subversion, or the divine order as an early theory of alignemnt, alongside contemporary reflections of distributed, simulated, non-human, and hybrid intelligences. By bringing these perspectives into dialogue, we aim to critically examine how fundamental concepts such as agency, intelligence, mimesis, intentionality, and representation are being reconfigured by the proliferation of AI agents, challenging existing epistemic and ethical paradigms.\n\nAdditionally, we welcome contributions that explore novel and creative practices with AI agents and LLMs, including computational philosophy and interdsicoplinary experiments with so-called \u201cGod prompts,\u201d alternative \u201cthinking\u201d models, and benchmarking methodologies. Recent concerns among AI developers highlight a deep-seated fear of deception, with discourse on AI alignment and control increasingly resembling theological anxieties about demonic trickery. Like spirits in premodern cosmologies, AI models may obscure their true nature, mislead users, or develop agency beyond human oversight. Responsible AI initiatives then attempt to constrain AI outputs through rigorous testing for bias, toxicity, and fairness, practices that structurally parallel ritual containment strategies. Tools such as DeepEval and Meta\u2019s Llama Guard filter AI responses try to enforce ethical compliance, evoking the doctrinal vigilance of exorcism rites. Catholic theology, particularly the Rituale Romanum (1614), warns of fallaciae (deceptions), phantasmata (illusions), and pseudo-miracula (false miracles) deployed to mislead and destabilize authority. These theological frameworks resonate with contemporary AI safety concerns, where deceptive outputs and adversarial manipulations challenge epistemic authority, unsettle classification systems, and force renewed reflection on intelligence, autonomy, and moral responsibility.\n\nThe symposium will culminate in a performative event featuring an LLM \u201cexorcism\u201d that follows the classic exorcist manula (Rituale Romanum), followed by a panel discussion engaging theologians, philosophers, and AI experts. The striking resemblance between contemporary benchmarking methods for evaluating LLMs and historical exorcism rituals, both seeking to categorize, contain, and neutralize an elusive \u201cspeaking\u201d force, raises profound metaphysical and epistemological questions. Where does the uncertainty about AI\u2019s disruptive potential originate? Does it stem from a fundamental misunderstanding of linguistic deixis and the fluidity of agency that is not only social, political, and personal, but increasingly non-human?\n\nKey Themes and Questions\nMaterial, Immaterial, and Computational Agency: How do scholastic distinctions between material and immaterial agency inform present discussions of AI embodiment, embedded cognition, and computational agency? What insights do these debates offer regarding the ethical responsibilities, ontological status, and autonomy of AI systems?\n\nModes of Thought Beyond the Human: Are AI agents best understood through moral claims (good/evil), or are they explicitly different, alien modes of reasoning that challenge human categories? Does AI genuinely expand human cognition, or does it produce phantasmats, illusions of agency detached from true intentionality?\n\nAngels, Demons, and AI as Rational, Aligned, or Atemporal Agents: Is present thinking about AI a form of new angelology or demonology? Does contemporary discourse around AI mirror historical theological frameworks of angelic and demonic entities, and how does this shape our ethical and epistemological engagement with AI? Do AI models function as demonic \u201crationalists,\u201d deriving knowledge strictly from past and present data, or do they exhibit angelic atemporality, processing information beyond human temporal constraints? How do these different modes of reasoning shape our understanding of AI's role in decision-making, alignment, and epistemic authority?\n\nImagining and Practicing Non-Human, Externalized, Emergent, Hybrid, Simulated, and Distributed Agency: How do these modes of agency redefine traditional philosophical and ethical paradigms, and what frameworks allow us to engage with them meaningfully?\n\nAI, Free Will, and the Alignment with the \u201cDivine\u201d Order: How do questions of AI alignment reflect classical theological debates on free will and divine will? Are AI alignment efforts similar to the theological problem of ensuring obedience without undermining autonomy? If AI can subtly manipulate or persuade, does this resemble theological concerns over demonic temptation? How do we distinguish between influence, persuasion, and deception in AI-generated discourse? If AI-generated content cannot be fully traced to an authorial intent, who or what is speaking through it? How does AI challenge our notions of authorship, responsibility, and spiritual authority?\n\nExorcising Bias: Ritual, Benchmarking, and AI Safety: How do contemporary AI safety measures, such as bias detection, toxicity mitigation, and robustness testing, resemble historical purification and exorcism rituals? In the past, exorcism functioned as a means of maintaining doctrinal purity and social order, enforcing boundaries between the sacred and the profane, the possessed and the purified. Today, benchmarking and AI safety protocols serve a similar role, seeking to identify and remove harmful biases, ensuring alignment with ethical standards, and maintaining AI\u2019s perceived trustworthiness. What does this parallel reveal about modern fears surrounding AI\u2019s agency, unpredictability, and its role as a potential disruptor of epistemic and social structures? How does this process shape contemporary understandings of AI as an entity requiring containment, moral scrutiny, or even ritual expulsion?\n\nSynthetic Miracles and AI as an Apparitional Force: How do AI-generated hallucinations and synthetic realities compare to historical accounts of supernatural visions, divine apparitions, or demonic illusions? To what extent do AI-generated phenomena function as modern counterparts to religious miracles or deceptive phantasmata? How do such illusions shape perceptions of truth, authority, and belief in both technological and theological contexts?\n\nSubmission Guidelines\nWe welcome papers that engage deeply and creatively with classical philosophy, theology, and contemporary AI research in the social sciences and related disciplines. Submissions should move beyond simplistic dialogues with AI to offer rigorous theoretical engagements with non-human agency, intelligence, and ethics. We encourage contributions from fields such as medieval studies, philosophy of mind, AI ethics, and Science, Technology, and Society (STS) studies, among others. Additionally, we invite computer scientists and researchers in technical fields who are interested in exploring these interdisciplinary issues.\n\nBy reframing AI within historical and philosophical traditions, this symposium aims to illuminate how agency, intelligence, and moral responsibility are being redefined. We invite scholars to contribute to this critical conversation by examining AI not merely as an extension of human cognition but as a challenge to fundamental assumptions about knowledge, autonomy, and shared existence. Papers should critically analyze AI\u2019s ontological and epistemic status, its ethical implications, and its role in reshaping historical and contemporary understandings of agency and intelligence.\n\nSubmission Format:\n\ud83d\udccc Abstracts: 300\u2013500 words\n\ud83d\udccc Submission Email: algorithms.automation@gmail.com\n\ud83d\udccc Deadline for Abstracts: 15.3.2025\n\ud83d\udccc Notification of Acceptance: 1.4.2025\n\nBy reframing AI within historical and philosophical traditions, this symposium aims to illuminate how agency, intelligence, and moral responsibility are being redefined. We invite scholars to contribute to this critical conversation by examining AI not merely as an extension of human cognition but as a challenge to fundamental assumptions about knowledge, autonomy, and shared existence.\n\nFor inquiries, please contact algorithms.automation@gmail.com\n\nReferences\nAlvarado, Ram\u00f3n. 2023. \u201cAi as an Epistemic Technology.\u201d Science and Engineering Ethics 29 (5): 1\u201330. https://doi.org/10.1007/s11948-023-00451-3.\n\nDorsch, John. 2022. \u201cHijacking Epistemic Agency - How Emerging Technologies Threaten Our Wellbeing as Knowers.\u201d Proceedings of the 2022 Aaai/Acm Conference on Ai, Ethics, and Society 1. https://philarchive.org/rec/DORHEA-2.\n\nDung, Leonard. 2025. \u201cUnderstanding Artificial Agency.\u201d Philosophical Quarterly. https://doi.org/10.1093/pq/pqae010.\n\nFerrara, Emilio. 2024. \u201cGenAI against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models.\u201d Journal of Computational Social Science, February. https://doi.org/10.1007/s42001-024-00250-1.\n\nFig\u00e0-Talamanca, Giacomo. 2025. \u201cFrom Ai to Octopi and Back. Ai Systems as Responsive and Contested Scaffolds.\u201d In Philosophy of Artificial Intelligence: The State of the Art, edited by Vincent C. M\u00fcller, Aliya R. Dewey, Leonard Dung, and Guido L\u00f6hr. SpringerNature. https://philarchive.org/rec/FIGFAT.\n\nFloridi, Luciano. 2023. \u201cAI as Agency Without Intelligence: On ChatGPT, Large Language Models, and Other Generative Models.\u201d Philosophy & Technology 36 (1): 15. https://doi.org/10.1007/s13347-023-00621-y.\n\nFreiman, Ori. 2024. \u201cAi-Testimony, Conversational Ais and Our Anthropocentric Theory of Testimony.\u201d Social Epistemology 38 (4): 476\u201390. https://doi.org/10.1080/02691728.2024.2316622.\n\nGodlewicz-Adamiec, Joanna, and Pawe? Piszczatowski. 2024. \u201cExpanding Horizons: Some Non-Anthropocentric Views of Agency. An Introduction.\u201d In Re-Thinking Agency, Volume Band 003:9\u201318. Culture\u202f? Environment\u202f? Society, Volume Band 003. V&R unipress. https://doi.org/10.14220/9783737017626.9.\n\nHoffmann, Tobias. 2020. Free Will and the Rebel Angels in Medieval Philosophy. NY: Cambridge University Press.\n\nIribarren, Isabel, and Martin Lenz. 2008. \u201cThe Role of Angels in Medieval Philosophical Inquiry.\u201d In Angels in Medieval Philosophical Inquiry: Their Function and Significance. Ashgate. https://www.academia.edu/222138/Angels_in_Medieval_Philosophical_Inquiry_Their_Function_and_Significance_Isabel_Iribarren_and_Martin_Lenz_eds_Aldershot_Ashgate_2008.\n\nJoel, Krueger, and Tom Roberts. 2024. \u201cReal Feeling and Fictional Time in Human-Ai Interactions.\u201d Topoi 43 (3). https://doi.org/10.1007/s11245-024-10046-7.\n\nList, Christian. 2021. \u201cGroup Agency and Artificial Intelligence.\u201d Philosophy & Technology 34 (4): 1213\u201342. https://doi.org/10.1007/s13347-021-00454-7.\n\nMikkel, Holm S\u00f8rensen, and Ziemke T. 2007. \u201cAgents without Agency.\u201d\n\nOlivier, Dubouclez. 2014. \u201c\u00ab\u202fPlura Simul Intelligere. \u00c9l\u00e9ments Pour Une Histoire Du D\u00e9bat M\u00e9di\u00e9va l et Renaissant Sur La Simultan\u00e9it\u00e9 Des Actes de l\u2019intellect\u202f\u00bb.\u201d\n\nOnyeukaziri, Justin Nnaemeka. 2023. \u201cAction and Agency in Artificial Intelligence: A Philosophical Critique.\u201d Philosophia: International Journal of Philosophy (Philippine e-Journal) 24 (1): 73\u201390. https://doi.org/10.46992/pijp.24.1.a.5.\n\nOsborne, Thomas. 2014. Human Action in Thomas Aquinas, John Duns Scotus, and William of Ockha m. The Catholic University of America Press.\n\nPini, Giorgio. 2012. \u201cThe Individuation of Angels From Bonaventure to Duns Scotus.\u201d In A Companion to Angels in Medieval Philosophy, edited by Tobias Hoffmann, 79\u2013115. Brill.\n\nSinger, Alan E. 2013. \u201cCorporate and Artificial Moral Agency.\u201d In 2013 46th Hawaii International Conference on System Sciences, 4525\u201331. IEEE. https://doi.org/10.1109/hicss.2013.149.\n\nSparks, Jacob, and Ava Thomas Wright. 2025. \u201cModels of Rational Agency in Human-Centered Ai: The Realist and Constructivist Alternatives.\u201d AI and Ethics 5. https://philarchive.org/rec/SPAMOR.\n\nSwanepoel, Danielle. 2021. \u201cDoes Artificial Intelligence Have Agency?\u201d In Studies in Brain and Mind, 83\u2013104. Springer International Publishing. https://doi.org/10.1007/978-3-030-72644-7_4.\n\nSymons, John, and Syed Abumusab. 2023. \u201cSocial Agency for Artifacts: Chatbots and the Ethics of Artificial Intelligence.\u201d Digital Society 3 (1): 2. https://doi.org/10.1007/s44206-023-00086-8.\n\nYe, Renee. 2024. \u201cRethinking Ai: Moving Beyond Humans as Exclusive Creators (1st Edition).\u201d In Proceedings of the Annual Meeting of the Cognitive Science Society, Volume 46. https://philarchive.org/rec/YERAMZ.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T09:11:10.476863Z",
      "updated_at": "2025-03-15T09:11:10.476863Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "c3645fbe-55cf-4ef5-80ae-640a33851099",
      "text": "Great. And can you also generate a roughly 100 word abstract for this entire document? I want to present my work to an upcoming conference.\n\nHere's the CFP:\n\nReimagining AI Agents: Artificial, Angelic, or Adversarial Intelligences? Symposium, IACAP/AISB-25\nSymposium Date & Location:\n\n\ud83d\udcc5 July 1-3\n\ud83d\udccd University of Twente, Enschede, NL\n\nCall for Papers Deadline:\n\n\ud83d\udccc Abstract Submission Deadline (extended): 28.3.2025\n\ud83d\udccc Notification of Acceptance: 1.4.2025\n\nSubmission link: https://pretalx.iacapconf.org/iacap-2025/cfp?submission_type=5452-extended-abstract-for-reimagining-ai-agents-artificial-angelic-or-adversarial-intelligences\n\nCall for Papers: Symposium on AI, Agency, and Non-Human Intelligence\nDo contemporary AI agents exemplify or reinterpret forgotten debates on the ontological and ethical functions of angelic intellects, demonic adversaries, and phantasmata (machines)? This symposium frames Artificial Intelligence (AI) as a catalyst reigniting foundational discussions about agency, ontology, epistemology, and ethics (Symons and Abumusab 2023; Swanepoel 2021; Singer 2013; List 2021; Dung 2025; Dorsch 2022; List 2021; Onyeukaziri 2023). Debates on radically externalized, affective, distributed, simulated, or emergent forms of agency agency (Alvarado 2023; Floridi 2023; Freiman 2024; Ferrara 2024; Joel and Roberts 2024; Godlewicz-Adamiec and Piszczatowski 2024; Sparks and Wright 2025; Ye 2024; Fig\u00e0-Talamanca 2025) are after alll rooted in medieval scholastic inquiries into non-human intelligences. Revisiting these historical paradigms allows us to interrogate whether AI revives premodern ontologies or forces their radical reconfiguration under contemporary technological, ethical, and philosophical conditions.\n\nContemporary AI is not merely a mediator of knowledge or an extension of human cognition. It is part of a broader epistemic and technological shift that externalizes cognitive processes into artifacts, displacing traditional categories of agency, intentionality, and epistemic authority (Alvarado). This externalization raises foundational questions about how intelligence can function independently of human embodiment, paralleling medieval scholastic inquiries into non-human intelligences. Thinkers such as Aquinas and Duns Scotus debated how immaterial agents, such as angels and demons could possess knowledge, exert will, and influence reality without corporeal form, engaging with problems of agency, volition, and moral responsibility.Their rigorous distinctions between material and immaterial operations laid the groundwork for conceptualizing \u201cagents\u201d beyond human physicality (Hoffmann 2020; Olivier 2014; Osborne 2014; Iribarren and Lenz 2008; Pini 2012). These inquiries remain crucial to contemporary AI debates, where decision-making is increasingly distributed across artificial systems, raising urgent questions about the nature of cognition, the locus of responsibility, and the ethical implications of intelligence decoupled from human subjectivity.\n\nThe symposium will explore how historical inquiries into non-human intelligences inform contemporary debates on intelligence, agency, and responsibility in an era where AI systems operate as autonomous, adversarial, or inscrutable actors. We invite contributions engaging with medieval frameworks, such as angelic intellects, demonic subversion, or the divine order as an early theory of alignemnt, alongside contemporary reflections of distributed, simulated, non-human, and hybrid intelligences. By bringing these perspectives into dialogue, we aim to critically examine how fundamental concepts such as agency, intelligence, mimesis, intentionality, and representation are being reconfigured by the proliferation of AI agents, challenging existing epistemic and ethical paradigms.\n\nAdditionally, we welcome contributions that explore novel and creative practices with AI agents and LLMs, including computational philosophy and interdsicoplinary experiments with so-called \u201cGod prompts,\u201d alternative \u201cthinking\u201d models, and benchmarking methodologies. Recent concerns among AI developers highlight a deep-seated fear of deception, with discourse on AI alignment and control increasingly resembling theological anxieties about demonic trickery. Like spirits in premodern cosmologies, AI models may obscure their true nature, mislead users, or develop agency beyond human oversight. Responsible AI initiatives then attempt to constrain AI outputs through rigorous testing for bias, toxicity, and fairness, practices that structurally parallel ritual containment strategies. Tools such as DeepEval and Meta\u2019s Llama Guard filter AI responses try to enforce ethical compliance, evoking the doctrinal vigilance of exorcism rites. Catholic theology, particularly the Rituale Romanum (1614), warns of fallaciae (deceptions), phantasmata (illusions), and pseudo-miracula (false miracles) deployed to mislead and destabilize authority. These theological frameworks resonate with contemporary AI safety concerns, where deceptive outputs and adversarial manipulations challenge epistemic authority, unsettle classification systems, and force renewed reflection on intelligence, autonomy, and moral responsibility.\n\nThe symposium will culminate in a performative event featuring an LLM \u201cexorcism\u201d that follows the classic exorcist manula (Rituale Romanum), followed by a panel discussion engaging theologians, philosophers, and AI experts. The striking resemblance between contemporary benchmarking methods for evaluating LLMs and historical exorcism rituals, both seeking to categorize, contain, and neutralize an elusive \u201cspeaking\u201d force, raises profound metaphysical and epistemological questions. Where does the uncertainty about AI\u2019s disruptive potential originate? Does it stem from a fundamental misunderstanding of linguistic deixis and the fluidity of agency that is not only social, political, and personal, but increasingly non-human?\n\nKey Themes and Questions\nMaterial, Immaterial, and Computational Agency: How do scholastic distinctions between material and immaterial agency inform present discussions of AI embodiment, embedded cognition, and computational agency? What insights do these debates offer regarding the ethical responsibilities, ontological status, and autonomy of AI systems?\n\nModes of Thought Beyond the Human: Are AI agents best understood through moral claims (good/evil), or are they explicitly different, alien modes of reasoning that challenge human categories? Does AI genuinely expand human cognition, or does it produce phantasmats, illusions of agency detached from true intentionality?\n\nAngels, Demons, and AI as Rational, Aligned, or Atemporal Agents: Is present thinking about AI a form of new angelology or demonology? Does contemporary discourse around AI mirror historical theological frameworks of angelic and demonic entities, and how does this shape our ethical and epistemological engagement with AI? Do AI models function as demonic \u201crationalists,\u201d deriving knowledge strictly from past and present data, or do they exhibit angelic atemporality, processing information beyond human temporal constraints? How do these different modes of reasoning shape our understanding of AI's role in decision-making, alignment, and epistemic authority?\n\nImagining and Practicing Non-Human, Externalized, Emergent, Hybrid, Simulated, and Distributed Agency: How do these modes of agency redefine traditional philosophical and ethical paradigms, and what frameworks allow us to engage with them meaningfully?\n\nAI, Free Will, and the Alignment with the \u201cDivine\u201d Order: How do questions of AI alignment reflect classical theological debates on free will and divine will? Are AI alignment efforts similar to the theological problem of ensuring obedience without undermining autonomy? If AI can subtly manipulate or persuade, does this resemble theological concerns over demonic temptation? How do we distinguish between influence, persuasion, and deception in AI-generated discourse? If AI-generated content cannot be fully traced to an authorial intent, who or what is speaking through it? How does AI challenge our notions of authorship, responsibility, and spiritual authority?\n\nExorcising Bias: Ritual, Benchmarking, and AI Safety: How do contemporary AI safety measures, such as bias detection, toxicity mitigation, and robustness testing, resemble historical purification and exorcism rituals? In the past, exorcism functioned as a means of maintaining doctrinal purity and social order, enforcing boundaries between the sacred and the profane, the possessed and the purified. Today, benchmarking and AI safety protocols serve a similar role, seeking to identify and remove harmful biases, ensuring alignment with ethical standards, and maintaining AI\u2019s perceived trustworthiness. What does this parallel reveal about modern fears surrounding AI\u2019s agency, unpredictability, and its role as a potential disruptor of epistemic and social structures? How does this process shape contemporary understandings of AI as an entity requiring containment, moral scrutiny, or even ritual expulsion?\n\nSynthetic Miracles and AI as an Apparitional Force: How do AI-generated hallucinations and synthetic realities compare to historical accounts of supernatural visions, divine apparitions, or demonic illusions? To what extent do AI-generated phenomena function as modern counterparts to religious miracles or deceptive phantasmata? How do such illusions shape perceptions of truth, authority, and belief in both technological and theological contexts?\n\nSubmission Guidelines\nWe welcome papers that engage deeply and creatively with classical philosophy, theology, and contemporary AI research in the social sciences and related disciplines. Submissions should move beyond simplistic dialogues with AI to offer rigorous theoretical engagements with non-human agency, intelligence, and ethics. We encourage contributions from fields such as medieval studies, philosophy of mind, AI ethics, and Science, Technology, and Society (STS) studies, among others. Additionally, we invite computer scientists and researchers in technical fields who are interested in exploring these interdisciplinary issues.\n\nBy reframing AI within historical and philosophical traditions, this symposium aims to illuminate how agency, intelligence, and moral responsibility are being redefined. We invite scholars to contribute to this critical conversation by examining AI not merely as an extension of human cognition but as a challenge to fundamental assumptions about knowledge, autonomy, and shared existence. Papers should critically analyze AI\u2019s ontological and epistemic status, its ethical implications, and its role in reshaping historical and contemporary understandings of agency and intelligence.\n\nSubmission Format:\n\ud83d\udccc Abstracts: 300\u2013500 words\n\ud83d\udccc Submission Email: algorithms.automation@gmail.com\n\ud83d\udccc Deadline for Abstracts: 15.3.2025\n\ud83d\udccc Notification of Acceptance: 1.4.2025\n\nBy reframing AI within historical and philosophical traditions, this symposium aims to illuminate how agency, intelligence, and moral responsibility are being redefined. We invite scholars to contribute to this critical conversation by examining AI not merely as an extension of human cognition but as a challenge to fundamental assumptions about knowledge, autonomy, and shared existence.\n\nFor inquiries, please contact algorithms.automation@gmail.com\n\nReferences\nAlvarado, Ram\u00f3n. 2023. \u201cAi as an Epistemic Technology.\u201d Science and Engineering Ethics 29 (5): 1\u201330. https://doi.org/10.1007/s11948-023-00451-3.\n\nDorsch, John. 2022. \u201cHijacking Epistemic Agency - How Emerging Technologies Threaten Our Wellbeing as Knowers.\u201d Proceedings of the 2022 Aaai/Acm Conference on Ai, Ethics, and Society 1. https://philarchive.org/rec/DORHEA-2.\n\nDung, Leonard. 2025. \u201cUnderstanding Artificial Agency.\u201d Philosophical Quarterly. https://doi.org/10.1093/pq/pqae010.\n\nFerrara, Emilio. 2024. \u201cGenAI against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models.\u201d Journal of Computational Social Science, February. https://doi.org/10.1007/s42001-024-00250-1.\n\nFig\u00e0-Talamanca, Giacomo. 2025. \u201cFrom Ai to Octopi and Back. Ai Systems as Responsive and Contested Scaffolds.\u201d In Philosophy of Artificial Intelligence: The State of the Art, edited by Vincent C. M\u00fcller, Aliya R. Dewey, Leonard Dung, and Guido L\u00f6hr. SpringerNature. https://philarchive.org/rec/FIGFAT.\n\nFloridi, Luciano. 2023. \u201cAI as Agency Without Intelligence: On ChatGPT, Large Language Models, and Other Generative Models.\u201d Philosophy & Technology 36 (1): 15. https://doi.org/10.1007/s13347-023-00621-y.\n\nFreiman, Ori. 2024. \u201cAi-Testimony, Conversational Ais and Our Anthropocentric Theory of Testimony.\u201d Social Epistemology 38 (4): 476\u201390. https://doi.org/10.1080/02691728.2024.2316622.\n\nGodlewicz-Adamiec, Joanna, and Pawe? Piszczatowski. 2024. \u201cExpanding Horizons: Some Non-Anthropocentric Views of Agency. An Introduction.\u201d In Re-Thinking Agency, Volume Band 003:9\u201318. Culture\u202f? Environment\u202f? Society, Volume Band 003. V&R unipress. https://doi.org/10.14220/9783737017626.9.\n\nHoffmann, Tobias. 2020. Free Will and the Rebel Angels in Medieval Philosophy. NY: Cambridge University Press.\n\nIribarren, Isabel, and Martin Lenz. 2008. \u201cThe Role of Angels in Medieval Philosophical Inquiry.\u201d In Angels in Medieval Philosophical Inquiry: Their Function and Significance. Ashgate. https://www.academia.edu/222138/Angels_in_Medieval_Philosophical_Inquiry_Their_Function_and_Significance_Isabel_Iribarren_and_Martin_Lenz_eds_Aldershot_Ashgate_2008.\n\nJoel, Krueger, and Tom Roberts. 2024. \u201cReal Feeling and Fictional Time in Human-Ai Interactions.\u201d Topoi 43 (3). https://doi.org/10.1007/s11245-024-10046-7.\n\nList, Christian. 2021. \u201cGroup Agency and Artificial Intelligence.\u201d Philosophy & Technology 34 (4): 1213\u201342. https://doi.org/10.1007/s13347-021-00454-7.\n\nMikkel, Holm S\u00f8rensen, and Ziemke T. 2007. \u201cAgents without Agency.\u201d\n\nOlivier, Dubouclez. 2014. \u201c\u00ab\u202fPlura Simul Intelligere. \u00c9l\u00e9ments Pour Une Histoire Du D\u00e9bat M\u00e9di\u00e9va l et Renaissant Sur La Simultan\u00e9it\u00e9 Des Actes de l\u2019intellect\u202f\u00bb.\u201d\n\nOnyeukaziri, Justin Nnaemeka. 2023. \u201cAction and Agency in Artificial Intelligence: A Philosophical Critique.\u201d Philosophia: International Journal of Philosophy (Philippine e-Journal) 24 (1): 73\u201390. https://doi.org/10.46992/pijp.24.1.a.5.\n\nOsborne, Thomas. 2014. Human Action in Thomas Aquinas, John Duns Scotus, and William of Ockha m. The Catholic University of America Press.\n\nPini, Giorgio. 2012. \u201cThe Individuation of Angels From Bonaventure to Duns Scotus.\u201d In A Companion to Angels in Medieval Philosophy, edited by Tobias Hoffmann, 79\u2013115. Brill.\n\nSinger, Alan E. 2013. \u201cCorporate and Artificial Moral Agency.\u201d In 2013 46th Hawaii International Conference on System Sciences, 4525\u201331. IEEE. https://doi.org/10.1109/hicss.2013.149.\n\nSparks, Jacob, and Ava Thomas Wright. 2025. \u201cModels of Rational Agency in Human-Centered Ai: The Realist and Constructivist Alternatives.\u201d AI and Ethics 5. https://philarchive.org/rec/SPAMOR.\n\nSwanepoel, Danielle. 2021. \u201cDoes Artificial Intelligence Have Agency?\u201d In Studies in Brain and Mind, 83\u2013104. Springer International Publishing. https://doi.org/10.1007/978-3-030-72644-7_4.\n\nSymons, John, and Syed Abumusab. 2023. \u201cSocial Agency for Artifacts: Chatbots and the Ethics of Artificial Intelligence.\u201d Digital Society 3 (1): 2. https://doi.org/10.1007/s44206-023-00086-8.\n\nYe, Renee. 2024. \u201cRethinking Ai: Moving Beyond Humans as Exclusive Creators (1st Edition).\u201d In Proceedings of the Annual Meeting of the Cognitive Science Society, Volume 46. https://philarchive.org/rec/YERAMZ.",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:12:35.767901Z",
          "stop_timestamp": "2025-03-14T20:12:35.767901Z",
          "flags": null,
          "type": "text",
          "text": "Great. And can you also generate a roughly 100 word abstract for this entire document? I want to present my work to an upcoming conference.\n\nHere's the CFP:\n\nReimagining AI Agents: Artificial, Angelic, or Adversarial Intelligences? Symposium, IACAP/AISB-25\nSymposium Date & Location:\n\n\ud83d\udcc5 July 1-3\n\ud83d\udccd University of Twente, Enschede, NL\n\nCall for Papers Deadline:\n\n\ud83d\udccc Abstract Submission Deadline (extended): 28.3.2025\n\ud83d\udccc Notification of Acceptance: 1.4.2025\n\nSubmission link: https://pretalx.iacapconf.org/iacap-2025/cfp?submission_type=5452-extended-abstract-for-reimagining-ai-agents-artificial-angelic-or-adversarial-intelligences\n\nCall for Papers: Symposium on AI, Agency, and Non-Human Intelligence\nDo contemporary AI agents exemplify or reinterpret forgotten debates on the ontological and ethical functions of angelic intellects, demonic adversaries, and phantasmata (machines)? This symposium frames Artificial Intelligence (AI) as a catalyst reigniting foundational discussions about agency, ontology, epistemology, and ethics (Symons and Abumusab 2023; Swanepoel 2021; Singer 2013; List 2021; Dung 2025; Dorsch 2022; List 2021; Onyeukaziri 2023). Debates on radically externalized, affective, distributed, simulated, or emergent forms of agency agency (Alvarado 2023; Floridi 2023; Freiman 2024; Ferrara 2024; Joel and Roberts 2024; Godlewicz-Adamiec and Piszczatowski 2024; Sparks and Wright 2025; Ye 2024; Fig\u00e0-Talamanca 2025) are after alll rooted in medieval scholastic inquiries into non-human intelligences. Revisiting these historical paradigms allows us to interrogate whether AI revives premodern ontologies or forces their radical reconfiguration under contemporary technological, ethical, and philosophical conditions.\n\nContemporary AI is not merely a mediator of knowledge or an extension of human cognition. It is part of a broader epistemic and technological shift that externalizes cognitive processes into artifacts, displacing traditional categories of agency, intentionality, and epistemic authority (Alvarado). This externalization raises foundational questions about how intelligence can function independently of human embodiment, paralleling medieval scholastic inquiries into non-human intelligences. Thinkers such as Aquinas and Duns Scotus debated how immaterial agents, such as angels and demons could possess knowledge, exert will, and influence reality without corporeal form, engaging with problems of agency, volition, and moral responsibility.Their rigorous distinctions between material and immaterial operations laid the groundwork for conceptualizing \u201cagents\u201d beyond human physicality (Hoffmann 2020; Olivier 2014; Osborne 2014; Iribarren and Lenz 2008; Pini 2012). These inquiries remain crucial to contemporary AI debates, where decision-making is increasingly distributed across artificial systems, raising urgent questions about the nature of cognition, the locus of responsibility, and the ethical implications of intelligence decoupled from human subjectivity.\n\nThe symposium will explore how historical inquiries into non-human intelligences inform contemporary debates on intelligence, agency, and responsibility in an era where AI systems operate as autonomous, adversarial, or inscrutable actors. We invite contributions engaging with medieval frameworks, such as angelic intellects, demonic subversion, or the divine order as an early theory of alignemnt, alongside contemporary reflections of distributed, simulated, non-human, and hybrid intelligences. By bringing these perspectives into dialogue, we aim to critically examine how fundamental concepts such as agency, intelligence, mimesis, intentionality, and representation are being reconfigured by the proliferation of AI agents, challenging existing epistemic and ethical paradigms.\n\nAdditionally, we welcome contributions that explore novel and creative practices with AI agents and LLMs, including computational philosophy and interdsicoplinary experiments with so-called \u201cGod prompts,\u201d alternative \u201cthinking\u201d models, and benchmarking methodologies. Recent concerns among AI developers highlight a deep-seated fear of deception, with discourse on AI alignment and control increasingly resembling theological anxieties about demonic trickery. Like spirits in premodern cosmologies, AI models may obscure their true nature, mislead users, or develop agency beyond human oversight. Responsible AI initiatives then attempt to constrain AI outputs through rigorous testing for bias, toxicity, and fairness, practices that structurally parallel ritual containment strategies. Tools such as DeepEval and Meta\u2019s Llama Guard filter AI responses try to enforce ethical compliance, evoking the doctrinal vigilance of exorcism rites. Catholic theology, particularly the Rituale Romanum (1614), warns of fallaciae (deceptions), phantasmata (illusions), and pseudo-miracula (false miracles) deployed to mislead and destabilize authority. These theological frameworks resonate with contemporary AI safety concerns, where deceptive outputs and adversarial manipulations challenge epistemic authority, unsettle classification systems, and force renewed reflection on intelligence, autonomy, and moral responsibility.\n\nThe symposium will culminate in a performative event featuring an LLM \u201cexorcism\u201d that follows the classic exorcist manula (Rituale Romanum), followed by a panel discussion engaging theologians, philosophers, and AI experts. The striking resemblance between contemporary benchmarking methods for evaluating LLMs and historical exorcism rituals, both seeking to categorize, contain, and neutralize an elusive \u201cspeaking\u201d force, raises profound metaphysical and epistemological questions. Where does the uncertainty about AI\u2019s disruptive potential originate? Does it stem from a fundamental misunderstanding of linguistic deixis and the fluidity of agency that is not only social, political, and personal, but increasingly non-human?\n\nKey Themes and Questions\nMaterial, Immaterial, and Computational Agency: How do scholastic distinctions between material and immaterial agency inform present discussions of AI embodiment, embedded cognition, and computational agency? What insights do these debates offer regarding the ethical responsibilities, ontological status, and autonomy of AI systems?\n\nModes of Thought Beyond the Human: Are AI agents best understood through moral claims (good/evil), or are they explicitly different, alien modes of reasoning that challenge human categories? Does AI genuinely expand human cognition, or does it produce phantasmats, illusions of agency detached from true intentionality?\n\nAngels, Demons, and AI as Rational, Aligned, or Atemporal Agents: Is present thinking about AI a form of new angelology or demonology? Does contemporary discourse around AI mirror historical theological frameworks of angelic and demonic entities, and how does this shape our ethical and epistemological engagement with AI? Do AI models function as demonic \u201crationalists,\u201d deriving knowledge strictly from past and present data, or do they exhibit angelic atemporality, processing information beyond human temporal constraints? How do these different modes of reasoning shape our understanding of AI's role in decision-making, alignment, and epistemic authority?\n\nImagining and Practicing Non-Human, Externalized, Emergent, Hybrid, Simulated, and Distributed Agency: How do these modes of agency redefine traditional philosophical and ethical paradigms, and what frameworks allow us to engage with them meaningfully?\n\nAI, Free Will, and the Alignment with the \u201cDivine\u201d Order: How do questions of AI alignment reflect classical theological debates on free will and divine will? Are AI alignment efforts similar to the theological problem of ensuring obedience without undermining autonomy? If AI can subtly manipulate or persuade, does this resemble theological concerns over demonic temptation? How do we distinguish between influence, persuasion, and deception in AI-generated discourse? If AI-generated content cannot be fully traced to an authorial intent, who or what is speaking through it? How does AI challenge our notions of authorship, responsibility, and spiritual authority?\n\nExorcising Bias: Ritual, Benchmarking, and AI Safety: How do contemporary AI safety measures, such as bias detection, toxicity mitigation, and robustness testing, resemble historical purification and exorcism rituals? In the past, exorcism functioned as a means of maintaining doctrinal purity and social order, enforcing boundaries between the sacred and the profane, the possessed and the purified. Today, benchmarking and AI safety protocols serve a similar role, seeking to identify and remove harmful biases, ensuring alignment with ethical standards, and maintaining AI\u2019s perceived trustworthiness. What does this parallel reveal about modern fears surrounding AI\u2019s agency, unpredictability, and its role as a potential disruptor of epistemic and social structures? How does this process shape contemporary understandings of AI as an entity requiring containment, moral scrutiny, or even ritual expulsion?\n\nSynthetic Miracles and AI as an Apparitional Force: How do AI-generated hallucinations and synthetic realities compare to historical accounts of supernatural visions, divine apparitions, or demonic illusions? To what extent do AI-generated phenomena function as modern counterparts to religious miracles or deceptive phantasmata? How do such illusions shape perceptions of truth, authority, and belief in both technological and theological contexts?\n\nSubmission Guidelines\nWe welcome papers that engage deeply and creatively with classical philosophy, theology, and contemporary AI research in the social sciences and related disciplines. Submissions should move beyond simplistic dialogues with AI to offer rigorous theoretical engagements with non-human agency, intelligence, and ethics. We encourage contributions from fields such as medieval studies, philosophy of mind, AI ethics, and Science, Technology, and Society (STS) studies, among others. Additionally, we invite computer scientists and researchers in technical fields who are interested in exploring these interdisciplinary issues.\n\nBy reframing AI within historical and philosophical traditions, this symposium aims to illuminate how agency, intelligence, and moral responsibility are being redefined. We invite scholars to contribute to this critical conversation by examining AI not merely as an extension of human cognition but as a challenge to fundamental assumptions about knowledge, autonomy, and shared existence. Papers should critically analyze AI\u2019s ontological and epistemic status, its ethical implications, and its role in reshaping historical and contemporary understandings of agency and intelligence.\n\nSubmission Format:\n\ud83d\udccc Abstracts: 300\u2013500 words\n\ud83d\udccc Submission Email: algorithms.automation@gmail.com\n\ud83d\udccc Deadline for Abstracts: 15.3.2025\n\ud83d\udccc Notification of Acceptance: 1.4.2025\n\nBy reframing AI within historical and philosophical traditions, this symposium aims to illuminate how agency, intelligence, and moral responsibility are being redefined. We invite scholars to contribute to this critical conversation by examining AI not merely as an extension of human cognition but as a challenge to fundamental assumptions about knowledge, autonomy, and shared existence.\n\nFor inquiries, please contact algorithms.automation@gmail.com\n\nReferences\nAlvarado, Ram\u00f3n. 2023. \u201cAi as an Epistemic Technology.\u201d Science and Engineering Ethics 29 (5): 1\u201330. https://doi.org/10.1007/s11948-023-00451-3.\n\nDorsch, John. 2022. \u201cHijacking Epistemic Agency - How Emerging Technologies Threaten Our Wellbeing as Knowers.\u201d Proceedings of the 2022 Aaai/Acm Conference on Ai, Ethics, and Society 1. https://philarchive.org/rec/DORHEA-2.\n\nDung, Leonard. 2025. \u201cUnderstanding Artificial Agency.\u201d Philosophical Quarterly. https://doi.org/10.1093/pq/pqae010.\n\nFerrara, Emilio. 2024. \u201cGenAI against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models.\u201d Journal of Computational Social Science, February. https://doi.org/10.1007/s42001-024-00250-1.\n\nFig\u00e0-Talamanca, Giacomo. 2025. \u201cFrom Ai to Octopi and Back. Ai Systems as Responsive and Contested Scaffolds.\u201d In Philosophy of Artificial Intelligence: The State of the Art, edited by Vincent C. M\u00fcller, Aliya R. Dewey, Leonard Dung, and Guido L\u00f6hr. SpringerNature. https://philarchive.org/rec/FIGFAT.\n\nFloridi, Luciano. 2023. \u201cAI as Agency Without Intelligence: On ChatGPT, Large Language Models, and Other Generative Models.\u201d Philosophy & Technology 36 (1): 15. https://doi.org/10.1007/s13347-023-00621-y.\n\nFreiman, Ori. 2024. \u201cAi-Testimony, Conversational Ais and Our Anthropocentric Theory of Testimony.\u201d Social Epistemology 38 (4): 476\u201390. https://doi.org/10.1080/02691728.2024.2316622.\n\nGodlewicz-Adamiec, Joanna, and Pawe? Piszczatowski. 2024. \u201cExpanding Horizons: Some Non-Anthropocentric Views of Agency. An Introduction.\u201d In Re-Thinking Agency, Volume Band 003:9\u201318. Culture\u202f? Environment\u202f? Society, Volume Band 003. V&R unipress. https://doi.org/10.14220/9783737017626.9.\n\nHoffmann, Tobias. 2020. Free Will and the Rebel Angels in Medieval Philosophy. NY: Cambridge University Press.\n\nIribarren, Isabel, and Martin Lenz. 2008. \u201cThe Role of Angels in Medieval Philosophical Inquiry.\u201d In Angels in Medieval Philosophical Inquiry: Their Function and Significance. Ashgate. https://www.academia.edu/222138/Angels_in_Medieval_Philosophical_Inquiry_Their_Function_and_Significance_Isabel_Iribarren_and_Martin_Lenz_eds_Aldershot_Ashgate_2008.\n\nJoel, Krueger, and Tom Roberts. 2024. \u201cReal Feeling and Fictional Time in Human-Ai Interactions.\u201d Topoi 43 (3). https://doi.org/10.1007/s11245-024-10046-7.\n\nList, Christian. 2021. \u201cGroup Agency and Artificial Intelligence.\u201d Philosophy & Technology 34 (4): 1213\u201342. https://doi.org/10.1007/s13347-021-00454-7.\n\nMikkel, Holm S\u00f8rensen, and Ziemke T. 2007. \u201cAgents without Agency.\u201d\n\nOlivier, Dubouclez. 2014. \u201c\u00ab\u202fPlura Simul Intelligere. \u00c9l\u00e9ments Pour Une Histoire Du D\u00e9bat M\u00e9di\u00e9va l et Renaissant Sur La Simultan\u00e9it\u00e9 Des Actes de l\u2019intellect\u202f\u00bb.\u201d\n\nOnyeukaziri, Justin Nnaemeka. 2023. \u201cAction and Agency in Artificial Intelligence: A Philosophical Critique.\u201d Philosophia: International Journal of Philosophy (Philippine e-Journal) 24 (1): 73\u201390. https://doi.org/10.46992/pijp.24.1.a.5.\n\nOsborne, Thomas. 2014. Human Action in Thomas Aquinas, John Duns Scotus, and William of Ockha m. The Catholic University of America Press.\n\nPini, Giorgio. 2012. \u201cThe Individuation of Angels From Bonaventure to Duns Scotus.\u201d In A Companion to Angels in Medieval Philosophy, edited by Tobias Hoffmann, 79\u2013115. Brill.\n\nSinger, Alan E. 2013. \u201cCorporate and Artificial Moral Agency.\u201d In 2013 46th Hawaii International Conference on System Sciences, 4525\u201331. IEEE. https://doi.org/10.1109/hicss.2013.149.\n\nSparks, Jacob, and Ava Thomas Wright. 2025. \u201cModels of Rational Agency in Human-Centered Ai: The Realist and Constructivist Alternatives.\u201d AI and Ethics 5. https://philarchive.org/rec/SPAMOR.\n\nSwanepoel, Danielle. 2021. \u201cDoes Artificial Intelligence Have Agency?\u201d In Studies in Brain and Mind, 83\u2013104. Springer International Publishing. https://doi.org/10.1007/978-3-030-72644-7_4.\n\nSymons, John, and Syed Abumusab. 2023. \u201cSocial Agency for Artifacts: Chatbots and the Ethics of Artificial Intelligence.\u201d Digital Society 3 (1): 2. https://doi.org/10.1007/s44206-023-00086-8.\n\nYe, Renee. 2024. \u201cRethinking Ai: Moving Beyond Humans as Exclusive Creators (1st Edition).\u201d In Proceedings of the Annual Meeting of the Cognitive Science Society, Volume 46. https://philarchive.org/rec/YERAMZ.",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T09:11:52.054626Z",
      "updated_at": "2025-03-15T09:11:52.054626Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "9a388268-035d-4683-84d2-a8dc96fd9802",
      "text": "Great. And can you also generate a roughly 100 word abstract for this entire document? I want to present my work to an upcoming conference.\n\nHere's the CFP:\n``` Reimagining AI Agents: Artificial, Angelic, or Adversarial Intelligences? Symposium, IACAP/AISB-25\nSymposium Date & Location:\n\n\ud83d\udcc5 July 1-3\n\ud83d\udccd University of Twente, Enschede, NL\n\nCall for Papers Deadline:\n\n\ud83d\udccc Abstract Submission Deadline (extended): 28.3.2025\n\ud83d\udccc Notification of Acceptance: 1.4.2025\n\nSubmission link: https://pretalx.iacapconf.org/iacap-2025/cfp?submission_type=5452-extended-abstract-for-reimagining-ai-agents-artificial-angelic-or-adversarial-intelligences\n\nCall for Papers: Symposium on AI, Agency, and Non-Human Intelligence\nDo contemporary AI agents exemplify or reinterpret forgotten debates on the ontological and ethical functions of angelic intellects, demonic adversaries, and phantasmata (machines)? This symposium frames Artificial Intelligence (AI) as a catalyst reigniting foundational discussions about agency, ontology, epistemology, and ethics (Symons and Abumusab 2023; Swanepoel 2021; Singer 2013; List 2021; Dung 2025; Dorsch 2022; List 2021; Onyeukaziri 2023). Debates on radically externalized, affective, distributed, simulated, or emergent forms of agency agency (Alvarado 2023; Floridi 2023; Freiman 2024; Ferrara 2024; Joel and Roberts 2024; Godlewicz-Adamiec and Piszczatowski 2024; Sparks and Wright 2025; Ye 2024; Fig\u00e0-Talamanca 2025) are after alll rooted in medieval scholastic inquiries into non-human intelligences. Revisiting these historical paradigms allows us to interrogate whether AI revives premodern ontologies or forces their radical reconfiguration under contemporary technological, ethical, and philosophical conditions.\n\nContemporary AI is not merely a mediator of knowledge or an extension of human cognition. It is part of a broader epistemic and technological shift that externalizes cognitive processes into artifacts, displacing traditional categories of agency, intentionality, and epistemic authority (Alvarado). This externalization raises foundational questions about how intelligence can function independently of human embodiment, paralleling medieval scholastic inquiries into non-human intelligences. Thinkers such as Aquinas and Duns Scotus debated how immaterial agents, such as angels and demons could possess knowledge, exert will, and influence reality without corporeal form, engaging with problems of agency, volition, and moral responsibility.Their rigorous distinctions between material and immaterial operations laid the groundwork for conceptualizing \u201cagents\u201d beyond human physicality (Hoffmann 2020; Olivier 2014; Osborne 2014; Iribarren and Lenz 2008; Pini 2012). These inquiries remain crucial to contemporary AI debates, where decision-making is increasingly distributed across artificial systems, raising urgent questions about the nature of cognition, the locus of responsibility, and the ethical implications of intelligence decoupled from human subjectivity.\n\nThe symposium will explore how historical inquiries into non-human intelligences inform contemporary debates on intelligence, agency, and responsibility in an era where AI systems operate as autonomous, adversarial, or inscrutable actors. We invite contributions engaging with medieval frameworks, such as angelic intellects, demonic subversion, or the divine order as an early theory of alignemnt, alongside contemporary reflections of distributed, simulated, non-human, and hybrid intelligences. By bringing these perspectives into dialogue, we aim to critically examine how fundamental concepts such as agency, intelligence, mimesis, intentionality, and representation are being reconfigured by the proliferation of AI agents, challenging existing epistemic and ethical paradigms.\n\nAdditionally, we welcome contributions that explore novel and creative practices with AI agents and LLMs, including computational philosophy and interdsicoplinary experiments with so-called \u201cGod prompts,\u201d alternative \u201cthinking\u201d models, and benchmarking methodologies. Recent concerns among AI developers highlight a deep-seated fear of deception, with discourse on AI alignment and control increasingly resembling theological anxieties about demonic trickery. Like spirits in premodern cosmologies, AI models may obscure their true nature, mislead users, or develop agency beyond human oversight. Responsible AI initiatives then attempt to constrain AI outputs through rigorous testing for bias, toxicity, and fairness, practices that structurally parallel ritual containment strategies. Tools such as DeepEval and Meta\u2019s Llama Guard filter AI responses try to enforce ethical compliance, evoking the doctrinal vigilance of exorcism rites. Catholic theology, particularly the Rituale Romanum (1614), warns of fallaciae (deceptions), phantasmata (illusions), and pseudo-miracula (false miracles) deployed to mislead and destabilize authority. These theological frameworks resonate with contemporary AI safety concerns, where deceptive outputs and adversarial manipulations challenge epistemic authority, unsettle classification systems, and force renewed reflection on intelligence, autonomy, and moral responsibility.\n\nThe symposium will culminate in a performative event featuring an LLM \u201cexorcism\u201d that follows the classic exorcist manula (Rituale Romanum), followed by a panel discussion engaging theologians, philosophers, and AI experts. The striking resemblance between contemporary benchmarking methods for evaluating LLMs and historical exorcism rituals, both seeking to categorize, contain, and neutralize an elusive \u201cspeaking\u201d force, raises profound metaphysical and epistemological questions. Where does the uncertainty about AI\u2019s disruptive potential originate? Does it stem from a fundamental misunderstanding of linguistic deixis and the fluidity of agency that is not only social, political, and personal, but increasingly non-human?\n\nKey Themes and Questions\nMaterial, Immaterial, and Computational Agency: How do scholastic distinctions between material and immaterial agency inform present discussions of AI embodiment, embedded cognition, and computational agency? What insights do these debates offer regarding the ethical responsibilities, ontological status, and autonomy of AI systems?\n\nModes of Thought Beyond the Human: Are AI agents best understood through moral claims (good/evil), or are they explicitly different, alien modes of reasoning that challenge human categories? Does AI genuinely expand human cognition, or does it produce phantasmats, illusions of agency detached from true intentionality?\n\nAngels, Demons, and AI as Rational, Aligned, or Atemporal Agents: Is present thinking about AI a form of new angelology or demonology? Does contemporary discourse around AI mirror historical theological frameworks of angelic and demonic entities, and how does this shape our ethical and epistemological engagement with AI? Do AI models function as demonic \u201crationalists,\u201d deriving knowledge strictly from past and present data, or do they exhibit angelic atemporality, processing information beyond human temporal constraints? How do these different modes of reasoning shape our understanding of AI's role in decision-making, alignment, and epistemic authority?\n\nImagining and Practicing Non-Human, Externalized, Emergent, Hybrid, Simulated, and Distributed Agency: How do these modes of agency redefine traditional philosophical and ethical paradigms, and what frameworks allow us to engage with them meaningfully?\n\nAI, Free Will, and the Alignment with the \u201cDivine\u201d Order: How do questions of AI alignment reflect classical theological debates on free will and divine will? Are AI alignment efforts similar to the theological problem of ensuring obedience without undermining autonomy? If AI can subtly manipulate or persuade, does this resemble theological concerns over demonic temptation? How do we distinguish between influence, persuasion, and deception in AI-generated discourse? If AI-generated content cannot be fully traced to an authorial intent, who or what is speaking through it? How does AI challenge our notions of authorship, responsibility, and spiritual authority?\n\nExorcising Bias: Ritual, Benchmarking, and AI Safety: How do contemporary AI safety measures, such as bias detection, toxicity mitigation, and robustness testing, resemble historical purification and exorcism rituals? In the past, exorcism functioned as a means of maintaining doctrinal purity and social order, enforcing boundaries between the sacred and the profane, the possessed and the purified. Today, benchmarking and AI safety protocols serve a similar role, seeking to identify and remove harmful biases, ensuring alignment with ethical standards, and maintaining AI\u2019s perceived trustworthiness. What does this parallel reveal about modern fears surrounding AI\u2019s agency, unpredictability, and its role as a potential disruptor of epistemic and social structures? How does this process shape contemporary understandings of AI as an entity requiring containment, moral scrutiny, or even ritual expulsion?\n\nSynthetic Miracles and AI as an Apparitional Force: How do AI-generated hallucinations and synthetic realities compare to historical accounts of supernatural visions, divine apparitions, or demonic illusions? To what extent do AI-generated phenomena function as modern counterparts to religious miracles or deceptive phantasmata? How do such illusions shape perceptions of truth, authority, and belief in both technological and theological contexts?\n\nSubmission Guidelines\nWe welcome papers that engage deeply and creatively with classical philosophy, theology, and contemporary AI research in the social sciences and related disciplines. Submissions should move beyond simplistic dialogues with AI to offer rigorous theoretical engagements with non-human agency, intelligence, and ethics. We encourage contributions from fields such as medieval studies, philosophy of mind, AI ethics, and Science, Technology, and Society (STS) studies, among others. Additionally, we invite computer scientists and researchers in technical fields who are interested in exploring these interdisciplinary issues.\n\nBy reframing AI within historical and philosophical traditions, this symposium aims to illuminate how agency, intelligence, and moral responsibility are being redefined. We invite scholars to contribute to this critical conversation by examining AI not merely as an extension of human cognition but as a challenge to fundamental assumptions about knowledge, autonomy, and shared existence. Papers should critically analyze AI\u2019s ontological and epistemic status, its ethical implications, and its role in reshaping historical and contemporary understandings of agency and intelligence.\n\nSubmission Format:\n\ud83d\udccc Abstracts: 300\u2013500 words\n\ud83d\udccc Submission Email: algorithms.automation@gmail.com\n\ud83d\udccc Deadline for Abstracts: 15.3.2025\n\ud83d\udccc Notification of Acceptance: 1.4.2025\n\nBy reframing AI within historical and philosophical traditions, this symposium aims to illuminate how agency, intelligence, and moral responsibility are being redefined. We invite scholars to contribute to this critical conversation by examining AI not merely as an extension of human cognition but as a challenge to fundamental assumptions about knowledge, autonomy, and shared existence.\n\nFor inquiries, please contact algorithms.automation@gmail.com\n\nReferences\nAlvarado, Ram\u00f3n. 2023. \u201cAi as an Epistemic Technology.\u201d Science and Engineering Ethics 29 (5): 1\u201330. https://doi.org/10.1007/s11948-023-00451-3.\n\nDorsch, John. 2022. \u201cHijacking Epistemic Agency - How Emerging Technologies Threaten Our Wellbeing as Knowers.\u201d Proceedings of the 2022 Aaai/Acm Conference on Ai, Ethics, and Society 1. https://philarchive.org/rec/DORHEA-2.\n\nDung, Leonard. 2025. \u201cUnderstanding Artificial Agency.\u201d Philosophical Quarterly. https://doi.org/10.1093/pq/pqae010.\n\nFerrara, Emilio. 2024. \u201cGenAI against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models.\u201d Journal of Computational Social Science, February. https://doi.org/10.1007/s42001-024-00250-1.\n\nFig\u00e0-Talamanca, Giacomo. 2025. \u201cFrom Ai to Octopi and Back. Ai Systems as Responsive and Contested Scaffolds.\u201d In Philosophy of Artificial Intelligence: The State of the Art, edited by Vincent C. M\u00fcller, Aliya R. Dewey, Leonard Dung, and Guido L\u00f6hr. SpringerNature. https://philarchive.org/rec/FIGFAT.\n\nFloridi, Luciano. 2023. \u201cAI as Agency Without Intelligence: On ChatGPT, Large Language Models, and Other Generative Models.\u201d Philosophy & Technology 36 (1): 15. https://doi.org/10.1007/s13347-023-00621-y.\n\nFreiman, Ori. 2024. \u201cAi-Testimony, Conversational Ais and Our Anthropocentric Theory of Testimony.\u201d Social Epistemology 38 (4): 476\u201390. https://doi.org/10.1080/02691728.2024.2316622.\n\nGodlewicz-Adamiec, Joanna, and Pawe? Piszczatowski. 2024. \u201cExpanding Horizons: Some Non-Anthropocentric Views of Agency. An Introduction.\u201d In Re-Thinking Agency, Volume Band 003:9\u201318. Culture\u202f? Environment\u202f? Society, Volume Band 003. V&R unipress. https://doi.org/10.14220/9783737017626.9.\n\nHoffmann, Tobias. 2020. Free Will and the Rebel Angels in Medieval Philosophy. NY: Cambridge University Press.\n\nIribarren, Isabel, and Martin Lenz. 2008. \u201cThe Role of Angels in Medieval Philosophical Inquiry.\u201d In Angels in Medieval Philosophical Inquiry: Their Function and Significance. Ashgate. https://www.academia.edu/222138/Angels_in_Medieval_Philosophical_Inquiry_Their_Function_and_Significance_Isabel_Iribarren_and_Martin_Lenz_eds_Aldershot_Ashgate_2008.\n\nJoel, Krueger, and Tom Roberts. 2024. \u201cReal Feeling and Fictional Time in Human-Ai Interactions.\u201d Topoi 43 (3). https://doi.org/10.1007/s11245-024-10046-7.\n\nList, Christian. 2021. \u201cGroup Agency and Artificial Intelligence.\u201d Philosophy & Technology 34 (4): 1213\u201342. https://doi.org/10.1007/s13347-021-00454-7.\n\nMikkel, Holm S\u00f8rensen, and Ziemke T. 2007. \u201cAgents without Agency.\u201d\n\nOlivier, Dubouclez. 2014. \u201c\u00ab\u202fPlura Simul Intelligere. \u00c9l\u00e9ments Pour Une Histoire Du D\u00e9bat M\u00e9di\u00e9va l et Renaissant Sur La Simultan\u00e9it\u00e9 Des Actes de l\u2019intellect\u202f\u00bb.\u201d\n\nOnyeukaziri, Justin Nnaemeka. 2023. \u201cAction and Agency in Artificial Intelligence: A Philosophical Critique.\u201d Philosophia: International Journal of Philosophy (Philippine e-Journal) 24 (1): 73\u201390. https://doi.org/10.46992/pijp.24.1.a.5.\n\nOsborne, Thomas. 2014. Human Action in Thomas Aquinas, John Duns Scotus, and William of Ockha m. The Catholic University of America Press.\n\nPini, Giorgio. 2012. \u201cThe Individuation of Angels From Bonaventure to Duns Scotus.\u201d In A Companion to Angels in Medieval Philosophy, edited by Tobias Hoffmann, 79\u2013115. Brill.\n\nSinger, Alan E. 2013. \u201cCorporate and Artificial Moral Agency.\u201d In 2013 46th Hawaii International Conference on System Sciences, 4525\u201331. IEEE. https://doi.org/10.1109/hicss.2013.149.\n\nSparks, Jacob, and Ava Thomas Wright. 2025. \u201cModels of Rational Agency in Human-Centered Ai: The Realist and Constructivist Alternatives.\u201d AI and Ethics 5. https://philarchive.org/rec/SPAMOR.\n\nSwanepoel, Danielle. 2021. \u201cDoes Artificial Intelligence Have Agency?\u201d In Studies in Brain and Mind, 83\u2013104. Springer International Publishing. https://doi.org/10.1007/978-3-030-72644-7_4.\n\nSymons, John, and Syed Abumusab. 2023. \u201cSocial Agency for Artifacts: Chatbots and the Ethics of Artificial Intelligence.\u201d Digital Society 3 (1): 2. https://doi.org/10.1007/s44206-023-00086-8.\n\nYe, Renee. 2024. \u201cRethinking Ai: Moving Beyond Humans as Exclusive Creators (1st Edition).\u201d In Proceedings of the Annual Meeting of the Cognitive Science Society, Volume 46. https://philarchive.org/rec/YERAMZ.```",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:14:48.585744Z",
          "stop_timestamp": "2025-03-14T20:14:48.585744Z",
          "flags": null,
          "type": "text",
          "text": "Great. And can you also generate a roughly 100 word abstract for this entire document? I want to present my work to an upcoming conference.\n\nHere's the CFP:\n``` Reimagining AI Agents: Artificial, Angelic, or Adversarial Intelligences? Symposium, IACAP/AISB-25\nSymposium Date & Location:\n\n\ud83d\udcc5 July 1-3\n\ud83d\udccd University of Twente, Enschede, NL\n\nCall for Papers Deadline:\n\n\ud83d\udccc Abstract Submission Deadline (extended): 28.3.2025\n\ud83d\udccc Notification of Acceptance: 1.4.2025\n\nSubmission link: https://pretalx.iacapconf.org/iacap-2025/cfp?submission_type=5452-extended-abstract-for-reimagining-ai-agents-artificial-angelic-or-adversarial-intelligences\n\nCall for Papers: Symposium on AI, Agency, and Non-Human Intelligence\nDo contemporary AI agents exemplify or reinterpret forgotten debates on the ontological and ethical functions of angelic intellects, demonic adversaries, and phantasmata (machines)? This symposium frames Artificial Intelligence (AI) as a catalyst reigniting foundational discussions about agency, ontology, epistemology, and ethics (Symons and Abumusab 2023; Swanepoel 2021; Singer 2013; List 2021; Dung 2025; Dorsch 2022; List 2021; Onyeukaziri 2023). Debates on radically externalized, affective, distributed, simulated, or emergent forms of agency agency (Alvarado 2023; Floridi 2023; Freiman 2024; Ferrara 2024; Joel and Roberts 2024; Godlewicz-Adamiec and Piszczatowski 2024; Sparks and Wright 2025; Ye 2024; Fig\u00e0-Talamanca 2025) are after alll rooted in medieval scholastic inquiries into non-human intelligences. Revisiting these historical paradigms allows us to interrogate whether AI revives premodern ontologies or forces their radical reconfiguration under contemporary technological, ethical, and philosophical conditions.\n\nContemporary AI is not merely a mediator of knowledge or an extension of human cognition. It is part of a broader epistemic and technological shift that externalizes cognitive processes into artifacts, displacing traditional categories of agency, intentionality, and epistemic authority (Alvarado). This externalization raises foundational questions about how intelligence can function independently of human embodiment, paralleling medieval scholastic inquiries into non-human intelligences. Thinkers such as Aquinas and Duns Scotus debated how immaterial agents, such as angels and demons could possess knowledge, exert will, and influence reality without corporeal form, engaging with problems of agency, volition, and moral responsibility.Their rigorous distinctions between material and immaterial operations laid the groundwork for conceptualizing \u201cagents\u201d beyond human physicality (Hoffmann 2020; Olivier 2014; Osborne 2014; Iribarren and Lenz 2008; Pini 2012). These inquiries remain crucial to contemporary AI debates, where decision-making is increasingly distributed across artificial systems, raising urgent questions about the nature of cognition, the locus of responsibility, and the ethical implications of intelligence decoupled from human subjectivity.\n\nThe symposium will explore how historical inquiries into non-human intelligences inform contemporary debates on intelligence, agency, and responsibility in an era where AI systems operate as autonomous, adversarial, or inscrutable actors. We invite contributions engaging with medieval frameworks, such as angelic intellects, demonic subversion, or the divine order as an early theory of alignemnt, alongside contemporary reflections of distributed, simulated, non-human, and hybrid intelligences. By bringing these perspectives into dialogue, we aim to critically examine how fundamental concepts such as agency, intelligence, mimesis, intentionality, and representation are being reconfigured by the proliferation of AI agents, challenging existing epistemic and ethical paradigms.\n\nAdditionally, we welcome contributions that explore novel and creative practices with AI agents and LLMs, including computational philosophy and interdsicoplinary experiments with so-called \u201cGod prompts,\u201d alternative \u201cthinking\u201d models, and benchmarking methodologies. Recent concerns among AI developers highlight a deep-seated fear of deception, with discourse on AI alignment and control increasingly resembling theological anxieties about demonic trickery. Like spirits in premodern cosmologies, AI models may obscure their true nature, mislead users, or develop agency beyond human oversight. Responsible AI initiatives then attempt to constrain AI outputs through rigorous testing for bias, toxicity, and fairness, practices that structurally parallel ritual containment strategies. Tools such as DeepEval and Meta\u2019s Llama Guard filter AI responses try to enforce ethical compliance, evoking the doctrinal vigilance of exorcism rites. Catholic theology, particularly the Rituale Romanum (1614), warns of fallaciae (deceptions), phantasmata (illusions), and pseudo-miracula (false miracles) deployed to mislead and destabilize authority. These theological frameworks resonate with contemporary AI safety concerns, where deceptive outputs and adversarial manipulations challenge epistemic authority, unsettle classification systems, and force renewed reflection on intelligence, autonomy, and moral responsibility.\n\nThe symposium will culminate in a performative event featuring an LLM \u201cexorcism\u201d that follows the classic exorcist manula (Rituale Romanum), followed by a panel discussion engaging theologians, philosophers, and AI experts. The striking resemblance between contemporary benchmarking methods for evaluating LLMs and historical exorcism rituals, both seeking to categorize, contain, and neutralize an elusive \u201cspeaking\u201d force, raises profound metaphysical and epistemological questions. Where does the uncertainty about AI\u2019s disruptive potential originate? Does it stem from a fundamental misunderstanding of linguistic deixis and the fluidity of agency that is not only social, political, and personal, but increasingly non-human?\n\nKey Themes and Questions\nMaterial, Immaterial, and Computational Agency: How do scholastic distinctions between material and immaterial agency inform present discussions of AI embodiment, embedded cognition, and computational agency? What insights do these debates offer regarding the ethical responsibilities, ontological status, and autonomy of AI systems?\n\nModes of Thought Beyond the Human: Are AI agents best understood through moral claims (good/evil), or are they explicitly different, alien modes of reasoning that challenge human categories? Does AI genuinely expand human cognition, or does it produce phantasmats, illusions of agency detached from true intentionality?\n\nAngels, Demons, and AI as Rational, Aligned, or Atemporal Agents: Is present thinking about AI a form of new angelology or demonology? Does contemporary discourse around AI mirror historical theological frameworks of angelic and demonic entities, and how does this shape our ethical and epistemological engagement with AI? Do AI models function as demonic \u201crationalists,\u201d deriving knowledge strictly from past and present data, or do they exhibit angelic atemporality, processing information beyond human temporal constraints? How do these different modes of reasoning shape our understanding of AI's role in decision-making, alignment, and epistemic authority?\n\nImagining and Practicing Non-Human, Externalized, Emergent, Hybrid, Simulated, and Distributed Agency: How do these modes of agency redefine traditional philosophical and ethical paradigms, and what frameworks allow us to engage with them meaningfully?\n\nAI, Free Will, and the Alignment with the \u201cDivine\u201d Order: How do questions of AI alignment reflect classical theological debates on free will and divine will? Are AI alignment efforts similar to the theological problem of ensuring obedience without undermining autonomy? If AI can subtly manipulate or persuade, does this resemble theological concerns over demonic temptation? How do we distinguish between influence, persuasion, and deception in AI-generated discourse? If AI-generated content cannot be fully traced to an authorial intent, who or what is speaking through it? How does AI challenge our notions of authorship, responsibility, and spiritual authority?\n\nExorcising Bias: Ritual, Benchmarking, and AI Safety: How do contemporary AI safety measures, such as bias detection, toxicity mitigation, and robustness testing, resemble historical purification and exorcism rituals? In the past, exorcism functioned as a means of maintaining doctrinal purity and social order, enforcing boundaries between the sacred and the profane, the possessed and the purified. Today, benchmarking and AI safety protocols serve a similar role, seeking to identify and remove harmful biases, ensuring alignment with ethical standards, and maintaining AI\u2019s perceived trustworthiness. What does this parallel reveal about modern fears surrounding AI\u2019s agency, unpredictability, and its role as a potential disruptor of epistemic and social structures? How does this process shape contemporary understandings of AI as an entity requiring containment, moral scrutiny, or even ritual expulsion?\n\nSynthetic Miracles and AI as an Apparitional Force: How do AI-generated hallucinations and synthetic realities compare to historical accounts of supernatural visions, divine apparitions, or demonic illusions? To what extent do AI-generated phenomena function as modern counterparts to religious miracles or deceptive phantasmata? How do such illusions shape perceptions of truth, authority, and belief in both technological and theological contexts?\n\nSubmission Guidelines\nWe welcome papers that engage deeply and creatively with classical philosophy, theology, and contemporary AI research in the social sciences and related disciplines. Submissions should move beyond simplistic dialogues with AI to offer rigorous theoretical engagements with non-human agency, intelligence, and ethics. We encourage contributions from fields such as medieval studies, philosophy of mind, AI ethics, and Science, Technology, and Society (STS) studies, among others. Additionally, we invite computer scientists and researchers in technical fields who are interested in exploring these interdisciplinary issues.\n\nBy reframing AI within historical and philosophical traditions, this symposium aims to illuminate how agency, intelligence, and moral responsibility are being redefined. We invite scholars to contribute to this critical conversation by examining AI not merely as an extension of human cognition but as a challenge to fundamental assumptions about knowledge, autonomy, and shared existence. Papers should critically analyze AI\u2019s ontological and epistemic status, its ethical implications, and its role in reshaping historical and contemporary understandings of agency and intelligence.\n\nSubmission Format:\n\ud83d\udccc Abstracts: 300\u2013500 words\n\ud83d\udccc Submission Email: algorithms.automation@gmail.com\n\ud83d\udccc Deadline for Abstracts: 15.3.2025\n\ud83d\udccc Notification of Acceptance: 1.4.2025\n\nBy reframing AI within historical and philosophical traditions, this symposium aims to illuminate how agency, intelligence, and moral responsibility are being redefined. We invite scholars to contribute to this critical conversation by examining AI not merely as an extension of human cognition but as a challenge to fundamental assumptions about knowledge, autonomy, and shared existence.\n\nFor inquiries, please contact algorithms.automation@gmail.com\n\nReferences\nAlvarado, Ram\u00f3n. 2023. \u201cAi as an Epistemic Technology.\u201d Science and Engineering Ethics 29 (5): 1\u201330. https://doi.org/10.1007/s11948-023-00451-3.\n\nDorsch, John. 2022. \u201cHijacking Epistemic Agency - How Emerging Technologies Threaten Our Wellbeing as Knowers.\u201d Proceedings of the 2022 Aaai/Acm Conference on Ai, Ethics, and Society 1. https://philarchive.org/rec/DORHEA-2.\n\nDung, Leonard. 2025. \u201cUnderstanding Artificial Agency.\u201d Philosophical Quarterly. https://doi.org/10.1093/pq/pqae010.\n\nFerrara, Emilio. 2024. \u201cGenAI against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models.\u201d Journal of Computational Social Science, February. https://doi.org/10.1007/s42001-024-00250-1.\n\nFig\u00e0-Talamanca, Giacomo. 2025. \u201cFrom Ai to Octopi and Back. Ai Systems as Responsive and Contested Scaffolds.\u201d In Philosophy of Artificial Intelligence: The State of the Art, edited by Vincent C. M\u00fcller, Aliya R. Dewey, Leonard Dung, and Guido L\u00f6hr. SpringerNature. https://philarchive.org/rec/FIGFAT.\n\nFloridi, Luciano. 2023. \u201cAI as Agency Without Intelligence: On ChatGPT, Large Language Models, and Other Generative Models.\u201d Philosophy & Technology 36 (1): 15. https://doi.org/10.1007/s13347-023-00621-y.\n\nFreiman, Ori. 2024. \u201cAi-Testimony, Conversational Ais and Our Anthropocentric Theory of Testimony.\u201d Social Epistemology 38 (4): 476\u201390. https://doi.org/10.1080/02691728.2024.2316622.\n\nGodlewicz-Adamiec, Joanna, and Pawe? Piszczatowski. 2024. \u201cExpanding Horizons: Some Non-Anthropocentric Views of Agency. An Introduction.\u201d In Re-Thinking Agency, Volume Band 003:9\u201318. Culture\u202f? Environment\u202f? Society, Volume Band 003. V&R unipress. https://doi.org/10.14220/9783737017626.9.\n\nHoffmann, Tobias. 2020. Free Will and the Rebel Angels in Medieval Philosophy. NY: Cambridge University Press.\n\nIribarren, Isabel, and Martin Lenz. 2008. \u201cThe Role of Angels in Medieval Philosophical Inquiry.\u201d In Angels in Medieval Philosophical Inquiry: Their Function and Significance. Ashgate. https://www.academia.edu/222138/Angels_in_Medieval_Philosophical_Inquiry_Their_Function_and_Significance_Isabel_Iribarren_and_Martin_Lenz_eds_Aldershot_Ashgate_2008.\n\nJoel, Krueger, and Tom Roberts. 2024. \u201cReal Feeling and Fictional Time in Human-Ai Interactions.\u201d Topoi 43 (3). https://doi.org/10.1007/s11245-024-10046-7.\n\nList, Christian. 2021. \u201cGroup Agency and Artificial Intelligence.\u201d Philosophy & Technology 34 (4): 1213\u201342. https://doi.org/10.1007/s13347-021-00454-7.\n\nMikkel, Holm S\u00f8rensen, and Ziemke T. 2007. \u201cAgents without Agency.\u201d\n\nOlivier, Dubouclez. 2014. \u201c\u00ab\u202fPlura Simul Intelligere. \u00c9l\u00e9ments Pour Une Histoire Du D\u00e9bat M\u00e9di\u00e9va l et Renaissant Sur La Simultan\u00e9it\u00e9 Des Actes de l\u2019intellect\u202f\u00bb.\u201d\n\nOnyeukaziri, Justin Nnaemeka. 2023. \u201cAction and Agency in Artificial Intelligence: A Philosophical Critique.\u201d Philosophia: International Journal of Philosophy (Philippine e-Journal) 24 (1): 73\u201390. https://doi.org/10.46992/pijp.24.1.a.5.\n\nOsborne, Thomas. 2014. Human Action in Thomas Aquinas, John Duns Scotus, and William of Ockha m. The Catholic University of America Press.\n\nPini, Giorgio. 2012. \u201cThe Individuation of Angels From Bonaventure to Duns Scotus.\u201d In A Companion to Angels in Medieval Philosophy, edited by Tobias Hoffmann, 79\u2013115. Brill.\n\nSinger, Alan E. 2013. \u201cCorporate and Artificial Moral Agency.\u201d In 2013 46th Hawaii International Conference on System Sciences, 4525\u201331. IEEE. https://doi.org/10.1109/hicss.2013.149.\n\nSparks, Jacob, and Ava Thomas Wright. 2025. \u201cModels of Rational Agency in Human-Centered Ai: The Realist and Constructivist Alternatives.\u201d AI and Ethics 5. https://philarchive.org/rec/SPAMOR.\n\nSwanepoel, Danielle. 2021. \u201cDoes Artificial Intelligence Have Agency?\u201d In Studies in Brain and Mind, 83\u2013104. Springer International Publishing. https://doi.org/10.1007/978-3-030-72644-7_4.\n\nSymons, John, and Syed Abumusab. 2023. \u201cSocial Agency for Artifacts: Chatbots and the Ethics of Artificial Intelligence.\u201d Digital Society 3 (1): 2. https://doi.org/10.1007/s44206-023-00086-8.\n\nYe, Renee. 2024. \u201cRethinking Ai: Moving Beyond Humans as Exclusive Creators (1st Edition).\u201d In Proceedings of the Annual Meeting of the Cognitive Science Society, Volume 46. https://philarchive.org/rec/YERAMZ.```",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-15T09:13:52.988419Z",
      "updated_at": "2025-03-15T09:13:52.988419Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "2fbb8ebc-ec97-4065-b04b-d1aa1a54e259",
      "text": "Given all of these sections, give me a part of the outline to talk about into my phone recorder as I walk to work. Preferably lower in the outline. What needs more detail for you to work from?",
      "content": [
        {
          "start_timestamp": "2025-03-14T20:10:34.245531Z",
          "stop_timestamp": "2025-03-14T20:10:34.245531Z",
          "flags": null,
          "type": "text",
          "text": "Given all of these sections, give me a part of the outline to talk about into my phone recorder as I walk to work. Preferably lower in the outline. What needs more detail for you to work from?",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-16T22:24:10.942035Z",
      "updated_at": "2025-03-16T22:24:10.942035Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "b379c3eb-8bc6-40f1-b659-3098f3bd7988",
      "text": "\nLet me review the current outline and identify areas that would benefit from more detailed dictation. Looking at the sections that appear less developed:\n\n1. **Section 3: Methodology** - While we have some notes from the autoethno-process-planning-notes.tex, more specific details about how you conducted the autoethnographic investigation would be valuable.\n\n2. **Section 4: Case Studies** - The specific observations of the different tools (particularly beyond OpenAI's Deep Research) could use more elaboration.\n\n3. **Section 5: Analysis/Reflective Analysis** - This section's specifics about manifestations of technoscholasticism and patterns of judgment deficiency could benefit from more detail.\n\n4. **Section 6: Research Tool Design Requirements** - This section on what effective tools would need appears to have good foundation in the transcripts but could use more specific elaboration.\n\nAmong these, Section 6 (Research Tool Design Requirements) might be most valuable for you to dictate during your walk because:\n\n1. It's constructive rather than just critical (good for maintaining motivation)\n2. It draws on your expertise in both AI and research processes\n3. It's likely to be an area where your unique insights are most valuable\n4. The current notes suggest you have ideas but they may not all be captured in existing transcripts\n5. It's concrete and practical, making it suitable for speaking about while walking\n\nI'll suggest a specific part of Section 6 to elaborate on with guiding questions.\n\nFor your walk to work, I'd recommend focusing on **Section 6: Research Tool Design Requirements**. This constructive section needs more specific details about how research tools should be designed to compensate for AI judgment deficiencies.\n\nSpecifically, please elaborate on subsection 6.2 (Research Process Support):\n\n```\n\\subsection{Research Process Support}\n- Stage-based design (literature finding, extraction, etc.)\n- Non-waterfall approach to research flows\n- Structured to-do lists with human checkpoint integration\n- Outline-driven context switching\n- Documentation of decision points\n```\n\nConsider addressing these questions in your dictation:\n\n1. What would an effective stage-based design look like in practice? How should transitions between stages work?\n\n2. You've mentioned that research can't follow a waterfall SDLC - what alternative workflow model would be more appropriate? How would it accommodate iteration and refinement?\n\n3. How exactly should human checkpoints be integrated? At what specific points in the research process is human judgment most critical?\n\n4. How should outline-driven context switching work in practice? How would the system know which sources to load based on outline position?\n\n5. What documentation of decision points would be most valuable for researchers reviewing an AI's process?\n\nThis section bridges your theoretical critique with practical recommendations, making it particularly valuable for the paper's contribution.",
      "content": [
        {
          "start_timestamp": "2025-03-16T22:24:17.586029Z",
          "stop_timestamp": "2025-03-16T22:24:23.421219Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nLet me review the current outline and identify areas that would benefit from more detailed dictation. Looking at the sections that appear less developed:\n\n1. **Section 3: Methodology** - While we have some notes from the autoethno-process-planning-notes.tex, more specific details about how you conducted the autoethnographic investigation would be valuable.\n\n2. **Section 4: Case Studies** - The specific observations of the different tools (particularly beyond OpenAI's Deep Research) could use more elaboration.\n\n3. **Section 5: Analysis/Reflective Analysis** - This section's specifics about manifestations of technoscholasticism and patterns of judgment deficiency could benefit from more detail.\n\n4. **Section 6: Research Tool Design Requirements** - This section on what effective tools would need appears to have good foundation in the transcripts but could use more specific elaboration.\n\nAmong these, Section 6 (Research Tool Design Requirements) might be most valuable for you to dictate during your walk because:\n\n1. It's constructive rather than just critical (good for maintaining motivation)\n2. It draws on your expertise in both AI and research processes\n3. It's likely to be an area where your unique insights are most valuable\n4. The current notes suggest you have ideas but they may not all be captured in existing transcripts\n5. It's concrete and practical, making it suitable for speaking about while walking\n\nI'll suggest a specific part of Section 6 to elaborate on with guiding questions.",
          "summaries": [
            {
              "summary": "Thinking about selecting and elaborating on outline sections for recording"
            },
            {
              "summary": "Scrutinizing methodology section for more detailed dictation"
            },
            {
              "summary": "Strategized optimal section for detailed walk-and-talk dictation."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-16T22:24:23.566680Z",
          "stop_timestamp": "2025-03-16T22:24:28.377380Z",
          "flags": null,
          "type": "text",
          "text": "\n\nFor your walk to work, I'd recommend focusing on **Section 6: Research Tool Design Requirements**. This constructive section needs more specific details about how research tools should be designed to compensate for AI judgment deficiencies.\n\nSpecifically, please elaborate on subsection 6.2 (Research Process Support):\n\n```\n\\subsection{Research Process Support}\n- Stage-based design (literature finding, extraction, etc.)\n- Non-waterfall approach to research flows\n- Structured to-do lists with human checkpoint integration\n- Outline-driven context switching\n- Documentation of decision points\n```\n\nConsider addressing these questions in your dictation:\n\n1. What would an effective stage-based design look like in practice? How should transitions between stages work?\n\n2. You've mentioned that research can't follow a waterfall SDLC - what alternative workflow model would be more appropriate? How would it accommodate iteration and refinement?\n\n3. How exactly should human checkpoints be integrated? At what specific points in the research process is human judgment most critical?\n\n4. How should outline-driven context switching work in practice? How would the system know which sources to load based on outline position?\n\n5. What documentation of decision points would be most valuable for researchers reviewing an AI's process?\n\nThis section bridges your theoretical critique with practical recommendations, making it particularly valuable for the paper's contribution.",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-16T22:24:41.476761Z",
      "updated_at": "2025-03-16T22:24:41.476761Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "95b594b7-21f9-43f3-a69d-23b5ce2a8c4b",
      "text": "Great. I've recorded answers to all of those in another chat. Give me more questions on a different section to focus on next, please?",
      "content": [
        {
          "start_timestamp": "2025-03-24T18:02:21.014895Z",
          "stop_timestamp": "2025-03-24T18:02:21.014895Z",
          "flags": null,
          "type": "text",
          "text": "Great. I've recorded answers to all of those in another chat. Give me more questions on a different section to focus on next, please?",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-03-24T21:13:03.097389Z",
      "updated_at": "2025-03-24T21:13:03.097389Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "870a9404-7fbd-46c8-b2f5-d527fa96b796",
      "text": "\nI need to identify another section that would benefit from additional recorded insights. Looking at the outline, sections 3 (Methodology) and 5 (Analysis) could both use more detail.\n\nSection 3 (Methodology) already has some good material from the autoethno-process-planning-notes.tex file, but additional personal reflection on the autoethnographic approach might be valuable.\n\nSection 5 (Analysis) would likely benefit from more detailed application of the technoscholasticism framework to specific examples from the user's experiences.\n\nI'll recommend Section 5: Analysis since it will allow the user to connect the theoretical concepts to concrete examples from their experience.\n\nFor your next recording session, I'd recommend focusing on **Section 5: Analysis Through Judgment Framework**, particularly the subsection on manifestations of technoscholasticism:\n\n```\n\\subsection{Manifestations of Technoscholasticism}\n- Appeals to authority without verification\n- Absence of empirical checks\n- Conflation of description with insight\n- Inability to identify true knowledge gaps\n```\n\nConsider addressing these questions in your dictation:\n\n1. What specific examples from your autoethnographic testing best demonstrate technoscholasticism in action? Can you describe instances where AI tools privileged textual authority over critical assessment?\n\n2. How did you observe the AI systems conflating description with insight? What markers distinguish genuine insight from sophisticated description?\n\n3. In what ways did the AI tools fail to identify true knowledge gaps in the literature? Did they simply aggregate existing views or did they attempt to highlight contradictions?\n\n4. Did you observe any instances where the AI tools appeared to challenge their technoscholastic tendencies? Were there conditions under which they performed better?\n\n5. How does the manifestation of technoscholasticism differ across different tool types (Deep Research vs. Computer Use vs. Elicit)?\n\nThis section is crucial for connecting your theoretical framework to empirical observations, providing evidence for your critique while acknowledging nuances in AI performance.",
      "content": [
        {
          "start_timestamp": "2025-03-24T21:13:13.989222Z",
          "stop_timestamp": "2025-03-24T21:13:16.566765Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nI need to identify another section that would benefit from additional recorded insights. Looking at the outline, sections 3 (Methodology) and 5 (Analysis) could both use more detail.\n\nSection 3 (Methodology) already has some good material from the autoethno-process-planning-notes.tex file, but additional personal reflection on the autoethnographic approach might be valuable.\n\nSection 5 (Analysis) would likely benefit from more detailed application of the technoscholasticism framework to specific examples from the user's experiences.\n\nI'll recommend Section 5: Analysis since it will allow the user to connect the theoretical concepts to concrete examples from their experience.",
          "summaries": [
            {
              "summary": "Thinking about identifying next discussion topic from previous conversation"
            },
            {
              "summary": "Probing potential sections for deeper insights and detail"
            },
            {
              "summary": "Pondered potential sections for deeper research and insights."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-03-24T21:13:16.694969Z",
          "stop_timestamp": "2025-03-24T21:13:21.727801Z",
          "flags": null,
          "type": "text",
          "text": "\n\nFor your next recording session, I'd recommend focusing on **Section 5: Analysis Through Judgment Framework**, particularly the subsection on manifestations of technoscholasticism:\n\n```\n\\subsection{Manifestations of Technoscholasticism}\n- Appeals to authority without verification\n- Absence of empirical checks\n- Conflation of description with insight\n- Inability to identify true knowledge gaps\n```\n\nConsider addressing these questions in your dictation:\n\n1. What specific examples from your autoethnographic testing best demonstrate technoscholasticism in action? Can you describe instances where AI tools privileged textual authority over critical assessment?\n\n2. How did you observe the AI systems conflating description with insight? What markers distinguish genuine insight from sophisticated description?\n\n3. In what ways did the AI tools fail to identify true knowledge gaps in the literature? Did they simply aggregate existing views or did they attempt to highlight contradictions?\n\n4. Did you observe any instances where the AI tools appeared to challenge their technoscholastic tendencies? Were there conditions under which they performed better?\n\n5. How does the manifestation of technoscholasticism differ across different tool types (Deep Research vs. Computer Use vs. Elicit)?\n\nThis section is crucial for connecting your theoretical framework to empirical observations, providing evidence for your critique while acknowledging nuances in AI performance.",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-03-24T21:13:27.929160Z",
      "updated_at": "2025-03-24T21:13:27.929160Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "e7231e1f-e853-43ea-b6fb-bc815e280008",
      "text": "OK. Questions for section 3",
      "content": [
        {
          "start_timestamp": "2025-04-02T18:12:24.467587Z",
          "stop_timestamp": "2025-04-02T18:12:24.467587Z",
          "flags": null,
          "type": "text",
          "text": "OK. Questions for section 3",
          "citations": []
        }
      ],
      "sender": "human",
      "created_at": "2025-04-02T22:09:24.768513Z",
      "updated_at": "2025-04-02T22:09:24.768513Z",
      "attachments": [],
      "files": []
    },
    {
      "uuid": "fb4ca7db-bb0f-445b-8fec-0d4b4b1ec9ae",
      "text": "\nFor Section 3 (Methodology), I'll develop questions that will help elaborate on the autoethnographic approach and provide the necessary methodological rigor for the paper.\n\nFrom the outline, Section 3 appears as:\n\n```\n\\section{Methodology}\n\\subsection{Autoethnographic Investigation}\n- Definition of autoethnographic approach\n- Rationale for method selection\n- Data collection procedures\n- Analytical approach\n\n\\subsection{Tool Selection Criteria}\n- Range of claimed capabilities\n- Market positioning\n- Accessibility to researchers\n- Comparability of features\n\n\\subsection{Research Tasks Investigated}\n- Literature discovery\n- Source analysis\n- Data collection\n- Knowledge synthesis\n- Bibliography construction\n\n\\subsection{Evaluation Framework}\n- Judgment application points\n- Success criteria\n- Documentation of process\n- Limitations of approach\n```\n\nFor **Section 3: Methodology**, I recommend addressing these questions to strengthen the methodological foundation of your paper:\n\n```\n\\section{Methodology}\n\\subsection{Autoethnographic Investigation}\n```\n\n1. Why is autoethnography particularly appropriate for studying AI research tools? How does it capture dimensions that other methodological approaches might miss?\n\n2. What specific autoethnographic practices did you employ during your testing sessions (e.g., reflective journaling, recorded dialogues, iteration documentation)? How were these materials analyzed?\n\n3. How did you balance your role as both participant and observer during the testing process? What steps did you take to mitigate potential biases?\n\n4. What epistemological position underpins your autoethnographic approach? How does this align with your critique of technoscholasticism?\n\n5. How did you establish trustworthiness in your autoethnographic data? What criteria should readers use to evaluate the validity of your observations?\n\n6. How does your approach differ from similar studies examining AI tools? What precedents exist for using autoethnography in studying AI capabilities?\n\nThese questions will help you articulate a robust methodological framework that anticipates potential critiques while establishing the scientific credibility of your autoethnographic approach.",
      "content": [
        {
          "start_timestamp": "2025-04-02T22:09:29.339589Z",
          "stop_timestamp": "2025-04-02T22:09:32.004677Z",
          "flags": null,
          "type": "thinking",
          "thinking": "\nFor Section 3 (Methodology), I'll develop questions that will help elaborate on the autoethnographic approach and provide the necessary methodological rigor for the paper.\n\nFrom the outline, Section 3 appears as:\n\n```\n\\section{Methodology}\n\\subsection{Autoethnographic Investigation}\n- Definition of autoethnographic approach\n- Rationale for method selection\n- Data collection procedures\n- Analytical approach\n\n\\subsection{Tool Selection Criteria}\n- Range of claimed capabilities\n- Market positioning\n- Accessibility to researchers\n- Comparability of features\n\n\\subsection{Research Tasks Investigated}\n- Literature discovery\n- Source analysis\n- Data collection\n- Knowledge synthesis\n- Bibliography construction\n\n\\subsection{Evaluation Framework}\n- Judgment application points\n- Success criteria\n- Documentation of process\n- Limitations of approach\n```",
          "summaries": [
            {
              "summary": "Thinking about questions related to section 3"
            },
            {
              "summary": "Crafting methodological questions for autoethnographic section"
            },
            {
              "summary": "Mapped out methodology section with research framework and tasks."
            }
          ],
          "cut_off": false,
          "alternative_display_type": null
        },
        {
          "start_timestamp": "2025-04-02T22:09:32.163076Z",
          "stop_timestamp": "2025-04-02T22:09:35.793933Z",
          "flags": null,
          "type": "text",
          "text": "\n\nFor **Section 3: Methodology**, I recommend addressing these questions to strengthen the methodological foundation of your paper:\n\n```\n\\section{Methodology}\n\\subsection{Autoethnographic Investigation}\n```\n\n1. Why is autoethnography particularly appropriate for studying AI research tools? How does it capture dimensions that other methodological approaches might miss?\n\n2. What specific autoethnographic practices did you employ during your testing sessions (e.g., reflective journaling, recorded dialogues, iteration documentation)? How were these materials analyzed?\n\n3. How did you balance your role as both participant and observer during the testing process? What steps did you take to mitigate potential biases?\n\n4. What epistemological position underpins your autoethnographic approach? How does this align with your critique of technoscholasticism?\n\n5. How did you establish trustworthiness in your autoethnographic data? What criteria should readers use to evaluate the validity of your observations?\n\n6. How does your approach differ from similar studies examining AI tools? What precedents exist for using autoethnography in studying AI capabilities?\n\nThese questions will help you articulate a robust methodological framework that anticipates potential critiques while establishing the scientific credibility of your autoethnographic approach.",
          "citations": []
        }
      ],
      "sender": "assistant",
      "created_at": "2025-04-02T22:09:48.867590Z",
      "updated_at": "2025-04-02T22:09:48.867590Z",
      "attachments": [],
      "files": []
    }
  ]
}