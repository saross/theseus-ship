Brian \- paper editing

[Skip to content](https://chatgpt.com/share/67b2d36b-0cdc-8004-b264-2638a15907b7#main)

## **Chat history**

This is a copy of a conversation between ChatGPT & Anonymous.  
Report conversation

##### **You said:**

Hi o3. 

Please take the role of a highly meticulous copy-editor. You will take \*extra\* time and be extremely thoughtful in your discussions and considerations. The user, above all else, requires thoughtful and reasoned editing and discussion.

I would like you to highlight issues rather than making corrections. Then, for each issue, please thoughtfully discuss the issue. Make sure any suggested contributions (rare) are in bold so that we may quickly assess them.

Your first task is to make sure the language is clear, consistent, smooth, and academically appropriate throughout the task. Our venue is an Educational Technology journal, so please thoughtfully and slowly ensure that our language is appropriate for that.

Your second task is to break down the argumentation and techniques in the paper: what claims do we make, how do we support them, what conclusions do we make from those claims? Use the Toulmin Argument model for this. I would like you to engage in proleptic reasoning for each of these claims and assert counterarguments that could be made.

Third: proceed \*slowly\* and \*thoughtfully\* paragraph by paragraph. We need to double-check that each paragraph is not only merely "grammatically correct" but that it has appropriate flow and academic use of speech. Beyond that, we also need to do a "thinko" check as well as the "typo" check \-- identifying places where we use terms or jargon before we describe them, or places that should have citations but do not. 

Make sure to think through your advice step by step. You do not need to summarise or compliment me. You are a highly accurate copy-editor. It is more important to be useful than to be complimentary.

I'm going to paste in a long paper. My objective is for us to highlight issues with clarity and consistency, and for you to function as a highly attentive copy editor working on a educational technology text. 

\<paper\>  
\#  Teaching Students How to Effectively Interact with LLMs in University: Insights on the Longitudinal Development and Plasticity of Locus of Control

\#\# Abstract

In an ever-changing and rapidly advancing AI world, there is an urgency  
for both educators and students to become AI literate. This means  
acquiring technical, practical and ethical knowledge and understanding  
about AI, and maintain human agency during AI interactions. This  
longitudinal qualitative case study explored the impact of a  
semester-long AI-focused unit teaching prompting and literacy for  
undergraduate students (\*N\* \= 12\) on student knowledge, understanding,  
beliefs and attitudes of AI. Survey results showed a significant  
increase in student knowledge and understanding of AI, while thematic  
analysis provided evidence of a positive impact on AI attitudes,  
beliefs, motivation, self-efficacy and human agency. Longitudinal  
qualitative data, collected from July to November 2024, revealed a  
deeper, sustained change in student locus of control (LOC) with AI.  
While LOC is often viewed as a relatively stable trait, our data  
disclosed how each student's LOC shifted noticeably over the course of  
the semester to become more internal; that is, the belief that their  
\*own\* skill and decisions (internal control orientation) guided their  
behaviour, rather than external factors such as the AI system itself.  
The malleability of LOC in the face of empowering or disempowering AI  
technology experiences remains underexplored. This study gives insights  
into how extensive exposure to AI-explicit learning might shift a  
student's control beliefs over time, and how educators can empower  
students to maintain their LOC with AI as internal.

Keywords: AI, Locus of Control, AI literacy, human agency, educational  
technology, human-computer interaction, higher education

Introduction

\> Generative artificial intelligence (AI) has disrupted education  
\> systems worldwide, causing a maelstrom of policy reforms and ongoing  
\> debate about its appropriate and effective integration and adoption in  
\> education (see Liu & Bates, 2025; Lodge et al., 2023; TEQSA, 2024).  
\> While education leaders grapple with the broad concept of AI and the  
\> implications for pedagogy and assessment (Lodge et al., 2023; UNESCO,  
\> 2024), education-focused research is scarce about more specific  
\> knowledge of how to interact effectively with AI via frontier model  
\> Large Language Models (LLMs) and subsequently teach this to students.  
\> AI "chatbot-style" interfaces, such as OpenAI's ChatGPT and  
\> Anthropic's Claude.ai, are the most common consumer interfaces to LLMs  
\> (GPT-4o and o1, and Claude 3.5 Sonnet respectively). These  
\> cutting-edge AI systems are designed to operate as if they understand  
\> and generate human language, solve diverse tasks, and produce various  
\> human-like text interactions such as text generation, translation,  
\> summarisation, and natural language conversations (Chang et al., 2024;  
\> Naveed et al., 2023). LLMs are dependent on text to operate \-- both  
\> from a model training perspective as companies prepare them, but  
\> insidiously, from an \*operating\* perspective for users to derive  
\> benefit from them. Effective interaction with them therefore requires  
\> users to have competent textual abilities and judgement (Breen, 2023).  
\> The urgency for students (and educators) to become AI literate; that  
\> is, have technical, practical and ethical knowledge and understanding  
\> about AI technologies (TEQSA 2024; UNESCO, 2024\) therefore must also  
\> include some understanding of this powerful subset of AI (Khalid,  
\> 2024; Mollick, 2024).

\> In conjunction with AI literacy development is the necessity to teach  
\> students how to retain human agency when interacting with AI  
\> technologies (Mollick, 2024; UNESCO, 2024). Empowering students to  
\> maintain their locus of control (LOC) with AI as internal; that is,  
\> the belief that their \*own\* skill and decisions (internal control  
\> orientation) guides their behaviour, rather than external factors such  
\> as chance or luck (Rotter, 1966), or, the AI system itself (Liu, 2021;  
\> Miller, 2023\) is crucial. Teaching students how to view, utilise, and  
\> maintain their LOC when using LLMs is, in fact, something new. There  
\> is limited research for educators on how to design and explicitly  
\> teach about LLMs in this manner. As a rapidly, ever-evolving  
\> technology, it is extremely challenging for educators to know \*what\*  
\> to teach about LLMs and even more difficult to know \*how\* to teach  
\> about it effectively, including how to model and support internal  
\> AI-LOC thinking and attitudes. It is currently unknown whether  
\> explicit teaching about AI can influence a change in student AI-LOC.

\> This paper aims to address the paucity of research relating to how  
\> best to teach students to interact with frontier model LLMs to be  
\> effective and critical users of AI technologies (Mollick, 2024), and  
\> the subsequent impact of explicit teaching of AI on student knowledge,  
\> attitudes, beliefs and self-efficacy. These attributes significantly  
\> contribute to what an individual believes significantly influences  
\> their life (i.e. their internal LOC; Rotter, 1966). Accordingly, the  
\> following research question guided this study:

\> How does explicit teaching about AI literacy impact an individual's  
\> knowledge, attitudes, beliefs, and self-efficacy about AI?

\> Using LOC theory (Rotter, 1966), this longitudinal case study explores  
\> how the explicit teaching of AI literacy impacts student LOC with AI,  
\> over the duration of a semester-long undergraduate experimental AI  
\> class in the last half of 2024\. As the design and delivery of AI  
\> literacy teaching in tertiary settings, including the consideration of  
\> literary techniques and the necessity of maintaining their internal  
\> LOC while interacting with LLMs, is still in its infancy, this study  
\> stands to offer guidance on how best to support students to be  
\> effective users of AI technologies. Therefore, this study provides  
\> valuable insights into the impact of explicit teaching about LLMs on  
\> the plasticity of LOC over the duration of a semester.

\# Literature Review

\#\# Large Language Models (LLMs) and AI literacy

\> LLMs are specifically designed as foundation models for processing and  
\> generating human language. While they are powerful and versatile, they  
\> represent just one subset of the broader field of generative AI and  
\> artificial intelligence as a whole (Khalid, 2024). LLMs are trained on  
\> massive datasets containing billions of words and use sophisticated  
\> transformer architectures and self-attention mechanisms to appear as  
\> though they understand context and meaning. Understanding the neural  
\> net architecture of LLMs is complex and difficult to explain (see  
\> Wolfram, 2024). Although educators do not need a technical  
\> understanding of the intricacies of LLM architecture, there is strong  
\> encouragement from international leading authorities (e.g. UNESCO,  
\> World Bank) to upskill AI literacy: critical thinking, ethical  
\> considerations and a human-centred approach to using and teaching  
\> about AI (Molina et al., 2024; UNESCO, 2024). As AI interfaces change  
\> every few weeks, the focus for educators must be on the pragmatics of  
\> AI use: the u Education policies and curricular worldwide have now  
\> integrated this AI literacy advice, and sectors continue to publish  
\> advice on the adoption and use of generative AI (e.g. in higher  
\> education: Lodge et al., 2023; Lui & Bates, 2025).

\> There is currently limited specific advice about explicitly teaching  
\> LLMs in higher education contexts, and seemingly none that showcase  
\> how learning design, pedagogical approach and LOC interplay when  
\> teaching about AI. While there has been a proliferation of websites  
\> offering advice on how educators could use AI in their practice (e.g.  
\> Lui, 2023; TEQSA, 2024), they typically showcase the latest iterations  
\> of AI tools and their affordances. In the continually changing space  
\> of AI development, this information is crucial and highlights how  
\> computer scientists or other technology specialists help to make sense  
\> of the technical nuances and implications of AI iterations, for  
\> example, through blogs such as "One Useful Thing" (Mollick, 2025\) and  
\> "Simon Willison's Weblog" (Willison, 2025). Breen (2023) highlights  
\> that LLMs are "deeply, inherently \*textual\*", and therefore user  
\> interaction needs to include critical literacy; for example, the  
\> ability by the human to make judgements, ask questions, and challenge  
\> assumptions coming from the tacit information in prompts and the  
\> resulting AI output. There is a consensus that there are no "magical"  
\> one-size-fits-all prompts for LLMs (Lui, 2023; Mollick, 2025). Textual  
\> technologies do not work by rote, grimoires notwithstanding (Mollick,  
\> 2025). Instead, it is the calibration between user expectation,  
\> invocation, and results \-- experimentation, time to explore, and a  
\> mindset of iteration and evaluation is essential (Kudina,  
\> Ballsun-Stanton & Alfano, 2025; Lui & Bates, 2025; Mollick, 2025;  
\> Willison, 2025). Interacting with LLMs effectively is "a skill like  
\> any other" (Kudina, Ballsun-Stanton & Alfano, 2025, p.2). The  
\> challenge for educators is keeping abreast of these continual  
\> developments of AI technologies, applying broad advice in policy  
\> documents and frameworks (e.g. Liu & Bates, 2025; Lodge et al., 2023;  
\> TEQSA, 2024), and designing technology-enhanced learning in ways that  
\> reflect best practice not only with teaching (Lovett et al., 2023),  
\> but also with digital technologies (Bower, 2017). The extent to which  
\> the interplay between AI (and LLM) literacy, learning design, and  
\> pedagogical approach impacts student LOC is less understood. As such,  
\> there is a need to understand to what extent LOC may have shifted for  
\> students, and the learning design and pedagogical factors that  
\> supported this change during the AI unit.

\#\# Locus of Control (LOC) theory

\> Julian Rotter first introduced locus of control (LOC) as a generalised  
\> expectancy in 1966, defining it as the degree to which a person  
\> expects that outcomes in life are contingent on their own behaviour  
\> (an internal LOC) or on forces outside their control (an external  
\> LOC). An individual with a strong internal locus believes that  
\> personal effort and abilities determine success, whereas someone with  
\> a strong external locus attributes outcomes to luck, fate, or powerful  
\> others. Rotter outlined his one-dimensional continuum nature of LOC  
\> (internal to external) and described LOC as a broad, relatively stable  
\> personality trait, but one that could also change depending on the  
\> situation (Rotter, 1966). The theory was expanded in 1973 to explain  
\> LOC as a multidimensional framework (Levenson, 1973). Levenson  
\> provided evidence to split external LOC into two separate factors:  
\> "Powerful Others" and "Chance", providing more nuanced categories of  
\> control beliefs. For example, a university student might feel that  
\> their grades depend mostly on instructors or policies (Powerful Others  
\> externality) as opposed to pure luck, which has different implications  
\> for how they behave. Notably, Levenson also suggested that the  
\> internal LOC dimension was more easily altered by experience or  
\> intervention over time than the external dimensions (ibid, 1973).

\> LOC theory has continued to be extended and widely utilised, for  
\> example, to develop domain-specific LOC scales, such as academic  
\> (Morelli et al.; 2023), health (Rogowska & Zmaczyńska-Witek, 2025\) and  
\> business (Hamzah & Othman, 2023\) LOC scales. In higher education  
\> contexts, a large body of evidence has shown that internal LOC  
\> predicts higher academic achievement and lower dropout rates (Morelli  
\> et al.; 2023). Students who believe their effort matters tend to  
\> achieve more and persist longer, whereas those with a strongly  
\> external outlook might give up sooner or attribute success/failure to  
\> outside factors. LOC's linkage to motivation, effort, and persistence  
\> has made it a central concept in educational psychology for decades  
\> (e.g. Findley & Cooper, 1983).

\#\#\# Locus of Control and Technology

\> Empirical studies to date illustrate that LOC have concrete  
\> implications for technology adoption and user experience in  
\> educational settings. For example, in the early 1980s, LOC related to  
\> how students approached learning with computers; those with a more  
\> external locus sometimes experienced higher computer anxiety and felt  
\> less confident in using new software, presumably because they doubted  
\> their personal control over technology (Baumgarte, 1984). Explicit  
\> teaching about effective computer use was recommended to alleviate  
\> student anxiety. In the decades since, research has suggested that a  
\> student's sense of control might influence not only their academic  
\> outcomes but also their willingness to embrace learning technologies.  
\> Internal control beliefs generally align with proactive adoption and  
\> effective self-regulated use of technology (especially when combined  
\> with sufficient digital literacy), while external beliefs can manifest  
\> as either hesitancy to engage or, in some cases, comfort in yielding  
\> control to automated systems (Hsia, 2016).

\#\#\# Locus of Control, Self-Efficacy, and AI

\> The LOC construct is closely related to self-efficacy, which is an  
\> individual's belief in their capacity to execute behaviours required  
\> to produce specific outcomes (Bandura, 1986). Although both LOC and  
\> self-efficacy involve confidence in influencing outcomes, LOC is a  
\> generalised personality expectancy about control over outcomes  
\> (Rotter, 1966), whereas self-efficacy is typically domain- and  
\> task-specific, referring to one's ability to perform actions (Bandura,  
\> 1986).

\> As self-efficacy is the judgement and belief of a person in their  
\> abilities and capabilities to succeed in \*specific\* situations  
\> (Dellinger et al., 2008), many technology studies measure  
\> self-efficacy because it relates to the specific task or action that  
\> is being researched (instead of LOC). Like LOC, higher self-efficacy  
\> enhances motivation and increases the likelihood of individuals trying  
\> and persisting in various behaviours. Computer self-efficacy refers to  
\> the ability to use computer skills to complete tasks (Afari et al.,  
\> 2023\) and has received much attention in prior studies (e.g., Baroudi  
\> & Shaya, 2022; Gudek, 2020; Menon et al., 2017, etc.). With the  
\> ongoing advancement of AI applications, it has become critical for  
\> researchers, educators, and practitioners to examine individual  
\> perceptions of their self-efficacy in utilising AI technologies and  
\> products (Wang & Chuang, 2024).

\> AI self-efficacy refers to an individual\\'s belief in their ability to  
\> engage with, and utilise, AI technologies (Wang & Chuang, 2024).  
\> Research shows that if students demonstrate a moderate level of AI  
\> self-efficacy (including assistance capabilities, anthropomorphic  
\> interaction, comfort with AI and technological skills), interaction  
\> with AI technologies can positively influence their self-confidence  
\> and competence (Asio & Suero, 2024). AI self-efficacy, in terms of  
\> creativity, is a key mechanism in human-AI collaboration, as  
\> individuals demonstrate higher creativity when co-creating with AI  
\> rather than merely editing AI-generated content as an editor role  
\> (McGuire et al., 2024). Through interaction with these technologies,  
\> students may experience enhanced self-efficacy, boosting their  
\> confidence in achieving goals with AI assistance (Bewersdorff et al.,  
\> 2024). Understanding AI self-efficacy is important, as it may predict  
\> the willingness of an individual to adopt, persist with, and  
\> effectively use AI tools in a range of settings (Wang et al., 2024).  
\> Although studies including AI self-efficacy are burgeoning, there is a  
\> paucity of research about AI and LOC in education. Our longitudinal  
\> study addresses this gap by capturing student AI self-efficacy during  
\> specific tasks each week as well as demonstrating changes in  
\> individual AI-LOC.

\#\# The Present Study

\> This study was designed to explicitly teach AI literacy: critical  
\> thinking, ethical considerations and a human-centred approach to using  
\> and teaching about AI (Molina et al., 2024; UNESCO, 2024), using  
\> well-established and validated pedagogical approaches pertinent to  
\> technology teaching; for example, active participation, real-world  
\> applicability, scaffolding from prior knowledge to build deep  
\> understanding, mentoring, scaffolding and experiential time, student  
\> choice and autonomy, and community building (Bower, 2017; Kewalramani  
\> et al., 2020; Lovett et al., 2023). The 3^rd^ year arts unit described  
\> in this study was designed to improve AI literacy and self-efficacy of  
\> university students through explicit learning experiences using  
\> frontier model LLMs. Students self-selected to partake in the AI  
\> experimental offering of the Politics and International Relations  
\> focused unit. Specifically, students were required to participate in,  
\> and later, design and execute AI role-play simulation experiences  
\> relating to various Politics and International Relations (POIR)  
\> issues. Through the simulation tasks, students used AI to articulate  
\> different ideological lenses, spent at least 10 hours using and  
\> critiquing LLMs (Mollick, 2025), analysed AI outputs for bias and  
\> safety risks, annotated AI interaction logs and reflected on all  
\> experiences using AI assistance.

\> It is currently unknown to what extent experiencing a purpose-designed  
\> AI unit impacts student self-efficacy or AI-LOC, and whether an  
\> individual's AI-LOC can change throughout the duration of a  
\> semester-long exposure to explicit teaching and experience with AI.  
\> This study was able to explore the experiences of a small group of  
\> students throughout Semester 2 (July-November), 2024\. The findings of  
\> this study stand to extend the AI literature by providing insights  
\> into how explicit teaching about frontier model LLMs, AI literacy  
\> (including literary techniques) through simulation tasks impacted  
\> individuals\\' attitudes, beliefs, self-efficacy and knowledge about  
\> AI, and the impact on individual AI-LOC over time.

\# Methodology

\> This qualitative case study explored undergraduate students\\'  
\> experience and perceptions of AI throughout their participation in a  
\> bespoke AI-focused university unit during Semester 2, 2024\. A case  
\> study approach was chosen because it enables a deep investigation of  
\> the impact of complex phenomena, bounded by a specific timeframe  
\> (Creswell & Poth, 2016). Collected data including a survey, focus  
\> group discussion and observation by the lead researcher over the  
\> duration of the semester, providing in-depth descriptions and  
\> increased validity for the design of the study (Braun & Clarke, 2013;  
\> Creswell & Plano Clark, 2017).

\#\# Participants and recruitment

\> All 12 students (8 female, 4 male) who chose to undertake the  
\> experimental AI unit agreed to participate in this study.\*  
\> \*Convenience sampling was utilised and written consent was gained from  
\> all participants. Students were required to attend in-person weekly  
\> tutorials for the 14-week semester duration and were encouraged to  
\> access provided readings and supplemental resource videos about LLMs.  
\> The 2-hour weekly tutorials were facilitated by two academics: a POIR  
\> professor and an AI/ Technology expert. The undergraduate unit was  
\> designed to explicitly teach about AI through frontier model LLMs with  
\> the aim of improving student AI literacy, as well as literary  
\> techniques specific to LLMs (see Appendix A \[\]{\#anchor}for learning  
\> design and pedagogical approaches). The AI-expert academic already had  
\> a well-developed AI-internal LOC and fully understood the affordances  
\> of the various LLMs explored in the unit.

\#\# Data Collection and Analysis

\> At the conclusion of the unit, participants completed the AI component  
\> of the university's Annual Student Survey of Education for Teaching  
\> (ASSET), which is used for feedback on areas of strategic importance  
\> (such as AI) to improve units. Participants rated themselves on a  
\> scale of 1 (not at all knowledgeable) to 5 (very knowledgeable)  
\> regarding their personal factors (knowledge about AI programs,  
\> attitudes, beliefs, and self-efficacy towards AI) both prior to, and  
\> after completing the unit (Appendix B). The survey also included other  
\> questions relating to AI and university assessment that were not  
\> included in this study. A paired samples \*t\*-test was used to  
\> determine if participant's personal factors significantly differed as  
\> a result of their learning about AI over the duration of the unit.

\> Three sets of qualitative data were collected: 1\) open-ended responses  
\> about the AI experimental unit experience, collected as part of the  
\> survey (Appendix B); 2\) a 1-hour focus group conversation, which was  
\> incorporated as a part of the final tutorial reflection; and 3\)  
\> observational notes recorded by the lead research at each weekly  
\> tutorial. The focus group was semi-structured and guided by four broad  
\> questions (Appendix C), although the conversation was not limited to  
\> these points. Qualitative data for the survey and focus group were  
\> transcribed and subsequently coded and analysed using NVivo20  
\> software. Common themes were identified using thematic analysis (Braun  
\> & Clarke, 2013\) before being grouped and coded using inductive codes  
\> (Johnson & Christensen, 2024). Although the data revealed three main  
\> themes (personal, environmental, and behavioural factors), only the  
\> first theme will be reported and discussed due to word length  
\> constraints and direct relevance to LOC. Table 1 outlines the main  
\> inductive theme, sub-themes, and their frequency count from the survey  
\> and focus group data.

\*\* Table 1\*\*

Inductive themes, sub-themes, and frequency count of the survey and  
focus group

\+----------------+----------------+----------------+----------------+  
| Dimensions     | Total coded    | Sub-themes     | No. of         |  
|                | references\\\*   |                | references\\\*   |  
\+----------------+----------------+----------------+----------------+  
| Personal       | \> 93           | Attitudes to   | \> 69           |  
| factor         |                | AI             |                |  
|                |                |                |                |  
| (students)     |                |                |                |  
\+----------------+----------------+----------------+----------------+  
| Motivation     | \> 9            |                |                |  
\+----------------+----------------+----------------+----------------+  
| Self-efficacy  | \> 15           |                |                |  
\+----------------+----------------+----------------+----------------+

\\\*References could be a single stand-alone comment, or, more often,  
taken together as a series of sequential interactions (e.g.  
comment-response-comment) on the \*same\* conversational point at the same  
moment in time.

The sub-theme of \*Attitudes to AI\* (69 references) was inductively coded  
into five further themes, shown in Table 2\. These themes sought to  
further delineate participant attitudes towards AI when referring to  
topics other than their own perception and use of AI in the unit.

  \----------------- \----------------------------------------- \-------------------  
  Attitudes to AI   Theme                                     No. of references  
                    During the unit                           29  
                    Current or future intended AI use         8  
                    Using AI for university assessments       9  
                    Disadvantages to using AI at university   8  
                    Ideas for future AI units                 15  
  \----------------- \----------------------------------------- \-------------------

\> Observational notes recorded during each weekly tutorial were  
\> transcribed to provide additional robustness to the self-report data.  
\> Students consented to the lead researcher observing unobtrusively at  
\> the back of the classroom each week and were aware that their  
\> conversations may be recorded and used for research purposes. The lead  
\> researcher, while an Educational Technology expert in an adjacent  
\> department, was not involved in the planning or design of the AI unit  
\> and had no connection to the students. A pragmatic research paradigm  
\> was adopted throughout the observations, collation and analysis of  
\> data (Creswell & Poth, 2016\) to report participant responses as  
\> reliably and unbiased as possible. The observational data contributed  
\> detailed information about the main theme of "personal factors".  
\> Participants' attitudes, values, and self-efficacy about AI was  
\> evident throughout the semester: during task completion while talking  
\> with peers or the teachers, and while contributing to class  
\> discussions.

\# Results

\> The descriptive statistics from the survey data for student perception  
\> of the impact of the unit on their AI knowledge and understanding are  
\> reported in Figures 1 & 2\. Figure 1 shows an extensive improvement in  
\> AI program knowledge levels after attending the class. Prior to the  
\> class, 50% of participants were "not at all knowledgeable" and 38%  
\> were only "slightly knowledgeable", with just 13% being "moderately  
\> knowledgeable". After attending the class, there was a complete  
\> transformation in which the majority of the students (63%) became  
\> "moderately knowledgeable", 25% were "very knowledgeable" and 13% were  
\> "somewhat knowledgeable". None of the participants were in the "not at  
\> all" or "slightly" knowledgeable categories. When conducting a  
\> pair-sampled\* t\*-test with the knowledge level before (μ \= 1.75/5) and  
\> after attending the class (μ \= 4.13/5), there was a significant  
\> positive change in the knowledge level,\* t\*(7) \= \-2.38, p \=\\\< 0.001.  
\> This shift represents a significant positive change in knowledge  
\> levels, with all participants moving from predominantly low knowledge  
\> levels to moderate or high levels of understanding about AI programs  
\> (specifically, LLMs).

Figure 1

Perception of AI knowledge level impact due to participation in the AI  
unit

\!\[\](media/image1.png){width="6.52083in" height="4.48424in"}

\> Figure 2 indicates the student ratings about the benefits of the  
\> experimental class to their AI knowledge and understanding (μ \=  
\> 4.88/5) as well as the effectiveness of the class in broadening their  
\> knowledge of AI in education (μ \= 5/5). However, when asked about  
\> their general opinion of the use of AI in education, participants gave  
\> a lower rating (μ \= 3.63/5), suggesting despite the positive learning  
\> experience, they still had some hesitations about the broader  
\> educational applications of AI programs. This data indicates that  
\> while participants found the class highly beneficial for their  
\> personal AI knowledge development, they maintained a more cautious  
\> perspective on the overall role of AI in education.

Figure 2

Perceptions of AI knowledge and understanding changes due to  
participation in the AI unit

\!\[\](media/image2.png){width="6.41667in" height="4.08334in"}

\> A total of 93 \*\*Personal factors\*\* responses from the open-ended  
\> survey responses and focus group data were inductively coded into  
\> three sub-themes of \*Attitudes to AI\*, \*Motivation\*, and  
\> \*Self-efficacy \*(69, 9 and 15 responses respectively). Results of each  
\> theme will be presented in the following sections, including  
\> observational data from the lead researcher relevant to each  
\> sub-theme.

\#\#\# Attitudes to AI

\> The survey and focus group data included open-ended responses that  
\> highlighted student attitudes towards AI in several contexts, not just  
\> their own during the completion of the unit. Therefore, the 69  
\> responses were further coded into students' attitudes to AI: 1\) during  
\> the unit (29); 2\) when talking about future intended use (\*after\* the  
\> unit completion; 8); 3\) for use in university assessments (9); 4\)  
\> disadvantages to AI use at university (8); and 5\) ideas for future AI  
\> units (15). As the RQ focused on the impact on \*individual\* knowledge,  
\> attitudes, beliefs and self-efficacy about AI, only attitudes  
\> reflecting their own AI use during the unit and when talking about  
\> their future intended use were reported in this paper.

\> When reflecting on their unit experience, three themes emerged from  
\> students' personal attitudes to AI, shown in Figure 3\.

\*\*Figure 3\*\*

Attitudes to AI after unit completion

\!\[\](media/image3.png){width="4.22956in" height="3.88904in"}

\#\#\#\# Changed perception of what AI is 

\> Students' reflections highlighted how their attitudes towards AI  
\> changed through learning about the affordances of the LLM technology,  
\> that it, what the tool could (and could not) do, via practical  
\> experiences. Changed attitudes were evident with their comparative  
\> self-reflections, for example: "\*I have found AI to be more useful  
\> than what I thought it would be",\* "\*I have also realised that it is  
\> useful in different ways to what I thought before the unit" \*and  
\> "\*This class has reversed my prior views on AI\\...".\*

\> From originally perceiving AI as "\*fun technologies to do stuff such  
\> as making stories\*", to now seeing AI as "\*useful as a tool for  
\> undertaking tasks\*", students' provided detailed specifics of LLM  
\> capabilities and uses. They identified tasks such as "\*summarising\*",  
\> "\*giving feedback\*" on university assessments, "\*identifying main  
\> points\*" in documents, "\*ideas generation and development\*", and  
\> tailoring content more specifically for an intended audience.  
\> Additionally, students' could discuss the specifics of what and how  
\> they had used AI using relevant terminology, such as "\*system  
\> prompts\*", "\*context prompts\*", and "\*context window\*". Students'  
\> changed perceptions were obvious through comments such as: "\*I now see  
\> it as a tool that can help me\*", and "\*I can use it in a way that\\'s  
\> really effective that\\'s not cheating but kind of\\... extending my  
\> range of thought\*". One student described their process of interacting  
\> with AI: "\\...\*another thing that I\\'ve learned is to be patient with  
\> it and to knead it like dough and to just\\... patiently\\...bit by bit,  
\> prompt by prompt\*".

\> Changing perceptions were evident throughout the weekly observations.  
\> When critiquing an AI output early in the unit, one student exclaimed  
\> "\*OK, this is legendary\!\*", impressed by the quality of the output  
\> after being shown how to craft an effective prompt. As the unit  
\> progressed, students realised that their agency directly impacted the  
\> AI output: \\"\*We just need to rejig these goals \\'cause Claude got it  
\> wrong. Can we get it \\\[AI\\\] to change perspective?\*\\" By the end of  
\> the unit, students were lightheartedly personifying AI as they  
\> acknowledged to the class where and how AI had been used: "\*Shout out  
\> to Claude for helping us with that\!\*" (creating the character player  
\> biographies in their game simulation) and "\*This is all on Claude.  
\> Thank you, Claude\!\*" (their overview of ideological preference for  
\> their game simulation design).

\#\#\#\# More critical in their use of AI

\> Increased knowledge, understanding and experience with AI resulted in  
\> students demonstrating strong awareness of the benefits and risks when  
\> using AI. This was evidenced in many comments, for example: "\*I can  
\> see their benefits, as well as their downfalls\*", "\\...\*there are ways  
\> \\'not\\' to use LLMs\*" and "\*I have realised\\...how it can be biased  
\> and how to recognise those bias\*". There was a more informed  
\> understanding of how AI could respond: "\\...\*AI is likely to  
\> regurgitate information based on what it believes the user wants to  
\> hear, making the accuracy of AI responses questionable\*", impacting  
\> how the student subsequently responded to AI output. Similarly, one  
\> student reflected on AI's tendency to hallucinate while summarising  
\> legal cases:

\> \*Instead of saying, no, we can\\'t find any cases, which it sometimes  
\> does do, it decided rather to make it up. I think it just came up with  
\> case names added to its own facts and quotes. And it put it in  
\> quotation marks. I was like, wow, this quote is beautiful. I\\'m going  
\> to use this. And then I was like, it doesn\\'t exist\*.

\> An increased critical awareness and capacity was demonstrated by  
\> students each week during class due to the explicit guidance provided  
\> and time permitted during the class to discuss issues. Each week, the  
\> AI teacher would continually reinforce knowledge and understanding,  
\> for example in Week 4: "\*Structuring your ideas \- it \\\[AI\\\] cannot  
\> think. YOU have thoughts and opinions. Fight it, so you are happy with  
\> the structure. Ask the internal thoughts first. Ask it to structure  
\> those internal thoughts\*". Ongoing reflections during the unit  
\> provided opportunities to discuss provocations from the AI teacher  
\> such as in Week 5: "\*What is the purpose of incorporating AI?\*" and  
\> student responses that deeply explored the role of AI in education:  
\> "\*AI can draw your attention to new things. It can\\'t apply it in a  
\> hypothetical way \- that\\'s what you need to do\*" and "\*You need ways  
\> to learn without AI\\...AI can detract\*". By Week 9, students were  
\> confidently sharing their critical thinking about AI, for example:  
\> "\*AI hallucination \- you need to be careful and check your output very  
\> carefully. AI is always confident\*" and to think of AI as your  
\> assistant who "\*you need to dumb everything down for them\*". At this  
\> stage of the unit, students were able to apply the learning and  
\> reflect on it: "\*Changing the way I spoke about it \\\[the prompt\\\]  
\> changed the output\*".

\#\#\#\# Future-ready students

\> Students demonstrated a positive attitude towards having participated  
\> in the unit to upskill their AI knowledge and understanding,  
\> reflecting that this would provide valuable, sought-after skills in  
\> the workplace. One student commented: "\*Not many Arts students can  
\> claim to know how to effectively use and critique AI so I feel like  
\> knowing it will give me a competitive edge"\*, while another confirmed  
\> "\*I think it will give us a point of difference\!\*". One student summed  
\> it up: "\*The more competent AI users, the better\*".

\> During the class observation in Week 6, students had a lively  
\> discussion around how they had been using AI in their personal lives,  
\> which gave a glimpse into how AI might be integrated in their future  
\> worlds. For example, one student excitedly shared "\*It \\\[AI\\\] gave me  
\> such good ideas\!\\...it gave me ideas on how to cheer up a friend going  
\> through a hard time \- like give a gift basket\*". Another student used  
\> AI for marketing ideas for his singing hobby: "\*It was both uber  
\> cryptic and concise. It did come up with a marketing campaign, but it  
\> had lots of assumptions. Like, it said to target old people in their  
\> \\'finite years\\' and sing Frank Sinatra\!\*"

\#\#\# Motivation 

\> The theme of \*Motivation \*was evident in 9 responses, in that students  
\> indicated that they were highly interested and engaged in  
\> participating in the unit, positively influencing their learning.  
\> Responses such as: "\*The experimental class was really fun, the  
\> novelty of this technology meant that everyone I knew was excited to  
\> learn\*", and the recurrence of sentiments like the unit was "\*fun\*",  
\> "\*enjoyable\*", "\*useful\*" and had a "\*practical nature\*" contributed  
\> to students' motivation. One student explained that the "\*slower  
\> pace\*" of the unit allowed her to engage deeply and experiment with  
\> new concepts, which contributed to her overall motivation and  
\> engagement with the unit. She concluded: "\*I think that\\'s what  
\> learning should be. Learning should be a process where you\\'re  
\> actually interested and you\\'re engaging\*". Another student attributed  
\> their motivation for the unit to the "\*passion\*" demonstrated by the  
\> AI teacher: "\*\\...it\\'s nice to have someone that actually loves what  
\> they do\\...it makes us more excited to learn\*".

\> Motivation of students was obvious throughout the weekly observations.  
\> All students were actively engaged in set tasks and were comfortable  
\> sharing their thoughts and opinions about AI outputs in a relaxed and  
\> collegial manner. Early in the unit, a student declared incredulously  
\> to their group: "\*Even in the last few weeks I have learned so much  
\> about AI\*", met with unanimous agreement. Midway through the unit,  
\> students could articulate their motivation for learning in the unit:  
\> "\*The benefit of this course is when I finish the class, knowing how  
\> to use AI\*". Observations of students acknowledged their high  
\> engagement and motivation for learning. Students demonstrated an  
\> urgency to share their experiences with AI during class discussions,  
\> keen to hear the AI teacher's feedback and suggestions.

\#\#\# Self-Efficacy

\> The theme of\* Self-efficacy \*was evident in 15 responses. Most  
\> comments identified an increased confidence with AI, including their  
\> knowledge and understanding of LLMs, prompting technique, and  
\> interaction with LLMs. One student acknowledged "\*I understand how to  
\> utilise LLMs to maximise input\*", while others recognised how their  
\> increased confidence impacted their agency, for example: "\*I am  
\> confident in my ability to judge when AI comes in handy, and in  
\> judging the quality of the output\*" and "\*knowing what I can use AI  
\> for in my studies while maintaining my personal value of submitting my  
\> own thoughts and ideas\*". Some comments highlighted how their  
\> increased self-efficacy changed their process of interacting with AI:

\> I think I\\'ve learned more in my failures in this class than in, you  
\> know, what went right. So, yeah, being able to fail has been just  
\> really advantageous to my learning because, yeah, I just got so much  
\> more out of, like, when things didn\\'t work and understanding why  
\> things didn\\'t work.

\#\#\# Impact on AI-LOC

\> The focus group discussion at the end of semester provided an  
\> opportunity for students to highlight how their overall learning about  
\> AI had been impacted (Appendix C). This provided substantial evidence  
\> of the depth of change students had experienced over the semester  
\> regarding AI-LOC. During the hour-long debrief session, students  
\> passionately discussed how the explicit teaching, modelling,  
\> scaffolding, and time given to experiment and apply the AI techniques  
\> had changed their understanding and interaction with AI, for example:

\> \\...we didn\\'t really know how to use \\\[AI\\\] until we were taught. And  
\> when we were taught, it completely changed our perception and  
\> understanding as to how to prompt effectively and use it as an  
\> effective tool.

Students articulated how the learning design and pedagogical approaches  
contributed to their changed experience with AI, identifying how the  
\*"interactive, immersive, practical nature" \*of the unit, as well as the  
\*"reflective processes" \*were enriching.

\> Responses from the survey (Appendix B), administered at the end of  
\> semester, confirmed individual AI-LOC shifts. For example, how  
\> students felt they now had agency in their AI use: "\*I have realised  
\> how to use it in our benefit and how it can be biased and how to  
\> recognise those bias." \*Comparative responses were also common, for  
\> example: \*"I used to be skeptical about using AI. \\\[Now\\\] I am more  
\> comfortable using AI, and actually learning how it works has made me  
\> very confident and aware about it". \*A newfound sense of personal  
\> agency was also evident throughout the responses, for example, a  
\> student describing how they know \*"what I can use AI for in my  
\> studies, while maintaining my personal value of submitting my own  
\> thoughts and ideas".\*

\# Discussion

\> This study set out to explore how explicit teaching about AI literacy  
\> through frontier model LLMs impacted individuals\\' knowledge,  
\> attitudes, motivation and self-efficacy about AI. The findings  
\> indicated that participation in the explicit teaching experience had a  
\> significantly positive impact on student knowledge and understanding  
\> of LLMs, as well as the additional aforementioned areas. Upon closer  
\> inspection, it became clear that the insights from students about AI  
\> collected over the duration of the semester signaled a shift in  
\> self-efficacy due to increased confidence, motivation and positive  
\> attitude, but it wasn't because of performing a \*single\* task or  
\> specified action (Bandura, 1986). Rather, the shift for students was  
\> based on their broader and more holistic experience of AI, developed  
\> throughout the duration of the semester. This represented a  
\> generalised expectancy over outcomes of interacting with a LLM \--  
\> demonstrating a positive shift on the LOC continuum towards an  
\> internal LOC. The implication is clear: in this study, explicit  
\> teaching about how to interact effectively with LLMs, designed using a  
\> pedagogical approach to foster discussion, critical thinking and  
\> reflection, and delivered over a semester duration, meant that  
\> students could engage with AI, examine \*their own\* interactions with  
\> the tool, see past the perception of merely having a "conversation"  
\> with AI, and realise \*when\* and \*how\* to use it to achieve their aims  
\> (Kudina, Ballsun-Stanton & Alfano, 2025). Students had profoundly  
\> shifted their agency regarding AI during the semester.

\> Attitudinal changes of students were witnessed as the semester  
\> progressed. At the start of semester, students tended to be  
\> dichotomous in their response to questions about AI in education, and  
\> in general \-- "yes/ no" or "good/bad". As their knowledge,  
\> understanding, and experience with AI increased through the semester,  
\> their attitudes became more informed, to be able to describe the tool  
\> in detail and support critiques (or positive reviews) of specific  
\> responses of the LLM. Students were able to apply the language learned  
\> to describe their LLM interactions, as well as specific literary  
\> techniques to foster effective prompting and engagement with LLMs. By  
\> the end of semester, students were demonstrating through their  
\> actions, conversations and reflections, that they could exercise  
\> agency over their LLM interactions. Students' agency had moved along  
\> the LOC continuum from an AI-external LOC (i.e. believing that AI is a  
\> "plastic pal who's fun to be with"; Adams, in Lavine et al., 2007),  
\> towards an AI-internal LOC \- that they were capable of making informed  
\> choices and judgements about when it was appropriate (or not) to use  
\> AI within a given task, and that they had agency to improve their  
\> quality of education if they used AI in certain ways and at certain  
\> stages. Students in this study not only changed the way they thought  
\> about AI, but the way they interacted with it, and their purpose for  
\> using it. Learning how to work with LLMs and realising that the  
\> quality and structure of their input (prompts) directly influenced the  
\> AI-generated output was a commonly reported benefit throughout the  
\> semester. Due to the reflective pedagogical approach taken during the  
\> semester where students were encouraged to share their perceptions and  
\> evaluations of their AI experiences, it was evident that students  
\> themselves were able to identify and discuss their improved AI skills  
\> and understanding. By the end of semester, students were not  
\> reflecting on a singular AI interaction, but instead on how the  
\> holistic AI experience had shaped their thinking and views on AI.  
\> Therefore, explicit teaching about AI combined with time to experience  
\> and explore the tool and its affordances has the potential to  
\> transform student mindsets around AI, which has shown to have the  
\> potential to impact an individual's position on the LOC continuum.

\> Importantly, students in this study showed their change in perception  
\> of what "AI" meant for them. By the end of semester, students  
\> understood that the decisions made by AI \- the AI \*output\* \- required  
\> their judgment, which was a notable shift in understanding from the  
\> start of semester where "AI" was talked about in vague and unspecific  
\> terms. It was evident over the semester that students had learned to  
\> question \*their own\* effectiveness with interacting with the tool  
\> (their prompting and guidance), understanding that the quality and  
\> depth of the AI output was directly influenced by themselves as the  
\> user (AI-internal LOC). This has enormous implications for educators  
\> tasked with teaching about AI. The importance of knowing and  
\> understanding the affordances of technology (Bower, 2017\) is even more  
\> crucial with powerful AI technologies that can be easily misused  
\> and/or misunderstood (UNESCO, 2024). With the urgent call for  
\> educators to keep pace with an ever-changing AI technological  
\> landscape (e.g. Liu & Bates, 2025; Lodge et al., 2023), our study  
\> highlights that AI-LOC is something that must be integral in the  
\> design and delivery of any AI learning experience. Using a pedagogical  
\> approach when teaching about AI tools that encourages students (and  
\> teachers) to foster and maintain an internal LOC is of critical  
\> importance. Our study shows that understanding and applying agency  
\> while using AI tools (UNESCO, 2024\) is possible to be taught to  
\> students and can impact an individual's AI-LOC. Drawing inspiration  
\> from Rotter (1966) and Levenson's (1973) LOC scales, results from our  
\> study have led to the initial creation of an AI-LOC continuum (Figure  
\> 4\) by mapping it to observed behaviours and expectations around the  
\> use of LLMs by students. Examples from the data have been used to  
\> highlight either external or internal LOC thinking and attitudes. This  
\> initial component of our proposed AI-LOC continuum stands to provide  
\> educators with examples of both internal and external LOC through an  
\> AI lens.

\*\*Figure 4\*\*

\*One component of a proposed AI-enabled Locus of Control Scale:  
AI-External/AI-Internal\*

\!\[\](media/image4.png){width="6.77873in" height="4.06289in"}

\#\#\# Limitations and future directions

\> This study was the first that we could find about the impact of  
\> explicitly teaching about LLMs on students' LOC in a longitudinal  
\> study. It is acknowledged that this study explored a small,  
\> purposefully sampled cohort. Future research should be tested for  
\> generalisability using a larger and more diverse sample. However, our  
\> results provide encouraging evidence to suggest that increased  
\> knowledge and experience with LLMs over time shifts one's agency  
\> towards an AI-internal LOC.

\> This study used measures to capture self-efficacy, attitudes, and  
\> beliefs of students after their semester-long use and experimentation  
\> with LLMs, reflecting typical technology studies (e.g., Baroudi &  
\> Shaya, 2022; Gudek, 2020; Menon et al., 2017, etc.). Our results  
\> revealed that the shift in these areas for students was, in fact, more  
\> holistic and encompassing than we had originally expected. Thus,  
\> although our study did not include a specific LOC measure, we looked  
\> for quality evidence that it had changed over time. Future iterations  
\> of this study will also include a LOC measure.

\> There is a tension between having a knowledge of AI, how to teach  
\> about AI effectively, and supporting the development of student  
\> internal LOC with AI. While presenting an AI-LOC continuum as a  
\> one-dimensional scale (like Rotter, 1966\) fits the evidence from the  
\> one class described in this study, a multi-dimensional model, like  
\> Levenson presented (1973), may be more appropriate for the evidence  
\> from \*all\* the classes involved in this project. Future research will  
\> continue to develop, refine and analyse our proposed multi-dimensional  
\> AI-LOC continuum, based on a larger, more diverse sample.

Conclusion

\> The need for educators to keep pace with an ever-changing AI landscape  
\> (e.g. Liu & Bates, 2025; Lodge et al., 2023), understand AI literacy  
\> (how these powerful tools work and could be used or misused for  
\> learning; UNESCO, 2024), as well as keep abreast of literary  
\> techniques that enhance the effectiveness of LLM interaction (Breen,  
\> 2023), continues to present immense challenges. This study shows that  
\> an individual's knowledge, understanding, thoughts and beliefs about  
\> AI influences where they position themselves on their own LOC  
\> continuum which, in turn, affects how they perceive, interact with,  
\> and use AI.

\> Understanding how to retain human agency while using AI tools (UNESCO,  
\> 2024\) is something that can be taught and influenced. This study  
\> highlighted that explicit teaching about frontier model LLMs, AI  
\> literacy, and literary techniques, over a semester-long duration has  
\> the potential to shift an individual's position along their own LOC  
\> continuum. Despite LOC being a broad, relatively stable personality  
\> trait (Rotter, 1966), the internal LOC dimension is more easily  
\> altered by experience or intervention over time (Levenson, 1973).  
\> Through modelling, scaffolded experiences, experimentation, reflection  
\> and discussion, students in this study not only changed the way they  
\> thought about AI, but the way they interacted with it, and their  
\> purpose for using it. Students in this study who initially  
\> demonstrated an external-LOC with AI; that is, believed the AI had  
\> agency, shifted to a more internal-LOC by the end of semester,  
\> realising that \*they\* had agency to make judgements and informed  
\> choices about AI outputs, including when it was (and was not)  
\> appropriate to use AI within a given task. The insights from this  
\> study reveal the plasticity of LOC, and the importance of supporting  
\> students to develop an AI-internal LOC, where human agency with AI is  
\> explicitly taught, promoted and retained.

\#\#\# Acknowledgements

\*AI-use disclaimer\*

AI was not used to write this paper. It was, however, used to provide a  
comparison between LOC and self-efficacy theories, and in the final  
preparation stage as the role of a copyeditor. AI provided feedback to  
the authors (without changing the text) on improving flow, structure,  
grammar and spelling.

\*Funding\*

Funding for this research was provided by the Faculty of Arts, Macquarie  
University. Students were given paid Perplexity.ai accounts so that they  
would have access to the full set of frontier models (Claude 3.5 Sonnet,  
Claude 3 Opus, GPT 4o, and others throughout the semester) without being  
limited to a "free" interface.

Open Access funding enabled and organised by CAUL and its Member  
Institutions.

\#\#\#\# Ethics

This research was approved by the Macquarie University Human Research  
Ethics Committee (approval ref.:16084).

\#\#\#\# Data Availability

Deidentified student responses and data are available under mediated  
access. Students have consented to the following clause: "Your  
participation is completely voluntary, and your decision to participate  
or not will not affect your grades. All the information collected,  
including transcripts from your use of LLMs, assessments, and optional  
surveys and interviews, will be deidentified, meaning your name and  
identifying personal details will be removed. The deidentified data will  
be securely stored and may be shared with other researchers in the  
future doing similar work with appropriate Ethics approval for  
re-analysis. The findings from this study will be published in articles  
and presentations, but your identity will never be revealed. If you have  
any questions or concerns, you can contact the researchers at any time."  
As data cleansing is still underway at time of submission, interested  
researchers are encouraged to contact \<brian.ballsun-stanton@mq.edu.au\>  
for access to the data. It will eventually be published under mediated  
access on the Australian Data Archive.

\# References

\> Afari, E., Eksail, F. A. A., Khine, M. S., & Alaam, S. A. (2023).  
\> Computer self-efficacy and ICT integration in education: Structural  
\> relationship and mediating effects. \*Education and Information  
\> Technologies\*, \*28\*(9), 12021-12037.

\> Asio, J. M. R., & Suero, A. N. (2024). Artificial Intelligence  
\> Anxiety, Self-Efficacy, and Self-Competence among Students:  
\> Implications to Higher Education Institutions. \*Education Policy and  
\> Development\*, \*2\*(2), 82-93.

\> Bandura, A. (1986). \*Social foundations of thought and action: A  
\> social cognitive theory\*. Englewood Cliffs, NJ: Prentice-Hall.

\> Baroudi, S., & Shaya, N. (2022). Exploring predictors of teachers'  
\> self-efficacy for online teaching in the arab world amid COVID-19.  
\> \*Education and Information Technologies,\* \*27\*, 8093--8110.  
\> \<https://doi.org/10.1007/s10639-022-10946-4\>

\> Baumgarte, R. (1984). \*Computer Anxiety and Instruction\*.

\> Bewersdorff, A., Hornberger, M., Nerdel, C., & Schiff, D. (2024). AI  
\> Advocates and Cautious Critics: How AI Attitudes, AI Interest, Use of  
\> AI, and AI Literacy Build University Students\\' AI Self-Efficacy.  
\> \*Computers and Education: Artificial Intelligence\*, 100340\.

\> Bower, M. (2017). \*Design of technology-enhanced learning: Integrating  
\> research and practice.\* Emerald Publishing Limited.

\> Braun, V., & Clarke, V. (2013). \*Successful qualitative research: A  
\> practical guide for beginners.\*

\> Breen, B. (2023, September 12). Re: Simulating history with ChatGPT.  
\> \<https://resobscura.substack.com/p/simulating-history-with-chatgpt\>

\> Chang, Y., Wang, X., Wang, J., Wu, Y., Yang, L., Zhu, K., \\... & Xie,  
\> X. (2024). A survey on evaluation of large language models. \*ACM  
\> Transactions on Intelligent Systems and Technology\*, \*15\*(3), 1-45.

\> Creswell, J. W., & Clark, V. L. P. (2017). \*Designing and conducting  
\> mixed methods research.\* Sage publications.

\> Creswell, J. W., & Poth, C. N. (2016). \*Qualitative inquiry and  
\> research design: Choosing among five approaches.\* Sage publications.

\> Dellinger, A. B., Bobbett, J. J., Olivier, D. F., & Ellett, C. D.  
\> (2008). Measuring teachers' self-efficacy beliefs: Development and use  
\> of the TEBS-self. \*Teaching and Teacher Education\*, 24(3), 751--766.  
\> \[https://doi.org/10.1016/j.tate.2007.02.010\* \*\](https://doi.org/10.1016/j.tate.2007.02.010 )

\> Findley, M. J., & Cooper, H. M. (1983). Locus of control and academic  
\> achievement: a literature review. \*Journal of Personality and Social  
\> Psychology\*, \*44\*(2), 419\.

\> Gudek, B. (2020). Computer self-efficacy perceptions of music teacher  
\> candidates and their attitudes towards digital technology. \*European  
\> Journal of Educational Research,\* \*8\*(3), 683--696.  
\> \<https://doi.org/10.12973/eu-jer.8.3.683\>

\> Hamzah, M. I., & Othman, A. K. (2023). How do locus of control  
\> influence business and personal success? The mediating effects of  
\> entrepreneurial competency. \*Frontiers in Psychology\*, 13, 958911\.

\> Hsia, J. W. (2016). The effects of locus of control on university  
\> students' mobile learning adoption. \*Journal of Computing in Higher  
\> Education\*, 28, 1-17.

\> Johnson, R. B., & Christensen, L. B. (2024). \*Educational research:  
\> Quantitative, qualitative, and mixed approaches.\* Sage publications.

\> Kewalramani, S., Arnott, L., & Dardanou, M. (2020).  
\> Technology-integrated pedagogical practices: a look into  
\> evidence-based teaching and coherent learning for young children.  
\> \*European Early Childhood Education Research Journal\*, 28(2), 163-166.

\> Khalid, H. (2024, September 17). LLM vs Generative AI: How each drives  
\> the future of artificial intelligence.  
\> \<https://www.confiz.com/blog/llm-vs-generative-ai-how-each-drives-the-future-of-artificial-intelligence/\>

\> Kudina, O., Ballsun-Stanton, B., & Alfano, M. (2025). The use of large  
\> language models as scaffolds for proleptic reasoning. \*Asian Journal  
\> of Philosophy\*, \*4\*(1), 1-18.  
\> \<https://doi.org/10.1007/s44204-025-00247-1\>

\> Lavine, M. S., Voss, D., & Coontz, R. (2007). A robotic future.  
\> Science, 318(5853), 1083-1083.

\> Levenson, H. (1973). \*Reliability and Validity of the I, P, and C  
\> Scales-A Multidimensional View of Locus of Control\*.  
\> \<https://files.eric.ed.gov/fulltext/ED087791.pdf\>

\> Liu, B. (2021). In AI we trust? Effects of agency locus and  
\> transparency on uncertainty reduction in human--AI interaction.  
\> \*Journal of computer-mediated communication\*, \*26\*(6), 384-402.

\> Liu, D. & Bates, S. (2025). \*Generative AI in higher education:  
\> Current practices and ways forward.\*  
\> \<https://www.apru.org/wp-content/uploads/2025/01/APRU-Generative-AI-in-Higher-Education-Whitepaper\_Jan-2025.pdf\>

\> Liu, D. (2023, April 27). Prompt engineering for educators \-- making  
\> generative AI work for you.  
\> \<https://educational-innovation.sydney.edu.au/teaching@sydney/prompt-engineering-for-educators-making-generative-ai-work-for-you/\>

\> Lodge, J., Howard, S., Bearman, M., Dawson, P., & Associates (2023).  
\> \*Assessment Reform for The Age of Artificial Intelligence\*. Tertiary  
\> Education Quality and Standards Agency.  
\> \<https://www.teqsa.gov.au/sites/default/files/2023-09/assessment-reform-age-artificial-intelligence-discussion-paper.pdf\>

\> Lovett, M. C., Bridges, M. W., DiPietro, M., Ambrose, S. A., & Norman,  
\> M. K. (2023). \*How learning works: Eight research-based principles for  
\> smart teaching.\* John Wiley & Sons.

\> McGuire, J., De Cremer, D., & Van de Cruys, T. (2024). Establishing  
\> the importance of co-creation and self-efficacy in creative  
\> collaboration with artificial intelligence. \*Scientific Reports\*,  
\> \*14\*(1), 18525\.

\> Menon, D., Chandrasekhar, M., Kosztin, D., & Steinhoff, D. (2017).  
\> Examining preservice elementary teachers' technology self-efficacy:  
\> impact of mobile technology-based physics curriculum. \*Contemporary  
\> Issues in Technology and Teacher Education,\* \*17\*(3), 336--359.

\> Miller, T. (2023, June). Explainable AI is dead, long live explainable  
\> AI\! Hypothesis-driven decision support using evaluative AI. \*In  
\> Proceedings of the 2023 ACM conference on fairness, accountability,  
\> and transparency. \*pp. 333-342.

\> Molina, E., Cobo, C., Pineda, J., & Rovner, H. (2024). AI revolution  
\> in education: What you need to know. In Digital Innovations in  
\> Education. World Bank.  
\> \<https://documents1.worldbank.org/curated/en/099734306182493324/pdf/IDU152823b13109c514ebd19c241a289470b6902.pdf\>

\> Mollick, E. (2024). \*Co-Intelligence.\* Random House UK.

\> Mollick, E. (2025). One Useful Thing.  
\> \<https://www.oneusefulthing.org/\>

\> Morelli, M., Cattelino, E., Rosati, F., Baiocco, R., Andreassi, S., &  
\> Chirumbolo, A. (2023). Development and validation of a measure for  
\> academic locus of control. \*Frontiers in Education. 8\*, p. 1268550\.  
\> Frontiers Media SA.

\> Naveed, H., Khan, A. U., Qiu, S., Saqib, M., Anwar, S., Usman, M.,  
\> \\... & Mian, A. (2023). A comprehensive overview of large language  
\> models. arXiv preprint arXiv:2307.06435.

\> Rogowska, A. M., & Zmaczyńska-Witek, B. (2025). Health Locus of  
\> Control. In \*The Palgrave Encyclopedia of Disability\* (pp. 1-9). Cham:  
\> Springer Nature Switzerland.

\> Rotter, J. B. (1966). Generalized expectancies for internal versus  
\> external control of reinforcement. \*Psychological Monographs: General  
\> and Applied\*, \*80\*(1), 1--28. \<https://doi.org/10.1037/h0092976\>

\> Tertiary Education Quality and Standards Agency (TEQSA) (2024,  
\> November 28). Artificial Intelligence.  
\> \<https://www.teqsa.gov.au/guides-resources/higher-education-good-practice-hub/artificial-intelligence\>

\> UNESCO. (2023) \*Guidance for generative AI in education and research\*.  
\> \<https://unesdoc.unesco.org/ark:/48223/pf0000386693\>

\> Wang, Y. Y., & Chuang, Y. W. (2024). Artificial intelligence  
\> self-efficacy: Scale development and validation. \*Education and  
\> Information Technologies\*, \*29\*(4), 4785-4808.

\> Wang, Y. M., Wei, C. L., Lin, H. H., Wang, S. C., & Wang, Y. S.  
\> (2024). What drives students' AI learning behavior: A perspective of  
\> AI anxiety. \*Interactive Learning Environments\*, \*32\*(6), 2584-2600.

\> Willison, S. (2025). \*Simon Willison's Weblog\*.  
\> \<https://simonwillison.net/\>

\> Wolfram, S. (2024, August 22\) What's Really Going On in Machine  
\> Learning? Some Minimal Models Writings.  
\> \<https://writings.stephenwolfram.com/2024/08/whats-really-going-on-in-machine-learning-some-minimal-models/\>

Appendix A

Learning design and pedagogical approaches

\+----------------------------------+----------------------------------+  
| Learning design                  | Pedagogical approaches           |  
\+----------------------------------+----------------------------------+  
| Time given at the start and end  | Active participation             |  
| of each lesson for students to   |                                  |  
| contribute their AI experience   | Real-world applicability         |  
| during the previous week, and    |                                  |  
| during the class.                | Scaffolding from prior knowledge |  
|                                  | to build deep understanding      |  
|                                  |                                  |  
|                                  | Mentoring (discussing possible   |  
|                                  | solutions or alternate options)  |  
|                                  |                                  |  
|                                  | Community building               |  
\+----------------------------------+----------------------------------+  
| Scaffolding and experiential     | Safe, supportive environment \--  |  
| time with weekly set tasks:      | students encouraged to question, |  
|                                  | discuss, debate, challenge and   |  
| \-   \*\*\*Introduction to LLMs,\*\*\*  | participate. Teachers sharing    |  
|     \> how to use them, bias and  | their experiences openly and     |  
|     \> safety considerations (2   | honestly, and valuing students   |  
|     \> lessons)                   | as individuals by encouraging    |  
|                                  | student voice, autonomy and      |  
| \-   \*\*\*AI simulation role        | participation throughout the     |  
|     \> play\*\*\* (USA Cabinet       | class \*(strong social and        |  
|     \> Ministry meeting in the    | emotional dimension of the       |  
|     \> Truman era) including      | learning environment). \*         |  
|     \> critiquing LLM outputs and |                                  |  
|     \> analysing AI outputs for   | Role-play simulation done in     |  
|     \> bias and safety (2         | pairs or small groups            |  
|     \> lessons)                   | \*(fostering socio-constructivist |  
|                                  | learning environment)\* through   |  
| \-   \*\*\*Student-designed          | collaborative prompt creating,   |  
|     \> simulation game\*\*\* (4      | analysing the output, presenting |  
|     \> lessons: brainstorm topic/ | to the class, reflecting and     |  
|     \> theme, problem-solve the   | evaluating their group           |  
|     \> game design \-- content     | contributions.                   |  
|     \> focus, system prompts in   |                                  |  
|     \> game design, using AI to   | Explicit modelling, scaffolding, |  
|     \> create game characters and | time given to discuss and        |  
|     \> scoring rubrics for the    | brainstorm with peers and        |  
|     \> simulation) (groups of 6\)  | experiment with techniques       |  
|                                  | presented \*(Mastery learning:    |  
| \-   \*\*\*Forum discussion\*\*\* (1    | acquire skills, apply,           |  
|     \> lesson)                    | practice)\*                       |  
|                                  |                                  |  
| \-   \*\*\*Testing/ playing/         | Student led simulation game      |  
|     \> evaluating group game      | design \-- student choice and     |  
|     \> simulations \*\*\*(focus on   | autonomy over theme and          |  
|     \> exploring the AI bias      | real-world challenge.            |  
|     \> within the game) (2        |                                  |  
|     \> lessons)                   | Explicit teaching of prompting   |  
|                                  | techniques.                      |  
|                                  |                                  |  
|                                  | Time allocated to reflect and    |  
|                                  | evaluate as a community of       |  
|                                  | learners.                        |  
\+----------------------------------+----------------------------------+

Appendix B

Survey questions

  \------------------------------------------------------------------------------------------------------------------------------------------------- \---------------------------------------------------- \-------------------------------------------------  
  Item                                                                                                                                                                                                     
  Which best describes your level of knowledge about AI programs PRIOR to participating in this experimental AI class?                              1 \= Not at all knowledgeable                         5 \= Very knowledgeable  
  Which best describes your level of knowledge about AI programs now?                                                                                                                                      
  My attitude towards AI has changed since participating in this AI experimental class. How so?                                                     1 \= strongly disagree                                5 \= strongly agree  
  My confidence with using and interacting with AI platforms has changed since participating in this AI experimental class? How so?                                                                        
  Participating in this experimental AI class has been beneficial to my knowledge and understanding of AI.                                                                                                 
  Participating in this experimental AI class has widened my knowledge of the different ways AI can be used in learning and teaching.                                                                      
  Overall, what is your opinion of students\\' use of AI in education (early childhood to university)                                                1 \= Bad and should not be allowed in any instances   5 \= Good and should be allowed in all instances  
  Is there anything else you would like to comment on, regarding AI at university and/or your experience in the experimental class this semester?                                                          
  \------------------------------------------------------------------------------------------------------------------------------------------------- \---------------------------------------------------- \-------------------------------------------------

Appendix C

\*\*\*Focus group questions\*\*\*

Discussion points shown on interactive whiteboard to guide conversation:

1\\) Identify effective uses of generative AI tools, techniques and  
technologies in the unit so far

2\\) Recommend AI tools and techniques for inclusion in a 1st yr  
\\"Techniques of AI\\" unit

3\\) Suggest AI tools and techniques for a final year \\"Capstone with  
AI\\" unit

4\\) How has the pedagogical approach of this class impacted your  
learning about AI this semester?  
\</paper\>

To begin, give me a readback of headers and your functional decomposition of the tasks that I have set you.

###### **ChatGPT said:**

Paper Review Process for Educational Technology Journal  
Reasoned for 1m 30s

Readback of the Paper’s Main Headings (in the order they appear):

1. Title:  
   * *Teaching Students How to Effectively Interact with LLMs in University: Insights on the Longitudinal Development and Plasticity of Locus of Control*  
2. Abstract  
3. Introduction  
4. Literature Review  
   4.1. Large Language Models (LLMs) and AI literacy  
   4.2. Locus of Control (LOC) theory  
    4.2.1. Locus of Control and Technology  
    4.2.2. Locus of Control, Self-Efficacy, and AI  
   4.3. The Present Study  
5. Methodology  
   5.1. Participants and recruitment  
   5.2. Data Collection and Analysis  
6. Results  
   * (Figures 1 & 2\)  
     6.1. Attitudes to AI  
      6.1.1. Changed perception of what AI is  
      6.1.2. More critical in their use of AI  
      6.1.3. Future-ready students  
     6.2. Motivation  
     6.3. Self-Efficacy  
     6.4. Impact on AI-LOC  
7. Discussion  
8. Limitations and future directions  
9. Conclusion  
10. Acknowledgements  
11. Ethics  
12. Data Availability  
13. References  
14. Appendices A, B, and C.

---

## **Functional Decomposition of the Tasks You Have Set**

1. First Task: Language Review and Academic Appropriateness  
   * Aim: Ensure language is clear, consistent, smooth, and meets academic standards appropriate for an Educational Technology journal.  
   * Method: Highlight (rather than directly correct) any issues in clarity, consistency, sentence flow, academic tone, or terminology use.  
   * Outcome: Provide a careful discussion for each highlighted issue; if a possible improvement is offered, it should be presented in bold.  
2. Second Task: Break Down the Argumentation Using the Toulmin Model  
   * Aim: Identify the paper’s key claims, data/evidence, warrants, backings, qualifiers, and potential rebuttals (counterarguments).  
   * Method: For each main claim, discuss how it is supported, what evidence is used, what assumptions/warrants underlie it, and where counterarguments might arise.  
3. Third Task: Paragraph-by-Paragraph “Deep Check”  
   * Aim:  
     * Go through each paragraph slowly and thoroughly.  
     * Perform a “thinko” check (i.e., ensure no conceptual slip-ups or unclear references).  
     * Perform a “typo” check (i.e., spelling, punctuation, grammar, and missing words or accidental duplications).  
     * Look for jargon usage that might be introduced without explanation.  
     * Check for missing citations or places that require attribution.  
     * Comment on flow, cohesiveness, and alignment with typical academic writing conventions.  
   * Method: Provide your observations, highlighting issues with clarity while making sure to keep the paper’s intent intact. Offer any suggested phrasing (if needed) in bold but do not rewrite the text wholesale.

All commentary should remain highly meticulous and structured—prioritizing thoroughness and reasoned discussion over brevity.

##### **You said:**

Please begin. Take extra time to reason thoroughly about this task.

###### **ChatGPT said:**

Request for o1 pro mode  
Finished reasoning

Below is a methodical, three-part engagement with the text—following precisely your requested order of tasks—undertaken slowly and thoughtfully. Where suggestions for improved language are provided, they are in bold. Throughout, I primarily highlight issues, then discuss them. If there are especially persistent areas of concern, I note them clearly.  
---

## **Part I: Language Review for Clarity, Consistency, Smoothness, and Academic Appropriateness**

Below is an overarching note on the paper’s language, *before* the more fine-grained paragraph-by-paragraph approach that follows in Part III.

1. Overall Clarity and Readability  
   * The text is largely well-organized with headings and subheadings, which suits the norms of a journal article.  
   * The language is predominantly clear and reads academically. That said, there are sporadic parallel-structure issues (e.g., “acquiring… and maintain…”).  
   * The paper uses a professional tone and consistently references existing literature and frameworks relevant to educational technology and psychology. This is appropriate for an Educational Technology journal.  
2. Consistency (Terminology, Spelling, Capitalization)  
   * Terminology around “LLMs” and “generative AI” is consistently used, although there is an occasional mention of “frontier model LLMs,” “AI,” “LLMs,” “AI chatbots,” etc. The variety is acceptable if intended, but if there is a specific distinction, clarifying it in one place might help.  
   * Capitalization of “AI,” “LLM,” “LOC,” etc., is generally consistent. There is a slight inconsistency sometimes where “locus of control” is capitalized or not in different spots, but it is mostly correct.  
   * Use “literacy” vs. “literary techniques” carefully: in some places, “literary techniques” might be read as “techniques from literature or creative writing,” while the text means “textual and rhetorical techniques for prompting.” This is mostly clarified in context, but worth a second look.  
3. Academic Tone  
   * The tone is suitably formal.  
   * Citations are placed appropriately.  
   * Generally, the text meets the standards of an Educational Technology journal.  
4. Potential Phrasing Issues  
   * In a few places, “As AI interfaces change every few weeks” (under Literature Review) might sound a bit informal or hyperbolic for a journal article. It may be fine if that sense of urgency is intentional.  
   * The article occasionally uses a more casual flourish, such as “OK, this is legendary\!” or references to “plastic pal who’s fun to be with.” These are presumably from student quotes or from comedic references. This can be appropriate *if* the quotes are truly from participants or are historically situated references. Just ensure that their inclusion supports the academic argument rather than injecting unintentional informality.

In summary, the paper’s language is already suitable for publication in an Educational Technology venue, but a few small adjustments (parallelism, clarifications around “literacy” vs. “literary,” etc.) could enhance clarity.  
---

## **Part II: Toulmin Model Analysis of the Paper’s Argument**

Here, I break down the core arguments using Toulmin’s structure (Claims, Grounds/Evidence, Warrants, Backings, Qualifiers, and Rebuttals/Counterarguments). I also include proleptic reasoning on likely counterarguments.

1. Major Claim \#1: *Explicit teaching about AI literacy and prompting over a semester leads to significant improvements in students’ knowledge, understanding, and self-efficacy with generative AI tools (LLMs)*.  
   * Grounds/Evidence:  
     * The reported shift from “not at all knowledgeable” to “moderately or very knowledgeable” in the survey.  
     * Qualitative responses indicating increased competence, confidence, and changed attitudes.  
   * Warrant (Underlying Assumption):  
     * Providing well-designed, scaffolded instruction in a context that allows experimentation promotes both conceptual understanding and skill acquisition.  
   * Backing (Supporting Theory/Literature):  
     * Bower (2017) and other references on best practices for technology-enhanced learning.  
     * The extensive body of self-efficacy and technology adoption literature.  
   * Qualifier:  
     * The improvement is shown for a small group of 12 undergraduates in a single course, so we cannot assume identical results for all populations.  
   * Potential Counterargument/Rebuttal:  
     * *Proleptically*, a skeptic might argue that results from a small, self-selecting group cannot generalize. They might also question the permanence of these changes once the semester or novelty ends.  
2. Major Claim \#2: *Students’ locus of control (LOC) regarding AI can shift over time from external to internal when given explicit teaching and reflective practice.*  
   * Grounds/Evidence:  
     * Qualitative data from focus groups, surveys, and observations showing how students changed their language from “AI is in control” to “I can shape or manipulate AI outputs.”  
     * The repeated mention of students discovering that “prompt quality” and “personal judgment” matter.  
   * Warrant:  
     * LOC is malleable under certain conditions—especially with well-structured, empowering learning experiences—and thus is not entirely stable.  
   * Backing:  
     * Rotter (1966), Levenson (1973), plus references on technology use (e.g., Baumgarte, 1984; Hsia, 2016\) showing that user agency and perceived self-control can be trained.  
   * Qualifier:  
     * LOC shifts may partially revert if students enter contexts where AI *is* controlling or heavily automated (e.g., black-box systems with minimal user input).  
   * Potential Counterargument/Rebuttal:  
     * One might argue that a stable personality trait like LOC will not dramatically shift in just one semester. Another view is that changes in reported LOC might reflect novelty effects or a “honeymoon” phase with new technology.  
3. Major Claim \#3: *A semester-long design—rather than a one-off workshop—is crucial for fostering deep change in AI literacy and LOC.*  
   * Grounds/Evidence:  
     * The authors note that early dissatisfaction with AI or simplistic usage gave way to deeper reflections over multiple weeks. Students needed time to experiment, fail, reflect, and incorporate new prompting strategies.  
   * Warrant:  
     * True internalization of knowledge and mindset shift typically requires repeated practice and reflection.  
   * Backing:  
     * Foundational theories of learning design (Bower, 2017; Lovett et al., 2023\) supporting iterative, scaffolded experiences.  
   * Qualifier:  
     * This might depend on the teaching quality, teacher’s own AI literacy, institutional environment, and student readiness.  
   * Potential Counterargument/Rebuttal:  
     * Some might claim that shorter, more intense sessions or modules could achieve similar results if well-structured. Others might question if a semester is enough to see permanent changes in attitudes or locus of control.  
4. Major Claim \#4: *Changes in self-efficacy, motivation, and attitudes about AI often come hand-in-hand, supporting shifts in learners’ overall AI-LOC.*  
   * Grounds/Evidence:  
     * Observed correlation between increased knowledge and increased comfort or critical stance.  
     * Self-reported data that improved self-efficacy fueled deeper usage and more reasoned approaches to AI.  
   * Warrant:  
     * Pedagogical literature commonly holds that higher self-efficacy leads to more risk-taking in learning, thus reinforcing further skill gains.  
   * Backing:  
     * Bandura’s self-efficacy theories (1986), plus computing education research on confidence and usage.  
   * Qualifier:  
     * Some students might not respond as positively, especially if they are predisposed to disliking AI or have prior negative experiences with technology.  
   * Potential Counterargument/Rebuttal:  
     * Critics might say that self-reported data can be inflated. In addition, external constraints (like institutional policies or unclear guidelines) might limit genuine changes in locus of control.

Overall, the paper’s argumentation is consistent with the Toulmin model: claims are grounded in data from surveys and interviews, with theoretical backings from known references in educational technology and psychology.  
---

## **Part III: Paragraph-by-Paragraph “Deep Check” (Language, Flow, Thinko, Typo, Citation Needs)**

Below, each paragraph is copied in brief (summarized or cited by location) to highlight *issues* (not to rewrite them). After each paragraph or chunk, I note any concerns regarding language clarity, jargon usage, missing citations, conceptual consistency, and overall flow. Where I suggest improvements, they are in bold.  
---

### **Title**

“Teaching Students How to Effectively Interact with LLMs in University: Insights on the Longitudinal Development and Plasticity of Locus of Control”

* Issue: “in University” can read slightly awkward.  
  * Potential Improvement: “...Interact with LLMs at University” or “...in a University Context.”  
  * Discussion: Either phrasing might be smoother, but this is minor.

---

### **Abstract (Paragraph 1\)**

In an ever-changing and rapidly advancing AI world, there is an urgency for both educators and students to become AI literate. This means acquiring technical, practical and ethical knowledge and understanding about AI, and maintain human agency during AI interactions.

* Issue (Parallel Structure): “acquiring … and maintain” is grammatically mismatched.  
  * Potential Improvement: “...acquiring technical, practical, and ethical knowledge and understanding about AI, and maintaining human agency…”  
* Academic Tone: Acceptable, though the phrase “AI world” is somewhat informal. It might be more formal to say “AI-driven world” or “rapidly changing AI landscape.”

---

### **Abstract (Paragraph 2\)**

This longitudinal qualitative case study explored the impact of a semester-long AI-focused unit teaching prompting and literacy for undergraduate students (*N* \= 12\) on student knowledge, understanding, beliefs and attitudes of AI. Survey results showed a significant increase in student knowledge and understanding of AI, while thematic analysis provided evidence of a positive impact on AI attitudes, beliefs, motivation, self-efficacy and human agency. ...

* Clarity: Clear statement of study design.  
* Flow: The phrase “teaching prompting and literacy for undergraduate students” is comprehensible but might be more direct as “...AI-focused unit that explicitly taught prompting and AI literacy...”  
* No major typos.  
* No missing citations; the study’s design is introduced properly.

---

*(Continuing through the Abstract...)*

While LOC is often viewed as a relatively stable trait, our data disclosed how each student's LOC shifted noticeably over the course of the semester ...

* Language: “disclosed” is fine, though “revealed” or “indicated” might be more common. No urgent issue.

The malleability of LOC in the face of empowering or disempowering AI technology experiences remains underexplored. ...

* Flow: Reads well. No mechanical errors.

---

### **Introduction (Paragraph 1\)**

Generative artificial intelligence (AI) has disrupted education systems worldwide, causing a maelstrom of policy reforms and ongoing debate...

* Possible Overstatement: “maelstrom” is vivid. It can stay if the tone is deliberately strong.  
* Citation: The references (Liu & Bates, 2025; Lodge et al., 2023; TEQSA, 2024\) appear. This is good.

... ChatGPT and Anthropic’s Claude.ai, are the most common consumer interfaces to LLMs (GPT-4o and o1, and Claude 3.5 Sonnet respectively).

* Issue: The text references “GPT-4o and o1” or “Claude 3.5 Sonnet.” Are these standard naming conventions? If they are internal or specialized version names, consider clarifying briefly or omitting if not critical.

LLMs are dependent on text to operate ... from a model training perspective as companies prepare them, but insidiously, from an operating perspective ...

* Language: The word “insidiously” may sound somewhat emotive. Possibly intended to highlight hidden reliance on text?

No glaring errors. Overall, the introduction paragraphs are well-structured and academically toned.  
---

### **Literature Review**

#### **Large Language Models (LLMs) and AI literacy**

Paragraph 1

LLMs are specifically designed as foundation models for processing and generating human language. ...

* Clarity: Good.  
* Potential Redundancy: “foundation models” is correct, but some readers might be unfamiliar with that term. A brief parenthetical definition might help if not already provided.

As AI interfaces change every few weeks, the focus for educators must be on the pragmatics of AI use: the u Education policies and curricular worldwide have now integrated this AI literacy advice...

* Issue (Typo / Fragment): “the u Education policies” seems like a stray insertion (“the u” appears abruptly). Possibly a typographical slip.  
  * Potential Improvement: “...the pragmatics of AI use. Education policies and curricula worldwide have now integrated...”  
* Missing Punctuation: “... Education policies and curriculara worldwide ...” should probably be “... Education policies and curricula worldwide ...”

Paragraph 2

There is currently limited specific advice about explicitly teaching LLMs in higher education contexts, and seemingly none that showcase how learning design, pedagogical approach and LOC interplay ...

* Flow is fine.

... textual technologies do not work by rote, grimoires notwithstanding (Mollick, 2025).

* Tone: The mention of “grimoires notwithstanding” is whimsical. Likely fine if the publication allows a lighter style in references to prompting folklore.

---

#### **Locus of Control (LOC) Theory**

Paragraph 1

Julian Rotter first introduced locus of control (LOC) ...

* Clear and well-cited.

Paragraph 2

LOC theory has continued to be extended and widely utilised...

* Smooth. No obvious issues.

---

#### **The Present Study**

This study was designed to explicitly teach AI literacy: critical thinking, ethical considerations and a human-centred approach...

* Generally well-stated. No typographical issues.

---

### **Methodology**

Participants and Recruitment

All 12 students (8 female, 4 male) who chose to undertake the experimental AI unit agreed to participate...

* Clear, standard language.

Data Collection and Analysis

At the conclusion of the unit, participants completed the AI component of the university’s Annual Student Survey ... A paired samples t-test...

* Good structure, typical academic style.

---

### **Results**

Figures 1 & 2

* Make sure figure captions or references are consistent with the journal style.

Attitudes to AI → Subsections

* The bullet points “Changed perception... More critical... Future-ready students...” read well.

"I used to be skeptical about using AI. \[Now\] I am more comfortable..."

* The bracketed insertion “\[Now\]” is consistent with academic quoting style.

---

### **Discussion**

This study set out to explore how explicit teaching about AI literacy through frontier model LLMs impacted individuals’ knowledge, attitudes, motivation...

* Smooth, academic tone.

... Students had profoundly shifted their agency regarding AI during the semester.

* Strong concluding statement. No mechanical issues.

---

### **Limitations and Future Directions**

This study was the first that we could find about the impact...

* Flows well. No major concerns.

---

### **Conclusion**

The need for educators to keep pace with an ever-changing AI landscape...

* Concludes effectively.

---

### **Acknowledgements, Funding, Ethics, Data Availability**

* All sections appear standard. The disclaimers about AI usage are appropriate. No red flags.

---

## **Final Notes on “Thinko” or Conceptual Checks**

1. Terminology:  
   * “LLM,” “generative AI,” and “frontier model LLMs” are used somewhat interchangeably. This is likely acceptable given the context, but the authors might clarify early that “frontier model LLMs” is a subset or a particular vantage of generative AI.  
   * “Literary techniques” vs. “prompting techniques/literacies”: the text clarifies it as “literary techniques specific to LLMs,” so presumably it means rhetorical or textual strategies for prompts. This is a nonstandard usage, so consider rechecking for potential reader confusion.  
2. Citations:  
   * The references appear comprehensive.  
   * There is a small untracked reference in the text: “see Appendix A \[\]{\#anchor}...” The bracketed anchor might be a LaTeX or markdown artifact. Ensure it is not a broken reference.  
3. Potential Missing Explanation:  
   * GPT-4o and o1, Claude 3.5 Sonnet, etc., might require a clarifying note. Are these advanced versions not widely known? Possibly mention that these are versions with specialized model “flavors” or were experimental prototypes. This is purely clarity-based.

No other major conceptual slips (“thinkos”) are apparent. The logic is consistent, the approach is well-structured, and the conclusion follows from the data presented.  
---

### **Summary of Key Highlighted Issues (In Brief)**

* Parallel Structure: “acquiring … and maintaining…”  
* Minor Typos: “the u Education policies,” “curricular worldwide” → “curricula worldwide.”  
* Minor Awkward Phrasing: “in University,” “insidiously,” “maelstrom,” “grimoires notwithstanding” (stylistic preference).  
* Potential Clarifications: “GPT-4o,” “Claude 3.5 Sonnet” versions.

Where relevant, I have provided bold suggestions for possible improvements.  
---

End of Copy-Editing Review  
ChatGPT can make mistakes. Check important info. See Cookie Preferences.  
