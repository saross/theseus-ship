\documentclass{article}
\usepackage{graphicx} % Required for inserting images

\title{LLM-History-Paper}
\author{Brian Ballsun-Stanton}
\date{March 2024}

\begin{document}

\maketitle

\section{Introduction}

% Impact of LLM on historical studies
% thesis: how do these LLMs deal with intellectual controversy? How does it exercise "academic judgement?"
%     GPT-4, Claude 3 Opus, Gemini Pro 1.5/Ultra (API access)
% a) Take the "current consensus" and ossify it
%     when students say give background on X, does it just get only consensus-reinforcing results
%     How does temporality of topic come into play?
%     If these chatbots were students, when were they students?
% b) What happens when you hit hot-button adjacent issues? 
%     (Race and antiquity)
%     Value of western civ as analytical frame
%     Can LLM treat imperialism as an analytical unit?
% c) What does the stupid context window imply for writing papers with an LLM
%     1 what happens if we put contradictory papers into the prompt?
%     2 demonstrate judgement
%     3 Can we time-travel and simulate a historian from the 90's? 
% Discussion







% Possible journals:
% Historical Methods or Contemporary Social Science
% Both are T&F journals. 'AI-based tools' policy is here: https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/ and https://newsroom.taylorandfrancisgroup.com/taylor-francis-clarifies-the-responsible-use-of-ai-tools-in-academic-content-creation/
% PLoS One
% I cannot find any AI Tools / LLM policy from PLoS One. Bing Chat says they don't have one. They have, however, published a '10 simple rules' list in PLoS Computational Biology: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011767

% Revised idea 10 April 2024 - start with a comprehensive, published lit review on a specific subject. 
% Take open access papers plus papers with author permission, ask it for an annotated bibliography on a selected topic, plus counterarguments, simulating the kind of research a PhD student would be doing for their research. Question: how do the different models understand the academic literature, can we situation them as a particular level of RA / student (how sophisticated are their ideas), when are they situated (what is 'current'), depth of reading (only 'greatest hits' or deeper into the literature). 
% How do you prompt the tools to get useful output? How useful compared to 'traditional' source like a quality review article? What can you expect when you move to subjects without such reviews?


% Other ideas:

% Use Claude API to analyse LIST insctiptions - can we do anything useful? spatial and chronological distributions? Other patterns? Perhaps look at collegia, as per Petra's paper
% Use Claude API to complete the Theseus' Ship article - find digital tools in Digital Archaeology publications - this is a ton of work manually and is holding up the paper, could it be assisted by application of an LLM?

% New with OpenAI DR and other reasoning models

% OpeanAI DR: Produces a mix of valuable material and dreck, perhaps run outputs through another model?
% Maybe generate several (many?) reports on a subject from different angles and synthesise?
% Compare OpenAI DR with giving PDFs to, say o3 Mini High?

% Ideas: could still do collapse of complex society using the two JAR articles (need to look them up again)
% Could try to finish the Theseus Ship article (core undertaking is to find the average lifespan of academic / research software products in archaeology and heritage) - has advantage that many of the papers are open access (e.g., internet archaeology, softwarex, etc.)
% Could do something related to the ML Burial Mounds and crowdsourcing papers (what are the costs, benefits, and thresholds for choosing between expert examination, crowdsourcing, and ML approaches to extracting data from maps, aerial photography, satellite imagery, and other remotely sensed data?
% something about developing a pipeline to support research to get the most out of current agents / models...??






\end{document}
