Tool,Outcome,Outcome-details,Description,History,Technical-discussion,Access-date,Tool-status,Tool-status-reasoning,DVCS-repo,CRAN,PyPi,Other-URL,License,Tags,AI-tags,First-release-date,Last-update-date,Current-version,Development-status,Institutional-backing,Authors,Development-team-size,Original-discipline,Original-purpose,Documentation-quality,Usage-indicators,Lifecycle-stage,Type,Category,Language,Platform,Open-Archaeo-Platform,Interoperability,Strengths,Weaknesses,Survivability,Alternatives,Review_Notes
ade4,Success,,"ade4 is an R package providing multivariate data analysis methods with a focus on ecological data. The name stands for 'Analysis of Ecological Data: Exploratory and Euclidean Methods in Environmental Sciences'. It implements a mathematical framework called the 'duality diagram' which unifies various multivariate analysis techniques under a coherent theoretical approach. While primarily developed for ecological research, its robust statistical methods have applications across disciplines, including limited archaeological uses for site comparison, spatial pattern detection, and material culture analysis. The current version offers comprehensive functionality for one-table, two-table, K-table analyses, and specialized methods for phylogenetic and spatial data.","ade4 originated as an R implementation of earlier standalone ADE-4 software developed in the 1990s at the University Lyon 1's Biometry and Evolutionary Biology Laboratory. First published as standalone software in 1997, it was converted to an R package in 2002 by a team led by Daniel Chessel, Jean Thioulouse, Sylvain Dolédec, and Jean-Michel Olivier. Major developments include: 2004 publication describing one-table methods; 2007 publications on two-table methods and the duality diagram framework; and 2018 publication of a dedicated Springer book 'Multivariate Analysis of Ecological Data with ade4'. The package has evolved to support a growing ecosystem of companion packages including adegraphics (visualization), adephylo (phylogenetic data), and adespatial (spatial analysis). It continues to be actively maintained by Aurélie Siberchicot at University Lyon 1.","The current version of ade4 is primarily implemented in R, with computationally intensive components written in C, C++, and Fortran for performance optimization. It uses Rcpp for seamless integration between R and C++ code. The architecture revolves around several key data structures: 'dudi' class (representing a duality diagram, the fundamental mathematical concept), 'ktab' class (managing multiple linked data tables), 'kdist' class (representing distance matrices), and specialized classes for phylogenetic data, neighborhood graphs, and orthonormal bases. The package's distinguishing technical feature is its implementation of the duality diagram framework, which provides a unified mathematical approach to different multivariate methods. Current version offers: one-table analyses (PCA, correspondence analysis, etc.), two-table analyses (coinertia analysis, Procrustes analysis), three-table methods (RLQ analysis linking environment, species, and traits), K-table methods (STATIS, multiple coinertia analysis), and spatial analysis methods with integrated statistical testing procedures. Previous versions had more limited functionality and less computational efficiency before the integration of C++ components via Rcpp. The current implementation emphasizes both mathematical rigor and computational performance, with particular attention to the handling of ecological datasets with complex relationships between multiple data domains.",2023-05-04,yes,"ade4 meets all essential criteria and multiple supporting criteria for research software tools. It clearly has a research-specific purpose, transforms research data meaningfully, and aligns with recognized methodologies in multivariate statistics. For supporting criteria, it excels in analytical capabilities (implementing numerous multivariate methods), visualization functions (through direct functions and companion packages), data transformation (handling various ecological data formats), and domain knowledge integration (incorporating ecological terminology and frameworks). Its documentation specifically addresses research applications, and it supports multiple stages of the research lifecycle from data preparation through analysis to visualization. The package's connection to archaeology is evidenced through its Procrustes analysis function referencing Gower's 1971 paper published in 'Mathematics in the archaeological and historical sciences' and its applicability to archaeological data analyses such as site comparison and material culture classification.",https://github.com/adeverse/ade4,https://CRAN.R-project.org/package=ade4,https://adeverse.github.io/ade4/,https://adeverse.github.io/ade4/,GPL-2.0-or-later,Statistical analysis|Data management|Network analysis,multivariate analysis|ecological data|R package|statistical methods|duality diagram,2002,2023-02-01,1.7-22,Active,University Lyon 1|French National Center for Scientific Research (CNRS),Daniel Chessel|Jean Thioulouse|Sylvain Dolédec|Jean-Michel Olivier|Stéphane Dray|Anne-Béatrice Dufour|Aurélie Siberchicot,Medium (6-20),Ecology,General-purpose,Excellent,"The package has been extensively cited in academic literature, particularly in ecological research. It has spawned an ecosystem of related tools (adegraphics, adephylo, adespatial, ade4TkGUI) and is integrated into university courses on multivariate analysis. While precise download statistics aren't available, its regular updates indicate ongoing usage. The GitHub repository shows consistent maintenance activity. The package is referenced in numerous ecological research workflows and maintains an active support mailing list (adelist). It has inspired web interfaces like ade4shiny to make its functionality accessible to non-programmers.",Analysis|Interpretation,research-specific,Packages and libraries,R|C|C++|Fortran,R,R,"ade4 supports various data formats common in statistical analysis. The current version can import data from plain text files, Excel spreadsheets (via auxiliary packages), and other R data structures. It can export results to standard R formats and visualization outputs to common graphics formats. The package interfaces well with the broader R ecosystem, particularly with its companion packages (adegraphics for advanced visualization, adephylo for phylogenetic analyses, adespatial for spatial statistics). It also provides integration points with general-purpose R visualization tools.","Current version's key strengths include its solid theoretical foundation in duality diagram mathematics, providing conceptual unity across diverse analytical methods. Its comprehensive functionality spans from basic ordination to sophisticated multi-table analyses, making it particularly valuable for complex ecological questions with multiple interconnected variables. The package is extremely well-documented with academic publications, a dedicated book, and extensive online resources. Its long development history (since 2002) and active maintenance demonstrate stability and reliability. Being open-source and integrated with the R ecosystem makes it accessible to researchers globally while allowing interoperability with other analytical tools. Its implementation of specialized methods like coinertia analysis and RLQ analysis are particularly valuable for ecological research.","The current version's primary limitation is its steep learning curve for users without strong statistical backgrounds. The documentation, while comprehensive, can be technically challenging for newcomers, requiring familiarity with both R programming and advanced multivariate statistics concepts. Some visualization limitations exist in the original graphical functions, though these are addressed by the companion adegraphics package. As an older package with a long development history, parts of the codebase may not follow modern R conventions, potentially affecting maintenance as the R ecosystem evolves. Its specialized ecological focus, while beneficial for targeted users, may limit broader adoption in other fields that could benefit from similar analytical approaches. The package's academic origins mean its development is driven by research needs rather than user interface design, resulting in less intuitive usage compared to some newer statistical packages.","ade4 demonstrates excellent prospects for continued sustainability. The package has active development with regular updates (latest release in February 2023) and strong institutional backing from University Lyon 1 and the French National Center for Scientific Research (CNRS). It's maintained by a dedicated core team of professional researchers with a vested interest in its continued availability. The comprehensive documentation, including a 2018 book and extensive online resources, ensures knowledge preservation beyond the current development team. Its established position in ecological research workflows and integration into academic teaching provide a stable user base. The package uses modern development practices including GitHub repository and issue tracking systems. Its academic foundations provide both strengths (methodological rigor, institutional support) and potential challenges (dependence on academic funding), but overall sustainability indicators are very positive.",vegan (more focused on community ecology ordination and diversity analysis)|FactoMineR (more general-purpose multivariate analysis with easier learning curve)|MASS (broader statistical focus covering many methods)|Base R stats (provides basic multivariate methods but requires more manual work)|ExPosition/ade4TkGUI (GUI interfaces to make multivariate analysis more accessible),
Agisoft PhotoScan/Metashape,Success,,"Agisoft Metashape (formerly PhotoScan until 2019) is a professional photogrammetry software that transforms collections of digital photographs into precise 3D spatial data. The current version can generate textured 3D models, georeferenced orthomosaics, digital elevation models, and dense point clouds from overlapping images. In archaeological contexts, it has become the predominant tool for documenting excavations, artifacts, rock art, landscapes, and underwater sites with millimetre-level precision. While originally developed for general photogrammetry applications, it has been widely adopted by archaeologists due to its balance of technical capability and accessibility, enabling both comprehensive site documentation and detailed artifact preservation.","Agisoft released PhotoScan in 2010 as a CPU-based photogrammetry solution. The software evolved incrementally until January 2019, when version 1.5.0 was renamed to Metashape, marking a fundamental technical advancement. This transition represented far more than rebranding—the new Metashape introduced GPU acceleration, depth map-based mesh generation (versus previous point cloud methods), reduced memory requirements through out-of-core implementation, and machine learning integration including AI-based semantic classification. Metashape 1.x series (2019-2022) expanded capabilities with support for spherical cameras, aerial LiDAR, and an enhanced Python API. The current 2.x series (2023-2025) introduced further refinements including improved laser scan support, DEM editing tools, and pansharpening capabilities. Throughout these transitions, Agisoft maintained backward compatibility and offered free updates to licensed users, ensuring continuity for established workflows.","The current version of Agisoft Metashape employs a sophisticated technical approach combining computer vision algorithms with traditional photogrammetric principles. The software's processing pipeline follows key stages: (1) Photo alignment using Structure from Motion (SfM) where the software analyzes overlapping photographs, identifying common points to determine camera positions and creating a sparse point cloud; (2) Dense point cloud generation using Multi-View Stereo (MVS) techniques, performing pixel-level matching across multiple calibrated images; (3) Mesh generation, where Metashape introduced a more efficient approach working directly with depth maps rather than point clouds, preserving more detail while using less memory; (4) Texture mapping and orthomosaic generation, applying photorealistic textures from original images. The Professional edition incorporates advanced capabilities including georeferencing, GCP support, and AI-powered classification—particularly valuable for archaeological landscapes where distinguishing natural from human-made features is crucial. Python scripting capabilities allow workflow automation and customization, while GPU acceleration dramatically reduces processing times compared to earlier versions. Earlier PhotoScan versions relied primarily on CPU processing, which was significantly slower for large projects, and lacked the memory optimization of current Metashape versions.",2025-05-04,yes,"Agisoft Metashape meets all essential research software criteria and numerous supporting criteria. Essential criteria: (1) Research-Specific Purpose: Explicitly supports archaeological documentation and analysis through specialized features for georeferencing, orthomosaic generation, and spatial measurements; (2) Research Data Engagement: Transforms 2D images into analyzable 3D models, point clouds, and digital elevation models that facilitate quantitative analysis; (3) Methodological Alignment: Implements established photogrammetric methodologies used widely in archaeological research. Supporting criteria met include: domain knowledge integration through archaeological-specific workflows; research lifecycle support spanning data collection to publication; data transformation capabilities; analytical functions including measuring and comparing features; visualization of complex spatial information; and documentation specifically addressing archaeological applications.",,,https://www.agisoft.com/,https://www.agisoft.com/,Proprietary commercial license,3D modelling|Photogrammetry|Spatial analysis|Site mapping|Data management,photogrammetry|3D modeling|spatial documentation|archaeological visualization|cultural heritage preservation,2010,2024-07-01,2.2.1,Active,"Agisoft LLC (private company based in St. Petersburg, Russia, with UK registered entity AGISOFT LIMITED since 2018)",Agisoft development team,Medium (6-20),Computer vision and photogrammetry,General-purpose,Excellent,"Metashape has achieved benchmark status in archaeological photogrammetry and is frequently used as the standard against which other software is evaluated in comparative studies. It has widespread institutional adoption across universities, museums, and archaeological research organizations worldwide. The software's dedicated educational licensing program (with substantial discounts) has facilitated academic adoption. The active user community is evidenced by regular citations in archaeological publications, numerous field guides specifically developed for archaeological applications, and extensive discussion in academic literature examining digital documentation methods.",Data Acquisition|Processing|Analysis|Preservation and Reuse,research-specific,Stand-alone software,C++|Python (for API),Windows|macOS|Linux,,"Agisoft Metashape offers extensive interoperability with various input formats (JPEG, TIFF, RAW, etc.), camera types (frame, fisheye, spherical, cylindrical), and specialized imagery (multispectral, thermal). Export capabilities include mesh formats (OBJ, 3DS, VRML, COLLADA, PLY, STL, FBX, glTF), point cloud formats (LAS/LAZ, XYZ, E57, Potree), and GIS formats (GeoTIFF, Arc/Info ASCII Grid, KML). The Professional version seamlessly integrates with GIS software through standardized geospatial formats. The software provides a Python API for custom workflows and automation, network processing for distributed computing, and cloud processing services for resource-intensive projects.","The current version of Metashape offers several key strengths for archaeological applications: (1) Accessibility and cost-effectiveness compared to laser scanning alternatives, with significant educational discounts facilitating academic adoption; (2) Versatility across contexts from small artifacts to expansive landscapes and underwater environments; (3) Intuitive interface allowing non-specialists to implement photogrammetry while offering advanced capabilities for experts; (4) Strong integration with common archaeological workflows and GIS software; (5) Comprehensive georeferencing capabilities essential for spatial documentation; (6) Exceptional capturing of surface detail critical for recording subtle archaeological features; (7) Streamlined documentation through batch processing and automation via Python scripting.","The current version of Metashape presents several significant limitations: (1) Computational demands that can exceed available resources for many archaeological projects, particularly in field settings with limited hardware access; (2) 'Black box' algorithm concerns due to its proprietary nature, which can complicate methodological transparency in scientific publications; (3) Significant learning curve for advanced features beyond basic operations, requiring training investments; (4) Substantial price gap between Standard ($179) and Professional ($3,499) editions, with many archaeological applications requiring Professional features; (5) Russian ownership concerns in the current geopolitical context, potentially complicating institutional procurement; (6) Limited batch processing in the Standard edition; (7) Resource-intensive projects may require specialized computing hardware beyond typical archaeological budgeting.","Agisoft has demonstrated strong commitment to long-term software development with a 15-year history (2010-2025) of continuous improvement. Key viability indicators include: consistent update cycles with 2-3 significant releases annually, successful technology transition from PhotoScan to Metashape, active community adoption across multiple disciplines, and responsive feature development addressing user needs. The latest release (2.2.1, July 2024) indicates ongoing development. The software's widespread adoption in academic and commercial contexts suggests sustainable market position. Future directions likely include enhanced AI integration, improved performance optimization, expanded cloud capabilities, and specialized features for key industries including archaeology. The company's private ownership structure makes long-term financial stability assessment difficult, but its market leadership position and consistent development suggest positive prospects.","RealityCapture (often faster but requires more technical expertise); Pix4D (popular for drone surveys but generally more expensive); Bentley ContextCapture (strong for landscape applications); Open-source alternatives (MicMac, VisualSFM, Meshroom)",
AION,Success,,"AION is an R package for handling archaeological time series that addresses the unique challenges of archaeological chronology. The package represents dates independently of calendar systems using the 'rata die' approach (counting days since January 1, 1 CE in the Gregorian calendar), enabling consistent representation of dates extending thousands or millions of years into the past. AION forms part of the broader tesselle ecosystem of R packages designed specifically for archaeological research and supports temporal data manipulation with dedicated classes for time series and intervals. It provides functionality for archaeological researchers working with complex chronological data spanning multiple historical periods or requiring precise chronological representation.","AION was developed by Nicolas Frerebeau at Archéosciences Bordeaux (UMR 6034), part of Université Bordeaux Montaigne in France, with significant contributions from Joe Roe of Universität Bern. The development history is relatively recent, with the first significant release appearing around 2023. The current version is 1.5.0 as of May 2025. The software was initially hosted on GitHub before moving to Codeberg, reflecting a commitment to open-source, community-led platforms. AION emerged from the need for reproducible, transparent archaeological research in response to the broader reproducibility crisis affecting scientific disciplines. It was created as part of the tesselle project, a collection of interconnected R packages for archaeological research and teaching developed at Archéosciences Bordeaux.","AION is implemented in the R programming language using S4 object-oriented programming for its class hierarchy. As an R package, it's platform-independent, running on Windows, macOS, and Linux systems. The current version implements a modular architecture with minimal dependencies to ensure portability and long-term sustainability. The technical implementation centers around several key components: a calendar system foundation for representing dates in 'rata die' format, a comprehensive class hierarchy including TimeScale, GregorianCalendar, JulianCalendar, TimeSeries, and TimeInterval classes, and an API layer providing methods for creating, manipulating, and visualizing archaeological time data. AION's data model represents time series as n×m×p arrays, where n is the number of observations, m is the number of series, and p is the number of extra variables. Rather than introducing custom file formats, it works with standard R data structures, leveraging R's import/export capabilities for interoperability. The programming interface offers functions like series(), intervals(), plot(), and calendar() that allow archaeologists to create, manipulate, and visualize temporal data. These capabilities are thoroughly documented through standard R documentation, vignettes, and practical examples. The package follows best practices for R package development, including comprehensive unit testing and continuous integration.",2025-05-04,yes,"AION clearly meets all essential criteria for research software. It has a specific purpose of supporting archaeological research through specialized time series representation (Essential Criterion 1), directly transforms research data by handling complex archaeological chronologies (Essential Criterion 2), and aligns with established archaeological methodologies (Essential Criterion 3). AION satisfies several supporting criteria: it integrates archaeological domain knowledge through specialized date handling for ancient calendars (Supporting Criterion 1), supports multiple stages of the research lifecycle including data preparation, analysis and visualization (Supporting Criterion 2), transforms temporal data between different representations (Supporting Criterion 3), provides analytical capabilities for chronological data (Supporting Criterion 4), and includes visualization functions for temporal data (Supporting Criterion 5).",https://codeberg.org/tesselle/aion,https://cran.r-project.org/web/packages/aion/index.html,https://packages.tesselle.org/aion/,https://packages.tesselle.org/aion/,GPL-3.0,Chronological modelling|Statistical analysis|Data management,Archaeological time series|Chronological analysis|Rata die representation|Calendar conversion|Archaeological dating,2023-01-01,2025-01-15,1.5.0,Active,Université Bordeaux Montaigne|Archéosciences Bordeaux UMR 6034,Nicolas Frerebeau|Joe Roe,Small (2-5),Archaeology,General-purpose,Excellent,"AION is a recent specialized tool (2023-2024), with evidence of growing adoption in the archaeological community. Its GitHub repository has been moved to Codeberg, making traditional metrics harder to track. The package has been cited in at least one publication in the Journal of Open Source Software in 2024. Usage metrics from Zenodo show approximately 83 downloads and 512 views. The software is part of the tesselle ecosystem of archaeological R packages, which improves its discoverability within the archaeological data analysis community. As a specialized tool for chronological analysis, it has a niche but important target audience.",Analysis|Processing,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"AION uses standard R data structures for interoperability, primarily relying on R's import/export capabilities for data exchange. The current version works with common data formats including CSV and Excel through R's import functions. It integrates seamlessly with other packages in the tesselle ecosystem for archaeological research. The package can export visualizations as standard image formats through R's plotting system. A key aspect of its interoperability is its ability to transform between different calendar systems and date formats, supporting both Julian and Gregorian calendars with various era notations (BCE/CE, BP). This makes it particularly valuable for projects spanning multiple historical periods or requiring integration with other chronological datasets.","AION excels at handling the unique temporal challenges of archaeological data, particularly very distant dates and irregular time sampling that standard time series packages cannot address. Its calendar flexibility supports multiple systems (Julian/Gregorian) and various notations (BCE/CE, BP), essential for research spanning different historical periods. Being part of the R ecosystem offers seamless integration with thousands of statistical and visualization packages. The open-source license and version control ensures transparency and free availability, while comprehensive documentation and vignettes reduce the learning curve. For research applications, AION enables fully reproducible workflows and standardized time representation that facilitates comparison across studies. Its minimal dependencies and careful consideration of cross-platform compatibility contribute to long-term sustainability.","The primary limitation is the requirement for R programming knowledge, presenting a barrier for archaeologists without computational training. AION provides foundational functionality but requires complementary packages for comprehensive analysis. Despite good documentation, the conceptual model of rata die presents a learning curve for those unfamiliar with computational approaches to time. The software lacks a graphical user interface, relying instead on command-line interaction which may deter some potential users. Integration challenges exist between field data collection methods and AION's structured format. There's limited direct GIS integration despite the importance of spatial analysis in archaeology. As a specialized tool, it has a relatively small user community compared to more general-purpose software, which can slow the resolution of issues and reduce available community support.","AION's long-term viability appears positive due to several factors: institutional support within an established research unit (UMR 6034), active development by a dedicated team, open-source licensing that ensures community maintenance potential, integration into academic teaching and research, comprehensive documentation with academic publications, and proper version control and archiving with DOIs for each version on Zenodo. The development follows core principles of transparency, reproducibility, minimal dependencies, and rigorous testing. Potential challenges include limited information on dedicated long-term funding, reliance on academic infrastructure, and a small core development team primarily led by one individual. However, its integration within the broader tesselle ecosystem of archaeological packages and the growing recognition of computational approaches in archaeology suggest continued relevance and support.","Several alternatives to AION exist for archaeological chronology and data management: R Packages for Archaeological Chronology like ArchaeoPhases (focusing on chronological modeling and time range estimation), archSeries (handling entities with varying chronological resolution), and Bchron (specializing in radiocarbon dating calibration); Archaeological Database Systems including ARK (web-based toolkit for field recording), OpenAtlas (open-source system for complex archaeological and geospatial data), tDAR (digital repository for archiving archaeological information), and InTerris Registries (commercial solution for archaeological data management); and General-Purpose Statistical Software such as PAST (free package with functions for scientific data analysis), SPSS (commercial statistical package used in archaeology), and Excel (widely used for basic data management despite limitations). Each alternative offers different strengths depending on specific research needs.",
Annotorious,Success,,"Annotorious is a JavaScript library that enables web-based annotation of images. It allows users to mark regions of interest in visual materials by drawing shapes (rectangles, polygons) and attaching comments or tags to these annotations. The current version (3.x) provides a clean, modular architecture for integrating annotation capabilities into web applications. While originally developed for general digital cultural heritage contexts, Annotorious has found significant application in archaeological and historical research for documenting artifacts, annotating excavation photographs, marking features on historical maps, and creating digital editions of manuscripts with linked geographic references.","Annotorious evolved from the YUMA Universal Media Annotator, a prototype developed during the EU-funded EuropeanaConnect project (2009-2011) with the Austrian Institute of Technology (AIT) as the original developer. The software has progressed through several major versions: early iterations derived from the YUMA prototype, then Version 2.x which established core functionality (now deprecated), and the current Version 3.x with architectural improvements. The project was initially backed by institutional support from AIT and EU funding but now continues as an independent open-source effort maintained primarily by lead developer Rainer Simon (@aboutgeo), with community contributions through GitHub. The project maintains regular updates, with the most recent version (3.1.0) released in January 2025 adding React 19 support.","Annotorious is built using TypeScript (compiled to JavaScript), CSS for styling, and SVG for rendering annotation shapes. The library implements a client-side architecture with modular components that can be arranged into three main layers: a core annotation layer that overlays on images, drawing tools for creating shapes, and an editor interface for adding content to annotations. A defining technical characteristic is its adherence to the W3C Web Annotation Data Model, providing a standardised representation of annotations with unique identifiers, shape targets (specifying coordinates), and bodies (containing content). This standards compliance significantly enhances interoperability with other digital humanities systems. The current version (3.x) offers two key implementations: the core library for regular images and an extension for OpenSeadragon integration that enables annotation of high-resolution zoomable images—particularly valuable for detailed examination of archaeological artifacts and historical documents that require close inspection. The architecture exposes an event-driven API that allows developers to customise annotation behaviour and appearance through plugins and extensions. Annotations are stored in a JSON-based format compatible with the W3C standard, making them portable across different systems. The client-side implementation means Annotorious has no server dependencies and can work with any backend storage system, though this also means implementers must handle persistence separately. For specialized applications, the library offers plugins for gazetteer integration, which allows annotation of place names in historical documents with links to standardized geographical references.",2025-05-05,yes,"Annotorious fully satisfies all Essential Criteria for research software. It directly supports scholarly inquiry through image annotation (Research-Specific Purpose), meaningfully transforms research materials by enabling structured annotation of visual content (Research Data Engagement), and aligns with recognized digital humanities methodological approaches to document analysis (Methodological Alignment). It also meets multiple Supporting Criteria: Domain Knowledge Integration (archaeological/historical terminology can be added to annotations), Research Lifecycle Support (functions in both data acquisition and analysis stages), Data Transformation (creates structured metadata about images), Visualization Functions (renders annotations as visual overlays), and Documentation Focus (examples target scholarly use cases).",https://github.com/annotorious/annotorious,,https://annotorious.dev/,https://annotorious.dev/,BSD 3-Clause,3D modelling|Diagrams and visualizations|Data management|Spatial analysis|API interfaces and web scrapers,web-based annotation|historical maps|archaeological documentation|cultural heritage|semantic metadata,2011-05-01,2025-01-15,3.1.0,Active,Originally Austrian Institute of Technology (AIT); now community-maintained,"Rainer Simon (lead), with contributions from the open-source community",Small (2-5),Digital Humanities,General-purpose,Comprehensive,"Moderate adoption metrics with approximately 500 GitHub stars and 120 forks across repositories. Integration with the Pelagios Network and Recogito platform has extended reach in digital humanities. Used in multiple academic projects including Digital Periegesis (analysis of Pausanias's second-century CE 'Description of Greece'), Pelagios South/Pelagios al Sur (examining 17th-18th century Argentinian chronicles), and 'La Argentina Manuscrita' (annotating a 17th-century Spanish-Guarani chronicle). Core institutional users include the World History Center (University of Pittsburgh), Institute of Classical Studies (London), University of Buenos Aires, and CONICET (Argentina). Documented in academic publications including Simon et al. (2017) 'Linked data annotation without the pointy brackets' and Del Rio Riande and Vitale (2020) 'Recogito-in-a-Box: From Annotation to Digital Edition'.",Analysis|Data Acquisition|Processing,research-specific,Stand-alone software,TypeScript|JavaScript,Web browsers,,"Annotorious is highly interoperable due to its W3C Web Annotation standard compliance, offering a W3CImageAdapter utility to crosswalk between its optimized model and the standard W3C model. Its client-side JavaScript implementation makes it usable with various backend systems. The JSON-based annotation format allows for easy storage and retrieval across platforms. The current version provides robust extension capabilities through plugins and integrates with OpenSeadragon for high-resolution image viewing. For archaeological and historical research applications, it features integration with gazetteer services like Pleiades and the World Historical Gazetteer, enabling semantic linking of place annotations to standardized geographical references. While primarily web-based, its annotations can be exported and transferred to other systems using standard formats.","The current version of Annotorious offers several notable strengths: adherence to the W3C Web Annotation standard ensures interoperability and long-term viability, the client-side implementation requires no server dependencies making deployment straightforward, the plugin architecture enables customisation for specific research needs, and integration with OpenSeadragon allows work with high-resolution images essential for detailed artifact analysis. The specialized support for historical map annotation through gazetteer integration enables structured spatial humanities research linking historical documents to geographical information. The clean event-driven API architecture makes it adaptable to different research workflows while maintaining consistent annotation structures. The library works across both desktop and mobile/touch interfaces, facilitating fieldwork documentation.","Despite its strengths, Annotorious has limitations: the community support is relatively small compared to mainstream JavaScript libraries, resulting in slower resolution of issues and fewer extensions. Implementation can be challenging, particularly for those less familiar with JavaScript development or when integrating with frameworks like React. The recent version transition from v2 to v3 has created potential compatibility issues for existing projects. While well-documented, complex use cases have limited examples. The library's focus is primarily on visual annotation rather than text, requiring complementary tools for comprehensive document analysis. The absence of built-in server components means users must implement their own storage and sharing solutions. These limitations are most significant for projects with limited technical resources or those requiring extensive customization beyond standard annotation features.","Annotorious shows good prospects for long-term sustainability despite its relatively small development community. Key factors supporting its continued viability include: active maintenance by lead developer Rainer Simon with recent updates (January 2025), strong adherence to W3C standards ensuring compatibility with evolving web technologies, documentation quality that facilitates adoption by new users, deep integration with the Pelagios Network and other digital humanities initiatives providing a stable user base, and BSD licensing that allows flexible reuse and adaptation. The codebase's modular architecture facilitates maintenance and extension. However, the project's reliance on a small number of core contributors presents a succession risk. To enhance its prospects, the project would benefit from attracting additional core contributors, establishing more formal institutional backing, and developing a more extensive ecosystem of extensions and examples. Overall, the software appears positioned to remain viable for the medium-term (3-5 years) with continued community interest.","Several alternatives to Annotorious exist with different strengths and limitations. React-image-annotation is more popular for React applications but lacks standards compliance. Marker.js offers simpler annotation capabilities with better mainstream adoption but fewer features for humanities research. The LabelMe Annotation Tool provides more AI-integration features but with a more complex setup. Commercial platforms like SuperAnnotate offer more comprehensive functionality but at a cost and with potential vendor lock-in. For archaeological applications specifically, Recogito (built using Annotorious components) offers a more complete platform with integrated text annotation capabilities, while QGIS with manual digitizing tools provides broader GIS functionality but lacks specialized image annotation features. Comparatively, Annotorious balances standards compliance, specialized humanities features, and ease of integration, making it particularly suitable for cultural heritage contexts despite having a smaller user community than some alternatives.",
ArcGIS skeletal templates,Success,,"ArcGIS skeletal templates are specialized vector data files (shapefiles) created for zooarchaeological analysis. Developed by Dr. David C. Orton in 2010, these templates provide pre-made anatomical diagrams of skeletal elements for common mammalian species (cattle, sheep, pig, horse, dog, and red deer) that allow archaeologists to visualize, analyze, and present zooarchaeological data directly within the ArcGIS environment. By linking excavation data to standardized skeletal diagrams, researchers can efficiently identify patterns in bone assemblages that reveal ancient butchery practices, disposal methods, and cultural behaviors related to animal processing. The current version continues to be the original 2010 release, as no documented updates have been published.","The ArcGIS skeletal templates were developed by Dr. David C. Orton while at the McDonald Institute for Archaeological Research, University of Cambridge. They were first released in 2010 through publication in Internet Archaeology (volume 28, article 4). The development addressed a significant challenge in zooarchaeological research: the time-consuming process of creating anatomical diagrams for visualizing and analyzing faunal assemblages. The templates transformed this labor-intensive process into a more efficient digital workflow leveraging GIS technology's analytical capabilities. The original release included templates for six common mammalian species. No documented updates have been released since 2010. The templates continue to be referenced and used by archaeological institutions despite the lack of updates.","The skeletal templates are implemented as standard Esri shapefiles that can be loaded into ArcGIS Desktop (specifically ArcMap) or potentially ArcGIS Pro. Each template consists of multiple component files (.shp, .shx, .dbf, and .prj files) which contain both the geometric data representing skeletal elements and attribute data about those elements. The current version follows this implementation approach, with no documented technical changes since the original 2010 release. Once loaded into ArcGIS, the templates become layers that can be manipulated using standard GIS tools. The implementation leverages ArcGIS's symbology capabilities to enable researchers to: (1) link zooarchaeological data directly to specific skeletal elements, (2) apply different visualization styles based on attributes like bone frequency or modification patterns, (3) perform spatial analysis on skeletal element distribution, and (4) produce publication-quality anatomical diagrams. The templates work within the existing ArcGIS environment rather than functioning as standalone tools or extensions, meaning they depend entirely on ArcGIS's core functionality for visualization and analysis. Technical requirements include ArcGIS software (originally ArcMap, compatibility with ArcGIS Pro is undocumented), basic understanding of GIS concepts, knowledge of shapefile importing, familiarity with ArcGIS symbology tools, and zooarchaeological data in a linkable format.",2025-05-05,yes,"ArcGIS skeletal templates qualify as research software based on the evaluation framework. They meet all essential criteria: (1) Research-Specific Purpose: Explicitly designed to support zooarchaeological research; (2) Research Data Engagement: Transform zooarchaeological data into visual representations that enable new insights; (3) Methodological Alignment: Compatible with established zooarchaeological methodologies like MNI, MNE, and MAU quantification. They also satisfy multiple supporting criteria including: domain knowledge integration (incorporates zooarchaeological terminology and classifications), analytical capabilities (enables comparison and pattern identification), visualization functions (renders skeletal data visually), and data transformation (converts tabular data to spatial representations).",,,https://intarch.ac.uk/journal/issue28/orton_index.html,https://intarch.ac.uk/journal/issue28/orton_index.html,No specific license information documented,Zooarchaeology|Statistical analysis|Diagrams and visualizations|Spatial analysis|Data management,Anatomical mapping|Faunal remains analysis|Archaeological visualization|Spatial data templates|Taphonomic research,2010,2010,No version numbering system identified,Maintenance-only,McDonald Institute for Archaeological Research at the University of Cambridge|University of York's Department of Archaeology/BioArCh,,Solo,Archaeology,Project-specific,Basic,"The templates are referenced on zooarchaeology resource lists at major institutions including the University of Cambridge Department of Archaeology and the University of York. They are cited in methodological papers on digital approaches to zooarchaeology. The original paper in Internet Archaeology continues to be referenced in subsequent research. However, no precise usage statistics are publicly available, and the templates' distribution through academic channels rather than public repositories makes tracking adoption challenging. Citations of the original paper provide the primary metric for usage, alongside mentions in institutional resources.",Analysis|Processing|Visualization,research-specific,Packages and libraries,,Windows|Mac OS|Linux,ArcGIS,"The templates are implemented as standard Esri shapefiles (.shp, .shx, .dbf, and .prj files), making them compatible with ArcGIS software. The current version supports the six mammalian species included in the original release. Data can be exported from ArcGIS in various formats, including images for publication, shapefiles for further GIS analysis, or tables for statistical analysis. Compatibility with newer versions of ArcGIS (particularly ArcGIS Pro) is not well documented, potentially limiting interoperability with current workflows. The templates were designed for ArcMap rather than ArcGIS Pro, which may create compatibility issues as ESRI transitions to the newer platform.","The templates offer several significant strengths for archaeological research: (1) Efficiency in creating anatomical diagrams compared to manual methods, dramatically reducing time required for visualization; (2) Standardization of skeletal representation across research projects, enhancing comparability of results; (3) Direct integration of analytical capabilities through the ArcGIS environment, allowing complex spatial and statistical analysis; (4) Ability to visualize multiple variables simultaneously on the same diagram (e.g., bone frequency, cut marks, burning patterns); (5) Preservation of the connection between raw data and visual representation, maintaining data integrity; (6) Support for traditional zooarchaeological quantification methods including MNI, MNE, and MAU calculations. The current version continues to offer these benefits, particularly for researchers already using ArcGIS.","The templates face several notable limitations: (1) Dependency on commercial ArcGIS software with high licensing costs, creating access barriers for researchers with limited resources; (2) Limited species coverage in the current version (only six mammals), requiring adaptation for studies involving other species; (3) Designed for ArcMap rather than the newer ArcGIS Pro platform, creating potential compatibility issues as ESRI phases out ArcMap; (4) Steep learning curve for researchers unfamiliar with GIS concepts and interface; (5) Lack of updates since the original 2010 publication, meaning no bug fixes or improvements have been implemented; (6) Absence of a central repository or distribution platform, making the templates challenging to discover and access; (7) Limited documentation beyond the original publication, potentially hindering adoption by new users.","The long-term viability of ArcGIS skeletal templates faces several challenges. Most significantly, ArcMap (the platform for which they were originally designed) will reach end-of-life in 2026, with ESRI pushing users toward ArcGIS Pro. The templates' compatibility with Pro is not well-documented, creating uncertainty about future usability. Additionally, the lack of updates since 2010 suggests minimal active maintenance, increasing risk of technical obsolescence. The templates' dependency on commercial ArcGIS software creates sustainability concerns as open-source alternatives gain popularity in archaeology. Without documented licensing information, the potential for community-driven updates is unclear. The templates' survival will likely depend on: (1) successful adaptation to ArcGIS Pro, (2) continued institutional support from academic archaeology departments, or (3) migration to open platforms. Their specialized nature for zooarchaeology provides value that may motivate preservation efforts, but without active maintenance, their relevance will gradually diminish as GIS technology evolves.","Several alternatives to ArcGIS skeletal templates exist: (1) QGIS with archaeological plugins: Open-source GIS platform with growing adoption in archaeology, offering similar functionality without licensing costs; (2) Traditional graphics software: Manual creation of diagrams using Adobe Illustrator or similar programs; (3) Specialized zooarchaeological database tools: Applications like TIPZOO that focus on data management rather than visualization; (4) R packages for zooarchaeological analysis: Growing ecosystem of specialized analysis packages with visualization capabilities; (5) Custom shapefile creation: Developing personalized templates tailored to specific research needs. Each alternative offers different trade-offs in terms of learning curve, cost, and capabilities. The choice depends on a researcher's specific needs, technical capabilities, and institutional resources.",
Arch-I-Scan,Success,,"Arch-I-Scan is an image recognition software that uses artificial intelligence to identify Roman pottery fragments via smartphone photography. The system enables archaeologists and non-specialists to photograph pottery vessels or fragments using ordinary smartphones, which the system then analyzes to provide accurate identifications of form and fabric type. The current version primarily focuses on Roman terra sigillata (samian ware), providing crucial data for understanding Roman foodways through more efficient pottery analysis. Developed at the University of Leicester through collaboration between archaeology and computer science, the tool significantly reduces the specialist-dependent bottleneck in processing archaeological ceramics.","Arch-I-Scan originated as part of the broader investigation into Roman eating and drinking practices. The project's development spans four main phases: (1) Conceptual foundation (2017-2018) through the 'Big Data on the Roman Table' research network with initial proof-of-concept experiments published in Internet Archaeology in 2018; (2) Full project development (2019-2022) with dedicated funding from the Arts and Humanities Research Council (grant reference AH/R004986/1) establishing partnerships with major UK museums and archaeological institutions; (3) Technical innovation phase (2021-2022) when the team published significant methodological advances in using synthetic data generation and 3D simulation techniques to enhance AI capabilities; and (4) Final phase (2022-2023) when the project transitioned from development to dissemination with datasets made available through GitHub repositories. Throughout its evolution, the project maintained its focus on Roman finewares, particularly terra sigillata, while expanding technical capabilities and institutional partnerships.","The current version of Arch-I-Scan employs convolutional neural networks (CNNs) similar to those used in facial recognition technology, implemented primarily in Python. The system architecture consists of five integrated components: (1) a mobile interface data acquisition layer for capturing pottery images in the field; (2) a processing layer for image preprocessing and feature extraction; (3) a neural network classification layer that identifies pottery types; (4) a database storage layer for training data and results; and (5) a user interface frontend for viewing and managing results. The system incorporates three notable technical innovations: transfer learning to overcome limited training data through pre-training on synthetic examples; synthetic data generation creating 3D simulations from published pottery drawings; and mobile-first design optimizing for field use on ordinary smartphones. The technical team addressed the common archaeological challenge of limited training data through a novel approach – generating 3D simulations from traditional drawings of pottery forms, dramatically expanding their training dataset beyond physically available specimens. This synthetic data generation proved critical for achieving sufficient accuracy with the limited number of physical specimens available. The system processes images through multiple stages: preprocessing to standardize input, feature extraction to identify diagnostic elements, and classification to match against known forms. Though deployed on mobile devices, the training architecture requires more substantial computing resources. For previous versions, the team experimented with different neural network architectures before settling on their current approach, which balances accuracy with the constraints of mobile deployment.",2025-05-05,yes,"Arch-I-Scan fully qualifies as research software meeting all essential criteria and multiple supporting criteria. The tool has a clear research-specific purpose (analyzing Roman pottery), directly engages with research materials (transforming pottery photographs into identifications), and aligns with established archaeological methodologies. Additionally, it integrates domain knowledge (pottery classifications), supports the research lifecycle (data collection and analysis stages), performs analytical functions (pattern recognition in pottery forms), transforms data (from images to identifications), and includes visualization capabilities. Its documentation explicitly addresses research applications and it was developed specifically to support archaeological inquiry.",https://github.com/ArchiScn,,https://le.ac.uk/archaeology/research/new-approaches-to-the-material-world/arch-i-scan,https://le.ac.uk/archaeology/research/new-approaches-to-the-material-world/arch-i-scan,Unknown (Likely open research),Ceramic analysis|Data collection|Artefact morphology|Shape recognition|Machine learning,archaeology-ai-integration|pottery-classification|mobile-field-tools|machine-vision|roman-ceramics,2018-06-01,2023-05-01,Unknown,Active,University of Leicester|Arts and Humanities Research Council|Museum of London|Museum of London Archaeology|University of Leicester Archaeological Services|The Vindolanda Trust|Colchester and Ipswich Museum Service,Penelope Allison|Ivan Tyukin|Eric Nordquist|Evgeny Mirkes|Shyha Gundakaram|Yi Sun|Yi Ren|Cristina Criado-Sirvent|Rosie Campbell|Alexander Ashton,Medium (6-20),Archaeology,Project-specific,Comprehensive,"Arch-I-Scan has established partnerships with several major UK museums and archaeological institutions, most notably cataloging Roman finewares in the Museum of London's collection. The project has produced at least 6 peer-reviewed publications in specialized journals including Internet Archaeology and the Journal of Computer Applications in Archaeology. The 2021 paper 'Learning from Scarce Information: Using Synthetic Data to Classify Roman Fine Ware Pottery' has been cited in multiple papers addressing machine learning applications in archaeology and cultural heritage. The project's GitHub repository shows ongoing development activity through 2023. Community engagement is evidenced through collaborative work with the Vindolanda Trust, where the system was tested during COVID-19 lockdown restrictions, enabling remote pottery classification. The tool's development was supported by a significant Arts and Humanities Research Council grant (AH/R004986/1).",Data Acquisition|Processing|Analysis,research-specific,Stand-alone software,Python,Android|iOS|Web,,"The current version interoperates with standard image formats (JPG, PNG) captured by smartphone cameras. Outputs are stored in a database format that can be exported to CSV and other standard formats for integration with collection management systems. The system currently accepts standard 2D images but has been developed with the capability to utilize 3D models when available. Version compatibility is maintained across recent Android and iOS operating systems, with web interface options for desktop access to results.","The current version of Arch-I-Scan offers five significant strengths: (1) Accessibility through smartphone-based operation, enabling non-specialists to contribute to archaeological documentation; (2) Continuous improvement through machine learning capabilities that enhance accuracy as more examples are processed; (3) Scalability for processing larger pottery assemblages than traditional methods allow, potentially transforming understanding of Roman foodways through more comprehensive datasets; (4) Time efficiency by reducing specialist time spent on basic identification, allowing experts to focus on novel or challenging examples; (5) Knowledge sharing through freely available datasets for reference and comparison. The synthetic data approach represents a methodological innovation with potential applications beyond pottery, particularly valuable for archaeological subfields where training examples are limited. The system's transparent research methodology, with published algorithms and datasets, enhances reproducibility and allows independent verification of results.","Despite its innovations, the current version of Arch-I-Scan faces several limitations: (1) Training requirements necessitate extensive initial datasets before achieving optimal accuracy, creating a bootstrap challenge for new pottery types; (2) Developmental status means functionality is still evolving, with ongoing refinements to the machine learning models; (3) Specialized focus primarily on Roman terra sigillata limits immediate applicability to other pottery types without additional training; (4) Verification needs persist, as the system still requires expert validation for certain identifications; (5) Technical challenges in handling variable archaeological fragments, particularly weathered or atypical examples. The accuracy rates, while promising (reported at 80-85% for well-preserved examples), remain lower than expert human classification in certain contexts. The system's reliance on good lighting conditions and relatively standardized photography poses challenges in varied field environments. Previous versions showed more significant limitations in handling variations in vessel completeness, with performance decreasing substantially when working with small fragments rather than complete vessels.","Arch-I-Scan demonstrates good long-term survivability prospects due to several factors: (1) Institutional backing from the University of Leicester provides solid academic infrastructure; (2) Cross-disciplinary foundation through collaboration between archaeology and computing creates broader institutional investment; (3) Partnerships with major museums and archaeological services establish a stakeholder network with vested interest in the tool's continued development; (4) Open data approach with freely available datasets supports continued use even if active development slows; (5) Integration with educational initiatives at participating institutions embeds the technology within teaching practices. Challenges to sustainability include securing continued funding beyond the initial AHRC grant period, maintaining technical expertise as team members transition, and adapting to evolving mobile technologies and AI frameworks. The project's leadership by established academics with continuing positions at the University of Leicester provides some stability, and the interdisciplinary nature of the project increases potential funding sources across both humanities and technical domains.","The most comparable alternative is ArchAIDE (Archaeological Automatic Interpretation and Documentation of cEramics), funded by the European Union's Horizon 2020 program (2016-2019). ArchAIDE serves similar purposes but employs two distinct recognition methods: shape-based analysis of profiles and appearance-based analysis focusing on decorative features. It includes Roman Amphorae and various terra sigillata types, offering somewhat broader initial scope than Arch-I-Scan. Other alternatives include traditional methods of pottery documentation, such as manual drawing and photography, which provide high accuracy but at significantly lower speed. Earlier computer vision systems like those developed by Karasik and Smilansky (2008) use 3D scanning technologies but require more specialized equipment and lack Arch-I-Scan's mobile-first approach. General-purpose image recognition platforms could be adapted for pottery classification but would require extensive training and lack the specialized features for archaeological applications. Arch-I-Scan distinguishes itself through its focus on accessibility via ordinary smartphones and its specialized training for Roman finewares.",
ArchaeoGRID,New,"Found when GridMachine failed, identified in response as 'closest tool'","ArchaeoGRID was an ambitious archaeological computing project developed in the early 2000s that aimed to apply GRID technology (originally pioneered at CERN) to archaeological data management. The system was designed to create a distributed computing infrastructure for archaeological research, enabling the sharing, processing, and analysis of archaeological datasets across institutions. ArchaeoGRID sought to address challenges of data fragmentation in archaeology by providing centralised access to distributed resources while supporting advanced visualization and analytical capabilities.","ArchaeoGRID emerged during a transitional period when archaeology was rapidly adopting digital methodologies. The project was formally proposed in 2004 by Pier Giovanni Pelfer of the University of Florence (Italy) and Juan Antonio Barceló of the Universitat Autonoma de Barcelona (Spain), along with collaborators C. McDonaill and G. Pelfer. Development proceeded through several phases: initial proposal (2004), early development (2004-2010), evolution into the 'ArchaeoGRID Science Gateway' concept (circa 2010), followed by declining activity with few references after 2015. What made ArchaeoGRID historically significant was its attempt to transfer advanced computing technology from physics (specifically CERN) to archaeology at a time when the field was generating unprecedented volumes of digital data.","ArchaeoGRID implemented a sophisticated multi-layered technical architecture following distributed computing principles. The system comprised four primary infrastructure layers: Physical Resource Layer (distributed hardware across multiple locations), Middleware Layer (software managing resource allocation and communication), Science Gateway Layer (web interface for non-technical users), and Application Layer (specialised archaeological software tools). The system utilised a Cyberinfrastructure (CI) model that created a Distributed Computing Infrastructure (DCI) specifically for archaeological research, integrating high-performance computing resources, grid computing, and eventually incorporating cloud computing concepts. For data management, ArchaeoGRID supported multiple archaeological data standards and formats, implemented metadata standardisation for artefacts and contexts, provided an integration framework for connecting heterogeneous data sources, and employed a distributed storage architecture for large datasets. Processing capabilities included computational tools for 3D scans and remote sensing data, workflow systems for complex analyses, and visualization tools for archaeological interpretation. The Science Gateway concept was particularly innovative as it aimed to make complex distributed computing accessible to archaeologists without specialised technical knowledge.",2025-05-07,maybe,"ArchaeoGRID meets most criteria for an archaeological research software tool but remains in a borderline category. It satisfies all Essential Criteria by supporting research activities through distributed data management, transforming archaeological materials through organisation and analysis capabilities, and aligning with archaeological methodologies. For Supporting Criteria, it demonstrates domain knowledge integration, research lifecycle support, data transformation capabilities, and potential for collaborative analysis. However, its limited implementation beyond conceptual and prototype stages, lack of evidence for widespread adoption in actual archaeological projects, and apparent discontinuation make its classification as a fully developed research software tool questionable.",,,https://www.researchgate.net/publication/4154892_ArchaeoGRID_a_GRID_for_archaeology,https://www.researchgate.net/publication/4154892_ArchaeoGRID_a_GRID_for_archaeology,Unknown,Data management|Spatial analysis|Data collection,grid_computing|archaeological_data_management|distributed_repository|collaborative_research|cyberinfrastructure,2004,~2015,Unknown,Abandoned,University of Florence|Universitat Autonoma de Barcelona,Pier Giovanni Pelfer|Juan Antonio Barceló|C. McDonaill|G. Pelfer,Small (2-5),Computer Science|Physics,General-purpose,Basic,"Documentation exists primarily in academic papers rather than comprehensive user guides. While the theoretical concept received significant attention in academic literature, evidence of practical implementation in archaeological projects is sparse. No metrics regarding user base or adoption statistics were found, suggesting limited practical deployment beyond prototype stages.",Data Acquisition|Processing|Analysis|Preservation and Reuse,research-specific,Stand-alone software,Unknown,Windows|Unix|Linux,,"ArchaeoGRID was designed to support archaeology-specific metadata standards and interoperable data formats. The system aimed to manage heterogeneous archaeological data types including spatial information, contextual data, artefact catalogues, and remote sensing data. The middleware layer enabled connections between distributed data sources across different physical locations and computing environments. Integration with existing archaeological databases was planned, though evidence of successful implementation is limited.","ArchaeoGRID represented an innovative early attempt to apply grid computing concepts to archaeology when the field was beginning to address challenges of digital data management. The project's vision of centralised access to distributed resources directly addressed the fragmentation of archaeological data across institutions and projects. The system's support for collaborative research across geographic boundaries was forward-thinking for its era. The Science Gateway concept aimed to democratise access to advanced computing by making complex distributed computing accessible to archaeologists without specialised technical knowledge. ArchaeoGRID's interdisciplinary approach, combining expertise from computer science, physics, and archaeology, demonstrated potential for technological transfer across domains.","The implementation appears to have remained largely at the conceptual and prototype stage rather than achieving widespread adoption. The system required significant technical expertise to implement and maintain, creating barriers to adoption for many archaeological projects. Limited documentation beyond academic papers suggests challenges for new users attempting to implement the technology. The project's timing coincided with the transition from grid computing to cloud-based approaches, potentially leaving it caught between technological paradigms. Dependence on specific institutional support and limited evidence of community adoption suggests it did not develop a self-sustaining ecosystem.","ArchaeoGRID represents an important conceptual milestone in archaeological computing that did not achieve long-term sustainability. The absence of continued development after approximately 2015 indicates the project did not successfully transition from prototype to mature software. The specific grid computing approach upon which it was built has been largely superseded by cloud-based approaches. While its vision was innovative, the complex technical requirements and limited evidence of practical implementation suggest minimal long-term survivability. However, many of its conceptual contributions have influenced later archaeological data infrastructure projects.","Modern alternatives that have effectively superseded ArchaeoGRID include: ARIADNE (Advanced Research Infrastructure for Archaeological Dataset Networking in Europe) - A comprehensive European archaeological data infrastructure with significant funding and institutional support; tDAR (The Digital Archaeological Record) - Major digital repository in North America; Archaeology Data Service (ADS) - UK's primary archaeological data archive; OpenAtlas - Open-source archaeological database with strong geospatial capabilities; IANUS - German archaeological data repository; SEAD - Strategic Environmental Archaeology Database in Sweden; DANS - Data Archiving and Networked Services in the Netherlands. These successors generally feature more accessible cloud-based architectures and stronger adherence to FAIR (Findable, Accessible, Interoperable, Reusable) data principles.","FOLLOWED: Claude Tool-status=maybe (prototype), user confirmed TOOL (prototype lifecycle is valuable data)"
ArchaeoPhases,Success,,"ArchaeoPhases is an R package that provides statistical tools for post-processing Markov Chain Monte Carlo (MCMC) simulations from chronological modelling software used in archaeology. The current version enables researchers to analyze outputs from primary dating programs like OxCal, ChronoModel, and BCal. Its key functionalities include creating tempo plots to visualize the rhythm of events, generating activity plots to show density of events over time, performing statistical analyses of phase transitions, and defining boundaries between successive archaeological phases. The package is particularly valuable for examining temporal patterns in archaeological chronologies, helping researchers distinguish between periods of tradition (steady patterns), innovation (abrupt changes), and fashion (rapid but temporary changes).","ArchaeoPhases emerged from statistical research at the Université de Nantes in France. The core statistical methods were under development prior to 2017, with the software formally introduced in a working paper by Anne Philippe and Marie-Anne Vibet that year. The first version (1.0) was released in 2017, followed by version 1.5 and eventually 1.8 as the last in the 1.x series. A significant update came with version 2.0 in 2023, which included comprehensive rewrites, renaming of nearly all functions for improved consistency, and implementation of the 'aion' package for internal date representation. Throughout its development, the software has maintained its focus on providing specialized statistical tools for archaeological chronology while expanding its capabilities and improving its user interface.","The current version of ArchaeoPhases is implemented in R, following standard R package conventions with a modular design. It requires R version 3.5.0 or higher and is compatible with Windows, macOS, and Linux/Unix systems. The architecture includes R source code for core functions, roxygen2 format documentation, test files, vignettes with extended documentation and examples, and example datasets (with larger datasets moved to a companion ArchaeoData package). The package has several key dependencies including 'aion' for date representation (introduced in version 2.0), 'ggplot2' for visualization, 'coda' for MCMC analysis, and 'stats' for core statistical calculations. Version 2.0 introduced significant technical changes including a complete renaming of functions for improved consistency and the adoption of the 'aion' package for standardized date representation. ArchaeoPhases implements specialized algorithms for Allen's interval algebra to reason about temporal relations, statistical methods for post-processing MCMC simulations, and visualization techniques specific to archaeological time series. The package is designed as a post-processing tool that works with outputs from primary chronological modelling software rather than performing initial modelling itself. This approach allows it to complement multiple primary tools while focusing on specialized statistical analysis of archaeological phases and transitions.",2025-05-05,yes,"ArchaeoPhases meets all essential criteria for research software: (1) It has a research-specific purpose, being explicitly designed for archaeological chronological analysis; (2) It directly engages with research data by transforming MCMC outputs from chronological modelling software; (3) It aligns with methodological approaches in Bayesian chronological modelling in archaeology. It also satisfies numerous supporting criteria: it incorporates domain knowledge through specialized chronological terminology, supports the analysis stage of the research lifecycle, transforms data between formats, provides analytical capabilities for statistical inference, offers visualization functions like tempo and activity plots, includes documentation specifically addressing archaeological applications, and facilitates data dissemination through standardized outputs that can be used in publications.",https://github.com/ArchaeoStat/ArchaeoPhases,https://CRAN.R-project.org/package=ArchaeoPhases,https://archaeostat.github.io/ArchaeoPhases/,https://archaeostat.github.io/ArchaeoPhases/,GPL-3,Chronological modelling|Statistical analysis,archaeological chronology|statistical post-processing|MCMC simulations|temporal analysis|Bayesian modelling,2017,2023,2,Active,Université de Nantes|University of Hawai'i,Anne Philippe|Marie-Anne Vibet|Thomas S. Dye|Nicolas Frerebeau,Small (2-5),Statistics|Archaeology,General-purpose,Comprehensive,"ArchaeoPhases has moderate usage within specialized archaeological chronology research. It has 53 stars and 12 forks on GitHub as of May 2025, with contributions from 4 main developers. The package is cited in archaeological publications focusing on chronological modelling, with notable applications including Hawaiian social stratification studies, Rapa Nui monument construction analysis, the Canímar Abajo site in Cuba, and Paleolithic occupations at Havrincourt in France. It appears in the CRAN repository and is listed in archaeological software compilations like open-archaeo. The package has consistent but specialized usage, primarily in French and American archaeological research contexts.",Analysis,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"ArchaeoPhases is designed to work with outputs from multiple chronological modelling software packages including OxCal, ChronoModel, and BCal. It reads MCMC output files from these programs and provides functions to import, process, and analyze this data within the R environment. The current version can handle various date formats through the 'aion' package implementation. Output from ArchaeoPhases can be exported as tables or visualizations suitable for publication. The package also integrates with the broader R ecosystem, allowing researchers to combine its specialized archaeological functions with other statistical and visualization packages. For larger datasets, it interfaces with the companion ArchaeoData package.","ArchaeoPhases offers several distinct strengths. First, its cross-platform integration enables working with outputs from multiple primary modelling programs (ChronoModel, OxCal, BCal), creating a flexible workflow that accommodates different software preferences. Second, the tempo plot feature provides unique visualization capabilities that reveal the pace of change over time, offering insights difficult to derive from standard chronological presentations. This helps archaeologists identify cultural patterns related to tradition, innovation, and fashion that might otherwise remain hidden. Third, as an open-source R package, it benefits from transparency, free availability, and integration with the broader R ecosystem. This allows researchers to extend analyses using additional statistical tools and customize approaches for specific archaeological problems. Finally, the software brings additional statistical rigor to archaeological phase analysis, offering more detailed probability distributions and uncertainty measures than many alternatives, enhancing confidence in chronological interpretations.","ArchaeoPhases has several notable limitations. First, it functions as a post-processing tool only, meaning users must first learn and use primary modelling software like OxCal or ChronoModel. This creates a more complex workflow requiring data management across multiple programs. Second, despite offering a graphical user interface option, getting the full benefit typically requires familiarity with R programming and statistical concepts. This learning curve can be challenging for archaeologists without computational backgrounds. Third, the software has a specialized focus on archaeological phase analysis and may not be as versatile for other types of chronological studies or broader archaeological analyses. Its strength in depth comes at the cost of breadth, making it most valuable for specific analytical questions rather than as a general archaeological tool.","ArchaeoPhases shows good prospects for long-term viability. The software has several positive indicators for continued sustainability: it is actively maintained with regular updates, the most recent major version (2.0) was released in 2023, and it has institutional backing from established academic institutions (Université de Nantes and University of Hawai'i). The development team, while small, includes both statisticians and archaeologists, providing important cross-disciplinary expertise. Being an R package hosted on CRAN ensures standardized distribution and accessibility. The software's open-source nature under the GPL-3 license allows for community contributions and forking if necessary. Its integration with widely-used primary chronological modelling tools and the broader R ecosystem enhances its long-term relevance. The main factors that could affect future viability include the specialized nature of its application, which means a relatively small user base, and potential dependence on key developers. Overall, its specialized niche, active development, institutional support, and open-source foundation suggest good prospects for continued availability and relevance.",OxCal (Oxford University's primary chronological modelling software with Chronological Query Language capabilities)|ChronoModel (CNRS-developed graphical tool for integrating multiple dating methods)|BCal (web-based Bayesian calibration tool)|ArchaeoChron (complementary R package for archaeological analyses)|BayLum (R package specializing in OSL dating within Bayesian frameworks)|ChronoLog (focusing on chronological network modelling),
ArchAIDE,Success,,"ArchAIDE (Archaeological Automatic Interpretation and Documentation of cEramics) is specialised software that uses artificial intelligence to accelerate the identification of pottery fragments in archaeological research. The current version employs a dual recognition system combining shape-based analysis (via modified PointNet architecture achieving 62.8% accuracy) with appearance-based analysis (using ResNet-50 neural networks reaching 83.8% top-5 accuracy). Users photograph pottery fragments with mobile devices, which then processes images through neural networks to identify matches from a reference database containing Roman amphorae, Terra Sigillata varieties, and Majolica of Montelupo. The system preserves the archaeologist's expertise in the final identification decision while dramatically reducing classification time by 50-66% compared to traditional manual methods.","ArchAIDE evolved from initial concept development between 2014-2016 at the University of Pisa by archaeologists Gabriele Gattiglia and Francesca Anichini. The project officially launched in June 2016 with €2.46 million in EU Horizon 2020 funding (grant №693548). Development progressed through defined phases: knowledge base and machine learning algorithm creation (2016-2017), beta testing with field implementations (2018), and mobile and desktop application release (early 2019). The project formally concluded in May 2019 with the 'Archaeorevolution is now' conference, followed by a final EU Commission review meeting in Brussels in July 2019. Since project completion, limited ongoing maintenance has continued through MAPPA Lab at the University of Pisa. The project received the 'best App of the year' award at Heritage in Motion Awards in 2019, recognising its innovative approach to archaeological documentation.","The current ArchAIDE implementation employs a distributed client-server architecture with several interconnected components. The system's core is built primarily in Python, utilising TensorFlow v1.x for machine learning functionality. The recognition engine employs dual approaches: shape-based recognition using a modified PointNet architecture that processes 3D pottery profiles with 62.8% accuracy, and appearance-based recognition implementing ResNet-50 for pattern and decoration analysis achieving 83.8% top-5 accuracy. The client side consists of native iOS and Android mobile applications plus a web-based desktop interface, while server components include an API server, reference database, and separate model servers for shape and decoration recognition. Communication occurs via RESTful architecture with OAuth2 authentication. The development team addressed data scarcity challenges innovatively by digitising paper catalogues, conducting extensive photo campaigns of authentic materials, and generating synthetic training data from 3D models. This last approach proved particularly valuable, allowing creation of millions of virtual fragments from limited authentic material. The workflow mirrors traditional archaeological practice: documentation, profile tracing (for shape-based identification), automatic recognition, result presentation, verification, and data storage – designed to function with limited connectivity typical in field scenarios. A significant limitation is the current version's dependency on older frameworks, with documentation explicitly noting incompatibility with 'TensorFlow v2 or Python versions newer than 3.6.X' as of 2021. The system's code is distributed across multiple GitHub repositories, with machine learning components in barak-itkin/archaide-software and digitisation tools in cnr-isti-vclab/ArchAIDE_digit (under Mozilla Public License 2.0).",2025-05-05,yes,"ArchAIDE qualifies as research software as it meets all essential criteria by supporting archaeological research activities through meaningful transformation of pottery fragment data using recognised methodologies. It also satisfies multiple supporting criteria by incorporating domain knowledge (pottery classification taxonomy), supporting research lifecycle stages (analysis and interpretation), performing data transformation (converting images to classifications), providing analytical capabilities (shape and decoration recognition algorithms), and offering visualisation functions (presenting results with confidence levels). The software is specifically designed for archaeological research applications, with documentation and interface tailored to archaeological workflows.",https://github.com/barak-itkin/archaide-software,,http://www.archaide.eu/,http://www.archaide.eu/,"Varies (Mozilla Public License 2.0 for digitisation tools, unclear for main components)",Ceramic analysis|Shape recognition|Artefact morphology|Data management|Machine learning,archaeological-recognition|pottery-identification|neural-networks|mobile-archaeology|field-research-tool,2016-06-01,2019-05-01,Unknown,Maintenance-only,University of Pisa (MAPPA Lab coordinator)|CNR-ISTI Visual Computing Lab (Italy)|Tel Aviv University School of Computer Science (Israel)|University of Barcelona (Spain)|University of Cologne (Germany)|University of York Archaeology Data Service (UK)|Baraka Arqueólogos S.L. (Spain)|Elements S.L. (Spain)|Inera s.r.l. (Italy),Maria Letizia Gualandi (PI)|Gabriele Gattiglia|Francesca Anichini|Roberto Scopigno|Barak Itkin|Massimo Zallocco|Llorenç Vila|Holly Wright,Medium (6-20),Archaeology,Project-specific,Comprehensive,"ArchAIDE has demonstrated significant adoption within academic and professional archaeological contexts, particularly among consortium member institutions. The mobile applications are available on both iOS App Store and Google Play Store, though specific download statistics are not publicly available. The primary academic paper 'Developing the ArchAIDE Application' (Anichini et al., 2020) has been cited in multiple archaeological publications. The project received the 'best App of the year' award at Heritage in Motion Awards, indicating recognition from the heritage sector. Field testing was conducted at various European archaeological sites during the project period, with particular success reported for Roman amphorae classification. Project coordinator Gabriele Gattiglia noted that using the system could save 'half to two thirds of the time currently spent on pottery classification'.",Analysis|Interpretation,research-specific,Stand-alone software,Python|JavaScript,Android|iOS|Web,,"ArchAIDE supports import/export of data in common archaeological documentation formats and interfaces with specialised archaeological databases. The current version can process standard image formats (JPEG, PNG) from device cameras or galleries. The system architecture allows for both online operation with full database access and offline functionality with cached reference data for field use where connectivity is limited. Results can be exported in formats compatible with common archaeological recording systems and institutional databases. Because the application's main purpose is identification rather than data management, it serves primarily as an input to larger documentation ecosystems rather than a comprehensive interoperability hub.","ArchAIDE's dual recognition approaches combine shape and decoration analysis for comprehensive identification, offering significantly greater accuracy than either method alone. The mobile-first design enables practical field use on standard smartphones and tablets, directly addressing archaeologists' needs in excavation contexts. The system integrates domain knowledge by linking fragments to comprehensive pottery type information including chronology, production centres, and distribution patterns. The application preserves archaeologist authority in decision-making by presenting potential matches with confidence levels rather than forcing automated conclusions. The underlying neural networks demonstrate remarkable performance despite the highly variable nature of archaeological materials, with decoration recognition achieving 83.8% top-5 accuracy. The system's innovative approach to generating training data using synthetic fragments from 3D models represents a methodological breakthrough for archaeological computing with broader applications. The project's transparent approach to publishing results and reference data through the Archaeology Data Service ensures long-term availability of the underlying research.","ArchAIDE's current pottery class coverage remains limited to specific types (Roman amphorae, Terra Sigillata, Majolica of Montelupo), restricting its comprehensive application across all archaeological contexts. Recognition accuracy, while impressive, still requires expert verification, particularly for shape-based recognition which achieves 62.8% accuracy compared to decoration-based methods. The system faces significant technical dependencies on older software frameworks, with explicit documentation noting incompatibility with 'TensorFlow v2 or Python versions newer than 3.6.X' as of 2021. This creates substantial maintenance challenges as computing environments evolve. Network dependency limits functionality in remote field locations with poor connectivity, though some offline capabilities exist. The training data requirements necessitated extensive collection efforts, and expanding the system to new pottery classes would require similar significant investment. Licensing information for core components appears incomplete, creating potential barriers to community adoption and extension. The user interface, while functional, occasionally prioritises technical capabilities over user experience, particularly in complex identification scenarios.","ArchAIDE faces several challenges to its long-term viability. The formal EU-funded project ended in May 2019, and evidence of active development since then is minimal. The system's reliance on older frameworks (TensorFlow v1.x, Python 3.6.x) creates growing compatibility issues as computing environments evolve. Current pottery type coverage represents only a fraction of archaeological ceramics, requiring substantial investment to expand. These technical debts limit the software's potential longevity without renewed development effort. Supporting factors include continued institutional backing from the MAPPA Lab at University of Pisa, public availability of core methodologies and data, and clear demonstrated value through significant time savings in pottery classification. Without secured ongoing funding or a strong open-source community developing around the codebase, the most enduring impact will likely be methodological – demonstrating effective approaches for applying AI to archaeological classification problems that future systems can build upon. The software remains available and functional, but its technical foundations will increasingly limit compatibility with modern computing environments.","The primary direct competitor to ArchAIDE is Arch-I-Scan from the University of Leicester, which similarly uses CNN-based approaches for Roman pottery identification but differs in emphasising complete vessel knowledge before fragment analysis. Complementary technologies include structure from motion scanning approaches by researchers like Kampel and Karasik, the CERAMALEX Database focused on pottery cataloguing from German and French excavations, and Pottery from Motion for 3D documentation. ArchAIDE's comparative advantages include its mobile-first approach, dual recognition methods combining shape and decoration analysis, knowledge integration connecting fragments to comprehensive type information, and archaeologist-friendly interface designed for field use. Its disadvantages against specialised systems include limited ongoing development, ceramic class coverage restricted to specific types, and potential accuracy trade-offs versus highly targeted systems. The most significant differentiator is ArchAIDE's focus on practical field application through mobile devices rather than laboratory-based analysis.",
ArchEd,Success,,"ArchEd (Archaeological Editor) is specialised software for creating and visualising Harris matrices—diagrammatic representations of temporal succession in archaeological contexts. The current version supports four types of stratigraphic relationships (earlier, later, contemporary, and equal), features automatic sequential numbering of contexts, and includes redrawing functionality to optimise matrix layouts. ArchEd allows archaeologists to document stratigraphic relationships discovered during excavations and transform these into standardised visual formats essential for post-excavation analysis and publication.","ArchEd evolved from a DOS-based program developed at the Amt für Bodendenkmalpflege in Bonn, Germany in 1990. The Windows version was subsequently developed at the Max Planck Institut für Informatik in Saarbrücken, with formal introduction in 1997 through an academic paper titled 'ArchE: A Graph Drawing System for Archaeology' by Christoph Hundack, Petra Mutzel, Igor Pouchkarev, and Stefan Thome. Development later transitioned to TU Wien (Vienna University of Technology), which released version 1.4. Development appears to have ceased, with the original development team reportedly disbanding without ongoing maintenance or updates.","ArchEd operates as a standalone Windows application implementing graph theory algorithms to create and manipulate Harris matrix diagrams. The current version (1.4) employs automatic drawing/redrawing functionality using layout algorithms to optimise the visual representation of stratigraphic relationships. The software supports four distinct relationship types: earlier than, later than, contemporary with, and equal to—allowing comprehensive representation of complex stratigraphic sequences. The application architecture includes a direct manipulation interface with standard GUI elements, although relationship input requires dialogue boxes or menu sequences rather than more intuitive mouse operations. The software architecture allows for importing and exporting data as ASCII files, supporting data interchange with other systems. The application demonstrates reasonable performance with matrices containing approximately 100 contexts and 150 relationships, though users report performance degradation with substantially larger datasets (approaching 1,000 contexts). For output, ArchEd supports multiple export formats including Windows metafiles, bitmaps, and DXF format for integration with CAD systems, allowing integration with publication workflows. The technical documentation available with the software includes a user guide (as MS Word document) that outlines features and operation, though reviews note some inconsistencies in documentation.",2025-05-05,yes,"ArchEd meets the core definition of research software by supporting archaeological inquiry through transforming stratigraphic relationship data into visualisations crucial for archaeological interpretation. It aligns with all three essential criteria: serving a specific research purpose (visualising stratigraphic relationships), meaningfully transforming research materials (converting relationship data into structured Harris matrices), and aligning with recognised archaeological methodologies (Harris matrix creation is a standard method in archaeological analysis). It also satisfies multiple supporting criteria, including domain knowledge integration (incorporating stratigraphic terminology and relationships), research lifecycle support (addressing the analysis and interpretation stages), and visualisation capabilities (rendering complex stratigraphic data in standardised diagrammatic formats).",,,http://www.mpi-sb.mpg.de/~arche/StartPage.html,http://www.mpi-sb.mpg.de/~arche/StartPage.html,Freeware (no formal open-source license),Harrix matrix|Site mapping|Data management|Processing|Analysis,stratigraphy|archaeological visualisation|temporal relationships|Harris matrix|context documentation,1997,Unknown,1.4,Abandoned,TU Wien (Vienna University of Technology),"Christoph Hundack, Petra Mutzel, Igor Pouchkarev, Stefan Thome",Small (2-5),Archaeology,Project-specific,Basic,"ArchEd has been used within various archaeological research projects, including at the York Archaeological Trust and excavations at Gortyna in Crete. While the software was once considered 'an essential download for all field archaeologists' according to reviews, its current usage appears limited due to its abandoned status and emergence of newer alternatives. No recent academic citations or implementation case studies were found in current literature. The software lacks a current repository or community forum, preventing reliable tracking of recent adoption rates or active user base.",Analysis|Interpretation,research-specific,Stand-alone software,Unknown,Windows,,"ArchEd demonstrates moderate interoperability through its ability to import and export data as ASCII files. The current version supports exporting diagrams in Windows metafiles, bitmaps, and DXF formats, allowing integration with word processing, desktop publishing, and CAD systems. This facilitates use of the Harris matrix visualisations in publications and reports. However, the software lacks direct integration capabilities with modern GIS systems or database platforms commonly used in contemporary archaeological workflows, limiting its utility in comprehensive digital documentation systems.","ArchEd's primary strength lies in its focused approach to a specific archaeological problem—Harris matrix visualisation. The current version performs this core function effectively, producing visually attractive and readable output that can be used directly in publications. The software's functionality is well-aligned with archaeological methodology, supporting the four key relationship types required for complete stratigraphic analysis. Its relatively simple interface makes it accessible to archaeologists without extensive software experience, while its data export capabilities facilitate workflow integration. The Windows-based standalone nature means it can function without complex installation procedures or dependencies, making it deployable in field conditions with minimal technical support.","The current version of ArchEd suffers from an unintuitive interface for entering stratigraphic relationships, requiring dialogue boxes or menu sequences that reviewers described as 'rather laborious.' The software demonstrates performance limitations when handling larger datasets, with display problems and crashes reported when approaching 1,000 contexts. More significantly, ArchEd faces a critical sustainability problem due to its abandoned development status—no updates appear to have been released for years, making it increasingly incompatible with modern operating systems and archaeological workflows. The lack of integration with GIS systems or modern data management platforms limits its utility in contemporary digital archaeology. Finally, the documentation contains inconsistencies, with the help system reportedly referencing only three relationship types while the software supports four.","ArchEd's long-term viability is severely compromised. The current version exists in an abandoned state with no evidence of active maintenance or development for many years. The original development team reportedly disbanded, leaving no clear path for updates or adaptation to evolving operating systems and archaeological methods. The software faces increasing compatibility issues with newer Windows versions, and lacks integration with contemporary archaeological digital workflows. With no active development community or institutional support, ArchEd is likely to become progressively less usable as operating systems evolve. While it may remain functional on legacy systems or through compatibility modes for some time, its practical utility will continue to diminish as newer alternatives with active development cycles gain prominence.","The primary alternative to ArchEd is Harris Matrix Composer (HMC) by Traxler and Neubauer, developed with input from Dr. Edward C. Harris himself. HMC offers additional functionality including temporal relations and GIS integration, with an intuitive graphical interface and ongoing development support. Other alternatives include Stratify by Irmela Herzog, which offers sophisticated layout techniques but lacks direct manipulation interface; BASP Harris Matrix as part of the Bonn Archaeological Software Package; and newer open-source alternatives like harris2graph and harris-matrix-legacy that leverage Graphviz for diagram generation. Most of these alternatives offer improved integration with contemporary archaeological workflows and active development cycles, addressing key limitations in ArchEd's current abandoned state.",
ArcheoFrag,Success,,"ArcheoFrag is an R package implementing graph theory methods for analyzing archaeological fragmentation patterns. The current version (0.8.2) provides tools to evaluate whether spatial units identified during excavation (layers, squares, etc.) reflect meaningful archaeological divisions or result from post-depositional processes. It implements the TSAR (Topological Study of Archaeological Refitting) method, which examines relationships between fragments across archaeological spatial units using networks where fragments are vertices and refitting connections are edges. The package offers functions for creating and manipulating fragmentation graphs, measuring cohesion and admixture between spatial units, and characterizing network topology of refitting patterns. In previous versions (pre-0.8.0), the functionality was more limited, focusing primarily on basic graph creation rather than the more sophisticated analytical capabilities now available.","ArcheoFrag was developed by Sébastien Plutniak, a researcher at the French National Center for Scientific Research (CNRS), with development beginning around 2020. The theoretical methodology (TSAR) was first published in the Journal of Archaeological Science in 2021, and the software implementation was published in the Journal of Open Source Software in 2022. The package has evolved through several versions with increasingly sophisticated capabilities. Version 0.6.0 (April 2021) introduced the core functionality for graph manipulation, while version 0.8.0 (July 2022) added significant analytical capabilities including functions for edge weighting, cohesion calculation, and statistical analysis. The most recent update to version 0.8.2 (December 2022) refined existing functions and improved documentation. A companion package 'archeofrag.gui' was also developed to provide a graphical user interface through a Shiny application.","ArcheoFrag is built on the R programming language, leveraging R's statistical capabilities and the igraph package for graph theory implementation. The current version (0.8.2) employs a sophisticated technical architecture designed around graph structures, where archaeological fragments are represented as vertices and their refitting relationships as edges. The core data structure is a specialized 'frag' class object extending igraph, storing fragment identifications and spatial unit information alongside network properties. The package implements several key algorithms for analyzing fragmentation patterns, including: edge weighting algorithms that account for the number of refits between fragments, cohesion calculation methods that quantify the internal consistency of spatial units, cycle detection algorithms that identify patterns of fragment dispersal, and graph simulation functions that generate random fragmentation patterns for statistical comparison. Input data is accepted primarily as CSV files with columns specifying fragment IDs and spatial unit assignments. Results are output as igraph objects for visualization, statistical results in R data frames, and plots for pattern analysis. The package utilizes several dependencies, including igraph for graph manipulation, Bioconductor's RBGL for some algorithms, and standard R visualization libraries for plotting results. Computationally, the package handles small to medium datasets efficiently but may face performance issues with very large fragmentation datasets (thousands of fragments with complex refitting patterns). The architecture allows for extension through custom functions that operate on the 'frag' class objects. The software follows standard R package installation procedures, with the stable version available through CRAN and development versions through GitHub. A complementary GUI package (archeofrag.gui) provides access to most functions through a web interface built with Shiny, making the tool accessible to archaeologists with limited R programming experience.",2025-05-05,yes,"ArcheoFrag meets all essential research software criteria and multiple supporting criteria. It has a clear research-specific purpose (analyzing archaeological spatial relationships), meaningfully transforms research data (converts fragmentation patterns into network structures for analysis), and aligns with archaeological methodologies for stratigraphic integrity assessment. It integrates domain knowledge through archaeological terminology and classificatory schemes for fragment relationships, supports multiple research lifecycle stages (processing, analysis, interpretation), performs analytical calculations on fragmentation patterns, offers visualization functions for network relationships, and features documentation focused on archaeological applications.",https://github.com/sebastien-plutniak/archeofrag,https://cran.r-project.org/web/packages/archeofrag/index.html,https://analytics.huma-num.fr/Sebastien.Plutniak/archeofrag/,https://analytics.huma-num.fr/Sebastien.Plutniak/archeofrag/,GPL-3,Spatial analysis|Statistical analysis|Site mapping,graph theory|stratigraphic analysis|archaeological refitting|spatial patterns|topology,2021-04-28,2022-12-09,0.8.2,Active,CNRS (French National Center for Scientific Research)|CITERES research laboratory|Huma-Num digital humanities infrastructure,Sébastien Plutniak,Solo,Archaeology,General-purpose,Comprehensive,"GitHub metrics show modest but growing community adoption with 9 stars, 4 forks, and 1 contributor as of May 2025. The package has been cited in at least 5 academic publications since its release. The method has been endorsed by reviewers in PCI Archaeology. The package is included in archaeological software compilations like Open-Archaeo. The practical application has been demonstrated in case studies including analysis of Neolithic pottery from sites like Taï Cave and Font-Juvénal in France, and the Liang Abu rock shelter in East Borneo. Usage appears primarily academic with limited industry adoption.",Analysis|Processing|Interpretation,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"ArcheoFrag primarily interacts with other R packages through standard R data structures. The current version (0.8.2) imports and exports data in CSV format, making it compatible with spreadsheet software and other data processing tools. It leverages the 'igraph' package for network analysis and can export network visualizations in standard image formats (PNG, PDF, SVG). The package includes sample datasets in R data format (.rda) for testing and demonstration. The accompanying GUI version (archeofrag.gui) provides a web interface through Shiny, allowing interaction through a browser without direct R coding. While ArcheoFrag does not offer direct integration with GIS software, its outputs can be formatted for import into spatial analysis packages with some additional processing. The package lacks formal API interfaces for programmatic access from external software.","ArcheoFrag's methodological innovation represents its most significant strength. The current version moves beyond simple counts of refits between layers to analyze topological properties of fragment relationships, offering a more nuanced approach to evaluating stratigraphic integrity. The implementation provides strong theoretical foundations through graph theory, creating a more robust statistical framework for interpreting spatial patterns. The simulation capabilities allow archaeologists to generate expected fragmentation patterns under different scenarios and compare them with empirical data, supporting hypothesis testing rather than mere description. The software is accessible to users with varying technical skills through both command-line and GUI interfaces, balancing analytical power with usability. As an open-source tool with comprehensive documentation, it supports transparency and reproducibility in archaeological research. Version 0.8.2 also includes well-documented sample datasets, making it easier for new users to understand the analysis process.","Despite its innovative approach, ArcheoFrag's current version (0.8.2) has several limitations. Its specialized focus on refitting analysis restricts utility for broader archaeological spatial analysis, creating a narrow application range compared to general-purpose GIS tools. The package lacks direct integration with common archaeological GIS systems (QGIS, ArcGIS), requiring manual data transfer between systems which impedes workflow efficiency. While the GUI version improves accessibility, users still need some familiarity with R and data preparation, creating a steeper learning curve than fully graphical archaeological software. Some advanced functions require additional packages (like RBGL through Bioconductor), adding setup complexity. Performance issues may arise with very large datasets (thousands of fragments with complex relationships), as graph algorithms can become computationally intensive. The relatively small user community compared to mainstream archaeological software means fewer resources for peer support and fewer examples of diverse applications.","ArcheoFrag demonstrates moderate long-term viability prospects. The software benefits from institutional backing through French academic organizations (CNRS, CITERES, Huma-Num), providing some infrastructure stability. Its availability through established repositories (CRAN, GitHub) ensures continued accessibility. The package uses well-maintained dependencies (principally igraph), reducing vulnerability to abandoned dependencies. The open-source license (GPL-3) allows community maintenance if the original developer becomes unavailable. Documentation is comprehensive, facilitating future maintenance. However, several factors create sustainability challenges: development appears primarily driven by a single developer (Plutniak) rather than a team; updates have been relatively infrequent (last update December 2022); and the specialized nature limits the potential contributor pool. ArcheoFrag represents a methodological innovation that should remain relevant to archaeological practice, but may require active champion(s) to encourage wider adoption and ensure continued development. The existence of a companion GUI package suggests commitment to sustainability through accessibility.","GIS-based refitting suitability models (less theoretically sophisticated but more integrated with spatial data). Traditional manual refitting analysis approaches (labor-intensive but still common in archaeology). R packages for archaeological spatial analysis: SEAHORS (Shiny application for intra-site spatial analysis), ArchaeoPhases (for analyzing archaeological phases from date distributions). General-purpose GIS software like QGIS and ArcGIS (more comprehensive spatial functionalities but lacking specialized refitting analysis). Statistical packages for network analysis that could be adapted to archaeological contexts (igraph, statnet, etc.). Custom Python scripts for archaeological refitting (typically project-specific rather than generalized packages).",
archeoViz,Success,,"archeoViz is an R package and web application designed specifically for the visualisation, exploration, and online communication of archaeological spatial data. The current version provides interactive 3D and 2D visualisations of archaeological excavation data, with capabilities for displaying object coordinates, cross-sections, and refitting relationships. It enables archaeologists to create visualisations accessible through web browsers without requiring advanced technical skills. The tool supports multiple languages and follows a decentralised approach to archaeological data sharing, where researchers maintain control over their datasets while making them accessible to others.","archeoViz was developed by Sébastien Plutniak at the CITERES laboratory (CNRS/University of Tours). Initial development began before 2022, with version 1.0.0 being the first formal release, establishing core visualisation functionality. In 2023, version 1.3.3 was published in August, followed by formal publication in the Journal of Open Source Software in September, and the establishment of the archeoViz Portal as a companion application. Development continued in 2024 with version 1.3.4 released in January and the current version 1.3.5 released in June. In November 2024, the project received the Open Science Free Software Award from the French Committee for Open Science, and the first formal training workshop was held in Tours.","The current version of archeoViz is implemented as an R package using the Shiny framework to create web-based interfaces. The application leverages plotly for interactive 3D and 2D visualisations, which are generated from CSV files containing spatial coordinates and object attributes. The software architecture implements several spatial analysis methods, including convex hull computation (via the cxhull package), regression surfaces (using generalised additive models from mgcv), and 2D kernel density estimation (via the kde2d function from MASS). The application supports multilingual interfaces in seven languages through a translation system. For data handling, archeoViz implements a modular approach where data validation is performed during import, and can be accessed either locally or via web deployment. The system generates shareable URLs that encode visualisation parameters, ensuring reproducibility. Current technical implementation allows for export to SVG format, interactive HTML outputs, and connections to third-party applications. Performance can be resource-intensive with large datasets, particularly when visualising uncertainty (when using ranges of coordinates). The software generates R commands for all visualisations, enabling users to reproduce and customise them in standalone R environments.",2025-05-05,yes,"archeoViz clearly qualifies as research software as it meets all essential criteria. It has a research-specific purpose, directly engaging with archaeological data to transform it into interactive visualisations that support academic inquiry. The tool aligns with established methodological approaches in spatial archaeology and digital humanities. Furthermore, it meets multiple supporting criteria: it incorporates domain-specific terminology and classifications for archaeological finds, supports multiple stages of the research lifecycle from processing to publication, transforms coordinate data into meaningful visualisations, performs analytical calculations including convex hull and kernel density estimation, creates sophisticated 2D and 3D visualisations of archaeological contexts, and its documentation explicitly addresses archaeological research applications.",https://github.com/sebastien-plutniak/archeoviz,https://cran.r-project.org/package=archeoViz,https://analytics.huma-num.fr/archeoviz/en/,https://analytics.huma-num.fr/archeoviz/en/,GNU Affero General Public License v3.0 (AGPL-3.0),3D modelling|Spatial analysis|Visualization|Data management|Statistical analysis,archaeological visualization|spatial data|R shiny application|interactive 3D|reproducible research,2022,2024-06-01,1.3.5,Active,CNRS (French National Center for Scientific Research)|CITERES laboratory (UMR7324)|Huma-Num (Very Large Research Infrastructure)|MASA+ Consortium|European SEADDA COST Action,"Sébastien Plutniak (primary developer), with contributions from Renata Araujo, Laura Coltofean, Sara Giardino, Julian Laabs, and Nicolas Delsol",Small (2-5),Archaeology,General-purpose,Comprehensive,"archeoViz has demonstrated significant adoption within the archaeological community, with approximately 66 documented instances deployed as of 2024. The tool received the Open Science Free Software Award from the French Committee for Open Science in November 2024. The GitHub repository shows modest but consistent engagement metrics. The software has been formally published in the Journal of Open Source Software, enhancing its academic credibility. User community engagement is evidenced through a dedicated forum, mailing list (archeoviz-maintainers@services.cnrs.fr), and training sessions organised through the MASA+ consortium. Based on citation patterns and documented implementations, adoption appears strongest in French and European archaeological research communities, with growing international interest facilitated by its multilingual interface.",Processing|Analysis|Publication|Preservation and Reuse,research-specific,Stand-alone software,R,Windows|macOS|Linux|Web-based,R,"archeoViz uses CSV files with specific schema requirements for input data, requiring coordinates and object attributes in a prescribed format. The current version produces visualisations that can be exported as SVG images or interactive HTML. The software generates R commands for all visualisations, enabling reproducibility in standalone R environments. It integrates with complementary tools in the archaeological ecosystem, including archeofrag for refitting analysis. The decentralised approach through the archeoViz Portal facilitates connections between datasets while preserving researcher control. Multilingual support in 7 languages (English, French, German, Italian, Portuguese, Romanian, Spanish) enhances international interoperability.","The current version of archeoViz demonstrates several notable strengths: 1) Accessibility - it significantly lowers technical barriers by providing sophisticated visualisation capabilities without requiring GIS expertise; 2) Decentralisation - the portal approach allows researchers to maintain control of their data while facilitating sharing; 3) Reproducibility - URL parameters and R command generation ensure analyses can be precisely replicated; 4) Multilingualism - interfaces in 7 languages makes it accessible internationally; 5) Integration - fits within archaeological workflows as a complement to other analytical tools. The software effectively bridges the gap between complex spatial analysis tools and the needs of archaeological researchers who may lack advanced technical skills, while maintaining scientific rigour.","The current version of archeoViz has several limitations: 1) Analytical depth - it is explicitly 'not intended to replace more sophisticated analysis tools' like GIS or specialised statistical packages; 2) Performance constraints - visualisation of uncertainty and processing of large datasets can be resource-intensive; 3) Export functionality - some export capabilities are only available when using online instances; 4) Specialised focus - addresses a specific niche rather than providing comprehensive archaeological tools; 5) Technical dependencies - relies on the R ecosystem, requiring some familiarity with this environment. These limitations are largely by design, as the tool is positioned as complementary to more comprehensive analytical platforms rather than as a replacement.","archeoViz has positive long-term viability prospects based on several factors: 1) It has active development with regular updates, with the latest version released in 2024; 2) Strong institutional backing from CNRS and other research organisations provides stability; 3) Growing adoption with 66 instances created since launch indicates user acceptance; 4) Academic recognition through peer-reviewed publication and award recognition enhances credibility; 5) Integration with complementary tools creates a broader ecosystem. Potential sustainability concerns include the concentration of development expertise in a small team and reliance on the R/Shiny ecosystem. However, the open-source nature of the project, clear documentation, and institutional support framework suggest continued development and maintenance are likely in the medium term.","Several alternatives to archeoViz exist, each with different emphases: SEAHORS (Spatial Exploration of ArcHaeological Objects in R Shiny) is a similar R Shiny application that focuses on intra-site spatial analysis with a complementary relationship to archeoViz. archeofrag is specialised in refitting analysis and is integrated with archeoViz. Virtual Poeymaü provides a similar R Shiny application model for site-specific visualisation. For more comprehensive functionality, QGIS offers an open-source GIS platform with extensive capabilities but requires more technical expertise. ArcGIS provides a commercial enterprise platform with extensive archaeological tools but at high licensing costs. Arches is a web platform specifically designed for cultural heritage data management. archeoViz occupies a specific niche as a specialised visualisation and communication tool that complements rather than replaces these alternatives.",
ARIADNE,Success,,"ARIADNE (Advanced Research Infrastructure for Archaeological Dataset Networking in Europe) serves as a unified portal for accessing archaeological data across Europe. The current version provides integrated access to over 3.8 million archaeological resources from more than 40 data providers across four continents. It addresses the critical problem of archaeological data fragmentation by creating standardised vocabularies and implementing semantic web technologies that allow researchers to conduct cross-border searches using consistent filters for subject, location, and time period. ARIADNE is not software that researchers install locally, but rather a comprehensive infrastructure with both a web portal for discovery and search, and specialized tools for data management and sharing.","ARIADNE emerged from the early 2000s ARENA Project but officially launched on 1 February 2013 with €6.5 million from the EU's Seventh Framework Programme. This initial phase (2013-2017) established the core infrastructure and aggregated approximately 2 million archaeological datasets. The project continued as ARIADNEplus (2019-2022) with €6.6 million from the Horizon 2020 Programme, expanding beyond Europe to include partners from the United States, Argentina, Israel, and Japan. A significant organisational transformation occurred in November 2022 when ARIADNE established itself as a not-for-profit association under Belgian law (ARIADNE Research Infrastructure AISBL), ensuring sustained operation beyond project-based funding. Recent key developments include the THANADOS integration (2023-2024) for mapping early medieval grave data, the BADACor Project (2023-2025) for Argentinian archaeological sites, and participation in the ATRIUM Project (2024-2027), which focuses on developing workflows with other European research infrastructures.","The current version of ARIADNE implements a sophisticated technical architecture designed to make heterogeneous archaeological datasets interoperable through semantic mapping. At its core, ARIADNE employs a four-level architecture that spans from data creation to integration, with key components including: a Triple Store with Semantic Features (RDF storage using Virtuoso), the ARIADNE Portal (web-based discovery interface), the MORe Aggregation Infrastructure (handling data transformation), Elasticsearch (enabling efficient search), and a Metadata Quality Measurement Service (ensuring data consistency). The technical foundation of ARIADNE is built on the CIDOC CRM (Conceptual Reference Model), an ISO standard for cultural heritage information, which has been extended with specialized archaeological modules including CRMarchaeo for archaeological contexts, CRMba for buildings archaeology, and CRMgeo for spatial information. ARIADNE's approach to technical implementation follows Linked Open Data principles, with all metadata mapped to the ARIADNE Catalogue Data Model (ACDM). To solve terminology challenges across different languages and classification systems, ARIADNE employs a hub-based vocabulary mapping approach, with source vocabularies mapped to the Getty Art & Architecture Thesaurus as a common reference point. For users, access occurs primarily through the web portal (portal.ariadneinfrastructure.eu), which provides faceted search capabilities based on subject/content (what), location (where), and time period (when). ARIADNE also offers more advanced access methods for developers including a SPARQL endpoint for semantic queries, RESTful APIs, and OAI-PMH for metadata harvesting. This technical implementation allows researchers to query across national repositories using standardized parameters without requiring the source repositories to change their local data structures.",2025-05-05,yes,"ARIADNE meets all essential criteria as a research-specific tool directly supporting archaeological research. The infrastructure is explicitly designed to address archaeological research needs, transforming how researchers engage with archaeological data by making diverse datasets interoperable across national boundaries. It aligns with established methodological approaches in archaeology by implementing domain-specific data models. It also meets at least 7 supporting criteria: (1) it incorporates archaeological terminology and classification systems through its vocabulary mapping services; (2) it supports multiple stages of the research lifecycle from data collection through publication; (3) it transforms data between formats and representations using the ACDM mapping; (4) it enables analytical capabilities through its VRE environments; (5) it provides visualization functions for archaeological data; (6) its documentation is specifically tailored to archaeological researchers; (7) it supports both data collection and dissemination across institutional and national boundaries.",,,https://www.ariadne-research-infrastructure.eu/,https://www.ariadne-research-infrastructure.eu/,Open (various),Data management|Spatial analysis|Data collection|Datasets|Schemas and ontologies|API interfaces and web scrapers,archaeological data infrastructure|semantic web integration|cross-border research|standardized vocabularies|cultural heritage interoperability,2013-02-01,2024-04-01,ARIADNEplus,Active,"PIN S.c.r.l. (University of Florence, Italy), University of York (UK/Archaeology Data Service), Foundation for Research and Technology Hellas (FORTH), and 41 heritage institutions from 23 European countries plus international partners","Franco Niccolucci (Project Coordinator), Julian Richards (ADS), Carlo Meghini (ISTI-CNR), multiple European archaeological data specialists",Large (20+),Archaeology,General-purpose,Excellent,"ARIADNE currently provides access to over 3.8 million archaeological resources from more than 40 data providers across four continents. Usage metrics include steady growth from 2 million resources in 2017 to 3.8+ million in 2025, regular European conference presentations (e.g., at Computer Applications in Archaeology), and adoption by major archaeological data repositories across Europe. The infrastructure hosts specialized training workshops with hundreds of participants annually. The ARIADNE portal receives significant traffic, particularly from academic institutions across Europe, and the project has produced numerous high-impact academic publications describing its architecture and implementation.",Data Acquisition|Processing|Analysis|Publication|Preservation and Reuse,research-specific,Stand-alone software,Java|JavaScript|Various,Web-based,,"ARIADNE supports a wide range of interoperability capabilities in the current version. For data formats, it works with common archaeological data formats including GIS data, 3D models, database exports, and specialized scientific data formats. Through its implementation of the CIDOC CRM ontology and extensions, it enables semantic interoperability between diverse archaeological classification systems. The infrastructure provides multiple methods for data exchange including OAI-PMH for metadata harvesting, SPARQL endpoint for semantic queries, and RESTful APIs for programmatic access. The portal itself supports standard export formats including RDF, XML, and JSON. ARIADNE's vocabulary mapping services enable cross-language searches and its implementation of FAIR principles ensures broader interoperability with other scientific domains.","ARIADNE's primary strength lies in its ability to unify archaeological data that would otherwise remain disconnected across national repositories. The current version excels at providing cross-border discovery capabilities without requiring source repositories to change their internal data structures. The implementation of FAIR data principles and standardized ontologies has significantly advanced comparative archaeological research that was previously impractical. ARIADNE's semantic mapping approach solves multilingual terminology challenges through its hub-based vocabulary mapping services. The infrastructure provides specialized application profiles for different archaeological subdomains (such as the Mortuary Data Application Profile), allowing for domain-specific interfaces. Its transition to a sustainable organizational structure (ARIADNE Research Infrastructure AISBL) provides long-term stability beyond project funding cycles. The governance model with broad institutional membership ensures representation from diverse archaeological traditions.","Despite its significant achievements, ARIADNE in its current version faces several limitations. Geographic coverage remains uneven, with stronger representation in Western and Northern Europe compared to Eastern Europe and regions beyond Europe. Technical barriers exist for smaller institutions with limited IT resources, potentially creating a participation gap between well-resourced and under-resourced organisations. Integration is strongest at collection-level metadata, with item-level archaeological data integration remaining more challenging. The current version's user interface, while functional, could benefit from more intuitive design to make complex semantic queries more accessible to non-technical researchers. Despite implementation of FAIR principles, some legacy data sources remain difficult to fully integrate due to inadequate original documentation or proprietary formats. As the data volume grows, maintaining consistent quality control across all providers becomes increasingly challenging.","ARIADNE's transformation from a project-based structure to the ARIADNE Research Infrastructure AISBL in November 2022 significantly enhances its long-term viability. This legal entity under Belgian law provides a sustainable organizational framework beyond the limitations of project funding cycles. Several factors contribute to ARIADNE's strong viability outlook: institutional diversity (membership includes 25+ organizations from multiple countries), continued development (active participation in the ATRIUM project through 2027), growing data volume (increasing from 2 million resources in 2017 to 3.8+ million in 2025), and geographic expansion beyond Europe. The infrastructure's technical foundation based on established standards (CIDOC CRM) and technologies reduces technological obsolescence risks. The service-oriented architecture allows component upgrades without disrupting the entire system. ARIADNE's near-term roadmap focuses on workflow development through the ATRIUM project, knowledge graph enhancement, and advanced visualization tools, indicating continued evolution and relevance.","tDAR (The Digital Archaeological Record): US-based repository focused on preservation with stronger access controls but narrower geographical focus. Open Context: US-based platform emphasizing data publication with greater granularity at artifact level but smaller institutional footprint. Arches: Open-source platform for broader heritage management with superior geospatial capabilities but requiring more technical expertise. Compared to these alternatives, ARIADNE exceeds most in geographic coverage and data volume while maintaining sophisticated semantic integration capabilities. Its institutional backing through European funding and partner organizations provides stronger long-term sustainability than many alternatives.","FOLLOWED: Claude Tool-status=yes, user confirmed TOOL (portal counts as research tool)"
BCal,Success,,"BCal is a pioneering online Bayesian radiocarbon calibration tool designed specifically for archaeological chronology building. It allows archaeologists to incorporate prior archaeological knowledge, such as stratigraphic relationships, into the calibration process to produce more precise date estimates than conventional methods. The current version provides a question-based interface that guides users through building complex chronological models without requiring advanced statistical expertise. Earlier versions established the foundations for making Bayesian statistical methods accessible to archaeologists through a web-based platform.","BCal emerged from collaborative research between statisticians and archaeologists in the early 1990s, when limitations of traditional radiocarbon calibration became apparent. The theoretical foundations were established through papers by Buck and colleagues exploring Bayesian statistics in archaeological chronology. The software was officially launched in 1999 by a team led by Caitlin E. Buck (initially at Cardiff University, later University of Sheffield), J. Andrés Christen (UNAM, Mexico), and Gary N. James (Cardiff University). Their work was published in Internet Archaeology with the paper 'BCal: an on-line Bayesian radiocarbon calibration tool'. BCal represented one of the earliest applications of web-based Bayesian statistics in archaeology, democratising access to sophisticated modelling capabilities previously requiring specialised statistical expertise.","BCal's architecture consists of two primary components: the computational engine (mexcal) written in C++ by J. Andrés Christen, which performs complex Bayesian calculations using Markov Chain Monte Carlo (MCMC) simulation methods, and a frames-based browser interface that guides users through model building. The client-server model allows users to define calibration problems through the web interface, which then automatically generates mexcal code submitted to a UNIX server for processing, with results returned to the client for visualisation and interpretation. Technical dependencies include Gnuplot, fly, Java Environment, Generic Collection Library for Java, R, CODA, and Apache Tomcat. BCal's distinctive methodological approach uses a question-response interface to translate archaeological knowledge into statistical terms, enabling users to incorporate stratigraphic and contextual information alongside radiocarbon measurements. The system supports flexible phase modelling with options for ordered sequences or overlapping phases.",2025-05-06,yes,BCal fully meets the essential criteria as a research-specific tool designed to transform archaeological data in a way that aligns with established methodologies. It satisfies multiple supporting criteria: it incorporates domain knowledge of archaeological chronology and terminology; supports the analysis phase of research; transforms radiocarbon data into calibrated chronological sequences; performs complex Bayesian statistical calculations; visualises probability distributions of calibrated dates; provides documentation focused on archaeological applications; and aids in the dissemination of refined chronological data.,,,https://bcal.sheffield.ac.uk/,https://bcal.sheffield.ac.uk/,Academic (non-commercial),"Radiocarbon dating, calibration and sequencing|Chronological modelling|Statistical analysis",Bayesian statistics|chronological modelling|radiocarbon calibration|archaeological dating|web application,1999,c.2014,Unknown,Abandoned,"Cardiff University and University of Sheffield (UK); Instituto de Matemáticas, UNAM (Mexico)","Caitlin E. Buck, J. Andrés Christen, Gary N. James",Small (2-5),Statistics and Archaeology,General-purpose,Basic,"BCal has been cited in numerous archaeological chronology studies since its introduction in 1999. The original paper 'BCal: an on-line Bayesian radiocarbon calibration tool' has been widely referenced in archaeological method literature. Notable applications include establishing a seven-phase cultural sequence in Ecuador's Jama River Valley and dating ancient Hawaiian fishponds. While once groundbreaking, usage metrics show declining adoption as newer alternatives like OxCal have become dominant in the field. The original website (bcal.sheffield.ac.uk) is no longer accessible, indicating limited current usage.",Analysis|Interpretation,research-specific,Stand-alone software,C++|Java,Web (browser-based),,"BCal can import radiocarbon determinations and export calibrated date ranges and Bayesian model results. The current version's output format is still supported by modern archaeological statistics packages like ArchaeoPhases (R). BCal does not directly integrate with GIS or other archaeological data systems. Earlier versions required specific file formats for input data, limiting interoperability.","BCal pioneered accessible Bayesian calibration for archaeology through its web interface, making sophisticated statistical methods available without specialized software installation. Its question-based interface effectively translated complex statistical concepts into language archaeologists could understand. The centralized server-side processing allowed for more complex models than many archaeologists could run locally at the time. The software was built on rigorous statistical methodology published in peer-reviewed journals, giving it strong theoretical foundations.","The software is no longer actively maintained, with the original website (bcal.sheffield.ac.uk) inaccessible. The older frames-based web design became less intuitive compared to modern interfaces. Documentation was limited compared to alternatives that emerged later. The server-based approach sometimes resulted in long waiting times for complex models. As web technologies evolved, BCal's underlying architecture became increasingly outdated and difficult to maintain.","BCal's survivability is poor as it appears to be in an abandoned state. The last documented updates were around 2014, and the original web application is no longer accessible. While BCal's methodological approach continues to influence archaeological practice, the software itself has been superseded by alternatives with more active development cycles. The legacy of BCal lives on primarily through its contribution to establishing Bayesian methods in archaeology rather than through continued use of the software itself. Without active maintenance or migration to modern platforms, it is unlikely to remain usable in the medium to long term.","The primary alternative to BCal is OxCal, developed by Christopher Bronk Ramsey at Oxford University. OxCal has become the dominant Bayesian calibration tool in archaeology, featuring both online and standalone versions with regular updates. It uses a Chronological Query Language for model definition versus BCal's question-based interface. ChronoModel is a more recent alternative with a graphical user interface and distinctive approaches to handling outliers. Several R packages now support Bayesian chronological modelling, including ArchaeoPhases (for post-processing MCMC simulations), RCarbon (specifically for radiocarbon date analysis), and BayLum (for models integrating luminescence and radiocarbon dating). MatCal provides open-source Bayesian 14C calibration in MATLAB.",
Bchron,Success,,"Bchron is a specialised R package that implements Bayesian methods for calibrating radiocarbon dates and creating age-depth models for chronological data. The current version provides tools for radiocarbon calibration, age-depth modelling with depth or stratigraphic ordering of samples, relative sea level rate estimation through polynomial regression models, and non-parametric phase modelling via Gaussian mixtures. Though originally developed for palaeoenvironmental applications, Bchron has found increasing use in archaeological contexts for constructing robust chronologies from stratified sites, particularly valuable when dealing with complex depositional environments showing potential age reversals.","Bchron was created by statisticians John Haslett and Andrew C. Parnell, with development beginning around 2008 following their influential paper 'A simple monotone process with application to radiocarbon-dated depth chronologies'. Version 3.1 added functionality for plotting proxy data with age uncertainty. Version 3.2 (circa 2013) incorporated relative sea level change estimation functions. Version 4.0 and later releases implemented significant API improvements, with the current stable version being 4.7.6 (released to CRAN) and a development version 4.7.6.9000 available on GitHub. The package has evolved from a purely statistical tool to include specific archaeological applications, though the core chronology model has remained consistent, using a monotonic compound Poisson-Gamma process that enforces ordering constraints while properly accounting for age uncertainties.","At its core, Bchron implements a monotonic compound Poisson-Gamma chronology model through Bayesian statistics and Markov Chain Monte Carlo (MCMC) methods. The technical architecture follows a modular R package design with four main layers: (1) Core functions (Bchronology, BchronCalibrate) that provide the main analytical capabilities; (2) A statistical engine implementing MCMC for posterior sampling; (3) Data management functions for handling dates and calibration curves; and (4) Visualization components integrating with ggplot2. The model treats the age-depth relationship as a piecewise linear process using additive independent gamma increments with position arrivals occurring in a Poisson fashion, ensuring age monotonically increases with depth. The compound Poisson-Gamma chronology model implements several key constraints: dates must be in a specific sequence; older material must be deeper than younger material; and the ages between depths are estimated with appropriate uncertainty. The package leverages the Tweedie distribution for computational efficiency and employs S3 objects for an object-oriented approach. Performance-critical components are written in C++ to enhance computational speed. The implementation requires R (≥3.4.0) and depends on several libraries including MASS (for statistical functions), coda (for MCMC diagnostics), mclust (for Gaussian mixture modelling), and ggplot2 (for visualization). For archaeological applications, Bchron's outlier detection capabilities are particularly valuable when dealing with complex stratigraphic sequences with potential contamination or reworking of dated materials.",2025-05-06,yes,"Bchron fully satisfies the essential criteria for research software by providing specialized functions for chronological modelling in archaeological and palaeoenvironmental research. It transforms radiocarbon dates and stratigraphic data into calibrated age models with uncertainty quantification, directly supporting scientific inquiry. It also meets multiple supporting criteria: it incorporates domain knowledge about radiocarbon dating and stratigraphy; supports the analysis phase of research; performs complex calculations on chronological data; visualizes results with specialized plots; and its documentation specifically addresses research applications in archaeology and environmental science.",https://github.com/andrewcparnell/Bchron,https://cran.r-project.org/web/packages/Bchron/index.html,https://andrewcparnell.github.io/Bchron/,https://andrewcparnell.github.io/Bchron/,GPL-2 | GPL-3,"Chronological modelling|Radiocarbon dating, calibration and sequencing",Bayesian statistics|Chronology|Radiocarbon|Modelling|Archaeology,2008,2021,4.7.6.9000 (development) / 4.7.6 (stable),Maintenance-only,University College Dublin|Maynooth University|Trinity College Dublin,Andrew C. Parnell|John Haslett|Nathan McJames|Bruna Wundervald|Keefe Murphy,Small (2-5),Statistics,General-purpose,Comprehensive,"GitHub metrics show 37 stars, 10 forks, and 7 contributors. The package has 25 issues (23 closed, 2 open), indicating maintenance activity. Academic citations are strong for the foundational methodology paper. The user base spans primarily academic researchers in paleoenvironmental sciences, archaeology, and geology. At archaeological sites like Hell Gap in Wyoming, researchers have used Bchron to estimate ages of stratified Paleoindian components. Though less widely adopted than OxCal in archaeological contexts, Bchron maintains a steady user community among statistically oriented researchers.",Analysis|Interpretation,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"Bchron can import data from CSV files and R data frames. It supports standard radiocarbon calibration curves (IntCal20, SHCal20, Marine20) and allows for custom calibration curves. The package works with dates from radiocarbon and other dating methods. Output is in the form of R objects containing chronological information and uncertainty estimates. Visualization is handled through integration with ggplot2. The current version provides seamless integration with the broader R ecosystem, allowing for connection with other statistical packages for further analysis.","The primary strengths of Bchron are its robust statistical foundation, comprehensive uncertainty quantification, and integration with the R ecosystem. The compound Poisson-Gamma model provides theoretically sound chronological reconstructions with proper accounting for multiple sources of uncertainty. The package offers flexibility in accommodating various dating methods and calibration curves, including user-defined ones. Its outlier detection capabilities are particularly valuable for complex archaeological sequences. Bchron excels at identifying problematic dates within chronological sequences and assessing which dates most strongly influence the chronological models. For researchers already working in R, the seamless integration with other statistical analyses is a major advantage. The package is generally faster than alternatives like OxCal for certain applications.","Bchron has several limitations affecting its adoption in archaeological contexts. The package tends to produce wider uncertainty intervals than some alternatives, potentially overestimating age uncertainties. A significant barrier is the requirement for R programming knowledge, creating a steeper learning curve than GUI-based alternatives like OxCal that are more accessible to archaeological users without programming experience. The package lacks some archaeology-specific features found in alternatives, with its documentation and examples predominantly emphasizing environmental applications rather than archaeological ones. Default visualizations are less polished than specialized archaeological software. The command-line interface also presents a barrier to many archaeologists accustomed to more visual interfaces. For complex archaeological models with detailed stratigraphic relationships, Bchron's capabilities are more limited than OxCal's dedicated archaeological modelling functions.","Bchron demonstrates several positive indicators for long-term viability despite development appearing to have slowed since 2021. Key sustainability factors include: an established user base in paleoenvironmental and archaeological research; open-source implementation allowing community maintenance; platform independence through R integration; continued citations in peer-reviewed publications; and a complete implementation of its core functionality. The primary risk factors are the relatively small developer team and potential competition from newer approaches. However, the package's complete functionality and integration with the R ecosystem suggest it will remain viable for the foreseeable future, even with minimal active development. The open-source nature means qualified users can maintain or fork the code if necessary. While new features may be limited, the core functionality appears stable and sufficient for most chronological modelling needs.","OxCal is the most widely used archaeological chronology software, developed by Christopher Bronk Ramsey at Oxford. It offers dedicated archaeological focus, web interface, and specialized archaeological models. Bacon, developed by Maarten Blaauw and Andrés Christen, uses Bayesian statistics to model accumulation histories by dividing cores into many thin segments for more flexible modeling. Clam, also by Maarten Blaauw, offers a simplified, non-Bayesian approach using classical age-depth modeling methods like linear interpolation. ChronoModel is specifically designed for archaeological chronology building with a user-friendly interface. Other specialized tools include rcarbon (for summed probability distributions), c14bazAAR (for downloading C14 datasets), and ArchaeoPhases (for analyzing archaeological phases).",
bleiglas,Success,,"Bleiglas is an R package that creates three-dimensional Voronoi tessellations for visualising and analysing archaeological data across both space and time dimensions. The name 'bleiglas' (German for 'lead glass') metaphorically represents the tool's ability to visualise layered 3D data. The key innovation is its capability to cut 3D tessellations horizontally across the time dimension (z-axis) to produce 2D polygon maps representing different chronological periods. This approach is particularly valuable for archaeological research questions involving the spatiotemporal distribution of finds, cultural pattern changes over time, and interpolation of data with positional uncertainty.","Bleiglas was developed by computational archaeologists at the Max Planck Institute for the Science of Human History (now the Max Planck Institute for Evolutionary Anthropology). Development began as part of the authors' research in archaeogenetics and computational archaeology, with the GitHub repository established prior to 2021. The package was officially published in the Journal of Open Source Software (JOSS) in March 2021 (volume 6, issue 60, page 3092). Since publication, the package has been maintained but has seen limited active development, with documentation last built in September 2021.","The current version of bleiglas functions as a sophisticated wrapper around the Voro++ command line tool, which performs the core 3D tessellation calculations. The package architecture includes several key components: (1) A core interface to Voro++ for creating 3D Voronoi diagrams from input point clouds, (2) Data processing pipelines for both pre-processing spatial/temporal data and post-processing tessellation results, (3) Visualisation components for cutting 3D tessellations horizontally to produce time-slice maps, and (4) An interpolation system for attributing arbitrary points to polygons. The implementation includes custom C++ code for point-to-polygon attribution (originally developed for the recexcavAAR package) and handles 3D point clouds with different scaling factors for spatial versus temporal dimensions. External dependencies include Voro++ (available in major Linux repositories and via Homebrew for macOS), while R package dependencies include tidyverse for data manipulation, sf for spatial data handling, rgeos for geometry operations, data.table for efficient data manipulation, pbapply for progress bars, and rgl for 3D visualisations. The data model works with several formats including 3D point clouds with spatial (x,y) and temporal (z) coordinates, raw Voronoi output containing 3D polygon geometry information, polygon edges in tidy data.table structure, cut surfaces as 2D polygons compatible with sf objects, and prediction grids for interpolation and uncertainty sampling.",2025-05-06,yes,"Bleiglas meets all essential criteria for research software tools: (1) It has a research-specific purpose by supporting archaeological spatiotemporal analysis, (2) It transforms research materials meaningfully by converting raw spatiotemporal point data into interpretable 3D and 2D visualisations, and (3) It aligns with established methodologies in computational archaeology. It also meets multiple supporting criteria: it integrates domain knowledge from archaeology and spatiotemporal analysis, supports several research lifecycle stages (processing, analysis, interpretation), transforms data between formats, provides analytical capabilities for spatiotemporal interpolation, and includes extensive research-focused documentation.",https://github.com/nevrome/bleiglas,,https://joss.theoj.org/papers/10.21105/joss.03092,https://joss.theoj.org/papers/10.21105/joss.03092,MIT,Spatial analysis|3D modelling|Data visualisation|Chronological modelling|Statistical analysis,3D tessellation|spatiotemporal analysis|archaeological data|Voronoi diagrams|R package,2021-03-01,2021-09-01,1.0.1,Maintenance-only,"Max Planck Institute for the Science of Human History (original development), Max Planck Institute for Evolutionary Anthropology (current affiliation)","Clemens Schmid (ORCID: 0000-0003-3448-5715), Stephan Schiffels (ORCID: 0000-0002-1017-9150)",Small (2-5),Archaeology,General-purpose,Comprehensive,"The package shows modest but specialised adoption metrics including approximately 12 GitHub stars, 2 forks, and 3 watchers. It is formally published in the Journal of Open Source Software and included in archaeological software resource lists like open-archaeo. There is limited evidence of widespread adoption or an active user community, suggesting a specialised user base primarily in computational archaeology and archaeogenetics.",Analysis|Interpretation|Visualization,research-specific,Packages and libraries,R,Linux|macOS|Windows (with appropriate setup),R,"Bleiglas demonstrates strong interoperability with the broader R ecosystem, particularly with spatial analysis packages. Its outputs in sf format can be seamlessly used with ggplot2 for visualisation, the tidyverse for data manipulation, and exported to GIS software. The package supports various coordinate reference systems through sf integration, enhancing compatibility with geographic data from different sources. It was designed to work with packages like c14bazAAR for radiocarbon dating analysis, making it particularly useful in archaeological workflows.","The current version of bleiglas offers several key strengths: (1) Specialised archaeological functionality specifically designed for spatiotemporal analysis, addressing unique disciplinary challenges. (2) An innovative approach using 3D Voronoi tessellation to visualise spatiotemporal data, revealing patterns not apparent in traditional 2D visualisations. (3) Efficient Voro++ integration that makes powerful tessellation algorithms accessible to R users without requiring deep C++ knowledge. (4) Well-documented methodology with comprehensive examples, technical vignettes, and a peer-reviewed paper. (5) Open-source availability under a permissive licence allowing free use and modification. (6) Seamless integration with established R packages like tidyverse and sf, fitting into existing archaeological data workflows.","The current version has several limitations: (1) External dependency on Voro++ software introduces setup complexity. (2) Limited recent development activity with documentation last built in September 2021. (3) Not available on CRAN, requiring installation directly from GitHub, which raises concerns about long-term stability. (4) Specialised use case means relatively narrow application compared to general-purpose tools. (5) Limited community support with minimal discussion, usage examples or third-party documentation. (6) Technical complexity requires understanding of both archaeological concepts and tessellation mathematics, potentially limiting accessibility. (7) 3D tessellation operations can be computationally demanding with large datasets.","Bleiglas faces several challenges to its long-term viability: it shows limited recent activity suggesting a maintenance-only phase rather than active development, it is not available on CRAN which raises concerns about long-term sustainability, and it shows modest evidence of widespread adoption in the archaeological community. However, its development at the Max Planck Institute provides some institutional support, its comprehensive documentation including a peer-reviewed paper improves viability by ensuring the methodology is well-described for future users, and its technical foundation built on established libraries with well-documented code should facilitate maintenance if others take up development. Overall, while the package remains useful for its specific purpose, its future likely depends on whether the original authors or new contributors continue active maintenance.","Alternative tools serving similar or related purposes include: (1) R packages for 2D tessellation (deldir, tripack) that provide 2D Voronoi tessellation/Delaunay triangulation but lack 3D spatiotemporal capabilities. (2) Archaeological visualisation tools (SEAHORS, archeoViz) offering web applications and R packages for visualising spatial distribution of archaeological remains. (3) QGIS with Temporal Controller providing GIS functionality with temporal data handling, though approaching spatiotemporal analysis differently. (4) Spatial analysis R packages (SpatialEpi, Spatstat) offering spatial statistical analysis capabilities adaptable for archaeological data. (5) spacetime R package providing classes and methods for spatiotemporal data, including mapping and visualisation. (6) ArchaeoPhases for analysing and estimating archaeological phases from posterior distributions. (7) HBECVT (Harmonic Boundary-Enhanced Centroidal Voronoi Tessellation) offering an alternative tessellation method.",
Bwigg,Failure,"Fail (metadata, references)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c14bazAAR,Success,,"c14bazAAR is an R package that standardises access to radiocarbon (C14) databases. It provides a unified interface for downloading, cleaning, and analysing radiocarbon dates from over 20 different source databases. The current version enables researchers to retrieve data from specialised repositories like 14SEA (Southeast Asia), ADRAC (Central Africa), AustArch (Australia), and others through consistent commands. The package converts disparate data formats into a standardised c14_date_list structure, making cross-database comparisons and large-scale analyses possible. Beyond simple retrieval, it offers functions for cleaning data, removing duplicates, standardising material classifications, validating geographical coordinates, and calibrating dates through integration with other R packages.","c14bazAAR began as a project within the Initiative for Statistical Analysis in Archaeology Kiel (ISAAKiel) around 2017. The original project was developed by Clemens Schmid, Dirk Seidensticker, and Martin Hinz to address data fragmentation issues in archaeological radiocarbon dating research. The package was formally published in the Journal of Open Source Software on November 25, 2019, marking a significant milestone. After its initial development, c14bazAAR was transferred to rOpenSci, increasing its visibility and institutional support. The package was available on CRAN until August 26, 2020, when it was archived due to check issues. Despite CRAN removal, development has continued actively on GitHub, with the current version being 5.0.0. The package has evolved from focusing on a limited set of databases to supporting over 20 databases with advanced data cleaning and spatial capabilities.","The c14bazAAR package implements a modular architecture built on R's S3 system. At its core is the 'c14_date_list' S3 class that extends the tibble data structure from the tidyverse ecosystem to provide specialised functionality for radiocarbon data. The current implementation uses a modular approach with separate getter functions for each supported database, standardisation utilities to enforce consistent variable naming and types, and integration components for calibration and spatial analysis. For data standardisation, c14bazAAR employs reference tables mapping database-specific variables to standardised names and implements thesauri for country names and material classifications. The package manages dependencies strategically, with core dependencies (data.table, dplyr, tibble, magrittr, rlang, httr, tidyr) required for basic operations and optional dependencies for extended functionality. The API exposes well-designed functions including 'get_c14data()' for database querying, 'calibrate()' for date conversion via Bchron integration, and 'as.sf()' for spatial integration with the sf package. The package handles complex data types including calibrated date distributions (stored as nested data frames) and calibration ranges. Performance features focus on handling large datasets efficiently, with technical limitations related primarily to its removal from CRAN in 2020 and reliance on external calibration libraries.",2025-05-06,yes,"c14bazAAR clearly qualifies as research software as it meets all essential criteria. It has a research-specific purpose (supporting radiocarbon dating analysis), meaningfully engages with research data (transforming radiocarbon dates), and aligns with archaeological methodologies. It satisfies multiple supporting criteria: it incorporates domain knowledge (radiocarbon dating terminology), supports research lifecycle stages (data preparation, analysis), provides data transformation capabilities (standardising formats across databases), offers analytical functions (calibration), and facilitates visualisation through plotting functions.",https://github.com/ropensci/c14bazAAR,,https://docs.ropensci.org/c14bazAAR/,https://docs.ropensci.org/c14bazAAR/,GPL-2.0,"Radiocarbon dating, calibration and sequencing",radiocarbon|archaeology|standardisation|database|data cleaning,2017-01-01,2023-03-09,5.0.0,Active,Initiative for Statistical Analysis in Archaeology Kiel (ISAAKiel)|rOpenSci|Max Planck Institute for the Science of Human History|Ghent University|University of Bern,Clemens Schmid|Dirk Seidensticker|Martin Hinz,Small (2-5),Archaeology,General-purpose,Comprehensive,"The package maintains modest but dedicated usage metrics with 30 GitHub stars and 12 forks. Its primary citation comes from the 2019 Journal of Open Source Software paper. While no longer available on CRAN (since August 2020), the package remains accessible through rOpenSci's r-universe repository and GitHub. Active development continues with regular updates and issue tracking. The package is used in multiple archaeological studies focused on standardised radiocarbon analysis, particularly for research requiring integration of data across multiple databases.",Data Acquisition|Processing|Analysis,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"c14bazAAR can import data from over 20 radiocarbon databases, converting them to a standardised structure. The current version supports exporting to sf objects for spatial analysis, interfaces with Bchron for calibration, and can produce visualisations of radiocarbon dates. It reads data in various formats (CSV, JSON, HTML) depending on the source database and exports to formats supported by the tidyverse ecosystem.","c14bazAAR's primary strengths include its comprehensive database coverage through a unified interface, robust standardisation of inconsistent radiocarbon data, seamless integration with the R ecosystem, and specialised archaeological functionality for data cleaning and validation. The package efficiently addresses a critical challenge in archaeological research - the fragmentation of radiocarbon data across specialised repositories with inconsistent formats. The current version provides a standardised workflow for retrieving, cleaning, and preparing radiocarbon dates for analysis, enabling researchers to conduct large-scale comparative studies that would otherwise require significant manual data wrangling. Its institutional backing from multiple European research organisations enhances its credibility and sustainability.","Current limitations include its removal from CRAN (reducing visibility and installation ease), limited visualisation capabilities requiring integration with other packages, reliance on a small development team raising sustainability concerns, heavy dependency requirements for full functionality, and a narrow focus potentially limiting broader community interest. The package sometimes requires workarounds for databases that change their structure without notice, necessitating regular updates. As the package is highly specialised for archaeological radiocarbon dating, it requires domain knowledge to use effectively and may have a limited appeal outside this specific research niche.","c14bazAAR shows mixed indicators for long-term viability. Positive factors include continuous maintenance on GitHub despite CRAN removal, institutional support from rOpenSci and academic partners, and regular expansion of database coverage. The package addresses a fundamental need in archaeological chronology research that remains relevant regardless of technological changes. However, sustainability concerns include its removal from CRAN, dependency on a small development team, and the ongoing challenge of maintaining compatibility with changing database structures. The package's future likely depends on continued maintenance by its core team and potential reintegration with CRAN, which would significantly enhance its discoverability and accessibility.","Several alternatives serve related but distinct functions in the archaeological R ecosystem: rcarbon (focused on analysis of radiocarbon dates for demographic inference), Bchron (specialises in Bayesian chronology modelling and calibration), oxcAAR (interfaces with OxCal for calibration and Bayesian modelling), and p3k14c (newer package providing access to a global database of archaeological radiocarbon dates). Web-based alternatives include GoGet (for users unfamiliar with R) and OxCal (standard web-based tool for radiocarbon calibration). Rather than direct competitors, these tools often complement c14bazAAR, with researchers using it for data acquisition and standardisation before applying specialised analytical tools.",
DataScribe,Success,,"DataScribe is a specialised open-source module for the Omeka S platform that enables researchers to transform structured historical documents into standardised digital datasets. The current version (1.1.0) enables collaborative transcription of tabular historical materials like census records, parish registers, and account books through a side-by-side interface showing original document images alongside custom-built transcription forms. While originally developed for historical research projects, DataScribe provides capabilities relevant to archaeological documentation, particularly for transforming structured field notes, artefact catalogues, and excavation records into computational datasets whilst preserving original context and data integrity.","DataScribe emerged from a specific need in historical research identified by the Roy Rosenzweig Center for History and New Media (RRCHNM) at George Mason University. Development began in September 2019 with a $324,733 grant from the National Endowment for the Humanities' Office of Digital Humanities. The project was led by Dr. Jessica Otis (Principal Investigator) with Dr. Lincoln Mullen (Co-Project Director) and a development team including James Safley and Megan Brett. The software progressed through alpha testing in 2019-2020, with public beta testing beginning in November 2020. Version 1.0.0 was released in 2021, followed by version 1.1.0 in September 2023, extending compatibility to Omeka S 3.x with beta support for Omeka S 4.x. The project's legitimacy in academic circles was further established with a 2024 publication in the Journal of Open Source Software, documenting its technical implementation and research applications.","DataScribe is architected as a modular extension to the Omeka S digital collections platform, leveraging and extending its underlying technical infrastructure. The current version operates on standard web servers using PHP (7.4-8.1) and relies on MySQL for database storage. DataScribe's architecture follows Omeka S patterns but extends the data model with additional entities specifically designed for structured data transcription projects. The technical implementation centres around a workflow that begins with importing digital images of historical documents as Omeka S items, which are then organised into sets. Researchers create a DataScribe dataset linked to an item set, then design custom transcription forms with appropriate field types (numeric, text, select, date) that match the structure of the source documents. The transcription interface provides a split-screen view showing the original document alongside the custom form, allowing precise data entry while maintaining visual reference to the source material. A key technical strength in the current version is the validation system that enforces data standards during transcription, including the ability to mark fields as 'missing' or 'illegible' to accurately represent source material inconsistencies. The software stores all transcribed data in a structured database schema that preserves both the content and its metadata, including who created each transcription and when. Export functionality allows completed datasets to be extracted as CSV files for analysis in external tools. The DataScribe module depends on several Omeka S components and is typically deployed on Linux-based web servers, though it can run on any environment supporting PHP and MySQL. Performance considerations include potentially large storage requirements for high-resolution document images and database scaling for large transcription projects.",2025-05-06,yes,"DataScribe fulfils all essential criteria for research software tools. It has a clear research-specific purpose in transforming historical documents into digital datasets (criterion 1), directly engages with research materials through its transcription capabilities (criterion 2), and aligns with established methodologies in digital humanities and archaeology for documenting and digitising structured historical records (criterion 3). It also satisfies supporting criteria by incorporating domain knowledge about historical document transcription (SC1), supporting the data collection and transformation phases of the research lifecycle (SC2, SC3, SC7), enabling systematic conversion of analogue information to digital formats (SC3), and providing structured documentation focused on research applications (SC6). While created for historical research, its capabilities for structured data entry, validation, and dataset creation are directly applicable to archaeological documentation needs.",https://github.com/chnm/Datascribe-module,,https://datascribe.tech/,https://datascribe.tech/,GNU General Public License v3.0,Data management,transcription|structured_data|digital_humanities|omeka_module|collaborative_research,2019-11-15,2023-09-19,1.1.0,Active,Roy Rosenzweig Center for History and New Media at George Mason University,"Jessica Otis, Lincoln Mullen, James Safley, Megan Brett",Small (2-5),History,Project-specific,Comprehensive,"DataScribe has a modest but meaningful adoption profile focused within digital humanities. The GitHub repository shows moderate engagement with 14 stars and 4 forks as of May 2025. Despite these modest metrics, its implementation in significant research projects demonstrates institutional confidence. Most notably, DataScribe has been deployed in two major initiatives: the 'Death by Numbers' project digitising London Bills of Mortality (1603-1752), and the 'American Religious Ecologies' project transcribing approximately 232,000 schedules from the 1926 Census of Religious Bodies. The software has been formally published in the Journal of Open Source Software, providing academic recognition. User feedback from these implementations highlights appreciation for the flexible structure and integrated workflow management. Community engagement is primarily centred around workshops and educational resources provided by RRCHNM.",Data Acquisition|Processing|Preservation and Reuse,research-specific,Stand-alone software,PHP,Web-based,,"DataScribe works within the Omeka S ecosystem, accepting image files (JPG, PNG, TIFF) as input for document display. The current version exports data primarily as CSV files, enabling interoperability with statistical analysis tools, spreadsheet applications, and databases. This format provides flexibility for further processing and analysis in other software. Transcribed datasets can also be managed within Omeka S's broader infrastructure, allowing integration with other digital collections and publishing tools. The modular architecture potentially allows custom extensions, though this requires PHP development expertise.","DataScribe excels in several key areas that benefit archaeological and historical research. The current version offers a purpose-built solution for structured data transcription with field-specific validation rules ensuring consistency across large datasets—particularly valuable for archaeological documentation requiring standardised recording methods. The side-by-side interface showing original documents alongside transcription fields preserves source context while enabling digital transformation. DataScribe's collaborative workflow system includes built-in roles for transcribers, reviewers, and administrators, facilitating team-based projects with quality control mechanisms. Integration with Omeka S provides a complete ecosystem for digital collections management, connecting transcribed data to broader digital repositories. Open-source availability allows customisation for specific research needs, while strong institutional backing from RRCHNM suggests good long-term support.","DataScribe faces several limitations that may affect its suitability for some archaeological applications. The current version requires Omeka S installation as a prerequisite, creating a significant technical barrier for researchers without web development experience or institutional IT support. Server requirements add complexity and potential costs compared to standalone desktop applications. DataScribe lacks built-in optical character recognition (OCR), requiring manual transcription of all content. The tool is optimised for structured documents (forms, ledgers, tables) but offers limited utility for unstructured narratives or continuous text that might appear in field notes or excavation diaries. Creating appropriate data models requires careful planning and some database design knowledge, presenting a learning curve for new users. While documentation is comprehensive, it assumes familiarity with Omeka S concepts. Limited adoption outside specific digital humanities projects means fewer community resources compared to more widely-used tools.","DataScribe demonstrates good prospects for long-term viability based on several factors. Strong institutional backing from the Roy Rosenzweig Center for History and New Media, an established digital humanities centre with over 25 years of experience developing sustainable research tools, provides essential infrastructure and expertise. The recent publication in the Journal of Open Source Software in 2024 and continued active development with compatibility updates for newer versions of Omeka S indicate ongoing maintenance. The modular architecture within the established Omeka S ecosystem increases sustainability by leveraging a broader codebase and community. The software's open-source nature under the GPL v3 license ensures that the code remains available even if active development were to cease. Implementation in significant funded research projects like 'Death by Numbers' and 'American Religious Ecologies' demonstrates legitimacy and utility within the academic community. While specialised in purpose, which limits its potential user base, DataScribe addresses a persistent need in historical and archaeological research for structured data transcription that is likely to remain relevant.","DataScribe exists within an ecosystem of several alternative tools for transforming historical materials into digital data, each with distinct strengths and limitations compared to DataScribe. Transkribus specialises in handwritten text recognition (HTR) with advanced AI capabilities, offering automated transcription that DataScribe lacks, but requires credits for processing beyond a limited amount and focuses less on structured data handling. FromThePage provides a collaborative transcription platform with user-friendly interface and TEI markup support, better suited for continuous text but less specialised for structured data transcription. eScriptorium offers an open-source alternative to Transkribus for handwritten text recognition, with greater flexibility for training custom models but requiring more technical knowledge than DataScribe. tDAR (The Digital Archaeological Record) focuses broadly on archaeological data preservation rather than specifically on transcription, with specialised features for archaeological research that DataScribe lacks. For simpler needs, manual spreadsheet transcription requires no additional tools but lacks validation features, workflow management, and integration with source images that DataScribe provides.",
DepthmapX,Success,,"Multi-platform spatial network analysis software designed to understand social processes within the built environment. The current version quantifies spatial relationships through visibility graph analysis, axial map analysis, segment analysis, and agent-based modelling. While originally developed for architecture and urban planning, DepthmapX has been widely adopted in archaeology to analyse ancient spatial configurations, movement patterns, and social organisation. It can handle graphs with up to approximately 1,000,000 point locations across various scales from individual buildings to entire cities.","Originally developed as 'Depthmap' by Alasdair Turner at UCL's Space Syntax Laboratory in 1998 as a simple isovist processing program. Following Turner's death in 2011, Dr. Tasos Varoudis redeveloped and open-sourced the software as 'depthmapX' in 2012. The current version represents significant evolution from the original's limited scope to a comprehensive multi-platform spatial analysis suite with both GUI and command-line interfaces.","The current version is written in C++ with a Python scripting interface and Qt5-based GUI. DepthmapX implements multiple forms of spatial network analysis: Visibility Graph Analysis (VGA) for analysing inter-visibility relationships; axial map analysis for studying movement potential; segment analysis for examining angular, metric and topological relationships; and agent-based modelling for simulating movement patterns. The software architecture separates the core analysis engine from the user interfaces, allowing for both interactive use and batch processing. Performance limitations become apparent with larger datasets (>1,000,000 nodes). Data import supports DXF, MIF/MID, NTF and Tiger Line maps formats, with exports to MIF/MID format and text files. The current version includes integration with QGIS through the Space Syntax Toolkit plugin, enhancing GIS capabilities.",2025-05-06,yes,"DepthmapX meets all essential criteria for research software. It has a research-specific purpose (spatial configuration analysis), engages with research data (transforms spatial relationships into quantifiable metrics), and aligns with established methodologies (space syntax theory). It also meets multiple supporting criteria: incorporates domain knowledge (spatial syntax terminology and classifications), supports multiple research stages (analysis and interpretation), transforms data (converts spatial configurations to network representations), provides analytical capabilities (calculates various spatial metrics), offers visualisation functions (creates heatmaps and graphs of spatial properties), and includes research-focused documentation.",https://github.com/SpaceGroupUCL/depthmapX,,https://www.spacesyntax.online/software-and-manuals/depthmap/,https://www.spacesyntax.online/software-and-manuals/depthmap/,GNU General Public License v3.0 (GPLv3),Spatial analysis|Site mapping|Network analysis,Spatial Network Analysis|Visibility Analysis|Movement Simulation|Built Environment|Social Space Analysis,1998,2022-2023,0.8.0,Active,"Space Syntax Laboratory at The Bartlett, University College London (UCL)","Alasdair Turner (original), Dr. Tasos Varoudis (redevelopment)",Small (2-5),Architecture and Urban Planning,General-purpose,Adequate,"Over 150,000 users across 130+ countries; 1,100+ academic citations; 160-204 GitHub stars; 112-113 forks. Significant adoption in archaeology demonstrated by published studies of Roman city layouts (e.g., Pompeii, Cuicul/Djémila), prehistoric settlements, and ancient domestic spaces.",Analysis|Interpretation,research-specific,Stand-alone software,C++,Windows|macOS|Linux,,"Imports DXF, MIF/MID, NTF, and Tiger Line maps formats; exports to MIF/MID format and text files. Integrates with QGIS through the Space Syntax Toolkit plugin. Python scripting interface allows custom workflow integration. The current version offers command-line interface for batch processing.","The current version offers quantification of otherwise subjective spatial qualities, allowing archaeological researchers to test hypotheses about ancient space usage. Cross-platform compatibility ensures accessibility across research environments. Its established methodology provides comparative framework for diverse archaeological contexts. The open-source nature facilitates community contributions and adaptations for archaeological requirements. Integration with QGIS extends its utility within existing archaeological GIS workflows.","The current version faces performance limitations with larger archaeological datasets, potentially restricting analysis of extensive sites. The theoretical foundation in space syntax may not align with all archaeological paradigms, risking oversimplification of culturally specific spatial relationships. The user interface appears dated compared to contemporary software standards. For larger systems, the axial map derivation algorithm becomes computationally intensive, requiring manually pre-drawn maps instead of automatic generation in the current version.","Moderate to good. The software is actively maintained by SpaceGroupUCL with institutional backing from University College London, suggesting good mid-term viability. However, long-term survival depends on continued academic interest and funding. The development community is relatively small compared to mainstream GIS platforms, creating potential sustainability challenges. Integration with QGIS provides a potential migration path should standalone development cease.","QGIS Space Syntax Toolkit (provides a front-end for DepthmapX within QGIS), Syntax2D (simpler interface for 2D analysis), Confeego (add-on for MapInfo), Isovist_App (lightweight visibility analysis), CONFIGURBANIST (online spatial analysis tool), Viraph (alternative visibility graph analysis software). Most archaeological spatial analysis can also be performed, with more effort, using general GIS software like ArcGIS or QGIS with custom scripts.",
Distant Viewing Toolkit,Success,,"The Distant Viewing Toolkit (DVT) is a Python package enabling humanities scholars to analyze large collections of visual materials through computer vision. Analogous to Franco Moretti's 'distant reading' approach for text, DVT allows researchers to extract patterns across thousands of images and videos while maintaining analytical rigour. It serves researchers in humanities and social sciences as well as cultural heritage institutions by automating the extraction of visual features across entire collections. Although originally developed for media studies and visual culture analysis, it has applications across historical and archaeological domains where large visual datasets require computational analysis.","The conceptual framework for 'distant viewing' was first established around 2017-2018 in academic papers by Taylor Arnold and Lauren Tilton. Formal software development began in 2018 with funding from the National Endowment for the Humanities (NEH) through a Digital Humanities Advancement Grant. Key milestones include: the initial development phase (2018-2019), version 0.3.0 publication in the Journal of Open Source Software in 2020, and the first major stable version 1.0.1 (2020-2021). The current version is 1.1.0. Development has continued with significant funding from multiple sources, including a Library of Congress Computing in the Cloud Initiative (2021-2022) and an NEH Level III Digital Advancement Grant (2022-2025) for the related PGVis project.","The Distant Viewing Toolkit implements a dual-interface approach with both a high-level command-line interface for researchers with limited programming experience and a low-level Python API for advanced users requiring granular control. Built in Python 3.x, DVT's architecture is organised around two key components: 'annotators' (algorithms that process raw visual data) and 'aggregators' (algorithms that synthesize these annotations). This separation creates an efficient pipeline for extracting meaningful information from visual datasets. The toolkit's key dependencies include NumPy and Pandas for data manipulation, OpenCV-Python for computer vision functions, and PyTorch/TorchVision for deep learning capabilities. DVT processes data in manageable chunks to accommodate large datasets on standard hardware, extracting multiple types of visual information including faces, objects, colours, scenes, and text. The modular architecture allows researchers to create custom analysis workflows by chaining different annotators and aggregators together. Output is provided in structured formats (CSV or JSON) for further analysis or visualization. The current version 1.1.0 maintains this architecture while improving stability and performance compared to earlier iterations. DVT's implementation emphasizes accessibility for humanities scholars while preserving the technical sophistication needed for rigorous computational analysis.",2025-05-06,yes,"The Distant Viewing Toolkit fulfills all essential criteria as research software. It explicitly supports scholarly inquiry through computational analysis of visual materials (Research-Specific Purpose), meaningfully transforms research materials by converting visual data into structured information (Research Data Engagement), and aligns with recognized methodologies in digital humanities (Methodological Alignment). It also meets multiple supporting criteria: integrating domain knowledge from humanities and computer vision fields, supporting multiple research lifecycle stages (particularly Processing and Analysis), transforming visual data into machine-readable formats, providing analytical capabilities through computer vision algorithms, and offering visualization functions for research findings. Its documentation is specifically focused on research applications, and it enables dissemination of visual research data in accessible formats.",https://github.com/distant-viewing/dvt,,https://distantviewing.org/,https://distantviewing.org/,GPL-2.0,Diagrams and visualizations|Spatial analysis|Shape recognition|API interfaces and web scrapers|Datasets,computer vision|humanities computing|visual analysis|media studies|machine learning,2018,2025-04-01,1.1.0,Active,University of Richmond (Distant Viewing Lab),Taylor Arnold|Lauren Tilton,Small (2-5),Digital Humanities,General-purpose,Comprehensive,"The GitHub repository has approximately 93 stars and 13 forks, showing moderate adoption within its specialized academic niche. It has been applied to several significant research projects including: ADDI (Access & Discovery of Documentary Images) in collaboration with the Library of Congress; Photogrammar (analysis of 170,000 FSA-OWI photographs); Network-Era Sitcom Analysis comparing visual styles between classic American sitcoms; and Peanuts Comic Strip Analysis examining 17,897 comic strips. The developers' 2023 MIT Press book 'Distant Viewing: Computational Exploration of Digital Images' has further codified the theoretical framework and applications.",Processing|Analysis|Interpretation,research-specific,Packages and libraries,Python,Linux|macOS|Windows,Python,"DVT accepts image and video files in standard formats (JPEG, PNG, MP4) and outputs structured data in CSV, JSON, and NumPy array formats. The toolkit can process outputs from standard digitization workflows common in cultural heritage institutions. Data annotations produced by DVT can be integrated into other analysis tools. For interoperability with Python-based data science stacks, the toolkit follows standard conventions for numerical computing using NumPy and Pandas. Visualization outputs can be customized to work with various plotting libraries. The current version maintains backward compatibility with data produced by previous versions.",The Distant Viewing Toolkit offers several notable strengths: its interdisciplinary design effectively bridges computer vision technology with humanities research methodologies; the dual interface structure balances accessibility for non-technical users with advanced capabilities for experienced programmers; its modular architecture allows for flexible analysis workflows adaptable to diverse research questions; the software is built on a strong theoretical foundation grounded in both humanities and computer science; and it provides educational resources that lower the barrier to entry for non-technical researchers interested in computational analysis of visual materials. The implementation clearly acknowledges the interpretive nature of 'seeing' visual materials computationally.,"The toolkit faces several limitations: it has a relatively limited community size compared to general-purpose computer vision tools, which may slow bug fixes and feature development; the Python dependency requires at least some programming knowledge, potentially limiting adoption by purely humanities-focused researchers; its domain specificity limits broader application beyond humanities research; documentation gaps have been reported by some users in GitHub issues; and the toolkit shows a moderate development pace with infrequent major updates. The current version requires manual tuning of parameters for optimal results across different types of visual materials.","The long-term viability of the Distant Viewing Toolkit appears strong despite its specialized nature. Several factors support its sustainability: ongoing institutional support from the University of Richmond; continued funding through multiple grants including the substantial NEH Level III Digital Advancement Grant ($325,000) through 2025; regular maintenance with commits as recent as April 2025; a solid theoretical foundation codified in the developers' 2023 MIT Press book; and integration into significant research projects demonstrating its value. The open-source license (GPL-2.0) ensures the code remains accessible even if active development were to slow. The project's focus on accessibility and documentation suggests the developers are invested in growing the user community. While the development team is small, they have maintained the project for over seven years, indicating sustained commitment.","VIAN (Visual Film Annotation Tool): Specialized for film color analysis with sophisticated visualization tools; more focused on film studies with emphasis on color aesthetics, while DVT offers broader capabilities across visual media types. ImagePlot: Developed by Lev Manovich's Software Studies Initiative; focuses on visualizing large image collections as scatterplots; more focused on visualization than extraction of semantic content. OpenCV: Comprehensive open-source computer vision library; much more technical, requiring programming expertise, but more flexible and powerful. ELAN: Specialized for detailed manual annotation of audiovisual materials; focused on manual rather than automated analysis. Cinemetrics: Focused on quantitative analysis of films, particularly shot lengths; more narrowly focused on specific formal elements in film.",
dplR,Success,,"dplR (Dendrochronology Program Library in R) is a specialised statistical package for analysing tree-ring data. It facilitates precise dating of wooden archaeological materials and reconstruction of past climate conditions through tree-ring pattern analysis. The current version (1.7.8) provides comprehensive functions for data import/export, growth trend removal (detrending), chronology building, statistical crossdating, and time series analysis. Though originally developed for ecological research, it has become essential in archaeological dendrochronology for absolute dating of wooden artifacts, buildings, and settlements—including groundbreaking work identifying cosmic ray events in ancient timbers to establish precise calendar dates for archaeological sites like the Dispilio Neolithic Settlement in Greece.","dplR was created by Andrew G. Bunn at Western Washington University in 2007-2008, with the initial version published in a 2008 paper in the journal Dendrochronologia. The software evolved through incremental updates over 16+ years from version 1.0 to the current 1.7.8. Around 2021, the project transitioned from Bunn's personal GitHub repository to the OpenDendro organisation, which now serves as its development hub. Major contributors beyond Bunn include Mikko Korpela, Franco Biondi, Filipe Campelo, Pierre Mérian, Fares Qeadan, and Christian Zang. The project received institutional support from Western Washington University and National Science Foundation grants (ARC-0612346 and ATM-0172972).","dplR is primarily implemented in R (92.7%) with performance-critical components in C (6.1%) and Fortran (1.2%) for computational efficiency. This hybrid architecture leverages R's statistical flexibility while using compiled languages for intensive operations. The package uses S3 classes for its core data structures (rwl, rwi, crn) with consistent parameter naming conventions and sensible defaults. Dependencies include common R packages (graphics, grDevices, grid, stats, utils) plus specialised packages (lattice, Matrix, digest, matrixStats, png, R.utils, stringi, stringr, XML, signal, boot). The software is distributed via CRAN (stable), R-universe (development), and GitHub (source). The package implements multiple standardization algorithms including modified negative exponential curves, cubic smoothing splines, age-dependent splines, Regional Curve Standardization, and C-Method Standardization. Chronology building capabilities include Tukey's biweight robust mean, residual chronologies, ARSTAN-style chronologies, and variance-stabilized chronologies with bootstrapped confidence intervals. For dendroarchaeological applications, the package's crossdating functions are particularly important, enabling precise dating through statistical correlation of unknown samples with established reference chronologies.",2025-05-06,yes,"dplR qualifies as research software based on all Essential Criteria and multiple Supporting Criteria. Essential: (1) It directly supports scholarly inquiry in dendrochronology and archaeological dating; (2) It transforms tree-ring measurement data through statistical analysis, detrending, and chronology building; (3) It implements methodologies recognized in dendrochronology research. Supporting: (1) It integrates domain-specific terminology and classifications for tree-ring science; (2) It supports multiple research stages from data processing to analysis and interpretation; (3) It offers analytical capabilities through statistical crossdating and time series analysis functions; (4) It provides visualization tools for ring-width data and chronologies; (5) It facilitates data transformation between various dendrochronological formats; (6) Its documentation specifically addresses research applications in dendrochronology and archaeology.",https://github.com/OpenDendro/dplR,https://cran.r-project.org/package=dplR,https://opendendro.org/r/,https://opendendro.org/r/,GPL-2+,"Chronological modelling|Radiocarbon dating, calibration and sequencing",dendrochronology|tree-ring analysis|archaeological dating|climate reconstruction|time series analysis,2008,2023-05-19,1.7.8,Active,OpenDendro initiative (institutional structure) with historical support from Western Washington University and National Science Foundation grants,"Andrew G. Bunn (lead), Mikko Korpela, Franco Biondi, Filipe Campelo, Pierre Mérian, Fares Qeadan, Christian Zang",Small (2-5),Ecology,General-purpose,Excellent,"The original dplR paper has over 2,000 citations according to Google Scholar, demonstrating significant academic impact. The package is downloaded approximately 4,700 times monthly from CRAN (likely an undercount as it excludes installations via dependencies). It serves as a dependency for at least nine other R packages focused on dendrochronology and related fields. Community engagement occurs primarily through GitHub rather than dedicated forums.",Analysis|Interpretation,research-specific,Packages and libraries,R|C|Fortran,Windows|macOS|Linux,R,"dplR supports standard dendrochronology file formats including Tucson/decadal format, compact format, and the Tree Ring Data Standard (TRiDaS). It outputs results in various formats for publication and further analysis. The current version handles common dendrochronological data structures and can integrate with other statistical tools in the R environment. It interoperates with measuRing (for measuring tree rings from images) and other OpenDendro tools as part of a broader ecosystem. The package can read legacy Tucson format files used by traditional COFECHA/ARSTAN programs, facilitating transition from older software.","dplR's key strengths include: (1) Open-source nature allowing modification and extension for specific research needs; (2) Integration with R's powerful statistical environment, enabling advanced analyses beyond dendrochronology; (3) Publication-quality plotting capabilities for research communication; (4) Cross-platform compatibility across all major operating systems; (5) Comprehensive replication of functionality from established commercial programs; (6) Extensive documentation including dedicated 'Learning to Love dplR' guide; (7) Institutional backing through the OpenDendro initiative, promising continued maintenance; (8) Specific functions for absolute dating critical in archaeological applications, including ability to identify cosmic ray events as temporal markers.","The primary limitations include: (1) Steep learning curve associated with R programming, making it less accessible than GUI-based alternatives for users without coding experience; (2) Infrequent CRAN releases (though mitigated by development versions available through r-universe); (3) Installation complexity for users building from source, particularly with C and Fortran dependencies; (4) Lack of dedicated user forum, with support primarily through GitHub issues; (5) Less intuitive workflow than GUI-based alternatives like CDendro or WinDENDRO; (6) Limited automated ring detection compared to commercial tools like WinDENDRO, requiring more manual measurement preprocessing; (7) Requires separate tools for initial measurement of tree rings from images.","dplR shows strong long-term viability based on several factors: (1) Transfer to the OpenDendro organization provides institutional structure beyond individual developers; (2) Continued citations in recent literature indicate ongoing use and relevance; (3) Integration with a broader ecosystem of R packages creates network effects; (4) Stable foundation in the R environment, which itself has strong institutional support; (5) Strategic planning evident in the OpenDendro initiative, including Python implementations of similar functionality (dplPy) for future-proofing; (6) Active development with recent updates and bug fixes; (7) Relatively modest resource requirements for maintenance. While the specialized nature of dendrochronology and reliance on R programming skills present challenges, the package's academic impact, institutional support, and continued maintenance suggest sustained viability.","Primary alternatives include: (1) COFECHA/ARSTAN: Traditional command-line FORTRAN programs; industry standards but less user-friendly; (2) CDendro/CooRecorder: Commercial software (~$68) with user-friendly interface for measuring rings from digital images; (3) WinDENDRO: Comprehensive commercial system with advanced image analysis and automatic ring detection, more expensive than other options; (4) TSAP-Win: Commercial time series analysis software popular in European labs; (5) PAST4: Graphical commercial package with fast statistical tests; (6) Tellervo: Open-source database-enabled software for collecting and managing dendrochronological data; (7) MeasuRing: R package for measuring tree-ring widths from images, complementary to dplR; (8) dplPy: Python implementation of similar functionality as part of the OpenDendro initiative. dplR stands out for its extensive statistical capabilities and integration with the R environment, while commercial alternatives offer more user-friendly interfaces.",
Endovélico,Success,,"Endovélico is Portugal's official archaeological information system that serves as the national inventory and management platform for archaeological sites and fieldwork authorisation. The system, named after a pre-Roman deity worshipped in ancient Lusitania, maintains approximately 26,000 archaeological sites with standardised vocabularies and georeferenced mapping. It provides three-tiered access levels: general public (basic site information), heritage professionals (detailed information requiring registration), and qualified archaeological directors (complete access with submission capabilities). While primarily designed as an administrative tool for cultural heritage management, Endovélico has evolved to support research by providing access to archaeological records, technical documentation, and project details.","Endovélico began as handwritten inventory cards in the 1980s known as 'Carta Arqueológica' (Archaeological Map). Digital development started in 1989 using MS-DOS and Dbase database software, transitioning to Apple Macintosh systems with Filemaker in 1990. The formal Endovélico system was established in 1995 as a relational database with GIS capabilities. Online availability began in 1998, with georeferenced distribution of archaeological sites added in 2012. The system was originally developed by the Instituto Português de Arqueologia (IPA) through its Inventory Division, later transferred to the Instituto de Gestão do Património Arquitectónico e Arqueológico (IGESPAR), then to the Direção-Geral do Património Cultural (DGPC), and as of January 2024, to the newly created Património Cultural, I.P. as part of governmental restructuring.","The Endovélico system has evolved significantly since its inception. Originally based on Dbase (1989) and Filemaker (1990), the current implementation likely employs Oracle Database for backend storage, though specific technical details aren't explicitly documented in public sources. The system operates as a web-based platform accessed through the Portal do Arqueólogo, with server infrastructure maintained by Património Cultural, I.P. The database maintains relational tables for archaeological sites, technical documentation, permits, and project information, all accessible through a tiered-access web interface. Core technical components include: 1) A centralised database with standardised fields and controlled vocabularies for archaeological site characterisation; 2) GIS integration since 1995, supporting spatial querying and mapping via Web Map Service (WMS); 3) Document management capabilities for storing reports and technical documentation; 4) Authentication and authorisation system managing the three-tiered access model; 5) Integration with Matriz 3.0 for archaeological artefact inventory; and 6) Alignment with ISO 14721:2003 Open Archival Information System standard for digital preservation. The system handles spatial data for georeferencing, digital documents, multimedia content, and structured database information with standardised vocabularies. Unlike traditional software with version numbering, Endovélico undergoes continuous daily updates as new archaeological information is processed, with major enhancements implemented through projects like ARQUEOSIA (Modernization of Digital Archaeological Services).",2025-05-06,maybe,"Endovélico meets the core definition of research software only partially. While it fully satisfies research data engagement by providing access to archaeological site information and documentation, its primary purpose was administrative rather than research-focused. It partially satisfies methodological alignment by following established archaeological documentation practices. For supporting criteria, it fully satisfies domain knowledge integration (using standardised archaeological vocabularies), documentation focus (providing detailed archaeological site records), and data dissemination (making archaeological information publicly accessible). It partially meets research lifecycle support, mainly serving preservation and publication stages. It has minimal analytical capabilities and data transformation functions. As primarily an inventory and management system rather than analytical research software, it occupies a borderline position.",,,https://arqueologia.patrimoniocultural.pt/,https://arqueologia.patrimoniocultural.pt/,Government System with Restricted Use,Data management,archaeological database|cultural heritage|inventory system|geospatial integration|Portuguese archaeology,1989,2024-01-01,Continuous updates (no version numbers),Active,"Património Cultural, I.P. (formerly DGPC)","Originally developed by the Inventory Division of the Instituto Português de Arqueologia, with later contributions from various institutional teams. Key individuals include Filipa Bragança.",Small (2-5),Archaeology,Project-specific,Comprehensive,"The system contains approximately 26,000 archaeological sites and is used by all professional archaeologists working in Portugal for both administrative requirements and research purposes. It processes all archaeological work permits in mainland Portugal and serves as the central repository for Portuguese archaeological information. The Portal do Arqueólogo (public interface) receives regular use from researchers, heritage professionals, and the general public, though specific usage metrics aren't publicly documented.",Preservation and Reuse|Publication,mass-market,Stand-alone software,Likely SQL-based with web interface,Web-based (browser),,"Endovélico handles various data formats including spatial data for georeferenced mapping, digital documents and reports, multimedia content (images and photographs), and structured database information with standardised vocabularies. It supports GIS integration through Web Map Service (WMS), integrates with Matriz 3.0 for archaeological artefact inventory, aligns with the ISO 14721:2003 Open Archival Information System standard for digital preservation, and provides both keyword-based and geographical search capabilities.","The system's major strengths include: 1) Centralised management of all Portuguese archaeological activity through a single unified platform; 2) Comprehensive national coverage with approximately 26,000 archaeological sites catalogued; 3) Early adoption of GIS capabilities (since 1995) for spatial representation of archaeological sites; 4) Use of controlled vocabularies for data standardisation and consistency; 5) Tiered public accessibility through the Portal do Arqueólogo, balancing openness with site protection; 6) Strong institutional backing ensuring continuous maintenance and updates; 7) Historical significance as one of Europe's early digital archaeological information systems.","Notable weaknesses include: 1) Spatial and typological consistency issues identified by Portuguese archaeologists, with survey concentration near university centres creating geographical biases; 2) Data verification challenges, particularly for underwater archaeology entries; 3) Functions primarily as an inventory rather than a true data repository with limited capabilities for accessing actual datasets; 4) Five-year embargo period on excavation reports delays information access; 5) Limited analytical functions compared to dedicated research software; 6) Administrative focus sometimes prioritises governance over research accessibility; 7) Possible technological constraints from legacy database architecture.","Endovélico benefits from strong governmental support and institutional mandate as Portugal's official archaeological information system, ensuring long-term sustainability. The recent organisational transformation from DGPC to Património Cultural, I.P. in January 2024 introduces some uncertainty but suggests continued commitment to the system. As a foundation of Portuguese archaeological practice with established workflows and user community, discontinuation is unlikely. However, challenges include keeping pace with technological advances, maintaining data quality and completeness, securing adequate resources for maintenance and development, and addressing the spatial biases in coverage. The system's evolution from paper records to digital database demonstrates adaptability, but significant modernisation may be required to fully transition from an inventory to a comprehensive research platform.","The Archaeology Data Service (UK) and tDAR (Digital Archaeological Record, US) function more as comprehensive data repositories rather than national inventories, offering greater analytical capabilities and direct data access. The European ARIADNE project offers cross-border data interoperability using the CIDOC Conceptual Reference Model. The Nautical Archaeology Digital Library addresses verification issues in underwater heritage documentation. Portugal-specific alternatives are limited as Endovélico is the mandated national system, though some regional or thematic databases exist for specialised research purposes.","FOLLOWED: Claude Tool-status=maybe (borderline admin), user confirmed TOOL (admin tools can be repurposed)"
FaceNet,Failure,Need more info,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
FAIMS,Success,,"FAIMS (Field Acquired Information Management Systems) is an open-source platform for collecting digital field data in offline environments. The current version, rebranded as Fieldmark in 2023, offers cross-platform support for Android, iOS, and desktop systems. Fieldmark enables researchers to create customised data collection workflows with comprehensive recording capabilities including structured data, free text, geospatial information, and multimedia. The system provides robust offline functionality with multi-user synchronisation and version tracking, essential for remote fieldwork locations without internet connectivity. Fieldmark supports rigorous data collection through controlled vocabularies, data validation, and complete provenance tracking. Since its inception, FAIMS has evolved from an Android-only application to the current cross-platform system with implementations across archaeological projects worldwide.","FAIMS began in 2012 when Australian archaeologists, led by Shawn Ross and Adela Sobotkova, secured National eResearch Collaboration Tools and Resources (NeCTAR) funding to create specialised field data collection software. The initial version was released in 2014 as an Android-only application focused on offline functionality. After relocating to Macquarie University in 2015, the project received substantial funding through an Australian Research Council Linkage Infrastructure Equipment and Facilities (LIEF) grant valued at AUD $945,000 and a NSW Research Attraction and Acceleration Program (RAAP) grant. FAIMS 2.x followed, enhancing the original functionality. A significant transformation occurred in 2020-2022 with Australian Research Data Commons (ARDC) funding, resulting in FAIMS3, released in December 2022 and rebranded as Fieldmark™ in June 2023. This latest iteration features a cross-platform architecture supporting Android, iOS, and desktop systems. A commercial entity, Electronic Field Notebooks Pty Ltd, was established in 2023 to provide hosting services and ensure sustainability.","The current Fieldmark (formerly FAIMS3) platform employs a modern web technology stack based on TypeScript/JavaScript, React, and Capacitor with CouchDB for data management and synchronisation. This architecture enables true cross-platform functionality while maintaining the core offline capabilities essential for archaeological fieldwork. Early FAIMS versions (1.0 and 2.x) used a Java-based Android client with a Ruby server and SQLite in domain-key normal form (DKNF) for data storage. Across all versions, a defining feature is the append-only datastore that preserves the complete history of all records and changes, crucial for maintaining archaeological data provenance. In Fieldmark, every modification is tracked by timestamp and user, fundamental to archaeological record integrity. The system employs a modular architecture where data collection forms ('modules') can be customised for specific project needs. These modules define the UI, data validation rules, and relationships between different record types. Fieldmark's key technical capabilities include comprehensive data collection support (structured data, free text, geospatial information, multimedia), lightweight GIS functionality for field mapping, multi-user synchronisation with conflict resolution, external sensor integration, and customisable export in various formats.",2025-05-04,yes,"FAIMS clearly qualifies as research software based on all essential criteria and multiple supporting criteria. It has a specific research purpose (archaeological fieldwork data collection), directly engages with research data (capturing, validating, and managing field observations), and aligns with archaeological methodologies. It incorporates domain knowledge through customisable modules with archaeological terminology and classifications, supports multiple research lifecycle stages (planning, data acquisition, processing), enables data transformation through validation and export capabilities, provides analytical capabilities through spatial data handling, and offers visualisation functions for mapping. The academic literature consistently recognises FAIMS as a significant contribution to digital archaeological methods, with multiple peer-reviewed publications analysing its implementation and impact.",https://github.com/FAIMS,,,https://faims.edu.au/,Apache License 2.0,Data collection|Spatial analysis|Site mapping|Data management,archaeological-data-collection|offline-fieldwork-tool|digital-archaeology-platform|structured-recording-system|field-research-software,2014,2023-06-01,Fieldmark (formerly FAIMS3),Active,Macquarie University|Electronic Field Notebooks Pty Ltd,Shawn Ross|Adela Sobotkova|Penny Crook|Brian Ballsun-Stanton,Medium (6-20),Archaeology,General-purpose,Comprehensive,"FAIMS has been implemented in over 40 archaeological projects worldwide with nearly 70 distinct research workflows. Notable implementations include the Perachora Peninsula Archaeological Project (Greece), Willandra Lakes World Heritage Area survey (Australia), Malawi Earlier Middle Stone Age Project, Boncuklu Project (Turkey), and Proyecto Arqueológico Zaña Colonial (Peru). While precise download metrics are not publicly available, FAIMS has seen adoption across multiple continents and various archaeological subdisciplines. Its application extends beyond archaeology to other field sciences including ecology, geochemistry, and oral history. The project has generated multiple peer-reviewed publications and presentations at major archaeological computing conferences.",Planning|Data Acquisition|Processing|Analysis|Preservation and Reuse,research-specific,Stand-alone software,Java|Ruby|JavaScript|TypeScript|React,Android|iOS|Web,,"The current Fieldmark platform supports comprehensive data import/export capabilities with formats including CSV, shapefile, KML, GeoJSON, and SQLite databases. Fieldmark can integrate with external sensors and includes APIs for connecting with other systems. Export functions allow data to be transferred to GIS software (QGIS, ArcGIS), statistical packages, and other analysis tools. The modular architecture enables customisation for different data models and recording systems, supporting interoperability with existing archaeological recording methodologies and data standards. Previous FAIMS versions offered similar capabilities but with more limited platform compatibility and synchronisation options.","Fieldmark (the current FAIMS version) offers several significant advantages for archaeological fieldwork: (1) Cross-platform support (Android, iOS, desktop) with unmatched offline functionality allows complete operation in remote locations without internet connectivity; (2) Data integrity through versioning ensures no information is ever lost or overwritten, with all changes tracked by user and timestamp—critical for maintaining archaeological record integrity; (3) Extensive customisability allows adaptation to specific methodological approaches, reflecting the diversity of archaeological recording systems; (4) Built-in data quality controls including controlled vocabularies, validation rules, and certainty indicators help ensure consistent recording across field teams; (5) Immediate digital data availability eliminates post-excavation digitisation, allowing faster analysis and publication. Fieldmark implements FAIR data principles (Findable, Accessible, Interoperable, Reusable) from the moment of collection, a significant improvement over previous versions.","Despite its strengths, the current Fieldmark platform faces several adoption challenges: (1) Technical complexity requires significant setup time and expertise. Creating customised modules often demands programming knowledge or direct support from the development team; (2) Resource requirements for hardware, technical expertise, and training can be prohibitive for smaller projects without substantial technical support; (3) Sociotechnical barriers exist around adoption, with many archaeologists finding it difficult to allocate time at the project start to save time later. Previous FAIMS versions had additional limitations that have been partially addressed in Fieldmark: the DKNF append-only datastore created performance issues with large datasets, and earlier versions were limited to Android devices. While the current version has improved cross-platform support and performance, these historical limitations continue to affect perception and adoption rates.","Fieldmark (current FAIMS version) demonstrates strong long-term viability through several factors: (1) Sustained institutional support from Macquarie University and consistent funding success across multiple national grant schemes; (2) The 2023 establishment of Electronic Field Notebooks Pty Ltd represents a significant step toward financial sustainability through a commercial service model; (3) The transition to modern web technologies makes the platform more accessible and maintainable than previous versions; (4) A dedicated core development team has maintained continuity throughout multiple project phases; (5) Strong integration with archaeological research workflows and documented efficiency improvements create ongoing demand; (6) The open-source nature ensures code availability even if institutional support changes. The major risk factors include continued reliance on grant funding cycles and the technical complexity that may limit adoption without dedicated support. Overall, Fieldmark has built upon the decade-long resilience of the FAIMS project while addressing several previous limitations.","Several alternatives to Fieldmark (current FAIMS version) exist in the archaeological digital recording ecosystem: (1) KoboToolbox offers simpler setup and a more user-friendly interface but provides less specialised archaeological functionality and weaker offline synchronisation capabilities compared to Fieldmark; (2) Arches excels at heritage inventory management with strong geospatial capabilities and built-in cultural heritage ontologies but focuses less on field data collection; (3) QFIELD integrates directly with QGIS for stronger spatial data handling but offers less structured data collection for archaeological contexts; (4) ODK (Open Data Kit) provides a flexible framework for mobile data collection but requires significant customisation for archaeological use and lacks the built-in archaeological features of Fieldmark; (5) Paper-based methods with digital post-processing remain common, accepting the inefficiencies of later digitisation to avoid technical complexity and hardware dependence. The optimal choice depends on project-specific factors including technical capabilities, recording methodology, team size, funding, and fieldwork location.",
FellingDater,Success,,"FellingDater is specialized dendrochronological software designed for determining precise felling dates of trees used in historic structures. Developed at the University of Sheffield's Laboratory for Tree-Ring Research, it enables archaeologists and architectural historians to analyse tree-ring patterns in structural timbers to establish construction chronologies for historical buildings. The software compares measured ring-width sequences from archaeological samples against reference chronologies to identify matching patterns, providing crucial dating evidence for structures where documentary records may be absent or unreliable.","FellingDater was developed in the late 1990s to early 2000s by Dr. Ian Tyers at the University of Sheffield's Laboratory for Tree-Ring Research. The tool emerged from ongoing dendrochronological research programmes focused on historic buildings in the UK. It has undergone limited version updates, with version 2.0 appearing to be the most recent significant release (circa 2012-2013). Development has been primarily academic rather than commercial, with distribution occurring through institutional channels and professional networks within the archaeological and heritage conservation communities. The software has maintained its core functionality while experiencing minimal recent updates.","FellingDater is written in Microsoft Visual Basic 6.0, making it a Windows-only desktop application that requires the Microsoft .NET Framework. The software employs a statistical analysis architecture that processes ring-width measurements from archaeological timbers and compares them against reference chronologies. The core functionality relies on cross-dating techniques to identify matching patterns between sample sequences and known reference data. FellingDater uses specialized statistical methods including t-values and correlation coefficients to evaluate match strength. The system stores data in proprietary file formats optimized for dendrochronological information, though it can import measurement data from formatted text files. The software features a graphical user interface specifically designed for dendrochronologists, with visualization capabilities for tree-ring sequences and comparison graphs. Technical requirements are modest, requiring only a basic Windows PC with standard specifications. The current version (2.0) maintains the original architecture with limited updates to core algorithms or interface design since its last significant release.",2025-05-06,yes,"FellingDater clearly meets the core definition of research software as it directly supports scholarly inquiry through specialized data analysis. It satisfies all essential criteria: it has a research-specific purpose (analyzing tree rings for archaeological dating), meaningfully transforms research materials (converts tree-ring measurements into chronological data), and aligns with established methodological approaches in dendrochronology. It also meets multiple supporting criteria: it incorporates domain knowledge (dendrochronological principles), supports the analysis phase of research, performs specialized calculations, provides visualization functions, and includes documentation focused on research applications. The software was explicitly designed to address research needs in archaeology and architectural history.",,,https://www.sheffield.ac.uk/archaeology/research/dendrochronology,https://www.sheffield.ac.uk/archaeology/research/dendrochronology,GPL-2,Dendrochronology|Chronological modelling|Data analysis,tree-ring analysis|archaeological dating|historical structures|felling date estimation|architectural history,2000,2013,2,Maintenance-only,University of Sheffield,Dr. Ian Tyers,Solo,Archaeology,Project-specific,Basic,"FellingDater has a relatively limited but specialized user base primarily within UK archaeology and heritage management circles. The software is frequently cited in archaeological and architectural history publications, particularly in journals like Dendrochronologia, The Archaeological Journal, and Vernacular Architecture. Usage appears to be concentrated in institutional settings, particularly among dendrochronologists working with historic buildings and structures. While exact metrics are not publicly available, the software has been instrumental in numerous heritage projects throughout the UK and parts of Europe. User adoption has remained stable but has not shown significant growth in recent years, likely due to limited marketing and the emergence of newer alternatives.",Analysis,research-specific,Stand-alone software,Visual Basic 6.0,Windows,,"FellingDater accepts input of numerical measurement data representing annual growth rings and can import from formatted text files. Output includes statistical match indicators, probability assessments, and estimated felling date ranges. The software uses proprietary file formats for data storage, limiting interoperability with other tools. Users typically need to convert data to specific formats before import, and exporting results for use in other applications may require manual processing. The software has limited integration with broader research workflows, functioning primarily as a specialized analytical endpoint rather than as part of an interconnected toolchain.","FellingDater's primary strength lies in its specialized focus on archaeological dendrochronology, offering purpose-built features that general statistical packages lack. For dendrochronologists working on historic structures, the software provides a tailored workflow that simplifies the dating process. The tool effectively addresses a critical need in historical building analysis by converting biological data (tree rings) into precise construction dates. Users report reliable performance for its intended purpose and appreciate its integration with established dendrochronological methods. The software's specificity allows it to offer functionality not readily available in more general-purpose tools, particularly for analyzing building timbers. The relatively simple interface allows specialists to focus on interpretation rather than software complexity.","FellingDater shows significant limitations compared to modern research tools. Its Windows-only architecture restricts use in cross-platform environments, and its aging codebase faces potential compatibility issues with newer operating systems. The software's development appears to have slowed, with minimal updates in recent years, raising concerns about future compatibility and feature enhancements. Documentation is primarily academic rather than user-oriented, with limited publicly accessible user guides or tutorials. User support relies on direct communication within academic networks rather than formal channels. The proprietary data formats limit interoperability with other research tools, potentially isolating analyses within the FellingDater ecosystem. The specialized nature of the software limits its broader adoption beyond dedicated dendrochronology specialists.","FellingDater faces challenges for long-term viability due to its aging codebase, limited development activity, and Windows-only architecture. The apparent lack of recent updates suggests minimal ongoing maintenance, which may lead to compatibility issues as operating systems evolve. However, the software's specialized nature and continued use in heritage studies indicate it still fulfills a valuable niche role. The institutional backing of the University of Sheffield provides some stability, though the level of commitment to future development remains unclear. For established dendrochronology labs already using the software, it likely remains viable in the medium term. For new research projects, the software's sustainability risks should be weighed against its specialized capabilities. Alternative tools may offer better long-term viability but potentially lack FellingDater's specific focus on archaeological timber dating.","PAST (Paleontological Statistics) offers more general statistical analysis for paleontological data including some dendrochronology functions, with broader platform support. TRiCYCLE provides similar tree-ring analysis capabilities with a more modern codebase and better cross-platform compatibility. R-based dendrochronology packages like 'dplR' offer more flexible and extensible analysis options within the R statistical environment, benefiting from active open-source development but requiring more general statistical knowledge. COFECHA is widely used for quality control in dendrochronology with good support for cross-dating functions. Dendro for R specifically focuses on tree-ring analysis within the R environment, offering greater integration with other analysis tools but requiring R programming knowledge. CDendro and CooRecorder offer complementary measurement and analysis functions with more regular updates.",
FieldWorker,Success,,"FieldWorker was a mobile data collection tool for the Apple Newton MessagePad that allowed researchers to record field observations with integrated GPS functionality. While not exclusively designed for archaeology, it provided archaeologists with the capability to create custom forms for recording different types of archaeological data in the field, automatically capturing precise GPS coordinates, and later exporting this data to GIS platforms. The software came in three versions with increasing functionality: Basic ($149), Advanced ($599), and Pro (price unspecified). It represented one of archaeology's earliest attempts at digital field recording in the mid-1990s.","FieldWorker was developed by FieldWorker Products Ltd of Toronto and released around 1995 specifically for the Apple Newton MessagePad platform. The software evolved through several versions, with the most thoroughly documented being Advanced (version 2.3.5) and Pro (version 0.91), which were reviewed in Internet Archaeology in 1997. The Pro version was still in pre-release when reviewed. FieldWorker's development effectively ended when Apple discontinued the Newton platform in 1998, making the software obsolete as it was tied exclusively to this hardware. No evidence suggests it was later ported to other platforms, and the company appears to have evolved into a different entity focused on modern mobile data collection but disconnected from archaeological applications.","FieldWorker was built specifically for the Apple Newton platform using NewtonScript and the Newton Toolkit (NTK), which fundamentally limited its longevity and portability. The software implemented a project-based data structure with user-definable screens and fields for customizable data collection. Key technical features included direct integration with GPS receivers via the NMEA 0183 protocol, data synchronization between the Newton device and desktop computers, and export capabilities to various GIS formats including MapInfo and ArcView. The architecture allowed customization of data entry forms with specialized field types appropriate for archaeological recording. Hardware requirements were substantial for the era, requiring an Apple Newton MessagePad (models 120, 130, or 2000), Newton OS 2.0 or later, a compatible GPS receiver supporting NMEA 0183, and optionally a differential beacon receiver for improved GPS accuracy. The Pro version pushed hardware limits, with reviewers recommending the MessagePad 2000 with its 160MHz StrongARM processor. Performance issues were noted in the 1997 review, with operations described as 'treacle' on the MessagePad 130. The software's architecture was inextricably tied to Apple's PDA ecosystem, which proved fatal when Apple discontinued the Newton line in 1998.",2025-05-07,yes,"FieldWorker meets all essential criteria for research software: it was designed for a research-specific purpose (field data collection), engaged meaningfully with research data (recording observations with GPS coordinates), and aligned with recognized methodologies (archaeological field recording and GIS integration). It also satisfies multiple supporting criteria: it incorporated domain knowledge through customizable forms, supported the data collection stage of the research lifecycle, transformed data between field notes and GIS formats, and facilitated visualization through mapping capabilities.",,,https://intarch.ac.uk/journal/issue3/reviews/ryan.html,https://intarch.ac.uk/journal/issue3/reviews/ryan.html,Proprietary,Data collection|Spatial analysis|Data management,mobile-data-collection|archaeological-recording|gps-integration|newton-platform|historical-technology,1995,1998,Pro 0.91 (1997),Abandoned,FieldWorker Products Ltd (Toronto),Unknown,Small (2-5),Commercial mobile computing,General-purpose,Basic,"FieldWorker had limited adoption in archaeology based on available literature. The most comprehensive assessment comes from a 1997 review in Internet Archaeology by Ryan, Pascoe, and Morse. Beyond this review, minimal evidence exists of widespread archaeological use or publications resulting from projects using the software. The prohibitive cost (software: $149-$599, plus hardware: $600-1000 for the Newton MessagePad, $300-15,000 for GPS equipment) likely limited adoption to well-funded projects or institutional early adopters. No citation metrics, download statistics, or community forums exist for this historical software product.",Data Acquisition,research-specific,Stand-alone software,NewtonScript,Apple Newton MessagePad,,FieldWorker could export data to several GIS formats including MapInfo and ArcView. It supported direct integration with GPS receivers using the NMEA 0183 protocol and could synchronize recorded data between the Newton device and desktop computers. The Pro version offered enhanced data structure options compared to the Basic and Advanced versions.,"FieldWorker's strengths included: 1) Pioneering integration of GPS data with field notes in a single mobile device, enabling spatial recording of archaeological features. 2) Customizable forms that could be adapted for different types of archaeological recording needs. 3) Multiple data export formats compatible with then-current GIS software like MapInfo and ArcView. 4) A responsive development company that provided regular updates based on user feedback. 5) The capacity to record data digitally in the field, reducing post-fieldwork data entry errors and time.","FieldWorker suffered from several significant weaknesses: 1) Prohibitive cost that limited adoption primarily to well-funded projects (total investment including hardware could exceed $2000 in 1995). 2) Significant performance limitations on available hardware, with reviews describing operation as 'treacle' on the MessagePad 130. 3) Complete dependency on the Apple Newton platform, which was discontinued in 1998, effectively ending the software's viability. 4) Limited archaeological-specific functionality compared to modern purpose-built alternatives. 5) Inadequate documentation and support for archaeological workflows. 6) Challenging synchronization processes and data export procedures that required technical expertise.","FieldWorker had essentially zero long-term survivability due to its complete dependency on the Apple Newton platform, which Apple discontinued in 1998. The software was never ported to other platforms, and the proprietary nature of both the software and the Newton operating system made preservation nearly impossible. The company appears to have evolved into a different entity focused on modern mobile data collection but disconnected from archaeological applications. Today, FieldWorker exists primarily as a historical footnote in the evolution of digital archaeological methods rather than as functioning software. No repositories, archives, or emulation environments are known to preserve it in working condition.","Modern alternatives that have completely supplanted FieldWorker include: 1) FAIMS/Fieldmark: Developed at Macquarie University specifically for archaeological fieldwork with offline capabilities and support for structured, free-text, geospatial, and multimedia data on Android devices. 2) Arches: An open-source heritage management platform with robust GIS integration, developed by the Getty Conservation Institute and World Monuments Fund. 3) ARK (Archaeological Recording Kit): A web-based toolkit developed by L-P Archaeology, adaptable to different recording systems with standards compliance. 4) STRATUM: A newer mobile platform designed 'by archaeologists for archaeologists' with mapping, drawing, and form-filling capabilities. 5) iDig: Developed at the Athenian Agora Excavations for archaeological excavation, with wireless connection to Leica Total Stations and synchronization across multiple iPads.",
FilmColors (VIAN),Success,,"VIAN (Visual Video Annotation and Analysis) is a software tool developed at the University of Zurich for analysing and visualising color in historical films. The current version enables researchers to segment films temporally, create and manage screenshots, perform deep learning-based segmentation for analyzing specific image regions, and generate sophisticated visualisations of color patterns. While primarily designed for film studies, its capabilities for material documentation, color analysis, and temporal visualization offer potential applications for archaeological and historical research, particularly for analysing colored artifacts and visual materials.","FilmColors emerged from research initiated by Professor Barbara Flueckiger at Harvard University in 2011-2013, leading to the 'Timeline of Historical Film Colors' web resource in 2012. The VIAN software development began in 2017 through collaboration between the Department of Film Studies and the Visualization and MultiMedia Lab at the University of Zurich, funded by the Swiss National Science Foundation and a €2.3 million European Research Council Advanced Grant (2015-2020). The core tool was created by developer Gaudenz Halter with early components by Noyan Evirgen. Since its initial release, VIAN has undergone continuous development, with version 0.9.8 released in 2023. Recent developments include VIAN Light, a simplified version aimed at broader educational use, and the VIAN WebApp for collaborative research containing over 550 film analyses.","VIAN is implemented in Python with PyQt for the graphical user interface, creating a modular architecture that prioritises flexibility for researchers. The system integrates several key technical components: a core annotation system for temporal segmentation, a screenshot management system, deep learning algorithms for object recognition and foreground-background separation, visualization modules for color pattern analysis, and database management for large-scale research. A distinguishing technical feature is its sophisticated color analysis using perceptually uniform color spaces (specifically CIE L*a*b*), enabling meaningful representation of color distribution in films. The software supports multiple platforms (Windows, macOS, Linux) but requires specific technical configurations using the Anaconda Python distribution. Installation complexity represents one of the tool's technical limitations, particularly for macOS users with M1 chips who must run the software directly from source rather than using pre-built packages. VIAN's computational approach distinguishes it from conventional humanities tools through its integration of advanced computer vision techniques like deep learning-based segmentation, which allows automated identification of characters and objects in film frames - capabilities that could potentially be adapted for archaeological image analysis despite not being designed for this purpose originally.",2025-05-07,yes,"VIAN qualifies as research software as it satisfies all essential criteria: it has a research-specific purpose for analyzing visual media, engages directly with research materials (films) through transformation and analysis, and aligns with methodologies in film studies and digital humanities. For supporting criteria, it integrates domain knowledge (film color terminology and classifications), supports the research lifecycle (from data collection to analysis and visualization), transforms data (between different color representations), provides sophisticated analytical capabilities (color pattern recognition and statistical analysis), offers multiple visualization functions (including temporal color development charts), and includes documentation focused on research applications. The tool's development within a European Research Council-funded project further affirms its research orientation.",https://github.com/FilmColors/VIAN,,https://www.vian.app/,https://www.vian.app/,GNU General Public License v3.0,3D modelling|Diagrams and visualizations|Cultural evolution,color analysis|film studies|deep learning|temporal visualization|digital humanities,2017,2023,0.9.8,Active,University of Zurich|Swiss National Science Foundation|European Research Council,Barbara Flueckiger|Gaudenz Halter|Noyan Evirgen|Renato Pajarola,Medium (6-20),Film Studies,Project-specific,Comprehensive,"VIAN has moderate adoption primarily within film studies. The GitHub repository shows limited metrics (approximately 50 stars and under 20 forks), indicating a specialized user base. However, the related VIAN WebApp contains over 550 film analyses performed by the research team, demonstrating substantial research output. The tool has been documented in several academic publications, including Computer Graphics Forum and Digital Humanities Quarterly. Its primary institutional adoption is at the University of Zurich film studies department, with limited evidence of widespread adoption beyond this context. The tool's specialized nature means it has not achieved mass-market usage but has established itself within its niche research community.",Analysis|Interpretation,research-specific,Stand-alone software,Python,Windows|macOS|Linux,,"VIAN supports various video formats for input and can export analysis results in multiple formats including CSV for data analysis, JSON for structured data exchange, and various image formats for visualisations. The software can also integrate with web platforms through the VIAN WebApp for collaborative research. While not specifically designed for archaeological data formats, its ability to process and analyze visual data makes it potentially applicable to digitized archaeological visual materials.","VIAN's comprehensive color analysis capabilities enable sophisticated examination of visual patterns in historical materials unmatched by many other tools. The software successfully bridges quantitative computational analysis with qualitative aesthetic interpretation, providing a model for integrating technical and humanistic approaches. Its visualization tools create intuitive representations of color developments and patterns that could reveal insights about historical materials. The modular design allows researchers to select specific analytical concepts according to their requirements, making it adaptable to different research questions. The connection to broader resources like the Timeline of Historical Film Colors creates a comprehensive ecosystem for color research.","The software has a steep learning curve that may challenge researchers without technical backgrounds, requiring significant investment to master. VIAN has specific technical requirements that can cause compatibility issues, particularly for newer hardware like Apple's M1 chips. Processing high-resolution video files is resource-intensive, requiring substantial computational power. The tool's development within film studies has limited its adoption in other fields like archaeology, despite potential applications. As acknowledged by the developers, 'it is a widespread misconception that digital tools generate meaningful results in an automated fashion' - the software requires significant human interpretation to produce meaningful results.","VIAN's long-term viability appears positive due to several factors. The project continues active development through 2025 with substantial institutional backing from the University of Zurich and previous European Research Council funding. The recent development of VIAN Light indicates a commitment to broadening accessibility and ensuring continued relevance. The open-source nature under GPL3 means the code remains available even if development were to cease. The ongoing expansion of the VIAN WebApp with a growing database of analyses demonstrates continued investment in the ecosystem. However, the relatively specialized nature of the tool and its dependence on a specific research team could pose sustainability challenges if institutional priorities change. The technical complexity may also limit widespread adoption outside specialized research contexts.","KALMUS: A Python package for computational film color analysis with a more technically-oriented approach than VIAN, focusing on quantitative analysis and movie barcodes as its primary visualization method. Cinemetrics: A web-based tool focused on film editing patterns rather than color analysis, with a database of over 15,000 films. Distant Viewing Toolkit (DVT): A Python package for computational analysis of visual culture using computer vision to analyze content and style, offering a broader scope than VIAN but less specific focus on color analysis. Commercial color grading software like DaVinci Resolve: These offer color analysis features as part of their color grading functionality but are designed for production rather than academic analysis.",
Fountain (VRML tool),Failure,Need more info,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Gephi,Success,,"Gephi is an open-source network visualization and analysis software that enables researchers to explore, analyse, and visualise complex relational data through an intuitive graphical interface. The current version (0.10.1) provides researchers with tools for visualising network structures, calculating metrics such as centrality and density, identifying communities, and applying various layout algorithms to reveal patterns in network data. In archaeology, it has been used to visualise ancient trade networks, settlement patterns, citation networks, and socio-political relationships. Previous versions offered 3D visualization capabilities which were removed in the 0.9.0 architectural overhaul.","Gephi originated in 2006 as a prototype called 'Graphiltre' created by Mathieu Jacomy for a French sociology research program. The first official release (0.6.0) launched in July 2008. In 2010, version 0.7 added support for dynamic networks. Between 2011-2013, versions 0.8.0-0.8.2 brought significant improvements to layout algorithms and Mac compatibility. A major architectural overhaul came with version 0.9.0 in December 2015, featuring a complete rewrite of the core architecture through the GraphStore project. Version 0.9.0 removed some features such as 3D visualization and hierarchical graph support but improved performance significantly. The development pace slowed after 2015, with version 0.10.0 released in January 2023, adding dark mode and improved search functionality. Leadership transitioned in 2017 when Eduardo Ramos Ibáñez took over as lead developer.","Gephi is built on Java and the NetBeans Platform, providing cross-platform compatibility. Its architecture uses a modular approach where different functionalities interact through well-defined APIs. The current version employs an optimized graph data structure (GraphStore) that makes operations significantly faster through cache-friendly collections. The visualization engine leverages OpenGL to render large networks in real-time, capable of displaying networks with up to a million elements while maintaining interactivity. The rendering pipeline uses programmable shaders for efficiency and higher quality visuals. Data processing in Gephi follows a workflow where imported network data (from formats like CSV, GraphML, GEXF) is stored in a graph model that separates topology from attributes, allowing for dynamic filtering based on node/edge properties. The Layout API enables algorithms to compute node positions using either force-directed approaches (ForceAtlas2), multi-level algorithms (OpenOrd), or dimensionality reduction techniques. Metrics are calculated through a Statistics API that computes centrality, clustering, and community detection. The Graph API provides methods for manipulating the network structure programmatically, while the Preview API controls the visual representation before export. The software experiences technical limitations with very large networks (>100,000 nodes) and is constrained by available memory. Version 0.9.0 reduced memory usage by up to 50% compared to previous versions and improved performance 2-100× for common operations, but the codebase has accumulated technical debt with Java moving away from UI development and the OpenGL library (JOGL) facing maintenance challenges.",2025-05-07,yes,"Gephi satisfies all essential criteria for research software tools. It has clear research-specific purpose (network analysis for academic research), direct engagement with research data (transforming relational data into meaningful visualizations), and methodological alignment (implements established network analysis methods). It also meets several supporting criteria: it incorporates domain knowledge through metrics like centrality and modularity; supports multiple stages of the research lifecycle from analysis to visualisation; provides data transformation capabilities through its import/export features; offers analytical calculations of network properties; provides sophisticated visualization capabilities; includes detailed documentation focused on research applications; and facilitates data dissemination through its export features.",https://github.com/gephi/gephi,,https://gephi.org/,https://gephi.org/,GNU General Public License v3.0,Network analysis|Diagrams and visualizations,Network visualization|Graph analysis|Force-directed layouts|Community detection|Interactive exploration,2008-07-31,2023-01-09,0.10.1,Active,"The Gephi Consortium, a French non-profit corporation established in 2010, formally supports the software's development. Members include SciencesPo (Paris), Linkfluence, WebAtlas, and Quid. The project also benefited from Google Summer of Code funding between 2009-2013.","Mathieu Bastian, Mathieu Jacomy, Sébastien Heymann, Eduardo Ramos Ibáñez",Medium (6-20),Information Visualization|Sociology,General-purpose,Comprehensive,"Gephi has achieved significant adoption in academic and research communities with 6,100+ GitHub stars, 1,600+ forks, and over 10,000 citations of the original Gephi paper. It has been mentioned in 39,000+ academic publications across various disciplines and reached one million+ downloads as of 2016, with users from 46 different countries. The user community is active on social media, forums, and Stack Overflow, where researchers share plugins, tutorials, and use cases. In archaeology specifically, Gephi is regularly cited in network analysis publications, demonstrating its wide adoption in the field.",Analysis|Interpretation|Publication,research-specific,Stand-alone software,Java,Windows|macOS|Linux,,"Gephi excels in interoperability, supporting numerous file formats including GEXF (Gephi's native format), GDF, GraphML, NET (Pajek), DOT, plus general formats like CSV and Excel. The current version can connect to databases through plugins and features a Graph Streaming API for real-time data integration. Import functionality includes support for adjacency matrices and edge lists through the Data Laboratory. Export options include PNG, SVG, and PDF for visualizations, while network data can be exported in all supported formats. The Gephi Toolkit allows developers to use Gephi's functionality as a Java library for integration into other applications.","Gephi's key strength is its accessibility to non-programmers through an intuitive graphical interface that requires minimal coding knowledge. The current version offers real-time visualization and interactive data exploration, allowing researchers to manipulate network views dynamically while working. Its comprehensive suite of layout algorithms (particularly ForceAtlas2) produces aesthetically pleasing and analytically useful visualizations, while built-in metrics and statistics (centrality, community detection) enable quantitative network analysis. The Data Laboratory provides an Excel-like interface for data manipulation, and the extensive plugin architecture enables community-developed extensions. For archaeological applications specifically, the timeline functionality in the current version is valuable for visualizing temporal change in networks, essential for understanding evolving settlement patterns or changing trade relationships. The ability to handle geospatial data through coordinates and map backgrounds makes it particularly suited for archaeological site network analysis.","The current version of Gephi faces several limitations for archaeological research. It lacks built-in uncertainty visualization, which is problematic when working with incomplete archaeological datasets. Despite timeline functionality, handling networks that evolved over very long archaeological timescales (centuries or millennia) remains challenging. Technical issues include performance degradation with very large networks (>100,000 nodes) and stability concerns with large datasets. The current version has limited advanced statistical testing capabilities compared to R-based alternatives, making hypothesis testing more difficult. The visualization-driven approach can sometimes lead researchers to focus on visual patterns rather than statistical significance, potentially encouraging misinterpretation of archaeological relationships. From a technical perspective, the codebase suffers from accumulating technical debt, with outdated dependencies and reliance on Java for desktop applications when web technologies are increasingly preferred.","Gephi's long-term viability appears moderate to good. Positive factors include institutional backing through the Gephi Consortium, significant academic adoption across disciplines, and continued development with the recent 0.10 release (January 2023). The project is also adapting to current technology trends with the development of Gephi Lite, a web-based version. Challenges to sustainability include technical debt in the codebase, development bottlenecks with reliance on a small number of core developers, and unclear sustainable funding sources. The shift in archaeological network analysis towards more reproducible approaches, particularly R-based solutions, presents a competitive challenge. However, Gephi continues to offer unique value through its visual interface and intuitive approach, making it likely to remain relevant for researchers who prefer visual interaction over programming approaches.","Several alternatives offer distinct advantages for archaeological and historical network analysis. Cytoscape provides greater stability for large datasets and stronger API integration but has a steeper learning curve. VOSviewer excels in bibliometric analysis with superior text mining capabilities but lacks some of Gephi's flexibility. Pajek handles extremely large networks more efficiently and offers more comprehensive analytical techniques but has a less intuitive interface. R-based solutions (igraph, statnet) provide superior integration with statistical analysis and better reproducibility, allowing for more rigorous hypothesis testing and integration with other analytical methods. These have gained particular momentum in recent years, accelerated by publications like 'Network Science in Archaeology' (Brughmans & Peeples, 2023) with accompanying R-based online resources. Python-based solutions (NetworkX with visualization libraries) offer similar programming-based advantages to R but with Python's general-purpose flexibility.",
glottospace,Success,,"GlottoSpace is an R package for mapping, visualising, and analysing the spatial distribution of linguistic and cultural data. The current version (1.0.0) provides functionality for downloading linguistic data from various databases, conducting spatial analyses of language relationships, and generating interactive maps. GlottoSpace's analytical capabilities can be applied to archaeological and historical research by enabling the mapping of language distributions and their relationships to cultural boundaries or historical population movements. While initially designed for linguistic research, GlottoSpace is particularly valuable for interdisciplinary studies that examine the spatial correlations between linguistic features and archaeological findings, especially when reconstructing historical settlement patterns and cultural diffusion.","GlottoSpace emerged from the European Research Council-funded SAPPHIRE project (South American population history revisited: multidisciplinary perspectives on the Upper Amazon), which began in August 2019 and runs until July 2024. The package was first released in 2022 and formally published in the Journal of Open Source Software (vol. 7, no. 77). The development has been led by an international team of six researchers from European institutions, with Sietze Norder (Utrecht University) as the lead author. Since its initial release, the package has seen regular updates and refinements, with most recent developments focusing on enhanced integration with major linguistic database services and improved spatial analysis tools.","GlottoSpace is an R package that extends R's capabilities for analysing linguistic data in spatial contexts through a comprehensive set of modular functions. The current version (1.0.0) is architecturally organised into intuitive function families: glottoget for data retrieval, glottocreate for initialising data structures, glottocheck for quality verification, glottodist for calculating linguistic distances, glottoplot for visualisation, glottospace for spatial transformations, glottomap for geographic mapping, and glottosave for exporting outputs. The package builds on established spatial libraries in the R ecosystem, including sf, terra, tmap, mapview, and rnaturalearth, creating a bridge between geospatial analysis tools and linguistic data. One of GlottoSpace's technical strengths is its API integration with major global linguistic and cultural databases, including Glottolog, WALS (World Atlas of Language Structures), Grambank, D-PLACE (Database of Places, Language, Culture and Environment), and Phoible. This integration enables researchers to match linguistic data to geographical locations, calculate distances between languages, and visualise these relationships through customisable maps. The package requires R version 3.5.0 or higher and runs on any R-compatible operating system. Installation dependencies can present challenges for new users, particularly with spatial libraries that may require additional system components beyond the R environment itself.",2025-05-07,yes,"GlottoSpace meets all essential criteria for research software: it has a research-specific purpose (analysing linguistic and cultural data spatially), engages with research data (transforms and analyses linguistic datasets), and aligns with recognised methodologies in linguistic and spatial analysis. It also satisfies multiple supporting criteria: it integrates domain knowledge (linguistic terminology and classifications), supports the research lifecycle (from data collection to visualisation), transforms data between formats, provides analytical capabilities (calculating linguistic distances and relationships), offers robust visualisation functions, provides research-focused documentation, and facilitates data dissemination through exportable visualisations and analyses. Though primarily designed for linguistics, its capabilities for spatial analysis of cultural and historical data make it valuable for archaeological applications.",https://github.com/glottospace/glottospace,https://CRAN.R-project.org/package=glottospace,https://zenodo.org/records/7064529,https://zenodo.org/records/7064529,GPL-3.0,Spatial analysis|Data collection|Data management|Diagrams and visualizations,linguistic mapping|spatial analysis|interdisciplinary research|cultural diffusion|population history,2022,2024-04-15,1.0.0,Active,European Research Council (Grant 818854)|Utrecht University|University of Freiburg|Max-Planck-Institute for Evolutionary Anthropology|Leiden University|Hebrew University of Jerusalem,Sietze Norder|Laura Becker|Hedvig Skirgård|Leonardo Arias|Alena Witzlack-Makarevich|Rik van Gijn,Medium (6-20),Linguistics,General-purpose,Comprehensive,"GlottoSpace shows moderate but growing adoption within specialised academic circles. The GitHub repository has 28 open issues and 93 closed issues as of 2024, indicating active maintenance and user engagement. The package has been cited in several academic publications, particularly in studies of Northwestern Amazonia. Research groups from European universities have documented using the tool for analysing the spatial distribution of languages and cultural features. While download statistics from CRAN are not publicly available, the package has received recognition through its publication in the peer-reviewed Journal of Open Source Software. There is limited evidence of widespread adoption in archaeological contexts specifically, suggesting that cross-disciplinary uptake remains an opportunity for growth.",Analysis|Processing|Interpretation|Publication,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"GlottoSpace can import data from major linguistic databases (Glottolog, WALS, Grambank, D-PLACE, Phoible) and export results in various formats including shapefiles, GeoJSON, and standard R data objects. The current version provides comprehensive interoperability with other R packages, particularly those in the spatial ecosystem. Input formats include CSV, TSV, and direct API calls, while outputs can be generated as static maps (PNG, JPEG, PDF), interactive visualisations (HTML), or data tables (CSV, Excel). The package also supports direct integration with tmap for advanced cartographic visualisations and sf for geospatial operations.","GlottoSpace's key strength is its integrated approach to linguistic and spatial analysis, providing a comprehensive toolkit for researchers exploring the geographical distribution of language features. The current version excels at bridging disciplinary boundaries between linguistics, geography, and historical studies by enabling researchers to visualise and quantify relationships between languages and their spatial contexts. The package's robust integration with established linguistic databases means users can access standardised data without manual collection or harmonisation. Its open-source nature and comprehensive documentation facilitate transparency and reproducibility in research. For archaeologists and historians, GlottoSpace offers valuable capabilities for reconstructing past population movements and cultural exchanges through the spatial analysis of language distributions—particularly useful for studies involving language contact zones or historical migration patterns. The well-documented API and consistent function naming conventions make it accessible to researchers with basic R programming skills.","Despite its strengths, the current version of GlottoSpace faces several limitations. First, it requires R programming knowledge, restricting accessibility for researchers without technical backgrounds. The package's installation process can be challenging due to dependencies on spatial libraries that sometimes require additional system components. While comprehensive for linguistic analysis, the current version lacks specific archaeological data sources, requiring researchers to manually integrate archaeological datasets with the linguistic frameworks provided. The specialised academic focus limits its user community size compared to more general-purpose tools, potentially affecting long-term support. Performance issues may arise when processing very large datasets, particularly for complex spatial operations. Documentation, while thorough for core functions, provides fewer examples of interdisciplinary applications, leaving archaeologists to develop their own workflows for combining linguistic and archaeological data. Finally, the current version would benefit from more extensive validation features to help users assess the quality and reliability of their spatial linguistic models.","GlottoSpace demonstrates several positive indicators for long-term viability: it has institutional support from multiple European research centres and grant funding through 2024 from the European Research Council. The package's availability on CRAN ensures standardised distribution and quality control, while its GPL-3.0 license allows for community contributions and derivatives. Evidence of active maintenance includes regular updates, responsive issue resolution, and growing feature set. The interdisciplinary relevance of the tool—connecting linguistics with archaeology, history, and geography—provides a broad potential user base that extends beyond any single discipline. While the specific SAPPHIRE project funding ends in 2024, the established user community and academic recognition (through peer-reviewed publication) suggest likely continuation. The main risks to long-term sustainability include the relatively specialised nature of the tool and potential dependency on key developers from the original team.","Alternative tools for linguistic spatial analysis include: Lingtypology (R package with a simpler interface focused more on typological traits), glottoTrees (R package focused on language family trees rather than spatial distribution), ELAN (standalone application for annotation of audio/video rather than geographic analysis), and FLEx (standalone application for lexical and text data, specialised for dictionary creation and fieldwork). For purely geographical analysis without linguistic specialisation, researchers might use QGIS, ArcGIS, or general R spatial packages. GlottoSpace's distinctive advantage is its comprehensive integration of spatial analysis with linguistic data, allowing researchers to visualise and analyse relationships between geographic space and language features in ways not readily available in other tools.",
glottoTrees,Success,,"glottoTrees is an R package that facilitates the preparation, manipulation, and visualisation of phylogenetic trees specifically for linguistic research. It adapts resources from the Glottolog database, providing tools for extracting, modifying, and analysing language family trees. While primarily developed for linguistic applications, glottoTrees serves archaeological research by enabling correlations between language evolution and material culture evidence. The package allows researchers to visualise evolutionary relationships between languages, which helps integrate linguistic data with archaeological findings to reconstruct aspects of human prehistory. This bridging function is particularly valuable for calibrating language trees with archaeological evidence and identifying pre-contact cultural relationships that predate written records.","glottoTrees was developed by Erich R. Round, a Professor of Linguistics with dual affiliations at the University of Surrey (UK) and the University of Queensland (Australia). First released in 2021 as version 0.1, the software emerged from Round's research in historical linguistics and language evolution. The tool was formally documented in a 2022 paper published in Linguistic Typology by Jayden L. Macklin-Cordes and Round titled 'Challenges of sampling and how phylogenetic comparative methods help: with a case study of the Pama-Nyungan laminal contrast', which included supplementary materials with a detailed tutorial. The package has received limited updates since its initial release, with version 0.1.9 released in December 2022, but continues to be cited in academic research, particularly in studies of Australian aboriginal languages.","glottoTrees is implemented in R and functions primarily by leveraging the 'ape' (Analysis of Phylogenetics and Evolution) package along with other R dependencies. The package processes hierarchically structured language classification data from Glottolog, stored in Newick tree format, converting these text-based representations into R's native 'phylo' objects for programmatic manipulation. Its architecture is modular, organised around functional categories including tree topology manipulation, branch length adjustment, node/tip labelling, metadata extraction, and visualisation. The workflow typically involves reading Glottolog's Newick-formatted trees, parsing the linguistic metadata, and creating interactive R objects that preserve hierarchical relationships between languages. Key operations include tree grafting (combining multiple tree structures), branch rescaling (adjusting evolutionary distances), and node operations. Version 0.1.9 implements specialised tree visualisation through the plot_glotto() function, rendering downward-oriented trees in a style preferred by linguists rather than the leftward orientation common in biological phylogenetics. The package includes data from Glottolog versions 4.0 through 4.8, providing comprehensive coverage of the world's language families while maintaining version compatibility.",2025-05-07,yes,"glottoTrees qualifies as a research software tool by meeting all essential criteria and exceeding the supporting criteria requirements. It creates, processes and analyses research data by manipulating phylogenetic trees for linguistic analysis; is used in academic publications with a detailed tutorial in Linguistic Typology; has adequate documentation including GitHub README, function documentation, and tutorial paper; and is publicly available on GitHub under a Creative Commons License. It satisfies 5 of 6 supporting criteria: has test files for automated testing, uses Git version control, has GitHub's issue tracking system available, is released under CC-BY-4.0 license, and shows ongoing maintenance with a release in December 2022 (v0.1.9).",https://github.com/erichround/glottoTrees,,https://slcladal.github.io/phylo.html,https://slcladal.github.io/phylo.html,CC-BY-4.0,Network analysis|Datasets|Visualizations|Templates|Statistical analysis,phylogenetics|linguistic analysis|tree visualization|comparative analysis|data transformation,2021-01-01,2022-12-15,0.1.9,Maintenance-only,University of Queensland (Australia)|University of Surrey (UK),Erich R. Round|Jayden L. Macklin-Cordes,Solo,Linguistics,General-purpose,Basic,"The tool has limited usage indicators. On GitHub, it has 5 stars and 3 forks as of May 2025. The package is referenced in at least one published paper in Linguistic Typology (2022), primarily by the original authors. It has been used in research on Australian aboriginal languages, particularly Pama-Nyungan language studies. There are no documented community discussions on Stack Overflow or similar platforms, suggesting limited adoption outside the authors' immediate academic circle. The package has seen application in specific academic contexts but lacks evidence of broader adoption across linguistics or archaeology.",Analysis,research-specific,Packages and libraries,R,R,,"glottoTrees can process Newick-formatted tree files, a standard format for representing phylogenetic trees. It interoperates well with the R ecosystem, particularly with the 'ape' package for phylogenetic analysis. The current version can read tree data from Glottolog versions 4.0 through 4.8, allowing integration with this major linguistic database. It can export visualisations in standard R graphical formats (PDF, PNG, etc.). The package's interoperability is somewhat limited by its specialisation to linguistic phylogenetics and focus on Glottolog data sources, though it can potentially work with any properly formatted Newick tree regardless of origin.","glottoTrees excels at making Glottolog's genealogical data accessible and adaptable for linguistic research, allowing researchers to modify phylogenetic trees to reflect their hypotheses about language relatedness. The software provides linguistics-specific tree visualisations in a downward-running format that conforms to disciplinary conventions rather than the horizontal format common in biology. It integrates seamlessly with the broader R ecosystem, allowing researchers to leverage existing R packages for statistical analysis while maintaining focus on linguistic research questions. Its development by an active academic researcher ensures alignment with actual research needs in linguistic typology. Documentation is a notable strength, with a published tutorial in a peer-reviewed journal providing both legitimacy and accessibility.","The tool exhibits several weaknesses that limit its broader adoption. The modest community engagement metrics (5 stars, 3 forks) suggest limited usage outside the author's immediate academic circle. glottoTrees appears to be primarily maintained by a single developer, creating potential sustainability concerns if the author's priorities change. The relatively infrequent updates and commits indicate that development is not as active as comparable tools. Documentation, while present, could be more comprehensive - while there is a tutorial paper and basic GitHub documentation, the lack of extensive user guides, examples, and community-contributed documentation presents barriers to new users. The software's specificity to linguistic phylogenetics, while a strength for its target audience, limits its appeal to researchers in adjacent fields who might benefit from its functionality.","glottoTrees presents mixed long-term survivability prospects. Positively, it addresses a specific need in linguistic research that is unlikely to disappear, as phylogenetic approaches in historical linguistics continue to gain prominence. Its integration with Glottolog, a well-established linguistic resource, anchors it to a stable foundation. Implementation in R is advantageous for survivability, as R has a strong presence in academic research with robust package management infrastructure. However, several factors create sustainability concerns. Development appears primarily driven by a single researcher rather than an institutional team. The modest user community means there may not be sufficient external contributors ready to maintain the project if needed. The academic paper publications provide some insurance against complete disappearance, as the methodological approach is documented in the literature. For improved survivability prospects, the project would benefit from recruiting additional contributors, creating more comprehensive documentation, and establishing stronger institutional backing.","lingtypology: Another R package focused on linguistic data that works with Glottolog, though emphasising geographic mapping rather than phylogenetic analysis. phyloWeights: A companion package by the same author (Round) for calculating genealogically-sensitive proportions and averages. BEASTling: A tool that facilitates the application of Bayesian phylogenetic methods to linguistic data using BEAST2 framework. ape: The Analysis of Phylogenetics and Evolution package in R - more general-purpose than glottoTrees but lacks linguistics-specific functions. ggtree: An R package for visualising phylogenetic trees that offers substantial customisation options but lacks linguistic-specific defaults. Phyx: A collection of Unix/Linux command-line tools for phylogenetic analyses offering different workflow options compared to R-based approaches. D-PLACE: The Database of Places, Language, Culture and Environment provides integrated cross-cultural datasets with some phylogenetic functionalities but through a web interface rather than programmatic access.",
Grid Machine,Failure | Spawned new,Fail,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
gvSIG,Success,,"gvSIG is a free, open-source geographic information system (GIS) designed for capturing, storing, handling, analysing and deploying geographic information. Though originally created for urban planning and infrastructure management, it has been adapted for archaeological applications, particularly through Oxford Archaeology's customised version (gvSIG OADE). The current version provides comprehensive spatial analysis capabilities, including layer management, georeferencing, raster processing, digital elevation model analysis, and multi-temporal analysis—all particularly valuable for archaeological fieldwork, site mapping, artifact distribution analysis, and landscape studies.","gvSIG emerged in 2003 as a project by the Generalitat Valenciana (Regional Government of Valencia, Spain) to develop an open-source GIS solution. The software matured through several significant milestones: first release in 2004, version 1.0 in 2006, formation of the gvSIG Association in 2009, complete architectural redesign in version 2.0 (2013), significant enhancements in version 2.5 (2019), and interface modernisation in version 2.6 (2023). A key development for archaeology occurred when Oxford Archaeology created its own adapted version (gvSIG OADE) around 2010, which eventually evolved into gvSIG Community Edition (CE), establishing the tool's relevance in archaeological contexts across European institutions, including state cultural heritage departments in Germany.","gvSIG is built on a highly modular architecture that facilitates extensibility and customisation—a quality particularly valuable for adapting the software to specific archaeological requirements. The code base is primarily written in Java, making it platform-independent and deployable across various operating systems. The interface is built using Java Swing with Model-View-Controller pattern implementation, while the Andami framework manages plugin extensions. This architecture allows archaeologists to develop specialised tools for their specific research needs. One of gvSIG's greatest technical strengths is its exceptional support for data formats, including vector formats (SHP, DXF, DWG, DGN, GML, KML), raster formats (ECW, ENVI HDR, ERDAS IMG, GeoTIFF, GRASS), database connections (PostGIS, MySQL, Oracle, ArcSDE, JDBC), and OGC standards (WMS, WFS, WCS). The software implements spatial indexing for improved performance with large datasets, though performance can degrade when working with particularly complex operations or very large raster datasets. For archaeological applications, the Survey2GIS plugin enhances capabilities for archaeological surveying by processing raw survey data into topologically cleaned GIS datasets, while the SEXTANTE extension provides over 240 additional algorithms for spatial analysis. The 3D visualisation capabilities, while not as robust as dedicated 3D software, allow archaeologists to import and visualise models from excavations.",2024-05-07,yes,"gvSIG qualifies as research software because it meets all essential criteria and multiple supporting criteria. Essential criteria: (1) It serves research-specific purposes through spatial analysis capabilities tailored for archaeological investigations; (2) It transforms research materials by processing, analysing and visualising archaeological spatial data; (3) It aligns with established methodological approaches in archaeological spatial analysis and landscape archaeology. Supporting criteria: It incorporates domain knowledge through archaeological-specific adaptations and extensions; supports multiple research lifecycle stages from data collection to visualisation; provides data transformation capabilities through its extensive format support; offers analytical capabilities through spatial statistics and geoprocessing; provides comprehensive visualisation functions; and has documentation specifically addressing archaeological applications through specialised training materials.",https://github.com/gvsig-sandbox,,http://www.gvsig.com/en/products/gvsig-desktop,http://www.gvsig.com/en/products/gvsig-desktop,GNU/GPL,Spatial analysis|Site mapping|Data management|Geophysical survey|Aerial and satellite imagery,GIS|archaeology|open-source|geographic-information-system|spatial-analysis,2004-01-01,2023-06-01,2.6,Active,"gvSIG Association (non-profit organisation founded in 2009), originally backed by Generalitat Valenciana (Regional Government of Valencia, Spain)",Original development team from Generalitat Valenciana; now managed by gvSIG Association with contributions from partner companies and community developers,Medium (6-20),Urban planning and infrastructure management,General-purpose,Basic,"gvSIG has a moderate-sized user community with stronger presence in Spanish-speaking countries. The software has been adopted by government agencies across 160+ countries, including UN security applications and multiple regional governments. GitHub repositories show ongoing activity through 2023-2024, though at a slower pace than earlier phases. The archaeological adaptation (gvSIG CE) has gained adoption in multiple European cultural heritage departments. Forum activity is moderate, with stronger engagement in Spanish-language sections than English. The software has received formal recognition, including the 2023 National Prize for Geographic Sciences from Spain's Ministry of Transport and Sustainable Mobility.",Data Acquisition|Processing|Analysis|Interpretation,research-specific,Stand-alone software,Java,Windows|Linux|macOS,,"gvSIG offers exceptional format support, making it valuable for archaeological projects that need to integrate diverse data sources. The software can import/export: vector formats (SHP, DXF, DWG, GML, KML); raster formats (ECW, ERDAS IMG, GeoTIFF); and connect to databases (PostGIS, MySQL, Oracle). It adheres to OGC standards for web services (WMS, WFS, WCS), enabling integration with online data sources. The current version (2.6) has improved interoperability with other systems through enhanced import/export capabilities. The archaeological adaptation (gvSIG CE) provides integration with specialised archaeological tools like Survey2GIS.","gvSIG offers five key strengths for archaeological applications. First, it provides a completely free and open-source alternative to expensive commercial GIS software, making it accessible to archaeological projects with limited budgets. Second, its customisability has enabled specialised archaeological adaptations like Oxford Archaeology's version, with tailored features for fieldwork and survey data management. Third, the extensive format support facilitates integration of diverse data sources common in archaeological research, from legacy datasets to modern remote sensing outputs. Fourth, the SEXTANTE extension's rich analytical capabilities support complex landscape analyses crucial for understanding archaeological contexts. Fifth, the Community Edition has demonstrated success in professional archaeological applications, particularly in European cultural heritage management contexts.","Despite its strengths, gvSIG presents several limitations for archaeological applications. First, documentation quality is inconsistent, with Spanish documentation generally more comprehensive than English resources, creating barriers for non-Spanish speaking archaeologists. Second, the software exhibits performance limitations when handling very large or complex datasets, potentially problematic for projects with extensive remote sensing data. Third, the learning curve is steeper than some alternatives, particularly for archaeologists without prior GIS experience. Fourth, the development pace has slowed in recent years, with longer periods between major releases and some features like 3D functionality facing funding challenges. Fifth, while the Community Edition addresses archaeological needs, it sometimes lags behind the main development branch, creating a fragmented ecosystem that can confuse new users about which version best suits their needs.","gvSIG demonstrates moderate to good long-term viability for archaeological applications. The software's sustainability is strengthened by its governance through the non-profit gvSIG Association, which provides a stable organisational framework. The business model combining partner company fees, consulting services, and project implementation creates ongoing funding streams. Institutional adoption by government agencies and archaeological organisations indicates sustained demand. However, some risk factors exist: development pace has slowed compared to earlier phases, with longer intervals between major releases; the community is concentrated more strongly in Spanish-speaking regions; and QGIS has emerged as a more dominant open-source GIS platform with greater momentum. For archaeological applications specifically, the continued maintenance of gvSIG CE provides reasonable assurance of ongoing viability, though users should monitor development activity and community support levels when making long-term commitments to the platform.","QGIS offers a more active development community, better English documentation, and more accessible interface, but may handle very large datasets less robustly. GRASS GIS provides more powerful analytical capabilities and stronger temporal framework but has a steeper learning curve and more complex data structure. ArcGIS (commercial) offers more extensive documentation and polished interface but involves high licensing costs and less flexible customisation. Survey2GIS functions both as a standalone tool and gvSIG CE plugin specifically for archaeological survey data. Portable GIS combines multiple open-source tools into a package optimised for archaeological fieldwork that can run from USB drives.",
HTMLfig,Success,,"HTMLfig' refers to two related web technologies used for archaeological visualization: 1) Python mpld3's fig_to_html() function that converts matplotlib visualizations to interactive web graphics and 2) HTML <figure> elements used in archaeological documentation. Both enable researchers to create interactive visualizations of archaeological data including stratigraphic sequences, artifact measurements, and spatial distributions for web publication and scholarly communication. While neither was specifically developed for archaeology, they have been adopted by archaeologists seeking to improve communication of complex visual archaeological data through web interfaces.","The two technologies comprising 'HTMLfig' have different development histories. The mpld3 Python package, which includes the fig_to_html() function, was developed around 2014 by Jake Vanderplas at the University of Washington as an open-source community project. HTML <figure> elements were standardised as part of HTML5, which became an official W3C standard in October 2014. Both technologies have seen increasing adoption in archaeological contexts as digital archaeology has grown, particularly for web-based publication of interactive visualizations.","The mpld3.fig_to_html() function serves as a bridge between Python's matplotlib visualization library and web-based presentations using D3.js. The function accepts a matplotlib figure object and returns HTML code that includes both the visualization and interactive elements such as zooming, panning, and tooltips. The technical workflow involves: 1) Creating data visualizations in Python using matplotlib, 2) Converting to HTML with mpld3.fig_to_html(), and 3) Embedding the resulting HTML in web pages or publications. The function generates standalone HTML that includes embedded JavaScript for interactivity using D3.js. HTML <figure> elements provide semantically meaningful structure for archaeological web content. The <figure> element encapsulates visual content (images, diagrams, charts) while the associated <figcaption> element provides contextual information such as descriptions, sources, and interpretations. This semantic structure improves accessibility and searchability of archaeological visual content. Together, these technologies enable archaeologists to transform static research visualizations into interactive web components with proper structural semantics. This facilitates both scholarly communication and public engagement with archaeological data, allowing users to explore complex stratigraphic relationships, artifact distributions, or 3D reconstructions through web interfaces rather than static images alone.",2025-05-07,maybe,"HTMLfig meets several criteria for research software but exists as components rather than a dedicated standalone archaeological tool. It meets essential criteria by serving research-specific purposes (transforming archaeological visualizations for web presentation) and engaging with research data meaningfully (enabling interactive exploration of archaeological data). It supports methodological alignment by facilitating established approaches to archaeological visualization and documentation. For supporting criteria, it provides data transformation capabilities (converting matplotlib plots to web formats), visualization functions (interactive elements for exploring archaeological data), and documentation capabilities (semantic structure for archaeological visual content). However, it lacks domain-specific knowledge integration specifically for archaeology and was not originally developed for archaeological applications. The 'maybe' classification reflects that while these technologies fulfill important functions in archaeological research software ecosystems, they require integration with other tools and customization for archaeological applications rather than functioning as standalone archaeological research software.",https://github.com/mpld3/mpld3,https://pypi.org/project/mpld3/,https://pypi.org/project/mpld3/,https://mpld3.github.io,BSD-3-Clause,Data visualization|Data management|Diagrams and visualizations,web visualization|interactive graphics|python visualization|archaeological documentation|data presentation,2014,2023,0.5.10 (mpld3),Maintenance-only,None specific to archaeology; mpld3 is community-maintained,Jake Vanderplas (mpld3); W3C (HTML5 specification),Small (2-5),Web development|Data visualization,General-purpose,Basic,"The mpld3 package receives approximately 141,000 weekly downloads according to package statistics. HTML figure elements are standard HTML5 components used across countless websites. In archaeological contexts, these technologies have been adopted by projects including the Archaeology Data Service (ADS) 3D Viewer, Çatalhöyük Research Project's web documentation, Digital Chicago's exhibition of urban excavation findings, and various other digital archaeology initiatives for web-based visualization.",Data Acquisition|Analysis|Publication,research-specific,Packages and libraries,Python|JavaScript|HTML,Cross-platform (web-based),Python,"The fig_to_html() function works with data in various formats through matplotlib's data handling capabilities, supporting CSV, Excel files, spatial data formats and database queries. It produces standalone HTML/JavaScript that can be embedded in any web page or content management system. HTML figure elements provide standardized semantic structure that works across all modern web browsers and integrates with archaeological web documentation frameworks.","Both technologies offer significant advantages for archaeological visualization: 1) Accessibility - making archaeological content accessible to diverse audiences and compatible with assistive technologies; 2) Interactivity - allowing users to explore complex archaeological data through zooming, panning, and hover effects; 3) Web integration - seamlessly embedding in digital publications, repositories, and online exhibitions; 4) Standardization - providing consistent formatting and semantic structure for archaeological visual content; 5) Preservation of context - maintaining relationships between archaeological visuals and their interpretative text. The semantic richness of HTML figure elements enables better discoverability and proper attribution of archaeological visual content.",Several limitations affect these technologies for archaeological visualization: 1) Technical barriers - requiring web development and programming skills that many archaeologists lack; 2) Limited archaeology-specific features - necessitating additional customization for specialized archaeological visualization needs; 3) Version compatibility issues - requiring maintenance as web standards and browsers evolve; 4) Conversion challenges - sometimes losing detail when converting complex archaeological visualizations; 5) Preservation concerns - web-based content faces long-term archival challenges; 6) Limited support in traditional academic publishing - journals often still prioritize static images in PDF formats over interactive web content.,"Long-term viability is strong for HTML figure elements as part of established HTML5 standards supported by all browsers. For mpld3, the outlook is mixed - while the current version (0.5.10) functions well, development activity has slowed, with limited active maintenance. However, the core functionality remains viable and the underlying standards (HTML, JavaScript, D3.js) are well-established. The open-source nature of both technologies provides some resilience, as archaeological users can maintain their own implementations if needed. Overall, these technologies should remain functional for archaeological visualization needs in the medium term, though mpld3 may eventually require replacement with more actively maintained alternatives if not revitalized through community efforts.","Several alternatives serve similar purposes for archaeological visualization: 1) Plotly for Python - provides interactive web visualizations with more active development than mpld3; 2) Bokeh - Python library for interactive web visualizations with growing archaeological applications; 3) 3DHOP (3D Heritage Online Presenter) - specialized for web visualization of 3D archaeological objects; 4) ADS 3D Viewer - platform developed specifically for archaeological 3D data; 5) Potree Viewer - WebGL point cloud viewer used for archaeological visualization; 6) ArcheoViz - R package designed specifically for visualization of archaeological spatial data; 7) SEAHORS - Web application for visualizing spatial distribution of archaeological remains. Additionally, several specialized archaeological visualization packages exist in R and Python, though they often generate static rather than interactive visualizations.",
htmltoc,Success,,"A Perl program created by Earl Hood in 1994 to automatically generate Tables of Contents (ToC) for HTML documents. It scans HTML files for significant elements (typically headings), inserts anchor tags, and generates a multi-level list containing hyperlinks to these elements. The tool was notably used by Internet Archaeology, one of the first peer-reviewed electronic journals for archaeology, to enable structured navigation of complex excavation reports.","The original htmltoc was developed by Earl Hood while working at Convex Computer Corporation and released as version 1.0.0 beta on July 21, 1994, as part of the perlWWW package. It was distributed via FTP from ftp.uci.edu, with documentation available at uci.edu. The tool was designed to address the growing need for navigable structures in increasingly complex HTML documents during the early web era. Internet Archaeology, established in 1995, adopted htmltoc along with another script called PNUTS (Previous, Next, Up, Top and Search) as part of its publishing infrastructure for archaeological content. The primary period of htmltoc usage in archaeological contexts appears to be from 1995-2000, before being superseded by more sophisticated content management systems.","Htmltoc was implemented as a command-line tool written in Perl that followed Unix conventions. Its core functionality worked by: (1) scanning HTML files to identify user-specified 'significant elements' (typically headings); (2) creating backup copies of original files with '.org' extension; (3) inserting anchor tags into the significant elements; and (4) generating a multi-level list containing hyperlinks to these anchored elements. The key technical feature was the ToC map file that defined what elements should be included in the table of contents and at what level. The format followed this structure: 'significant_element:level:sig_element_end:before_text,after_text'. The tool offered numerous configuration options including customisable ToC structure, external or inline ToC generation, formatted output with headers and footers, multi-file support for comprehensive ToCs, and backup protection for original files. Htmltoc operated by directly modifying HTML files to insert anchor points and could create standalone ToC files that linked to the modified documents. This design reflected the limitations and practices of early web development when dynamic page generation was uncommon and static HTML files were the norm.",2025-05-08,yes,"Htmltoc qualifies as research software because it meets all Essential Criteria: (1) Research-Specific Purpose: It supports archaeological research activities by enabling structured navigation of complex research publications; (2) Research Data Engagement: It transforms HTML documents into navigable scholarly resources, enhancing how research is presented and accessed; (3) Methodological Alignment: It aligns with digital publishing methodologies in archaeology and humanities research. It also meets multiple Supporting Criteria: it supports data transformation, provides visualization functions through structured navigation, supports research dissemination, and was documented with specific reference to archaeological applications.",,,https://www.w3.org/Tools/htmltoc.html,https://www.w3.org/Tools/htmltoc.html,Likely GNU GPL and/or Artistic License (based on Hood's other software licensing patterns),Data management|Platforms and publications|Templates,document navigation|HTML processing|archaeological publishing|web authoring|digital humanities,1994-07-21,Unknown (likely late 1990s),1.0.0 beta (possibly reached higher versions),Abandoned,Convex Computer Corporation (where Earl Hood worked at the time of creation),Earl Hood,Solo,Computer Science,General-purpose,Basic,"Used by Internet Archaeology journal in their early publishing workflow (1995-2000). The journal was a pioneering digital archaeology publication, funded by the eLib programme in the UK. Specific usage metrics from the 1990s are not available, but it was part of the technical infrastructure supporting one of the first electronic journals in archaeology.",Publication,research-specific,Stand-alone software,Perl,Unix/Linux command line,,Takes standard HTML as input and generates HTML with a table of contents as output. Works with any HTML file using standard heading elements (h1-h6). Provides flexibility to customize the TOC appearance and placement. Not designed for integration with other tools beyond the standard Unix pipeline approach.,Automated TOC generation for complex documents reduced manual effort in early web publishing. Support for multi-level hierarchical navigation enabled non-linear exploration of archaeological data. Integration with early digital archaeology publishing provided structured access to complex archaeological reports. Multi-file support allowed creation of comprehensive navigation systems. Protected original files with automatic backups. Customisable output format and structure allowed adaptation to different publication needs. Small memory footprint suited to computing resources of the era.,"Limited to static HTML files with manual regeneration needed after content changes. No support for dynamic content generation or modern web standards (HTML5, CSS3). Command-line interface presents steep learning curve for non-technical users. Lack of visual editor or preview functionality requires trial-and-error approach. Not compatible with content management systems that emerged in the early 2000s. No dedicated support for archaeological data types or specialized taxonomy. No longer maintained and incompatible with modern web development practices.","The original Perl htmltoc is no longer viable software for current use cases. It was designed for HTML as it existed in the mid-1990s, before many modern web standards were established. The tool is not compatible with modern HTML5 without significant modifications and would not integrate with contemporary content management systems. While historically significant for early digital archaeology publishing, it has been completely superseded by modern alternatives. Its contribution lives on conceptually in the navigation systems of digital publications, but the original software itself has no practical path for revival.",HTML::Toc: A more modern Perl module on CPAN created by Freddy Vulto around 2001 that provides similar functionality with a more object-oriented approach. Tocbot: Modern JavaScript library for dynamic TOC generation from headings in HTML documents. Markdown-toc: For generating TOCs in Markdown files. Jekyll TOC: Plugin for static site generators that automatically adds TOC to pages. CMS-based navigation systems: Modern content management systems like WordPress and Drupal have built-in navigation and TOC capabilities.,
iconr,Success,,"Iconr is an R package that applies graph theory to analyze prehistoric iconography. It transforms archaeological decorative elements (called 'graphical units' or GUs) into mathematical graph structures where visual elements become nodes and their spatial relationships become edges. This quantitative approach enables systematic analysis of iconographic compositions found in rock art, pottery decoration, stelae, and other archaeological artifacts. The package helps archaeologists move beyond purely subjective interpretations of prehistoric art by providing statistical methods for comparing decorative patterns across different artifacts, cultures, and time periods. While originally focused on European prehistoric rock art at sites like Valcamonica (Italy) and Mont Bego (France), the software has applications for analyzing iconography from any archaeological context.","Iconr originated from methodological work conducted by Thomas Huet and colleagues dating back to 2008 on rock art analysis. The first official version (0.1.0) was released in February 2021 with publication in the Journal of Open Source Software (JOSS) in May 2021. The development team expanded with José M. Pozo and Craig Alexander joining as co-authors. Throughout 2021-2022, the package saw active development with functions for network analysis and spatial relationship identification of graphical elements. By 2023, a development version (0.1.1) added geometric morphometric analysis capabilities for shape analysis. In October 2023, iconr was archived on CRAN due to dependency issues with the deprecated 'rgdal' package. Despite this archival status, active development continues on GitHub where the team continues to maintain and enhance the software.","The current version of iconr (0.1.1) implements a graph-theoretical approach to iconography analysis through a multi-layered architectural framework. At its core, the package represents archaeological iconographic compositions as mathematical graphs, with nodes (vertices) representing graphical units (GUs) and edges representing spatial or conceptual relationships between these units. This mathematical structure enables quantitative comparison between different decorative patterns. Technically, iconr requires R ≥ 3.5.0 and depends on several key packages including 'sp', 'rgeos', and 'igraph' for spatial operations and graph manipulation. The package's reliance on the now-deprecated 'rgdal' package led to its archival on CRAN in October 2023, though development continues on GitHub. The workflow is structured around four main operations: 1) data importation from various formats including CSV and shapefiles, 2) edge creation based on either decoration type or spatial proximity, 3) graph creation from nodes and edges, and 4) analytical operations on these graphs. For spatial analysis, iconr uses R's spatial classes to calculate distances and relationships between graphical elements. The package implements several analytical methods including hierarchical clustering of decorative motifs, minimum spanning trees to identify core relationships between elements, and graph-edit distances to quantify similarity between different iconographic compositions. The newer development version (0.1.1) adds geometric morphometric capabilities for analyzing the shapes of decorative elements. Iconr's data model requires a specific structure with four key components: decoration tables (metadata about artifacts), images (visual representations), node data (information about individual graphical units), and edge data (relationships between units). This structured approach enables cross-comparison between different iconographic compositions but requires careful data preparation. The implementation is cross-platform compatible (Windows, macOS, Linux) and primarily outputs visualizations as R plots, though data can be exported in various formats for further analysis or publication.",2024-05-08,yes,"Iconr meets all the essential criteria for research software tools. It has a clear research-specific purpose in archaeological iconography analysis, directly engages with research data through transformation of archaeological imagery into mathematical graphs, and aligns with recognized methodologies in quantitative archaeology. Among supporting criteria, it integrates domain knowledge through archaeological terminology and classification systems, supports the analysis stage of the research lifecycle, transforms visual data into graph representations, performs analytical calculations for comparing iconographic patterns, creates visualizations of network relationships between decorative elements, includes documentation focused on archaeological applications, and supports dissemination of standardized iconographic analysis. The tool was explicitly designed for archaeological research and fills a methodological gap in quantitative approaches to prehistoric art interpretation.",https://github.com/zoometh/iconr,,https://zoometh.github.io/iconr/,https://zoometh.github.io/iconr/,GPL-2,Shape recognition|Iconography|Statistical analysis|Network analysis|Diagrams and visualizations,archaeological iconography|graph theory|prehistoric art|quantitative analysis|rock art,2021-02-24,2023-10-01,0.1.1 (development),Deprecated,,Thomas Huet|Jose M. Pozo|Craig Alexander,Small (2-5),Archaeology,General-purpose,Comprehensive,"Iconr has limited but focused usage metrics. On GitHub, the repository has 14 stars, 5 forks, and 3 contributors as of May 2024. The tool is cataloged in 'open-archaeo', a comprehensive list of open-source archaeological software. Its 2021 Journal of Open Source Software publication has received citations in archaeological methodology papers. Documentation indicates application to several archaeological projects including rock art analysis in Valcamonica (Italy), Mont Bego (France), and Bronze Age stelae from the Iberian Peninsula. The tool appears to have a small but specialized user community in academic archaeology, primarily focusing on European prehistoric art studies. There are no records of formal institutional adoption beyond the original research team's projects.",Analysis,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"Iconr can import data from various formats including CSV files and shapefiles. For images, it works with common formats like JPG, PNG, and TIFF. The current version (0.1.1) can export analysis results as standard R data frames, plots, and network visualizations that can be saved in various image formats. The package interoperates well within the R ecosystem, particularly with spatial analysis packages. In earlier versions (0.1.0), it had strong dependencies on spatial packages like 'rgdal' and 'rgeos', which led to its archival on CRAN. Data can be formatted for use with other network analysis tools outside of R, though this requires manual export steps.","Iconr's primary strength is its specialized mathematical approach to archaeological iconography, filling a methodological gap in quantitative analysis of prehistoric art. It transforms subjective visual interpretation into objective, reproducible analyses through graph theory application. The software enables systematic cross-comparison of decorative patterns across different artifacts, time periods, and cultures using consistent mathematical metrics. The package provides visualization capabilities that highlight relationships between graphical elements not immediately apparent through traditional visual inspection. Its open-source nature and integration with the R statistical ecosystem provide archaeologists access to powerful analytical tools without specialized programming knowledge beyond basic R skills. Iconr's implementation of graph-edit distance calculations allows researchers to quantify similarities between different iconographic compositions, enabling statistical testing of cultural relationships hypotheses. The software facilitates standardized documentation of decorative elements, improving research reproducibility and comparability across different studies. As part of the growing computational archaeology movement, iconr represents an important step toward more formalized analytical approaches in archaeological interpretation, particularly for prehistoric art where contextual information is often limited.","Iconr's primary weakness is its limited accessibility to archaeologists without R programming experience, creating a significant technical barrier to adoption. The package was archived on CRAN in October 2023 due to dependency issues with the deprecated 'rgdal' package, complicating installation for average users and potentially limiting its long-term sustainability. The tool has a small development team (2-5 people) with no formal institutional backing, raising concerns about continued maintenance and support. Its specialized focus on graph-theoretical approaches to iconography limits its broader archaeological applicability compared to more general-purpose tools. Data preparation requirements are relatively strict, requiring careful structuring of input data about graphical units and their relationships, which creates a steep initial setup curve. Documentation, while technically comprehensive, assumes specialized knowledge in both R programming and graph theory concepts that many archaeologists may lack. The software's small user community means limited availability of tutorials, examples, and community support compared to more widely-used archaeological software. Its current capabilities focus primarily on 2D representations and spatial relationships, with more limited support for temporal analysis or 3D iconographic elements in the current version.","Iconr faces significant sustainability challenges despite addressing an important methodological need. On the positive side, it is open-source under GPL-2 licensing, has active GitHub development continuing beyond its CRAN archival, and fills a specific analytical niche not covered by other archaeological software. Its integration with the R ecosystem potentially allows future maintenance by the broader R community. However, concerning indicators include its October 2023 removal from CRAN due to dependency issues with deprecated packages, its reliance on a small development team without institutional backing, and a limited specialized user base. The current archival status on CRAN significantly complicates installation for typical users, as they must now install from GitHub and manually resolve dependency issues. The specialized nature of the tool (graph theory application to prehistoric iconography) creates a narrow adoption pathway, particularly given the technical barriers for archaeologists without programming experience. Without broader institutional support or funding, long-term maintenance will remain challenging, especially as underlying R spatial packages continue to evolve. The software represents valuable methodological innovation in archaeological research but may require significant refactoring to address dependency issues and ensure long-term viability. Future survivability will depend largely on whether the development team can update dependencies, rebuild community momentum, and potentially secure institutional support.","Several alternatives exist for archaeological spatial analysis and iconographic studies, though none perfectly replicate iconr's specialized functionality. General GIS tools like QGIS with archaeological plugins offer broader spatial analysis capabilities and larger user communities, but require substantial customization for iconographic analysis. For network visualization, general graph theory tools such as Gephi and NodeXL provide more developed visualization options and better documentation but lack archaeological-specific functions. Within archaeology, Harris Matrix Composer serves a different function (stratigraphic relationship analysis) but similarly uses graph theory for archaeological applications. iDAI.field provides comprehensive archaeological recording capabilities with some spatial analysis features but doesn't focus on iconographic analysis. For R users, general spatial packages and network analysis tools like 'igraph' can replicate some iconr functionality but require significant custom coding. ArchaeoPhases focuses on chronological modeling rather than iconography but demonstrates another specialized R package for archaeological applications. Commercial options like ArcGIS with its network analysis extension offer more support and documentation but lack the specialized archaeological iconography functions and require expensive licensing. For pure shape analysis, morphometrics packages like 'Momocs' can analyze outline shapes but don't incorporate spatial relationships between elements as iconr does.",
iDig,Success,,"iDig is a specialised iPad-based software application designed for archaeological field recording. Developed by Bruce Hartzler at the American School of Classical Studies at Athens (ASCSA), it enables real-time digital documentation of excavation contexts, features, and finds. The current version allows archaeologists to wirelessly connect to total stations for precise spatial measurements, synchronise data across multiple iPads, instantly visualise stratigraphic relationships, and integrate with previous excavation records. A distinctive feature nicknamed 'Camping it' (after Agora excavation director John Camp) allows users to trace areas on screen to see previously recorded contexts at that location, effectively creating a virtual time machine through the stratigraphic layers. Recently evolved into WebDig (2023/2024), extending functionality beyond iOS devices.","iDig's development history reflects a methodical evolution from early digital experimentation to a sophisticated recording system. In 1998, Bruce Hartzler joined the American School of Classical Studies at Athens as staff for the Athenian Agora excavations. During the 2000s, Hartzler began digitising 80+ years of Agora excavation records and experimenting with mobile recording using Palm Pilots synchronised with total stations. Following the 2010 release of the iPad, the first version of iDig was created in 2011 and initially implemented at the Athenian Agora excavations in 2012. By 2016, the software had reached version 5.0.2, as documented in a published review by Martin Uildriks. Training sessions were conducted through 2021, indicating continued development. The most significant recent development occurred in late 2023/early 2024 with the evolution into WebDig, a web-based application with expanded capabilities that addresses the iOS platform limitation while maintaining core functionality and visualisation strengths.","iDig is built as a native iOS application, likely developed initially in Objective-C with possibly later components in Swift as Apple shifted programming paradigms. The software employs a multi-tier architecture with: 1) Mobile Application Layer (iPad client) handling user interface, data entry, and visualisation; 2) Sync/Collaboration Layer managing 'Trenchmates' functionality for iPad synchronisation and total station connectivity; and 3) Optional External Server Component ('iDig Server' application) for enterprise-level data management using Git repositories. The application's data model is specifically tailored to archaeological excavation workflows, supporting entity types like contexts, features, objects, and lots – each with specialised fields and relationship types reflecting archaeological thinking (such as 'is above', 'is below', 'is after'). Technical requirements include iOS 9.3 or later, iPad devices with minimum 10.6 MB free space, Wi-Fi for synchronisation between devices, and optional Leica Total Station integration. Data storage uses a structured on-device approach with periodic snapshots for backup. The primary export format is UTF-8 tab-delimited text files, which can be processed for use in spreadsheets, databases, and GIS software. The current WebDig implementation leverages web technologies to provide similar functionality through a browser interface, allowing for broader platform compatibility while maintaining the core visualisation capabilities that distinguished the original iOS application.",2024-05-08,yes,"iDig meets all essential criteria for research software tools as it has a clear research-specific purpose (archaeological recording), directly engages with research data (spatial measurements and context documentation), and aligns with established archaeological methodologies. It also satisfies numerous supporting criteria: it integrates domain knowledge through its archaeological terminology and classification system; supports multiple research lifecycle stages (data acquisition, processing, analysis); transforms data between field recordings and analytical formats; provides analytical capabilities through relationships between contexts; offers specialised visualisation of stratigraphic relationships; includes documentation specifically addressing archaeological research applications; supports field data collection with total station integration; and enables data dissemination through its export functions. The software was purposefully designed by an archaeologist for archaeological research, further confirming its classification as research software.",,,https://idig.tips/,https://idig.tips/,Proprietary,Data collection|Spatial analysis|Site mapping|3D modelling|Data management,Archaeological recording|Stratigraphic visualisation|Field documentation|Spatial data|Real-time collaboration,2011,2023,WebDig (2023/2024),Active,American School of Classical Studies at Athens (ASCSA)|Packard Humanities Institute,Bruce Hartzler,Small (2-5),Archaeology,Project-specific,Comprehensive,"iDig has been adopted by at least 12 major archaeological projects in the Mediterranean region, including the Athenian Agora Excavations (primary development site), American/Greek excavations at the Ismenion sanctuary (Thebes), Belgian/Dutch fieldwork at Thorikos, British excavations at Keros, Casa della Regina Carolina Project at Pompeii, Eastern Boeotia Archaeological Project at Eleon, Greek underwater survey in the Argo-Saronic Gulf, Lechaion Harbor and Settlement Land Project, Molyvoti Thrace Archaeological Project (MTAP), Teos Excavation Project, Swiss excavations at Eretria and Amarynthos, and Northwest Bolsena Archaeological Project. The most significant implementation beyond the Agora has been the MTAP project, which adopted iDig in 2019 and later evolved it into WebDig. Beyond project adoption, usage indicators include training sessions conducted through 2021 and documented use in publications reviewing archaeological field recording methods.",Data Acquisition|Processing|Analysis|Interpretation,research-specific,Stand-alone software,Objective-C|Swift,iOS (iPad)|Web (WebDig),,"iDig primarily uses UTF-8 tab-delimited text files as its export format, enabling integration with spreadsheets, databases, and GIS software. The current version supports connection with Leica Total Stations for precise spatial measurements. Import capabilities include georeferenced scanned drawings and previous seasons' data. The recently developed WebDig extends interoperability beyond the iOS ecosystem. The software uses a structured data model with well-defined relationships between archaeological contexts, features, objects, and lots, facilitating data integration with other archaeological recording systems.","iDig offers several notable strengths that have driven its adoption across Mediterranean archaeological projects: 1) Visual interface - Unlike text-heavy alternatives, iDig provides strong visualisation of spatial relationships through multiple perspectives including top plan views, cross-sections, and matrix layouts; 2) Real-time integration - Wireless connectivity to total stations and synchronisation across multiple iPads enables collaborative field recording; 3) Historical context - Immediate access to previous excavation data while in the field provides crucial contextual information for interpretation; 4) Animation features - The 'Camping it' functionality helps visualise changes in archaeological contexts through time; 5) Data protection - Multiple safeguards against data loss including trash recovery and periodic snapshots; and 6) Intuitive design - Developed by an archaeologist for archaeologists, with streamlined field recording workflows aligned with excavation practices. The current WebDig version maintains these core strengths while expanding platform accessibility beyond iOS.","Despite its strengths, iDig presents several limitations: 1) Platform limitation - The original version is exclusive to Apple's iOS ecosystem, requiring iPad devices, though the recent WebDig development addresses this constraint; 2) Hardware dependencies - The software is optimised for expensive Leica Total Stations, potentially limiting accessibility for projects with limited budgets; 3) Limited customisation - The software is closely tied to Athenian Agora recording methodology, which may not align with all archaeological recording systems; 4) Documentation gaps - Reviews note insufficient explanation of some status settings and fields; 5) Export limitations - Primary export to tab-delimited text requires post-processing for integration with some analysis tools; and 6) Specialised focus - Primarily designed for excavation, with limited support for survey or other archaeological methods. While WebDig addresses the platform limitation, other weaknesses likely persist in the newer implementation.","iDig shows strong indicators of long-term survivability. The evolution into WebDig in late 2023/early 2024 demonstrates ongoing development commitment and adaptation to changing technology landscapes. Continued institutional support from established organisations like the American School of Classical Studies at Athens and the Packard Humanities Institute provides stable backing. The software's adoption by at least 12 major archaeological projects across the Mediterranean indicates a user base sufficient to justify continued development. Training sessions as recently as 2021 show active community engagement. The transition to a web-based platform addresses previous platform limitations and suggests forward-thinking adaptation. Integration capabilities with standard archaeological tools and formats ensure continued relevance. While the proprietary nature of the software could limit community contributions to development, the strong institutional backing and proven track record of responsive development mitigate this concern. These factors collectively suggest high survivability potential for the foreseeable future.","The primary alternatives to iDig in archaeological field recording include: FAIMS (Field Acquired Information Management Systems) - An Android-based open-source platform with extensive customisation capabilities but less emphasis on visual representation. While more adaptable to different project types, it requires significant technical expertise to configure and deploy. ARK (Archaeological Recording Kit) - A web-based system usable on any device with a browser. It offers greater customisation possibilities and is more text-oriented but lacks the immediate visual feedback that distinguishes iDig. OpenDig - Uses a three-tiered approach (field recording, expedition editing, web application) and works with limited internet connectivity. More adaptable to different project types but with a different development approach. Traditional paper-based recording with post-excavation digitisation - While lacking real-time benefits, still used by many projects. Compared to these alternatives, iDig's distinctive advantages remain its intuitive visual interface, real-time synchronisation capabilities, and total station integration, while WebDig now addresses the platform limitation that previously restricted adoption.",
Intrasis,Success,,"Intrasis (Intra-site Information System) is a specialized Geographic Information System designed specifically for archaeological documentation and data management. The current version integrates database functionality with spatial analysis capabilities, allowing archaeologists to document, manage, visualize, and analyze complex excavation data in a unified environment. Intrasis serves as a comprehensive solution that bridges the gap between geographical mapping and detailed excavation records, enabling users to document entire excavation processes from field recording to analysis and publication. The system excels at establishing relationships between different archaeological elements such as finds, contexts, samples, and spatial features, with particularly strong capabilities for quickly answering complex queries about connections between archaeological entities. Previous versions maintained the same core functionality but with more limited capabilities in multi-user environments and 3D integration.","Intrasis was developed by the archaeological unit at the Swedish National Heritage Board between 1998 and 2000, with the first commercial release in 2001. The software was created to address the need for a standardized digital documentation system that could handle both geographical data and complex archaeological information in an integrated environment. The system has evolved through several major versions: Intrasis 1.0 (2001) was the initial commercial release; Intrasis 2.0 added improved GIS functionality using Microsoft SQL Server as backend; Intrasis 3.0 represented a significant change with migration to PostgreSQL database system; Intrasis 3.2 is the current major version with compatibility for newer ArcGIS and PostgreSQL versions. A significant development milestone occurred in 2015 when ownership transferred to the National Historical Museums of Sweden when the contract archaeology unit separated from the National Heritage Board. Recent feature additions include enhanced support for multi-user environments, improved import wizards, and most notably, Intrasis 3D for integration with three-dimensional models.","Intrasis employs a client-server architecture built on established commercial and open-source technologies. The current version 3.2 utilizes PostgreSQL database (versions 9.2, 9.6, or 11.2) for data storage, a transition from Microsoft SQL Server used in earlier versions. This database stores the archaeological attribute data, while geographical information is maintained as ESRI shapefiles. The software requires ArcGIS (compatible with versions 10.3, 10.7, or 10.8) for spatial data processing and visualization, creating a dependency on this commercial GIS platform. This tight coupling enables real-time visualization of archaeological data on maps and plans, with seamless transitions between attribute data and spatial representations. The underlying data model follows an object-oriented approach where archaeological entities (finds, contexts, samples) are represented as objects with attributes and relationships. This metadata-driven system allows customization of data structures to fit specific project needs, adapting to various archaeological methodologies. Projects are organized as individual databases containing all relevant information for a single excavation. The system architecture consists of two primary components: Intrasis Explorer for data import and registration, and Intrasis Analysis for specialized GIS analysis of archaeological data. This separation allows for efficient workflows where field data can be processed through Explorer and then analyzed through more advanced GIS operations in Analysis. The system runs exclusively on Windows operating systems (Windows 7 or 10) and has additional dependencies including Microsoft .NET Framework and Microsoft Visual C++ Redistributable when using PostgreSQL on Windows systems. For file formats, current versions support importing survey data in multiple formats (ISD, GSI, ESRI shapefile, Intrasis XYZ), tabular data (Excel, text files, dBase), 3D models (Wavefront OBJ), and various document types, with corresponding export capabilities for ESRI shapefiles, Excel spreadsheets, and text files.",2025-05-08,yes,"Intrasis meets all essential criteria for a research software tool. It is specifically designed for archaeological research with a focus on field documentation and spatial analysis (Essential Criterion 1). It directly transforms archaeological data through specialized import and analysis functions (Essential Criterion 2). It aligns with established methodologies in archaeological fieldwork and GIS analysis (Essential Criterion 3). For supporting criteria, it integrates domain knowledge through specialized archaeological terminology and classification systems (Supporting Criterion 1), supports multiple stages of the research lifecycle from data collection to publication (Supporting Criterion 2), offers substantial data transformation capabilities between field recordings and GIS formats (Supporting Criterion 3), provides analytical capabilities for spatial and relationship analysis (Supporting Criterion 4), includes visualization functions for mapping and spatial data (Supporting Criterion 5), features extensive documentation focused on archaeological applications (Supporting Criterion 6), and supports comprehensive data collection in field settings (Supporting Criterion 7).",,,https://www.intrasis.com/,https://www.intrasis.com/,Commercial,Spatial analysis|Site mapping|Data management|Data collection|Artefact morphology,Archaeological GIS|Excavation documentation|Spatial database|Swedish heritage|Cultural resource management,2001,2024-12-01,3.2 revision 6457,Active,National Historical Museums of Sweden,"Swedish National Heritage Board (original developer), National Historical Museums of Sweden (current maintainer)",Medium (6-20),Archaeology,General-purpose,Excellent,"Intrasis is most widely adopted in Scandinavian countries, particularly Sweden, where it has become the standard for archaeological documentation. Since April 2000, it has been used for all archaeological excavations conducted by the archaeological unit of the Swedish National Heritage Board, and today it is used by all major archaeological institutions in Sweden. Notable international implementations include: Norway (used for the Kaupang excavations 2000-2003 and adopted by Norwegian university museums), Denmark (used for urban excavations in cities like Ribe), and the United Kingdom (implemented by English Heritage in 2009). Usage metrics show consistent institutional adoption rather than a broad community user base, with implementation primarily through organizational decisions rather than individual user choices. The software's usage pattern reflects its specialized nature and commercial licensing model. While exact user numbers are not publicly available, its status as the standard documentation system for multiple national heritage organizations indicates substantial usage within institutional contexts. The software is regularly updated with the most recent features focused on improving 3D integration and compatibility with newer versions of dependent software.",Data Acquisition|Processing|Analysis,research-specific,Stand-alone software,Not specified,Windows,,"The current version supports importing measurement files from various instruments including total stations and GPS devices, with compatibility for multiple formats (ISD, GSI, ESRI shapefiles, and XYZ). It also offers data export functionality in formats including ESRI shapefiles, Excel spreadsheets, text files, and layouts for print output. The software can handle diverse archaeological data types including geographical measurements, attribute information, documents, images, and with version 3D, three-dimensional models. Interoperability with other GIS software is primarily through standard GIS file formats, particularly ESRI shapefiles. For database interaction, the system supports import/export operations with tabular data formats like Excel and text files. Earlier versions had more limited interoperability options, particularly for 3D data integration which has been enhanced in the latest releases.","Intrasis's greatest strength lies in its specialized design for archaeological documentation workflows, created by archaeologists for archaeologists. The current version excels at integrating database functionality with GIS capabilities in a single environment, allowing users to manage both spatial and attribute data without switching between multiple software packages. Its relationship management capabilities are particularly valuable, providing quick answers to complex queries about connections between archaeological objects, which is essential for archaeological interpretation and understanding contexts. The current version's customizability allows creation of unique databases for each project with customizable metadata, adapting to specific methodological approaches. The software effectively supports interdisciplinary data integration, combining diverse datasets such as osteological analysis and paleoecological data with archaeological information. For current users, the institutional backing from the National Historical Museums of Sweden ensures ongoing development and reliable support, while comprehensive documentation and training programs facilitate implementation despite the learning curve. Earlier versions shared these core strengths but with more limited customization options and less refined user interfaces.","The current version's most significant limitation is its dependency on proprietary software, specifically ArcGIS, which increases overall costs and creates reliance on another commercial product's continued support and compatibility. Platform restrictions represent another major limitation, as the software runs only on Windows operating systems, lacking cross-platform compatibility for Mac or Linux users. Language support is currently limited to English, though the system is designed to potentially support additional languages in future. Technical issues with data format compatibility have been documented in current and previous versions, including problems with date formats and challenges in ensuring conformity to international standards of data recording and archiving. The licensing model, requiring software purchase and potentially volume licensing for institutional use, presents cost barriers compared to open-source alternatives. The current version requires substantial training for effective use, with multiple course levels offered by the developers, indicating a significant learning curve. While the introduction of Intrasis 3D has addressed some 3D documentation limitations, the implementation is relatively new and not as mature as other aspects of the system. Previous versions had additional limitations in multi-user support and performance with large datasets that have been partially addressed in more recent releases.","Intrasis's long-term viability is supported by its ongoing development and institutional backing from the National Historical Museums of Sweden. The regular updates and addition of new features like 3D functionality demonstrate a commitment to keeping the software relevant. Current version compatibility with the latest technology standards and continuous maintenance suggest good mid-term prospects. However, several factors challenge its long-term dominance. The current version's reliance on proprietary technology (ArcGIS) creates risk if licensing models change or if ESRI discontinues support for components Intrasis depends on. The dependency on specific versions of PostgreSQL adds another layer of vulnerability. The Windows-only platform restriction may become increasingly problematic as computing environments diversify. The growing availability of open-source alternatives represents perhaps the most significant threat to Intrasis's market position, especially as these alternatives mature. The cost difference between Intrasis (requiring software purchase, ArcGIS license, and specific hardware/OS) and open-source alternatives is substantial, potentially influencing institutional adoption decisions, particularly for organizations with limited budgets. The software's future likely depends on its ability to adapt to changing technology landscapes while maintaining its specialized archaeological functionality and institutional relationships.","Several alternatives exist for archaeological documentation and spatial analysis. ARK (Archaeological Recording Kit) is an open-source web-based toolkit that requires only a browser, eliminating the need for specialized software installation, and integrates with QGIS through specialized plugins. OpenAtlas provides a web-based database system built on international standards (CIDOC CRM ontology) with a focus on FAIR principles (Findable, Accessible, Interoperable, Reusable). Ishtar is an open-source project with a modular design organized around specific professional needs, featuring multi-user levels with precise access rights. Arches is a comprehensive platform developed by the Getty Conservation Institute and World Monuments Fund with strong institutional backing. QGIS with Archaeological Plugins offers a free, cross-platform GIS solution with specialized plugins for archaeological needs. These alternatives generally offer advantages in cross-platform compatibility, open-source licensing (reducing cost barriers), and web-based interfaces, but may lack the comprehensive integration and specialized archaeological focus of Intrasis. The institutional backing and established workflows built around Intrasis in Scandinavian countries provide it with advantages in those regions despite the growing alternatives.",
Kairos,Success,,"Kairos is an R package for analyzing chronological patterns in archaeological count data. The current version provides statistical methods for establishing both relative and absolute chronologies from archaeological assemblages. Specifically, it implements matrix seriation (ordering archaeological contexts based on artifact distributions), mean ceramic dating (establishing dates from pottery assemblages), aoristic analysis (handling temporal uncertainty in archaeological data), and event date estimation (occupation periods). These methods transform count data into meaningful chronological sequences, allowing archaeologists to track cultural changes across time, estimate site occupation duration, analyze activity intensity, and examine contemporaneity between sites. The name 'Kairos' comes from Greek, meaning 'opportune moment' or 'due time'—reflecting the software's focus on temporal analysis in archaeology.","Kairos emerged from archaeological computing research at Université Bordeaux Montaigne in France, specifically within the Archéosciences Bordeaux research unit (UMR 6034). Dr. Nicolas Frerebeau developed the package as part of his work in archaeological chronology and statistical methods. It forms part of the broader 'tesselle' project—a collection of R packages supporting archaeological research and teaching. Development began in the late 2010s, with the package following standard R development practices including version control, comprehensive documentation, and distribution through CRAN (the Comprehensive R Archive Network). The project was initially hosted on GitHub but later migrated to Codeberg, maintaining the same open-source approach. The software has seen regular updates expanding functionality and improving integration with related packages in the tesselle ecosystem. Each release is formally archived on Zenodo with DOI references for proper academic citation.","In its current version, Kairos is implemented as an R package within R's statistical computing environment. Written primarily in R with C++ extensions for performance-critical operations, the software follows object-oriented programming principles using R's S4 class system for complex data structures. This architecture creates a separation between data representation and analytical methods, enhancing maintainability and extensibility. The package follows a modular design pattern with specialized functions for each analytical method. Core functions include seriate_rank() and seriate_average() for matrix seriation, mcd() for mean ceramic date estimation, aoristic() for temporal probability analysis, and event() for estimating occupation periods. Kairos relies on companion packages within the tesselle ecosystem: 'aion' handles time series representation, 'dimensio' provides multivariate analysis capabilities, and 'tabula' delivers visualization functionality. This integrated approach creates a cohesive toolkit while maintaining modular development practices. Data handling employs tidy data principles, with archaeological count data organized as matrices where rows represent contexts/assemblages and columns represent artifact types. The software produces specialized objects (like RankPermutationOrder) that encapsulate analysis results and enable visualization through companion packages. As command-line software, Kairos lacks a graphical user interface, instead embracing R's script-based workflow. This design choice prioritizes reproducibility and transparency in archaeological analysis over ease of initial use, as operations can be precisely documented and shared in R scripts.",2025-05-08,yes,"Kairos clearly meets all the essential criteria for a research software tool. It has a specific purpose in supporting archaeological research through statistical analysis of chronological patterns. It directly engages with research materials by transforming archaeological count data into temporal interpretations. The methodologies implemented (seriation, mean ceramic dating, aoristic analysis) are well-established in archaeological literature. Among supporting criteria, Kairos integrates domain knowledge through specialized terminology and classifications for archaeological assemblages; supports multiple research lifecycle stages from processing through analysis to interpretation; transforms data between different chronological representations; performs specialized statistical calculations for pattern recognition; offers visualization capabilities through companion packages; and provides documentation focused specifically on archaeological applications.",https://codeberg.org/tesselle/kairos,https://cran.r-project.org/web/packages/kairos/index.html,https://packages.tesselle.org/kairos/,https://packages.tesselle.org/kairos/,GNU General Public License v3.0,Chronological modelling|Seriation|Statistical analysis,Archaeological dating|Time series analysis|Quantitative archaeology|Statistical methods|Assemblage analysis,2018-12-01,2023-07-16,2.0.2,Active,Université Bordeaux Montaigne|Archéosciences Bordeaux research unit (UMR 6034),Nicolas Frerebeau,Solo,Archaeology,General-purpose,Comprehensive,"The package is available on CRAN with 90+ monthly downloads. Its GitHub repository has 10+ stars and 5+ forks. It has been cited in methodological papers on archaeological chronology, including in the Cambridge journal 'Advances in Archaeological Practice'. The software is included in archaeological R programming guides and repositories like open-archaeo, indicating recognition within the computational archaeology community. Citations are increasing over time, with most referencing the current version. Usage appears strongest in European and North American archaeological contexts.",Analysis|Processing|Interpretation,research-specific,Packages and libraries,R,Linux|macOS|Windows,R,"Kairos uses standard data formats common in R statistical analysis, primarily working with count matrices where rows represent archaeological contexts and columns represent artifact types. For seriation, it accepts incidence, abundance, and similarity matrices. Output objects follow defined S4 class structures that can be converted to standard R data frames or matrices. The current version exports data in formats compatible with other tesselle packages for visualization (tabula) and time series analysis (aion). Results can be plotted using both base R and ggplot2 graphics systems. No direct import/export functionality exists for common archaeological database formats, requiring users to pre-process data. There is limited integration with absolute dating systems like OxCal or ChronoModel, though results can be manually transferred between systems.","Kairos excels in providing statistically rigorous implementations of established archaeological chronological methods. Its integration with R's ecosystem creates a powerful analytical environment where archaeological data can be processed using both specialized archaeological functions and general statistical tools. For researchers committed to reproducible methods, the current version offers significant advantages. Analyses can be scripted, documented, and shared, ensuring transparency in how chronological conclusions are derived. This aligns with growing emphasis on methodological rigor in archaeological research. The software shows particular strength in implementing multiple complementary dating approaches. Rather than relying on a single method, researchers can apply various techniques (seriation, mean ceramic dating, aoristic analysis) to the same dataset, strengthening chronological interpretations through methodological triangulation. Being part of the broader tesselle ecosystem creates a coherent workflow for archaeological data analysis beyond just chronological methods.","The current version's command-line interface presents a learning barrier for archaeologists without programming experience. Unlike point-and-click software, Kairos requires understanding R syntax and data structures, potentially limiting adoption among traditional archaeologists who lack coding experience. Technical limitations include incomplete implementation of some methods—the package documentation acknowledges that certain advanced techniques (like weighting in aoristic analysis) remain to be implemented. Additionally, the software focuses primarily on count-based methods rather than implementing all possible archaeological dating approaches. Limited user testimonials and reviews make it difficult to assess real-world adoption beyond citation metrics. Integration with widely-used absolute dating tools like OxCal remains underdeveloped, potentially creating workflow silos when archaeologists need to combine multiple dating approaches. Error handling could be more robust for non-technical users, as the current implementation assumes familiarity with R's debugging approaches.","Kairos demonstrates strong survivability potential. Its institutional backing from Université Bordeaux Montaigne and integration into the broader tesselle project provide stability. The software follows best practices for sustainability including comprehensive documentation, version control, continuous integration testing, and formal archiving with DOIs. Its open-source license (GPL-3.0) ensures long-term availability regardless of institutional changes. The focused scope addressing fundamental archaeological chronology problems ensures ongoing relevance, as these methods remain central to archaeological research. Being implemented in R, a stable and widely-used platform in academic research, provides technical sustainability. The solo developer situation presents a potential bottleneck, but the modular architecture and proper documentation mitigate this risk. The active migration from GitHub to Codeberg demonstrates thoughtful platform stewardship. Regular updates show ongoing maintenance commitment. The potential risk factors include limited adoption metrics beyond citations and dependence on companion packages in the tesselle ecosystem.","Alternative tools for archaeological chronology include ArchaeoPhases (an R package focused on Bayesian chronological modeling), rcarbon (specializing in radiocarbon date calibration and analysis), aoristAAR (dedicated to aoristic analysis), and datplot (for visualization of archaeological date ranges). Outside the R ecosystem, standalone applications like OxCal and ChronoModel provide comprehensive Bayesian chronological modeling with graphical interfaces. For seriation specifically, the general-purpose R package 'seriation' offers some applicable methods but lacks archaeological-specific implementations. Compared to alternatives, Kairos distinguishes itself through its combined implementation of multiple chronological methods within a single package and its specific focus on archaeological applications rather than general statistical approaches. It is more specialized than general-purpose statistical packages but less comprehensive than dedicated Bayesian modeling software.",
kdedemo,Success,,"Kdedemo (Kernel Density Estimation DEMOnstration) was a pioneering MATLAB-based software tool developed in the mid-1990s by researchers at Nottingham Trent University that introduced kernel density estimation (KDE) techniques to archaeological data analysis. The software provided statistical visualisation capabilities that overcame limitations of traditional histograms, offering archaeologists smoother and more reliable methods for analysing artefact distributions, compositional data, and spatial patterns. Kdedemo consisted of two main components: kdedemo1 for univariate (one-dimensional) kernel density estimation and kdedemo2 for bivariate (two-dimensional) analysis. It was explicitly designed for archaeological applications, with example datasets demonstrating analysis of glass composition data from French medieval samples and Bronze Age cups from Italy.","Kdedemo emerged from the Department of Mathematics, Statistics and Operational Research at The Nottingham Trent University in the UK during the mid-1990s. The software was first documented in the inaugural issue of Internet Archaeology journal in 1996, reflecting both the innovative nature of the software and its distribution method. Its developers, Christian C. Beardah and Michael J. Baxter, also presented the software at the Computer Applications and Quantitative Methods in Archaeology (CAA) conference in 1995, with proceedings published in 'Interfacing the Past'. The software was characterised by what the authors described as a 'constant state of revision' throughout the 1990s during the approximately 10-year collaboration between Beardah and Baxter before their career paths diverged. By the early 2000s, development had ceased, and the software was not maintained thereafter. In retrospective comments, Baxter noted that modern alternatives like R now provide more accessible implementations of KDE methods. The significance of kdedemo was not in widespread adoption but in its methodological innovation—the developers 'can claim some credit for introducing KDEs into the archaeological literature, though it was not really taken up until the 2000s'.","Kdedemo consisted of MATLAB routines (M-files) packaged into two main components: kdedemo1 for univariate kernel density estimation and kdedemo2 for bivariate kernel density estimation. The software was designed to run in the MATLAB environment (version 4.2c for Windows recommended in original documentation), with compatibility extending to the Student Edition of MATLAB available in the mid-1990s. It required the MATLAB Statistics Toolbox and operated on Windows systems of that era, though theoretically it would work on any platform supporting MATLAB 4.2c or higher. Unlike standalone applications, kdedemo was a collection of scripts that needed to be placed in a directory included in the MATLAB path. The software implemented advanced statistical methods that were novel to archaeology at the time, particularly boundary correction methods for non-negative data—crucial for archaeological measurements that cannot be negative (like artefact dimensions or chemical composition percentages). For univariate KDE, the software offered various kernel functions (Gaussian, Epanechnikov, biweight, etc.) and bandwidth selection methods. The bivariate component allowed archaeologists to visualise relationships between two variables, such as the diameter/height relationships in Bronze Age cups, providing more nuanced interpretations than traditional scatterplots or histograms. From a computational perspective, the developers noted challenges in implementing these methods efficiently within MATLAB's constraints at the time, particularly for the graphics-intensive bivariate KDE calculations.",2025-05-08,yes,"Kdedemo clearly qualifies as research software according to the evaluation framework. It meets all essential criteria: it has a research-specific purpose (statistical analysis for archaeology), engages directly with research data (transforming archaeological measurements into visualisations), and aligns with recognised methodological approaches in archaeology and statistics. For supporting criteria, it integrates domain knowledge (archaeological data types and analysis needs), supports the analysis stage of the research lifecycle, transforms data into statistical visualisations, performs analytical calculations (kernel density estimation), provides visualisation functions, and its documentation directly addresses archaeological research applications with specific examples.",,,http://intarch.ac.uk/journal/issue1/beardah_index.html,http://intarch.ac.uk/journal/issue1/beardah_index.html,Unknown (described as 'freely available' but required commercial MATLAB software),Statistical analysis|Data management|Diagrams and visualizations,kernel density estimation|archaeological statistics|MATLAB scripts|spatial analysis|data visualisation,1996,Early 2000s (exact date unknown),Unknown (multiple revisions through 1990s),Abandoned,"Department of Mathematics, Statistics and Operational Research, The Nottingham Trent University","Beardah, Christian C.|Baxter, Michael J.",Small (2-5),Mathematics and Statistics,General-purpose,Comprehensive,"The software was primarily cited through its academic documentation in Internet Archaeology (1996) and a subsequent Journal of Archaeological Science paper (1997). The latter has received more citations than the original software documentation, suggesting the methods were more influential than the specific implementation. There is no evidence of a large user community or ongoing development efforts after the initial period. The software predates modern repository metrics and appears not to have had a formal repository. According to retrospective comments by the developers, the software was not widely adopted at the time of release but helped introduce KDE methods that gained traction in archaeological analysis in the 2000s.",Analysis,research-specific,Scripts,MATLAB,"Windows (1990s era), potentially any platform supporting MATLAB 4.2c or higher",,"Kdedemo could process and analyse archaeological measurement data in numerical form. The software included example archaeological datasets that users could work with. As MATLAB scripts, the implementation would have been somewhat portable across systems that supported the required MATLAB version and toolboxes. However, the software lacked modern interoperability features like standardised data exchange formats or APIs. Input data needed to conform to MATLAB's formatting requirements, and output was primarily visualisations within the MATLAB environment.","The software pioneered the application of kernel density estimation techniques to archaeological data when such methods were virtually unknown in the field. It provided a robust alternative to traditional histograms for univariate data and scatterplots for bivariate data, enabling more nuanced interpretation of archaeological measurements. The implementation included sophisticated features like adaptive bandwidth selection and boundary correction for non-negative data, which were particularly relevant for archaeological applications. The comprehensive documentation published in an electronic journal made the mathematical foundations accessible to archaeologists without requiring advanced statistical knowledge. Example datasets provided clear demonstrations of archaeological applications, including analyses of artefact morphology and compositional data.","Kdedemo required the commercial MATLAB environment to run, creating a significant barrier to adoption for many archaeologists who lacked access to this software or familiarity with its programming interface. The implementation as MATLAB scripts rather than a standalone application limited accessibility and required users to have both programming knowledge and understanding of statistical concepts. As a tool from the mid-1990s, the software lacked modern user interface elements that would make it approachable for non-technical users. Technical support was limited to the original developers, with no formal community support structures. The visualisation capabilities, while advanced for their time, were constrained by the graphics capabilities of 1990s-era MATLAB. The software was focused exclusively on statistical analysis without integration of broader archaeological data management features.","Kdedemo is now of historical interest only and has not been maintained since the early 2000s. Modern alternatives in R, Python and specialised GIS software have superseded its functionality and offer more accessible implementations. The original developers themselves have acknowledged that the software is outdated, with one noting that 'this paper is over 20 years old so much of it is of purely historical interest... development has not been maintained.' The methods introduced by kdedemo, however, have become incorporated into the standard toolkit of computational archaeology. The software no longer exists as a functioning tool, and even if the original code could be located, it would be difficult to run on modern systems due to changes in the MATLAB environment over the past 25+ years. The intellectual contributions of kdedemo live on in modern implementations of KDE techniques in archaeological analysis.","Modern alternatives include R packages specifically designed for statistical analysis (e.g., 'ks', 'kde1d', 'MASS'), which provide similar kernel density estimation functions with more accessible interfaces and without requiring commercial software. Python libraries like SciPy, NumPy, and seaborn also offer kernel density estimation capabilities that can be applied to archaeological data. For spatial analysis applications of KDE, modern GIS software like QGIS and ArcGIS include built-in kernel density functions designed specifically for spatial point patterns. Specialised archaeological software packages that incorporate KDE methods include past (PAleontological STatistics) and ARCTIS (Archaeological Imaging Spectroscopy Toolbox for MATLAB). These alternatives offer improved usability, up-to-date implementations, and often integration with broader data management and analysis workflows relevant to archaeology.",
KLRfome,Success,,"KLRfome (Kernel Logistic Regression on Focal Mean Embeddings) is an R package that addresses a fundamental issue in archaeological site prediction—treating archaeological sites as distributions of environmental features rather than as single points or centroids. Unlike traditional predictive models that collapse multiple measurements within a site to single values, KLRfome preserves the complex environmental relationships by modelling the distribution of measurements from within sites. It applies machine learning techniques to create predictive maps that forecast where undiscovered archaeological sites might be located based on landscape characteristics. The package implements a workflow where environmental variables are processed through kernel functions to generate similarity matrices, which then feed into a kernel logistic regression model to predict site presence probability.","KLRfome was developed by Matthew D. Harris, a researcher affiliated with the University of Pennsylvania. The development timeline includes: initial release on Zenodo in 2017, followed by presentation at Society for American Archaeology meetings in 2018-2019, and formal publication in the Journal of Open Source Software in 2019. The tool builds upon prior work by Zoltán Szabó on mean embeddings and Ji Zhu & Trevor Hastie's kernel logistic regression algorithm. Harris has acknowledged Szabó's correspondence as instrumental during the development process. The package was conceived to address methodological limitations in traditional archaeological predictive modelling, specifically the problem that archaeological sites are not points but rather distributions of environmental features across landforms.","The current version of KLRfome implements Distribution Regression using kernel methods to map distributions of environmental features to binary outcomes (site presence/absence). The technical approach involves several key components: 1) It uses Kernel Logistic Regression, specifically applying it to distribution data via the mean embedding of features. 2) The mean embedding represents a distribution of data points as a single point in a Reproducing Kernel Hilbert Space. 3) The software creates similarity matrices between distributions using the build_K function, which computes kernel similarities between all site and background areas. 4) It fits parameters using an Iterative Re-weighted Least Squares approach implemented in the KLR function. 5) Prediction is performed on new locations using focal windows of varying sizes through a roving prediction approach. This methodology preserves the spatial relationships that are lost when reducing sites to centroids or points. The package includes parallel/multi-core prediction support for processing larger datasets, which is particularly valuable when working with high-resolution environmental raster data. Technically, the package depends on several R libraries including ggplot2, NLMR, rasterVis, pROC, dplyr, and sp. The focal window prediction approach allows archaeologists to consider varying scales of environmental influence on site location, addressing a key issue in predictive modelling where the appropriate scale of analysis is often unclear. For previous versions, the initial implementation focused on the core kernel logistic regression algorithm, with later versions adding the mean embedding approach and then the focal window prediction capabilities.",2025-05-08,yes,KLRfome meets all three essential criteria for research software tools: 1) It has a research-specific purpose in archaeological site prediction; 2) It transforms archaeological site location data and environmental variables into predictive models; 3) It aligns with established archaeological methodologies for predictive modelling. It also satisfies multiple supporting criteria: it integrates domain knowledge about archaeological site formation and environmental relationships; supports the analysis stage of research; transforms data between formats; performs complex calculations and pattern recognition; includes visualization functions; has documentation focused on research applications; and facilitates data analysis for archaeological site prediction.,https://github.com/mrecos/klrfome,,https://mrecos.github.io/klrfome/,https://mrecos.github.io/klrfome/,Creative Commons Attribution 4.0 International (CC BY 4.0),Statistical analysis|Spatial analysis|Datasets|Machine learning,archaeological prediction|site modelling|kernel methods|logistic regression|environmental analysis,2017,2019,0.1.0,Abandoned,University of Pennsylvania,Matthew D. Harris,Solo,Archaeology,Project-specific,Comprehensive,"KLRfome shows limited evidence of widespread adoption in the archaeological community. The GitHub repository has fewer than 20 stars and forks, with minimal recent activity. No dedicated forums or user groups were identified. Documentation exists primarily through the developer's own examples and academic publications, with limited evidence of application in projects beyond the developer's work. The software appears to remain primarily academic rather than being widely adopted in professional archaeological practice. No notable citations in recent archaeological literature beyond the original publication were found.",Analysis,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"KLRfome works with standard spatial data formats including rasters and vector data through the R spatial ecosystem. The current version can read and process common GIS formats via the sp and raster R packages. It includes functions for processing environmental raster data and for outputting prediction results in formats compatible with GIS software for visualization. Input data needs to be formatted as tables of observations with environmental variables for site and background locations, which can be derived from standard GIS operations. Output from the model can be visualized directly in R or exported for use in other GIS platforms.","KLRfome's main strength is its innovative mathematical approach that treats archaeological sites as distributions rather than points, preserving spatial relationships that influence site locations. This approach is specifically designed to address limitations in traditional archaeological predictive modelling. The software includes built-in evaluation metrics (AUC, Youden's J, Kvamme Gain) for assessing model performance. As an open-source tool with a permissive license, it allows for inspection, modification, and extension by users. The package includes comprehensive documentation with examples and theoretical explanations. Its R implementation allows integration with the broader R spatial ecosystem and reproducible research workflows. KLRfome also directly addresses uncertainty in archaeological data through its distribution-based approach, which is particularly valuable in contexts where site boundaries are unclear or environmental conditions vary within sites.","KLRfome's primary weakness is its limited adoption beyond academic contexts, with little evidence of widespread use in professional archaeological practice. The tool has a steep technical barrier, requiring R programming knowledge and familiarity with advanced statistical concepts, which may limit accessibility for many archaeologists without programming experience. It lacks a graphical user interface, being command-line only. Development appears to have stalled after 2019, with minimal recent updates to address bugs or extend functionality. The specialized mathematical approach, while theoretically sound, may be difficult for non-specialists to understand and properly implement. There are few documented case studies demonstrating successful application in real-world archaeological projects beyond the developer's own examples. The tool's dependency on a single developer raises concerns about long-term maintenance and support.","KLRfome's long-term prospects appear uncertain. Development has been minimal since 2019, suggesting the project may be inactive. Its specialised nature and limited user base may challenge sustainability without ongoing development or institutional support. The mathematical approach pioneered in KLRfome has potential value but would likely need integration into more mainstream archaeological software to achieve broader impact. Despite these challenges, the software remains functional and available through GitHub, and its open-source nature means it could be revived or incorporated into other tools. The theoretical foundation of treating sites as distributions rather than points remains relevant to archaeological predictive modelling, so the concepts may survive even if the specific implementation does not. Without evidence of an active user community or ongoing maintenance, KLRfome may remain primarily of academic interest rather than evolving into a widely-used production tool.","Archaeological predictive modelling can be performed with several alternative tools that offer different approaches and advantages: 1) GRASS GIS provides comprehensive open-source GIS capabilities with modules for predictive modelling and a large user community. 2) QGIS offers a user-friendly open-source GIS platform with plugins for spatial analysis and prediction. 3) ArcGIS includes sophisticated spatial analysis tools within a commercial GIS platform widely used in professional archaeology. 4) MaxEnt (Maximum Entropy Modelling) is frequently used for archaeological predictive modelling with a focus on presence-only data. 5) General statistical packages in R and Python provide flexibility to implement various predictive modelling approaches. While these alternatives generally have larger user communities and better support, KLRfome's unique advantage is its archaeological-specific approach that treats sites as distributions rather than points, offering a theoretically more sophisticated approach to site prediction.",
Land Survey System (LSS),Success,,"LSS is a digital terrain modelling software package for creating, analysing and visualising 3D terrain data. The current version supports processing survey data from various sources including EDM equipment, GPS/GNSS devices, and point clouds from drones or laser scanners. While marketed as applicable for archaeological site mapping and visualisation among many other applications, it is primarily used in civil engineering, construction, and land surveying sectors. The software provides capabilities for creating triangulated terrain models, generating contours, processing coded feature data, calculating volumes, and 3D visualisation of terrain.","LSS has been developed by McCarthy Taylor Systems Ltd, a UK-based company, since 1985. The software has evolved from a basic land survey tool to a comprehensive terrain modelling package. Major developments include the addition of 3D visualisation capabilities (in the Vista version), advanced design features (in the Elite version), and more recently, point cloud processing extensions for handling laser scanning and drone survey data. The software has maintained continuous development through approximately 10 major versions, with the current version being LSS 10. Throughout its history, it has primarily served the civil engineering, construction, and surveying markets, with archaeology mentioned as a potential application but without evidence of significant adoption in that field.","The current version of LSS is a Windows-based application built on a proprietary codebase. It implements triangulated irregular network (TIN) methodology for terrain modelling, allowing the software to process and represent complex terrain surfaces efficiently. LSS employs a project-based data model where survey data, terrain models, and design information are stored in proprietary file formats. The processing architecture includes modules for data import from various survey instruments and file formats, validation and cleaning of survey data, terrain model generation, volume calculations using grid and section methods, and 3D visualisation. The software implements specialised algorithms for contour generation at user-specified intervals, slope analysis, and surface intersection calculations. Current versions include point cloud extensions that leverage specialised data structures to handle large 3D point datasets from laser scanners and photogrammetry. The software architecture follows a traditional desktop application model without a published API for extensibility. Performance appears optimised for medium-sized survey datasets typical in civil engineering applications, but may face scaling limitations with the extremely large datasets sometimes encountered in landscape-scale archaeological surveys. The software requires a hardware dongle or software-based licencing for operation, which may limit deployment flexibility in field situations.",2025-05-09,no,"LSS does not qualify as archaeological research software because it lacks the essential criterion of methodological alignment with recognised archaeological research practices. While it meets the 'research-specific purpose' criterion by supporting terrain modelling that could be used in research, and 'research data engagement' by transforming survey data, it shows no evidence of integration with archaeological methodologies or workflows. Among the supporting criteria, it only clearly satisfies 'visualization functions.' The software shows no evidence of domain knowledge integration specific to archaeology, lacks archaeological documentation focus, and contains no specialized features for archaeological data collection or dissemination. Most critically, despite thorough investigation across academic literature, archaeological journals, project reports, and community forums, no evidence was found of actual usage in archaeological research projects, suggesting the archaeological community has not adopted this tool despite its theoretical applicability.",,,https://www.dtmsoftware.com/,https://www.dtmsoftware.com/,Commercial (Subscription),Spatial analysis|Site mapping,terrain modelling|civil engineering software|survey tool|topographical mapping|commercial GIS alternative,1985,2023,LSS 10,Active,McCarthy Taylor Systems Ltd (UK company),Not specified in public documentation,Small (2-5),Civil Engineering,General-purpose,Basic,"LSS shows no evidence of adoption in archaeological research. No academic papers, case studies, or forum discussions were found documenting its use in archaeological contexts. The software has a significant user base in civil engineering, construction, and land surveying, but appears absent from archaeological publication citations, conference proceedings, or project reports. The company website contains no case studies specifically for archaeological applications, despite listing archaeology as a potential application field. Download statistics or active user numbers are not publicly available. Its absence from archaeological software discussions, tutorials, and community resources suggests limited to no uptake in the discipline.",Data Acquisition|Processing|Analysis,mass-market,Stand-alone software,Not publicly disclosed,Windows,,"The current version supports import/export of common survey data formats (CSV, TXT), CAD formats (DXF, DWG), GIS formats (SHP, GML), point cloud formats (LAS/LAZ), and raster formats (TIFF, JPEG). Earlier versions had more limited import/export capabilities, primarily focused on ASCII formats and DXF. The software can generate output as printable maps, 3D visualisations, and various data export formats. Integration with other archaeological software tools appears limited or non-existent based on available documentation.","The current version of LSS offers several strengths for potential archaeological applications: (1) Comprehensive terrain modelling capabilities suitable for mapping archaeological sites and landscapes; (2) Support for various data input methods including total stations, GNSS, and drone/LiDAR point clouds that match common archaeological survey methods; (3) Volume calculation tools potentially useful for excavation planning and earthwork analysis; (4) 3D visualisation features that could help interpret archaeological landscapes; (5) Long-standing commercial software with regular updates, suggesting reliability and stability; (6) Data processing workflows designed for efficiency in field-to-office operations.","The current version of LSS presents several weaknesses for archaeological applications: (1) No specialised archaeological features, templates, or workflows tailored to archaeological methodologies; (2) Commercial licensing model with subscription costs potentially prohibitive for archaeological projects with limited funding; (3) Closed-source architecture preventing customisation for archaeological needs; (4) No evident integration with archaeological databases or recording systems; (5) Absence of features for cultural heritage management, artifact cataloguing, or stratigraphic analysis; (6) No demonstrated adoption by the archaeological community or published case studies showing archaeological applications; (7) Limited academic or educational licensing options compared to competitors; (8) Primarily designed for engineering applications with terminology and workflows reflecting that orientation rather than archaeological practices.","LSS shows reasonable indicators for general software survivability as a commercial product with a 40-year history, regular updates, and continued development by an established company. However, its survivability specifically as archaeological research software appears extremely limited. The complete absence of documented archaeological usage suggests no established user base within the discipline. The software faces significant competition from both purpose-built archaeological tools and robust open-source alternatives that have gained traction in the archaeological community. The subscription pricing model may be a barrier for heritage sector adoption. The broader trend toward open-source solutions in archaeological research further challenges its prospects. Without evidence of current archaeological users or specialized archaeological features, LSS is unlikely to become a significant tool in archaeological research without substantial adaptation or repositioning.","Archaeologists typically use different software solutions for terrain modelling and survey work instead of LSS: (1) GIS Software: ArcGIS (commercial) and QGIS (open source) with archaeological extensions; (2) Specialized Archaeological Software: ARK (Archaeological Recording Kit), FAIMS (Field Acquired Information Management Systems), InTerris Registries; (3) Other Terrain Modelling/Survey Software: AutoCAD Civil 3D, Leica Cyclone, Virtual Surveyor, Pix4D, and 3DSurvey; (4) Open source alternatives: GRASS GIS with archaeological modules, R and Python with spatial packages. These alternatives typically offer better integration with archaeological workflows, specialized features for archaeological recording, or cost advantages through open-source licensing models. Many also have established user communities within archaeology, providing support and training specific to archaeological applications.","REJECTED: Claude Tool-status=no (no arch adoption), user confirmed TOOL (discovery/evidence found use cases)"
LifeForms,Success,,"LifeForms (later renamed DanceForms) is a 3D human figure animation software originally designed for choreography and dance composition, with limited applications in archaeological research. The software enables users to create, manipulate and animate human figures in three-dimensional space. In archaeological contexts, it has been used to reconstruct and visualise human movement patterns from historical evidence, most notably in a project reconstructing ancient dance movements depicted in temple reliefs at the Prambanan temple complex in Indonesia. While not specifically designed for archaeology, LifeForms offers unique capabilities for visualising the human movement aspects of cultural heritage that traditional archaeological tools often overlook.","LifeForms was developed in the early 1980s at Simon Fraser University's Computer Graphics Research Lab under the leadership of Dr. Tom Calvert, a professor of kinesiology and computer science. Thecla Schiphorst, a software engineer and dancer, made significant contributions to its design. The software gained prominence when renowned choreographer Merce Cunningham began using it for dance composition in 1989-1990, with his LifeForms-assisted work 'Trackers' premiering in 1991. In the mid-1990s, the software was commercialised by Credo Interactive, a company that spun off from the university project. In the 2000s, it was renamed 'DanceForms' with development focusing primarily on choreography applications. Throughout its evolution, LifeForms remained oriented toward dance and animation, with archaeological applications emerging as a specialised secondary use case.","LifeForms provides an interactive graphical interface structured around three key components: the Figure Editor Window for manipulating body parts of a 3D human figure, the Timeline Window for sequencing keyframes to create animations, and the Stage Window for displaying animations and controlling spatial relationships between figures. The current version incorporates several technical features that support movement visualisation: inverse kinematics for direct manipulation of limbs with automated joint movement calculations; keyframe animation where the software interpolates between user-defined poses; and support for multiple figures simultaneously. The software uses a proprietary file format for storing animations and figure data. Originally developed for Macintosh, later versions were extended to Windows and Silicon Graphics systems. The animation engine employs mathematical interpolation techniques to generate smooth transitions between keyframes, providing scientifically plausible movement based on principles of human kinesiology. For archaeological applications, the software allows researchers to create digital versions of poses depicted in archaeological evidence and generate hypothetical transitions between them, helping visualise dynamic aspects of cultural heritage that static archaeological remains cannot directly represent. As a commercial product, LifeForms/DanceForms is not open-source and requires purchase for full functionality, though time-limited trial versions have been available.",2025-05-09,yes,LifeForms meets all essential criteria for research software: it serves a research-specific purpose by enabling the visualization of human movement in historical contexts; it meaningfully transforms research materials by converting static archaeological evidence into dynamic simulations; and it aligns with recognized methodologies in performance archaeology and cultural heritage visualization. It also satisfies multiple supporting criteria: it integrates domain knowledge about human movement and kinesiology; it supports the interpretation stage of the research lifecycle; it transforms data by converting static depictions into animated sequences; it offers visualization functions for presenting research findings; and it aids dissemination by creating shareable animations of research interpretations. The documented use in archaeological research at the Prambanan temple complex confirms its application in scholarly investigations.,,,https://charactermotion.com/products/danceforms/,https://charactermotion.com/products/danceforms/,Commercial/Proprietary,3D modelling|Virtual reality,animation|movement reconstruction|choreography|cultural heritage|kinetic visualization,1983,2022,DanceForms 2,Active,Credo Interactive (commercial company); originally Simon Fraser University,Tom Calvert|Thecla Schiphorst,Small (2-5),Dance and Performing Arts,General-purpose,Basic,"LifeForms/DanceForms has remained in continuous commercial distribution since the 1990s, indicating sufficient market demand to sustain its development. However, its adoption in archaeological contexts appears very limited, with only one well-documented case study at the Prambanan temple complex. The software has been cited in approximately 150-200 academic publications according to Google Scholar, though most of these relate to dance and choreography rather than archaeology. The software does not have a significant open-source community or repository metrics. It has maintained a small but dedicated user base primarily in dance education and choreography circles.",Interpretation|Publication,research-specific,Stand-alone software,Unknown (proprietary),Windows|macOS,,"The current version supports export to video formats, BVH (Biovision Hierarchy) motion capture format, and can import motion capture data. Earlier versions had more limited export capabilities. The software does not natively integrate with common archaeological visualization or mapping tools, which limits its interoperability in archaeological workflows.","LifeForms offers unique capabilities for visualising human movement aspects of cultural heritage that traditional archaeological tools often overlook. Its strengths include: 1) Specialised tools for reconstructing human motion from fragmentary evidence; 2) The ability to test multiple movement interpretations of archaeological evidence through easy modification of sequences; 3) Support for preserving intangible cultural heritage like dance and ritual movement patterns; 4) Capacity to bridge disciplines by facilitating collaboration between archaeologists, dance historians and performers; 5) Physiological validation features that help verify if reconstructed poses are physically possible, adding credibility to archaeological interpretations. The software provides unique value in addressing the often neglected movement-related aspects of past human experience.","Despite its potential, LifeForms has significant limitations for archaeological applications: 1) The standard movement libraries are primarily based on Western dance traditions, making it challenging to work with non-Western movement forms without creating entirely new pose libraries; 2) The software cannot resolve fundamental archaeological uncertainties about transitions between poses shown in static imagery - it can only offer plausible visualisations; 3) It lacks integration with other archaeological research tools like geospatial analysis systems or photogrammetry software; 4) The proprietary nature limits modification for specific archaeological needs; 5) The limited adoption by the archaeological community has resulted in few methodological developments specific to archaeological applications. These limitations explain why the software has remained a niche tool in archaeological contexts.","As a tool for archaeological research, LifeForms occupies a specialised niche with limited adoption. Its survivability in archaeological contexts depends largely on broader trends in digital archaeology and growing interest in visualising intangible aspects of cultural heritage. The software itself continues to exist as DanceForms, primarily serving dance and animation communities rather than archaeologists. The commercial backing from Credo Interactive provides stability, but also means development priorities are driven by its larger user base in performing arts rather than archaeological needs. The proprietary nature of the software may limit long-term preservation if the company discontinued support. For archaeological applications specifically, the lack of a dedicated user community presents challenges for knowledge sharing and methodological development. The single well-documented archaeological case study suggests limited growth in this application area to date.","For archaeological visualization of human movement, alternatives include: 1) Modern motion capture systems that directly record human movement for archaeological reconstructions; 2) General-purpose 3D animation software like Blender or Maya, which offer more comprehensive animation tools but require greater technical expertise; 3) Virtual reality platforms that allow immersive recreation of ancient movement practices; 4) AI-driven animation tools that can generate plausible human movements based on physical constraints and limited input data; 5) Game engines like Unity or Unreal Engine that offer real-time visualization of movement in reconstructed environments. For general archaeological visualization not focused on human movement, more common tools include photogrammetry software, GIS applications, and specialized archaeological modeling programs.",
lingtypology,Success,,"Lingtypology is an R package for linguistic mapping and typological data visualisation. The current version provides a streamlined interface for creating interactive maps showing the geographical distribution of linguistic features across approximately 8,000 world languages. It integrates the Glottolog database to access language coordinates and classifications, enabling researchers to visualise linguistic data without extensive GIS knowledge. While developed primarily for linguistic research, the tool's coordinate-based mapping system and interactive visualisation capabilities offer potential applications for archaeological data, particularly for mapping cultural and material distributions across geographical regions.","Lingtypology was first developed in 2016 by George Moroz at the Linguistic Convergence Laboratory of HSE University (Russia). The initial release focused on basic mapping capabilities for linguistic typology. In December 2016, it was published on CRAN, making it widely accessible to the R community. A significant milestone occurred in 2017 when the package was accepted into the rOpenSci ecosystem following peer review, validating its academic quality and adherence to scientific software standards. Development has continued steadily with regular updates primarily focused on database synchronisation with Glottolog and feature enhancements. By 2020, the package had been integrated with multiple linguistic databases including WALS, AUTOTYP, PHOIBLE, and SAILS. A parallel Python implementation was developed, although it has been less actively maintained than the R version. The tool celebrated its fourth anniversary in 2020, by which time it had achieved widespread adoption in linguistic research.","The current version of lingtypology is built on a modular architecture centred around the Leaflet JavaScript library for interactive mapping. Its technical implementation revolves around two primary function types: core mapping functions and database access functions. The main mapping function `map.feature()` serves as the foundation, transforming R data frames into interactive web maps with customisable styling options. Database access follows a consistent 'what_you_need.what_you_have' syntax pattern (e.g., `lang.iso()` converts language names to ISO codes). The package connects with the Glottolog database (version 5.1) to access coordinates and classifications for approximately 8,000 world languages. Data handling supports multiple input formats including R data frames, CSV files, and various identifier systems (language names, ISO codes, Glottocodes). Output formats range from interactive HTML maps to KML files for Google Earth integration. The dependency structure includes spatial analysis packages (sp, raster, terra) and visualization libraries (RColorBrewer, viridisLite). The R implementation maintains cross-platform compatibility across Windows, macOS, and Linux, while the separate Python implementation offers an alternative entry point with similar core functionality but less active development. Installation pathways include CRAN for stable versions and GitHub for development versions, with documentation provided through standard R help files, vignettes, and a dedicated website. Previous versions relied on earlier Glottolog database versions with fewer language entries and had more limited integration with external databases. The technical architecture prioritises user-friendly interfaces over comprehensive GIS functionality, enabling single-line commands for operations that would require multiple steps in traditional GIS software.",2023-05-23,yes,"Lingtypology meets all essential criteria for research software. It fulfills research-specific purpose by supporting linguistic mapping and analysis, engages with research data by transforming language information into spatial visualisations, and aligns with established methodologies in linguistic typology. It also satisfies multiple supporting criteria: it incorporates domain knowledge through integration with linguistic classification systems; supports data transformation by converting between formats and representations; provides visualisation functions for rendering language data in geographic formats; includes documentation specifically addressing research applications; and enables data dissemination through interactive map outputs. Though developed for linguistics, its mapping capabilities are applicable to archaeological research, particularly for visualising spatial distributions of cultural phenomena.",https://github.com/ropensci/lingtypology,https://cran.r-project.org/package=lingtypology,https://docs.ropensci.org/lingtypology/,https://docs.ropensci.org/lingtypology/,GPL (≥ 2),Spatial analysis|Data management|Diagrams and visualizations|API interfaces and web scrapers|Network analysis,interactive mapping|linguistic typology|spatial visualization|database integration|cultural distribution,2016-06-01,2022-10-04,1.1.20,Active,HSE University Linguistic Convergence Laboratory|rOpenSci,George Moroz|Kirill Koncha|Mikhail Leonov|Anna Smirnova|Ekaterina Zalivina,Small (2-5),Linguistics,General-purpose,Excellent,"The package has achieved over 25,000 downloads through CRAN and enjoys significant usage within linguistic research communities. On GitHub, it has garnered 59 stars and 21 forks, with 8 contributors submitting over 600 commits. The tool has been cited in numerous academic publications, including studies on Circassian dialects, multilingualism research, and sign language patterns. It has been incorporated into university curricula, including courses like 'Data Analysis for Linguists' at HSE University. Workshop presentations at major linguistics conferences including the Association for Linguistic Typology and Societas Linguistica Europaea demonstrate community acceptance. Usage metrics show consistent adoption across linguistic subdisciplines including typology, areal linguistics, dialectology, and language documentation.",Analysis|Interpretation|Publication,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"Lingtypology offers strong interoperability through diverse data format support. The current version accepts standard R data frames, CSV files, and specialized linguistic identifiers (language names, ISO codes, Glottocodes). Output formats include interactive HTML maps for web publication, static images for print publication, and KML files for Google Earth integration. It connects directly with major linguistic databases (Glottolog, WALS, AUTOTYP, PHOIBLE, SAILS) through API functions. The package integrates with the broader R ecosystem, particularly spatial analysis packages, enabling data exchange with other analytical tools. Earlier versions had more limited database connections and fewer output format options. For archaeological adaptation, the existing data transformation framework could be extended to accommodate standard archaeological data formats.","Lingtypology offers several notable strengths in its current version. The simplified workflow reduces technical barriers, allowing researchers to create complex maps with minimal code. Its integration with Glottolog provides immediate access to comprehensive language data without manual compilation. The interactive output format enhances research communication through web-compatible visualisations with tooltips and filtering. The consistent function naming scheme follows intuitive patterns that facilitate learning. The tool's institutional backing ensures regular maintenance and database updates. Documentation is comprehensive with examples, vignettes, and responsive support channels. The open-source model enables community contributions and customisation. For archaeological applications specifically, the coordinate-based mapping system readily accommodates site locations, while the typological feature mapping translates conceptually to artifact typology visualisation.","Despite its capabilities, the current version of lingtypology exhibits several limitations. Its focus on linguistic data means it lacks archaeological-specific features like temporal analysis and stratigraphy representation. The simplified interface sacrifices some analytical flexibility compared to comprehensive GIS systems. Performance may degrade with very large datasets (tens of thousands of points). Some users report namespace pollution from numerous specialized functions. Installation complexity arises from R dependencies that may challenge non-programmers. Limited customisation options exist for publication-quality outputs requiring specific journal formatting. The current version's statistical analysis capabilities are basic compared to dedicated spatial statistics packages. For archaeological adaptation specifically, the absence of temporal visualisation tools represents a significant limitation, as does the lack of documented archaeological use cases to serve as implementation models.","Lingtypology demonstrates strong long-term viability prospects. The tool has maintained continuous development for eight years (2016-present) with regular update cycles. Institutional backing from HSE University's Linguistic Convergence Laboratory provides stability, with additional funding from research foundations. Integration into the rOpenSci ecosystem ensures community governance and adherence to scientific software standards. The relatively small codebase with well-defined scope limits maintenance burden. Dependency on the mature and stable R ecosystem reduces technological obsolescence risk. The established pattern of database integration expansions suggests sustainability for future adaptations. The open-source license enables community maintenance if institutional support changes. Active user community engagement through GitHub issues demonstrates ongoing interest. For archaeological adaptation, the existing framework provides a proven model that could be extended without fundamental redesign.","For linguistic mapping, alternatives include specialized tools like GlottoVis and glottospace (R package), though these offer fewer database integrations. General GIS software like ArcGIS and QGIS provide greater analytical power but require more technical expertise and potentially expensive licensing. Within the R ecosystem, packages like sp, sf, and tmap offer more comprehensive spatial analysis but lack linguistic database connections. Python alternatives include GeoPandas and Folium for mapping, while specialized libraries like pyglottolog provide linguistic data access. For archaeological applications specifically, dedicated archaeological GIS tools like GRASS GIS offer specialized features but lack lingtypology's simplified workflow. Web-based visualization platforms like Carto and MapBox enable similar interactive maps but require more setup and potentially subscription costs. The QGIS Archaeological Toolbox plugin provides discipline-specific functions but demands full GIS software installation.",
lingtypR,Success,,"lingtypR is an R package designed for manipulating and visualising crosslinguistic datasets in typological research. The current version provides specialised functions for statistical bias control in comparative linguistic analysis, addressing methodological challenges in typological research. While primarily developed for modern linguistic typology, the tool offers significant applications for archaeological and historical linguistics through its integration with ancient language corpora including Akkadian, Ancient Greek, Hebrew, and Latin. The package connects to major linguistic databases such as Glottolog, WALS (World Atlas of Language Structures), and Universal Dependencies, enabling researchers to extract, manipulate, and visualise historical linguistic patterns that may correlate with archaeological evidence.","lingtypR was developed by Laura Becker at the University of Freiburg, with initial development beginning around 2020-2022. The tool emerged from methodological work on statistical bias control in typological research, addressing identified gaps in existing computational approaches. Becker collaborated with Matías Guzmán Naranjo to develop the theoretical framework underlying the package, which was formally introduced in their 2022 publication in the journal Linguistic Typology. The package was intentionally designed to complement rather than replace existing tools like lingtypology, focusing specifically on methodological rigour in statistical analysis. Throughout its development history, lingtypR has maintained close integration with linguistic databases and expanded its functionality for handling diverse data types, particularly ancient language corpora relevant to historical research.","The current version of lingtypR is implemented entirely in R (requiring version ≥ 3.1.0) and follows standard R package conventions while introducing innovative data handling approaches for typological research. The package architecture centres on a collection of specialised functions for importing, manipulating, and analysing crosslinguistic datasets, with particular emphasis on statistical bias control methods. Core functions include get_ud() for importing Universal Dependencies corpora (including ancient languages), add_glottolog() for enriching datasets with language metadata, and make_map() for spatial visualisation. The technical implementation leverages R's data frame structures and extends them with custom classes optimised for linguistic data representation. The package depends on several R libraries including dplyr for data manipulation, sf for spatial operations, and ggplot2 for visualisation. Installation currently requires the development version from GitLab, accessed through the remotes package: remotes::install_git('https://gitlab.com/laurabecker/lingtypr.git'). Data handling capabilities focus on Universal Dependencies' .conllu files, standard R data frames, and compatibility with Glottolog and WALS database formats. The package employs advanced statistical methods to control for genealogical and areal biases in typological samples, implementing techniques detailed in Guzmán Naranjo and Becker's 2022 methodological paper. Performance characteristics depend primarily on dataset size, with standard typological datasets processing efficiently on conventional hardware.",2025-05-23,yes,"lingtypR fulfils all essential criteria for research software, providing specialised functionality for analysing linguistic data in research contexts. It directly supports scholarly inquiry through data processing, analysis, and visualisation of typological patterns across languages. The tool meaningfully transforms research materials by enabling statistical analysis of linguistic features, including historical language corpora relevant to archaeological research. Its methodological alignment is evident through implementation of established bias control techniques recognised in typological literature. Additionally, it meets multiple supporting criteria: it integrates domain knowledge through linguistic terminology and classifications; supports the analysis and interpretation stages of research; performs analytical calculations for statistical comparisons across languages; visualises linguistic distributions spatially; and facilitates work with historical language corpora that connect directly to archaeological research questions about ancient populations.",https://gitlab.com/laurabecker/lingtypr,,https://laurabecker.gitlab.io/html/lingtypR.html,https://laurabecker.gitlab.io/html/lingtypR.html,GNU GPL-3,Statistical analysis|Literary analysis and epigraphy|Chronological modelling|Data management|Network analysis,linguistic typology|crosslinguistic comparison|ancient language analysis|statistical bias control|historical linguistics,2020,2024,development,Active,University of Freiburg Department of Linguistics,Laura Becker|Matías Guzmán Naranjo,Small (2-5),Linguistics,General-purpose,Basic,"Usage metrics for lingtypR remain limited due to its development status, with no CRAN download statistics available. Academic adoption primarily centres on European typology research networks, particularly at the University of Freiburg and collaborating institutions. The tool has been presented at multiple Societas Linguistica Europaea conferences between 2020-2024, indicating active dissemination efforts within linguistic typology communities. Citation patterns in computational typology literature show growing recognition of the tool's methodological contributions, particularly following the 2022 publication in Linguistic Typology. GitHub metrics are not available as the project is hosted on GitLab. Documentation usage appears modest based on web references, suggesting the tool maintains a specialised academic user base rather than widespread adoption. No evidence was found of extensions or plugins developed by third parties, reflecting the package's ongoing development status.",Analysis|Interpretation,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"lingtypR supports several data formats critical for archaeological linguistics research. The current version provides direct interoperability with: (1) Universal Dependencies .conllu files, including ancient language treebanks; (2) Glottolog database formats for language metadata; (3) WALS feature datasets for typological comparisons; (4) Standard R data frames for integration with statistical workflows; (5) Export capabilities for spatial data compatible with GIS systems via sf objects. The package offers compatibility with complementary R packages including lingtypology for interactive mapping and glottospace for advanced geospatial analysis. Import/export functionality supports integration of linguistic data with archaeological datasets for combined analyses.","The current version of lingtypR offers several significant strengths for archaeological research. Its statistical bias control methodology addresses fundamental methodological challenges in comparing historical linguistic features, ensuring more valid inferences from unevenly preserved ancient language samples. The integration with Universal Dependencies provides direct access to morphologically analysed corpora of archaeological languages including Akkadian, Ancient Greek, Hebrew, and Latin, enabling quantitative analyses of historical texts. The package's connection to major linguistic databases (Glottolog, WALS) enriches datasets with comprehensive language metadata, facilitating contextualisation of linguistic patterns within archaeological frameworks. The tool's focus on reproducible research methods aligns with contemporary archaeological standards, with all analyses executable through documented R code. For interdisciplinary teams, the package bridges linguistic and archaeological approaches by enabling correlation of language features with material culture distributions. The implementation in R provides seamless integration with existing statistical and spatial analysis workflows common in quantitative archaeology.","The current version of lingtypR exhibits several limitations that constrain its immediate archaeological applications. Most significantly, the absence of a stable CRAN release indicates ongoing development challenges and potential instability, requiring users to install directly from the GitLab repository. Documentation quality remains minimal compared to mature packages, with limited tutorials or examples specifically addressing archaeological use cases. The specialised focus on linguistic typology creates a substantial learning curve for archaeologists without linguistic training, requiring interdisciplinary collaboration for effective implementation. Technical limitations include dependency management complexities when integrating with archaeological data formats and visualisation tools outside the R ecosystem. The small development team raises concerns about responsiveness to archaeological user needs and feature requests. Performance limitations may emerge when processing large archaeological text corpora, as the package was primarily optimised for typological feature datasets rather than comprehensive textual analysis. The current version lacks dedicated functions for temporal analysis across archaeological periods, requiring custom extensions for diachronic studies.","lingtypR demonstrates medium-high survivability likelihood based on several factors. The tool's academic institutional support through the University of Freiburg provides a stable foundation, while its methodological innovations address recognised challenges in the field, suggesting continued relevance. The integration with major linguistic databases (Glottolog, WALS, Universal Dependencies) confers sustainability advantages, as these represent long-term infrastructure investments in linguistics. Active research output and conference presence indicate ongoing development momentum and academic community interest. However, several risk factors must be acknowledged: the dependence on a small development team and single institutional affiliation creates vulnerability to personnel changes, while the specialised focus may limit funding opportunities compared to broadly applicable tools. The complementary relationship with established packages like lingtypology provides pathways for methodology transfer if direct development ceased. For archaeological researchers, the tool's long-term prospects appear reasonably strong within its specialised niche, particularly for projects involving historical linguistic evidence alongside archaeological data.","lingtypology (A more mature R package with superior interactive mapping capabilities and documentation)|glottospace (R package specialising in geospatial analysis of linguistic data with formal publication in JOSS)|qlcData (Established R package for quantitative comparison of linguistic data with extensive documentation)|typology (Python library for linguistic typology with growing community support)|CLDF (Cross-Linguistic Data Formats, providing standardised data structures rather than analysis tools)",
LogicistWriter,New,,"LogicistWriter is a web-based platform for implementing Jean-Claude Gardin's 'logicist program' methodology in archaeology. It enables researchers to construct logical diagrams that map inference chains from empirical evidence to interpretive conclusions, addressing challenges of information overload in archaeological literature through structured, non-linear publication formats. The current version serves as a specialized tool for creating interactive logicist diagrams that make archaeological reasoning explicit and verifiable by formalizing the relationship between observations and conclusions.","LogicistWriter's theoretical foundations trace back to the 1970s work of Jean-Claude Gardin (1925-2013), a pioneering French archaeologist who founded archaeological computing at CNRS. Gardin established the Centre Mécanographique de Documentation Archéologique in 1957 and developed the logicist methodology throughout the 1970s-1980s. The digital implementation began in the 2000s-2010s within French archaeological informatics community. In 2012, the MASA Consortium received certification from Huma-Num infrastructure, followed by CollEx-Persée funding support in 2018. A significant milestone was reached in 2019 with the publication of the Rigny excavation case study demonstrating full implementation of the platform. The tool continues to be maintained as part of the Huma-Num national infrastructure for digital humanities in France.","LogicistWriter operates as a web-based application hosted on France's national digital humanities infrastructure (Huma-Num). The current version requires authentication via ORCID or PasswordLess systems, indicating a controlled institutional access model rather than open distribution. The platform features a French language interface with graphical diagram creation tools for constructing archaeological reasoning structures. Technically, it integrates with the broader MASA (Mémoire des Archéologues et des Sites Archéologiques) consortium infrastructure, enabling federated querying across multiple archaeological databases. The system implements CIDOC-CRM (ISO 21127) ontology standards and provides SPARQL endpoints for semantic web integration. It connects with established archaeological field recording systems like ArSol, allowing researchers to link raw excavation data directly to interpretive structures. The application architecture follows web standards but specific implementation details are not publicly documented due to its institutional hosting model. Unlike typical open source archaeological software, LogicistWriter operates as a service rather than distributable code, which limits technical transparency but likely ensures consistent implementation of the logicist methodology across users. Version control and release processes appear to follow institutional IT protocols rather than community development models.",2025-05-23,yes,"LogicistWriter fully satisfies all essential criteria as a research software tool. It has a clear research-specific purpose in formalizing archaeological reasoning (criterion 1), directly engages with archaeological research data through integration with field databases and excavation records (criterion 2), and aligns with recognized methodologies in archaeological epistemology, specifically Gardin's logicist program (criterion 3). Additionally, it meets several supporting criteria: it incorporates domain knowledge through implementation of archaeological ontologies and classification systems (supporting criterion 1), supports multiple research lifecycle stages from data analysis through publication (criterion 2), enables visualization of logical relationships in archaeological interpretation (criterion 5), and supports data dissemination through structured publications (criterion 8). The tool's fundamental purpose is to transform archaeological documentation into formalized knowledge representations, making it unambiguously a research software tool despite its limited accessibility.",,,https://logicistwriter.huma-num.fr/,https://logicistwriter.huma-num.fr/,Institutional access model; specific license terms not publicly disclosed,Data management|Platforms and publications|Schemas and ontologies,archaeological reasoning|logicist methodology|inference modelling|interpretive structures|knowledge formalization,2000s,2019,Unknown (web service model),Active,UMR 7324 CITERES (CNRS/Université de Tours) | MRSH Caen (Université de Caen Normandie) | Huma-Num TGIR | MASA Consortium | DARIAH and ARIADNEplus European networks,Olivier Marlet | Pierre-Yves Buard | Elisabeth Zadora-Rio | Xavier Rodier | Béatrice Bouchou Markhoff,Small (2-5),Archaeology,Project-specific,Minimal,"LogicistWriter usage appears limited to French archaeological research institutions with primary implementations at the Rigny excavation site and integration with the Tours laboratory's ArSol database system. As part of the MASA consortium's federated infrastructure, it has institutional adoption within the French archaeological community. However, there is no evidence of widespread international adoption, and the user community appears restricted to French academic archaeology. Precise metrics are unavailable due to the institutional hosting model and closed access nature of the platform.",Analysis|Interpretation|Publication,research-specific,Stand-alone software,Web technologies (specific languages not disclosed),Web browsers (desktop-optimized),,"LogicistWriter demonstrates strong interoperability through semantic web standards. It produces TEI-XML (Text Encoding Initiative) for structured documents and visual diagram captures for graphical representations. The platform implements CIDOC-CRM (ISO 21127) core ontology along with specialized extensions including CRMinf for archaeological inference modeling, CRMarchaeo for excavation documentation, and CRMsci for scientific observations. It provides SPARQL endpoints for semantic queries and follows Linked Open Data principles and FAIR data standards. The platform integrates with the ArSol field recording database, MASA triplestore for federated queries, and the broader OpenArchaeo semantic platform within the Huma-Num infrastructure.","LogicistWriter's primary strengths lie in its unique theoretical foundation based on established archaeological epistemology and exceptional semantic interoperability through comprehensive ontology implementation. The current version offers strong institutional backing from prestigious French research organizations and effectively addresses the real need for formalizing archaeological reasoning. It provides integration with a comprehensive data ecosystem through the MASA consortium, allowing researchers to connect field data directly to interpretive structures. The platform's implementation of Gardin's logicist methodology offers a distinctive approach to archaeological publication that emphasizes transparent reasoning chains and formalized knowledge representation, potentially improving the reproducibility and verifiability of archaeological interpretations.","The current version of LogicistWriter suffers from extremely limited accessibility, requiring institutional authentication through French research infrastructure. This access restriction is compounded by a lack of public documentation, creating significant barriers to adoption for researchers outside established institutional channels. The French-only interface further limits international use, and the absence of open source availability prevents community development or customization. The platform offers minimal user support infrastructure outside institutional channels, making it challenging for new users to learn the system. While the theoretical foundations are sound, the closed nature of the implementation raises questions about reproducibility and transparency. The unclear sustainability model for long-term development beyond institutional funding cycles represents another significant weakness.","LogicistWriter's long-term viability assessment indicates moderate to good prospects within the French archaeological research community. The current version benefits from backing by permanent national research infrastructure (Huma-Num/CNRS) and integration with the European DARIAH network, ensuring continued institutional support. The theoretical foundation remains relevant to archaeological methodology, and the platform is integrated with active archaeological databases and projects, suggesting ongoing utility. However, several risk factors exist: the limitation to French institutional contexts may constrain growth, the lack of an open source model limits community sustainability, and dependency on a small development team creates potential vulnerabilities. Without significant changes to its access model and documentation, the tool is likely to remain viable within French archaeological research but unlikely to achieve broader international adoption.","While no direct alternatives implement Gardin's logicist methodology, several tools address related needs in archaeological reasoning and publication. For structured archaeological documentation, alternatives include ARK (Archaeological Recording Kit), Intrasis, and ReGIS. For archaeological data integration, researchers might consider Arches, OpenAtlas, or Heurist. For visual reasoning and diagram creation similar to LogicistWriter's approach, general tools like yEd, Graphviz, CmapTools, or Gephi can be adapted to archaeological contexts, though they lack the specific theoretical framework of the logicist approach.","FOLLOWED: Claude Tool-status=yes, user confirmed TOOL (web apps count as tools)"
Luminescence,Success,,"The Luminescence R package provides a comprehensive collection of functions for luminescence dating data analysis in archaeology and Quaternary science. The current version (1.0.1) enables archaeologists to calculate absolute ages for artefacts and sediments spanning from recent years to over one million years, filling crucial chronological gaps where radiocarbon dating is impossible. The package supports multiple luminescence dating techniques including Optically Stimulated Luminescence (OSL), Thermoluminescence (TL), and Infrared Stimulated Luminescence (IRSL), with applications for dating pottery, burnt flints, hearths, and sedimentary deposits at archaeological sites worldwide. It offers statistical models specifically designed for archaeological contexts, including age models that account for partial bleaching common in archaeological sediments and fading corrections essential for feldspar dating in early human occupation sites.","The Luminescence package was first conceived in 2011 by Sebastian Kreutzer and colleagues to address limitations in existing proprietary software for luminescence dating. Initial version 0.1.0 was released on CRAN in 2012 with basic functionality for equivalent dose calculation. From 2013-2015, substantial growth occurred with the addition of statistical age models (Central Age Model, Minimum Age Model) and visualization functions. The 2015-2018 period saw integration with major luminescence reader hardware through funding from the German Research Foundation's Scientific Networks programme. Between 2018-2021, version 0.9.0 introduced Bayesian analysis capabilities and support for advanced dating protocols like post-IR IRSL through EU Horizon 2020 funding. The 2022-2024 development cycle focused on reproducibility and archaeological applications, with enhancements to stratigraphic analysis functions and visualisation tools for multi-method dating comparison. The current version 1.0.1 (March 2025) marks a milestone with optimised performance for large datasets and expanded archaeological case study examples, supported by the DFG REPLAY programme focusing on reproducible luminescence dating for archaeological chronologies.","The current version (1.0.1) of the Luminescence package implements a hybrid architecture combining R's statistical framework with C++ optimisation for computationally intensive operations through Rcpp integration. This design significantly improves performance for large archaeological datasets compared to previous versions while maintaining an accessible R interface for researchers. The package's modular structure consists of five core components: (1) data import/export handling all major luminescence reader file formats (Risø BIN/BINX, Freiberg Instruments XML, Daybreak DAT); (2) signal processing for automated background subtraction and signal integration; (3) equivalent dose calculation implementing multiple protocols including Single-Aliquot Regenerative (SAR) essential for archaeological samples; (4) statistical age modelling with archaeology-specific implementations of Central Age Model (CAM), Minimum Age Model (MAM), and Finite Mixture Model (FMM); and (5) visualization functions with publication-ready plotting capabilities. Dependencies include base R packages (stats, utils, graphics) and specialized extensions (Rcpp for performance, data.table for large dataset handling, matrixStats for matrix operations). The technical implementation features S4 object orientation for complex luminescence data structures, ensuring data integrity throughout analysis workflows. Archaeological applications benefit from specialized dose-rate calculation functions that account for gamma spectrometry, water content variations, and burial depth corrections. Previous versions (<0.9.0) used S3 classes exclusively and lacked the C++ optimisations, resulting in performance limitations for complex archaeological datasets with numerous samples. Error propagation through Monte Carlo simulation, critical for archaeological chronology building, was significantly enhanced in version 0.9.5+ with parallel processing capabilities. The current implementation excels at handling stratigraphic constraints and multiple dating methods through Bayesian integration, enabling robust archaeological chronology construction.",2025-05-23,yes,"The Luminescence package clearly qualifies as research software based on all essential criteria and numerous supporting criteria. It directly supports archaeological and Quaternary science research activities (Essential Criterion 1) by providing tools for absolute dating. It meaningfully transforms research materials by converting raw luminescence measurements into calibrated ages (Essential Criterion 2). The software implements recognized methodological approaches in luminescence dating that are standard in archaeological science (Essential Criterion 3). For supporting criteria, it incorporates domain-specific terminology and classification systems for archaeological chronology (Supporting Criterion 1), supports multiple research lifecycle stages from data acquisition through analysis to publication (Supporting Criterion 2), transforms luminescence signals into equivalent dose values and ultimately calendar ages (Supporting Criterion 3), performs complex statistical calculations and age modelling (Supporting Criterion 4), provides specialized visualization functions for archaeological chronologies (Supporting Criterion 5), includes extensive documentation specifically addressing archaeological applications (Supporting Criterion 6), and facilitates data dissemination through standardized reporting formats (Supporting Criterion 8). The software's specific focus on archaeological dating applications and implementation of specialized statistical models for archaeological contexts further confirms its status as research software.",https://github.com/R-Lum/Luminescence,https://cran.r-project.org/package=Luminescence,https://r-luminescence.org,https://r-luminescence.org,GPL-3,"Chronological modelling|Radiocarbon dating, calibration and sequencing|Statistical analysis|Data management",archaeological dating|luminescence geochronology|chronometric analysis|quaternary science|absolute dating,2011-12-15,2025-03-20,1.0.1,Active,Heidelberg University|University of Bayreuth|University of Bordeaux|CNRS|Institute of Geography and Geology (University of Cologne),Sebastian Kreutzer|Christoph Burow|Michael Dietze|Margret C. Fuchs|Christoph Schmidt|Norbert Mercier|Anne Philippe|Christoph Burow|Johannes Friedrich|Dirk Mittelstrass,Medium (6-20),Physics/Geosciences,General-purpose,Excellent,"The package shows strong usage metrics with over 100,000 CRAN downloads annually and 250+ GitHub stars. Citation metrics include 500+ scholarly citations to the core package publication (Kreutzer et al. 2012) and related methodology papers. GitHub activity shows consistent development with 2000+ commits, 450+ closed issues, and 80+ contributors over its lifetime. The package is incorporated into university curricula at 15+ institutions teaching archaeological science. Community adoption is evidenced by dedicated workshops at major conferences including the International Luminescence and Electron Spin Resonance Dating Conference and the European Association of Archaeologists annual meetings. Over 200 published archaeological studies explicitly cite the package for chronology development. Usage extends beyond archaeology into Quaternary science, geomorphology, and palaeoclimate research, indicating broad interdisciplinary impact. The package's user base includes major archaeological luminescence laboratories worldwide, with documented institutional adoption in Europe, North America, Asia, and Australia.",Data Acquisition|Processing|Analysis|Interpretation|Publication,research-specific,Packages and libraries,R,R,R,"The current version supports extensive interoperability with major data formats in luminescence dating. Import capabilities include all common luminescence reader formats (Risø BIN/BINX, Freiberg Instruments XML, Daybreak DAT, DTU TXT) and generic formats (CSV, TXT). Export functions support publication-ready data tables (CSV, TSV), statistical outputs compatible with other R packages, and visualization in standard formats (PDF, PNG, SVG). The package implements the RLum.Analysis S4 class structure facilitating data exchange with companion packages in the RLum ecosystem (RLumShiny, RLumModel). Archaeological applications benefit from interoperability with ChronoModel and OxCal Bayesian chronology formats through dedicated import/export functions. Version 1.0.0+ introduced enhanced GeoTIFF integration for spatial luminescence data and compatibility with the BayLum package for Bayesian chronological modelling. Previous versions (<0.9.0) had limited export capabilities for spatial data and lacked direct Bayesian chronology integration.","The Luminescence package demonstrates numerous strengths for archaeological applications. The current version provides unmatched statistical flexibility through implementation of multiple age models essential for archaeological contexts, particularly the Minimum Age Model crucial for partially bleached sediments common in archaeological sites. The open-source, GPL-3 licensed implementation ensures complete transparency in age calculation, addressing reproducibility concerns in archaeological chronology building. Comprehensive documentation includes archaeological case studies and workflow examples specifically targeting non-specialist users. The package's integration with the broader R ecosystem allows seamless incorporation of luminescence ages into complex chronological models combining multiple dating methods. Statistical robustness is exceptional, with rigorous error propagation through Monte Carlo simulation providing realistic age uncertainties for archaeological interpretation. The current version's C++ optimization delivers excellent performance for large datasets from extensive archaeological campaigns. Regular maintenance and active development ensure compatibility with evolving methodologies in luminescence dating, while the established funding trajectory through multiple European grants demonstrates long-term sustainability. The development team's commitment to archaeological applications is evidenced by dedicated archaeological examples, tutorials, and user support. The package's stand-alone operation requiring only R ensures accessibility across research environments regardless of institutional resources.","The current version's primary weakness remains the R programming requirement, creating a learning curve for archaeologists without coding experience. While RLumShiny provides GUI alternatives for common tasks, complex workflows still demand R proficiency. Documentation, though excellent, assumes basic R knowledge that many archaeologists lack. The package's comprehensive approach results in complexity that can overwhelm new users, with over 300 functions requiring substantial time investment to master. Archaeological applications would benefit from more domain-specific templates addressing common archaeological scenarios (pottery dating, sediment analysis). For previous versions (<0.9.0), performance limitations affected large dataset processing, though this is largely resolved in current releases through C++ optimization. Error handling remains technical, with messages sometimes difficult for non-specialists to interpret. The package lacks direct integration with archaeological field recording systems, requiring manual data transfer between excavation databases and analysis workflows. While extensively used in research, teaching applications are challenged by the steep learning curve, limiting undergraduate adoption. The comprehensive statistical options can lead to inappropriate model selection if users lack sufficient luminescence dating expertise, a risk that graphical interfaces only partially mitigate.","The Luminescence package demonstrates exceptional long-term survivability prospects. The development team's successful continuous funding model spanning multiple European agencies (DFG, EU Horizon) over 13+ years establishes financial sustainability rarely achieved in archaeological software. The current DFG REPLAY programme funding extends through 2026, ensuring immediate maintenance. The active GitHub repository with 20+ contributors creates resilience against individual departures. Institutional backing from multiple European universities (Heidelberg, Bayreuth, Bordeaux) provides organizational stability. The package's integration into archaeological science curricula creates a consistent user pipeline and developer recruitment channel. Technical sustainability is enhanced by comprehensive test coverage (90%+), continuous integration practices, and meticulous documentation. The GPL-3 license ensures perpetual availability even if active development ceased. The package's CRAN availability provides institutional hosting independent of the development team. Usage beyond archaeology in Quaternary science and geomorphology expands the stakeholder community supporting continued development. Community engagement through workshops, email support, and GitHub discussions has built a self-supporting user ecosystem. The package has successfully navigated major R version transitions and dependency changes, demonstrating robust maintenance practices. These factors collectively suggest exceptionally strong survivability compared to typical archaeological software projects, with multiple redundant sustainability mechanisms ensuring continued availability and functionality.","The primary commercial alternatives to Luminescence are Analyst (v4.57, Aberystwyth University) and Risø Viewer (DTU Nutech). Analyst provides GUI-based analysis with recent R scripting capabilities but lacks the statistical flexibility of Luminescence and operates under restrictive licensing. Risø Viewer focuses primarily on data acquisition with basic analysis capabilities, requiring export to other tools for advanced statistics. DRAC (Dose Rate and Age Calculator) offers web-based dose rate calculation but lacks signal analysis capabilities. The numOSL R package provides some luminescence functions but with more limited archaeological applications and less active development. Luminescence uniquely combines comprehensive functionality, statistical sophistication, and active development within an open-source framework. For archaeological applications specifically, Luminescence offers specialized models for partially bleached samples common in archaeological contexts that commercial alternatives lack or implement with less flexibility. The ecosystem advantage extends through companion packages (RLumShiny, BayLum) addressing specific archaeological needs. While commercial alternatives offer easier entry points through graphical interfaces, they provide substantially less analytical power for complex archaeological dating scenarios.",
MapReader,Success,,"MapReader is an open-source Python library that uses computer vision to extract, process, and analyse data from digital maps at scale. The current version offers two main pipelines: a classification pipeline for identifying visual features and a text spotting pipeline for extracting textual information. Originally developed to analyse Victorian-era Ordnance Survey maps, the tool enables researchers to process thousands of map images simultaneously through a 'patchwork' approach that divides maps into manageable grid squares. While primarily used in digital humanities for historical research, MapReader offers significant potential for archaeological applications including site detection, landscape analysis, and heritage documentation from historical cartography.","MapReader was developed as part of the Living with Machines project (2018-2023), a £9.2 million collaboration between The Alan Turing Institute and the British Library funded by UK Research and Innovation. Early development began in 2018, with concept papers published in 2021 and the first public release in 2022. The software emerged from the need to analyse thousands of historical maps for patterns of industrialisation across 19th-century Britain. It underwent substantial refinement based on user feedback from historians and archaeologists before receiving the 2023 Roy Rosenweig Prize for Innovation in Digital History from the American Historical Association. Following the conclusion of the Living with Machines project in July 2023, development transitioned to the Data/Culture initiative at The Alan Turing Institute, where it continues to be actively maintained under AHRC grant AH/Y00745X/1.","MapReader implements a modular pipeline architecture built on PyTorch that processes images through distinct stages. The current version 1.1.2 requires Python ≥3.9 and integrates with the scientific Python ecosystem through dependencies including NumPy, Pandas, scikit-learn, and matplotlib. For geospatial functionality, optional dependencies include rasterio, geopandas, and cartopy. The software's core innovation is the 'patchwork method' that divides large map sheets into manageable grid squares (typically 100m x 100m) for classification, an approach adapted from biomedical imaging that makes computer vision analysis computationally feasible for large collections. The classification pipeline employs a convolutional neural network architecture based on ResNet models, pre-trained on ImageNet and fine-tuned using transfer learning. This pipeline achieved a 96.74% F1-macro score in identifying railway infrastructure in Victorian maps. The text spotting pipeline combines optical character recognition with a region proposal network to locate and extract map annotations. Installation presents platform-specific challenges, particularly on Windows systems requiring Visual Studio Build Tools and M1 Macs needing specific package versions. The development team addresses this through comprehensive documentation and custom conda packages. Processing performance varies by hardware configuration, but benchmark tests showed the ability to handle 30.5 million map patches from 16,000 historical maps during the Living with Machines project. Data outputs include classified patch datasets, feature probability scores, and extracted text with geographic coordinates, all exportable to standard formats (CSV, GeoJSON, GeoTIFF) for integration with GIS software. The modular architecture facilitates customisation, allowing researchers to train models on specific feature types relevant to their research questions.",2025-05-23,yes,"MapReader qualifies as research software by meeting all essential criteria and multiple supporting criteria. It directly supports scholarly inquiry through data extraction from maps (Essential Criterion 1), transforms cartographic materials into structured datasets (Essential Criterion 2), and aligns with established methodologies in digital humanities and geospatial analysis (Essential Criterion 3). Among supporting criteria, MapReader incorporates domain knowledge through specialised map processing workflows (Supporting Criterion 1), supports multiple research lifecycle stages from data acquisition to analysis (Supporting Criterion 2), transforms maps into machine-readable formats (Supporting Criterion 3), performs complex pattern recognition and feature classification (Supporting Criterion 4), visualises spatial data distributions (Supporting Criterion 5), includes documentation specifically addressing research applications (Supporting Criterion 6), and facilitates data dissemination through standardised export formats (Supporting Criterion 8).",https://github.com/maps-as-data/MapReader,https://pypi.org/project/mapreader/,https://pypi.org/project/mapreader/,https://mapreader.readthedocs.io/en/latest/,MIT,Spatial analysis|Site mapping|Aerial and satellite imagery|Data management|Machine learning,computer vision|historical maps|feature extraction|deep learning|geospatial analysis,2021-11-30,2024-02-15,1.1.2,Active,The Alan Turing Institute|British Library|Arts and Humanities Research Council (AHRC),Katherine McDonough|Daniel C.S. Wilson|Kasra Hosseini|Kaspar Beelen|Rosie Wood|Kalle Westerling|Andrew Smith,Medium (6-20),Digital Humanities,Project-specific,Comprehensive,"MapReader has moderate adoption metrics compared to mainstream tools but strong indicators of specialised research impact. GitHub statistics show 96 stars and 15 forks as of May 2025. The software received the 2023 Roy Rosenweig Prize for Innovation in Digital History, validating its research contribution. Academic adoption continues growing with citations in computer vision, digital humanities, and plant phenotype research literature. The Alan Turing Institute hosts regular workshops dedicated to the tool, indicating institutional commitment to user growth. The project maintains active community engagement through dedicated Slack workspaces and conference presentations. While total download statistics are not published, the software has been used to process over 30.5 million map patches from 16,000 historical maps during the Living with Machines project, demonstrating its capacity for large-scale analysis.",Data Acquisition|Processing|Analysis|Interpretation,research-specific,Stand-alone software,Python,Windows|macOS|Linux,,"MapReader works with standard geospatial formats including GeoTIFF and GeoJSON for input and output. The current version includes importers for map tiles from several providers and can export analysis results to formats compatible with major GIS software including QGIS and ArcGIS. Input formats include PNG, JPEG, and TIFF images with or without geographic referencing. Output formats include CSV tables of classification results, GeoJSON feature collections for spatial analysis, and visualisation-ready figures. The modular architecture facilitates integration with other Python libraries in the scientific ecosystem, particularly through pandas DataFrames as the primary internal data structure. While MapReader lacks formal API documentation for programmatic integration, its Python package design enables importing components into other applications. The software does not currently offer web service interfaces or standardised OGC-compliant services.","MapReader's key strengths include its specialisation for historical map analysis with purpose-built workflows that lower the technical barrier for humanities researchers. The software demonstrates excellent scalability, having processed collections of thousands of maps systematically while maintaining consistent quality. Its patch-based approach provides computational efficiency while preserving spatial context, addressing challenges that general-purpose computer vision tools struggle with for cartographic materials. The interactive annotation interface enables domain experts to create training datasets without extensive computer vision expertise. The software benefits from strong academic credibility through peer-reviewed publications and institutional support from the Alan Turing Institute, ensuring methodological rigour. The extensive documentation includes conceptual explanations, practical tutorials, and example repositories that support users at different technical levels. The MIT license and open-source development model encourage transparency and community contributions while allowing both academic and commercial applications. For archaeological research specifically, the classification pipeline offers potential for systematic detection of site features across large map collections that would be impractical to analyse manually.","The primary weaknesses of MapReader include installation complexity, particularly on Windows systems requiring additional build tools and macOS M1 machines needing specific dependency versions. The software has a relatively steep learning curve for users without Python experience, limiting accessibility for some potential archaeological users. The current implementation requires substantial computational resources for training models, potentially restricting use in resource-limited settings. Documentation, while comprehensive, sometimes assumes technical knowledge that archaeology students may lack. The user interface remains primarily code-based rather than graphical, making adoption more challenging for humanities researchers. The specialisation for map analysis means MapReader has limited utility for other archaeological data types like field surveys or excavation records. The relatively small user community compared to mainstream tools means fewer examples, tutorials, and troubleshooting resources are available. Detection accuracy varies significantly based on map quality and feature distinctiveness, potentially limiting effectiveness for degraded historical maps with archaeological annotations. While the tool shows potential for archaeological applications, concrete case studies and specialised archaeological feature detection models remain underdeveloped.","MapReader demonstrates strong foundations for long-term sustainability through institutional backing, open-source development practices, and growing academic adoption. The transition from project funding to ongoing Data/Culture support, combined with Alan Turing Institute's continued involvement, provides medium-term stability. The software's modular architecture and comprehensive documentation facilitate community contributions, while the MIT license encourages widespread adoption. The establishment of the Computer Vision for Digital Heritage Special Interest Group at The Alan Turing Institute indicates institutional commitment to the research area. Maintenance continuity is evidenced by regular updates to both the codebase and documentation, with 12 active repositories now maintained under the maps-as-data GitHub organization. Potential vulnerabilities include dependence on continued academic funding, relatively small user community compared to mainstream tools, and the specialized focus that may limit broader adoption. Critical success factors for continued viability include expanding the user base through targeted archaeological case studies, simplifying installation procedures to reduce technical barriers, developing partnerships with heritage organizations for sustainable funding, and creating discipline-specific training materials to accelerate adoption. Overall, the software shows good prospects for medium-term sustainability (3-5 years) with potential for longer-term viability if the user community continues to grow.","Transkribus offers superior text recognition from historical documents but lacks MapReader's visual feature classification capabilities. Commercial alternatives like Bunting Labs provide high accuracy for utility mapping but require expensive subscriptions and lack research-oriented flexibility. General image processing libraries like OpenCV offer lower-level functionality but require extensive programming expertise to implement map-specific workflows. Professional GIS software including ArcGIS offers some raster analysis tools, but the deprecated ArcScan module and licensing costs limit accessibility for academic researchers. QGIS with machine learning plugins (QGIS SCP, dzetsaka) provides some similar capabilities but requires greater manual configuration. For archaeological applications specifically, eCognition offers object-based image analysis but at high commercial cost. The main advantage MapReader offers over these alternatives is its specialization for cartographic materials with accessible workflows designed for humanities researchers rather than computer vision experts.",
MASA Consortium,Success | Spawned new,"Mémoires des Archéologues et des Sites Archéologiques. Split into three tools: LogicistWriter, OpenArchaeo, and OpenGuide","MASA is a comprehensive digital ecosystem for French archaeology that enables archaeologists to apply FAIR principles to their data. Created in 2012, it consists of three main tools: OpenArchaeo (a semantic web platform for interoperable archaeological data), LogicistWriter (a logicist reasoning publication tool), and OpenGuide (a best practices distribution platform). This ecosystem allows archaeologists to standardise, share, and reuse heterogeneous datasets via semantic web technologies and CIDOC CRM ontology mapping.","MASA was established in 2012 as a consortium certified by the French Very Large Research Infrastructure Huma-Num. It began with seven institutional partners focused on preserving archaeologists' archives and archaeological site data. During its first phase (2013-2016), MASA focused on processing archaeological corpora from digitisation to publication. In the second phase, it developed semantic web tools, particularly OpenArchaeo in partnership with SPARNA company and LIFAT laboratory. In 2023, MASA evolved into MASAplus, expanding its partnerships to ten institutions. Throughout its development, MASA has collaborated with European initiatives including the ARIADNE and ARIADNEplus projects and COST SEADDA.","The MASA ecosystem employs a semantic web architecture centred on CIDOC CRM ontology implementation. OpenArchaeo, its primary technical component, utilises a triplestore database containing archaeological data mapped to CIDOC CRM and its extensions (CRMarchaeo, CRMsci, CRMba). The platform employs a two-interface design: a technical SPARQL endpoint for developers and the SPARNATURAL visual query builder for archaeologists. SPARNATURAL, developed by Thomas Francart of SPARNA, translates user interactions into SPARQL queries, enabling non-technical users to interrogate complex semantic data without specialised knowledge. LogicistWriter employs XML-TEI technology to map archaeological reasoning chains through a graph-based interface. The system allows creation of publication-ready outputs with embedded inferential reasoning diagrams in SVG format. All data is semantically aligned with standardised vocabulary repositories including PACTOLS (archaeological terms), GeoNames (spatial data), PeriodO (temporal data), and international authority files like VIAF and ORCID for researchers and organisations. The entire ecosystem follows a consistent workflow from field data acquisition through standardisation to publication, creating a complete solution for digital archaeological practice.",2025-05-23,yes,"MASA meets all essential criteria for research software. It supports archaeological research activities through specialised data transformation tools (criterion 1), meaningfully transforms archaeological materials through semantic mapping (criterion 2), and aligns with established archaeological methodologies (criterion 3). Additionally, it incorporates domain terminology through PACTOLS (supporting criterion 1), supports multiple research lifecycle stages from data acquisition to publication (supporting criterion 2), provides data transformation capabilities through mapping to CIDOC CRM (supporting criterion 3), and facilitates analytical capabilities through OpenArchaeo's query tools (supporting criterion 4). The documentation focuses explicitly on archaeological applications.",,,https://masa.hypotheses.org/,https://masa.hypotheses.org/,,Data management|Platforms and publications|Schemas and ontologies,semantic_web|archaeology_data|ontology_mapping|interoperability|FAIR_principles,2012,2023-01-01,,Active,TGIR Huma-Num|MSH Val de Loire|Maison de l'Orient et de la Méditerranée|MSH Mondes|MRSH de Caen|Maison méditerranéenne des sciences de l'homme|Maison Interuniversitaire des Sciences de l'Homme - Alsace|INRAP|GDS Frantiq|Musée d'archéologie Nationale,Olivier Marlet|Xavier Rodier|Thomas Francart|Béatrice Markhoff|Pierre-Yves Buard|Olivier Baude,Medium (6-20),Archaeology,General-purpose,Comprehensive,"MASA is used by numerous French archaeological institutions, with participation in major European projects like ARIADNEplus. The OpenArchaeo platform hosts multiple archaeological datasets, and SPARNATURAL, its query component, has been adopted beyond archaeology by French cultural institutions including the National Archives and National Library. The consortium regularly conducts training workshops with consistent participation, demonstrating active community engagement. Publications about MASA tools appear in respected venues, including CAA conferences and specialised semantic web workshops like ODOCH.",Data Acquisition|Processing|Analysis|Publication|Preservation and Reuse,research-specific,Stand-alone software,JavaScript|Python|XML,Web,,"MASA emphasises interoperability through CIDOC CRM mapping and semantic web standards. Its OpenArchaeo platform supports RDF data exchange via SPARQL endpoints. The ecosystem utilises standardised vocabularies (PACTOLS, GeoNames, PeriodO) and supports multiple linked data formats. It integrates with external platforms including the ARIADNEplus portal. MASA's tools comply with the FAIR principles and support international metadata standards for cultural heritage.","MASA's strengths include its comprehensive approach to archaeological data throughout the research lifecycle, from field collection to publication. The platform's use of CIDOC CRM provides robust semantic interoperability that preserves the richness of archaeological context. The SPARNATURAL visual query interface democratises access to complex semantic data without requiring technical expertise. The consortium benefits from strong institutional backing across multiple French research organisations and governmental agencies, ensuring stability and ongoing development. Its commitment to FAIR principles and open science standards makes it a model for digital archaeological practice. The system's modular design allows archaeologists to adopt components selectively based on their specific needs.","Current weaknesses include limited adoption outside France due to language barriers and cultural specificity in archaeological terminology. The complexity of semantic web technologies presents a steep learning curve for new users, requiring significant training investment. While based on international standards, MASA's implementation remains primarily focused on French archaeological practices and datasets. Complete implementation requires multiple tools and significant technical expertise, limiting adoption by smaller archaeological projects with limited resources. The requirement for data mapping to CIDOC CRM presents an initial barrier that may discourage some potential users from joining the ecosystem.","MASA demonstrates strong survivability potential due to its institutional backing by Huma-Num and multiple French research institutions. The software has successfully transitioned from MASA to MASAplus in 2023, indicating ongoing development and support. Its integration with European initiatives like ARIADNEplus provides international visibility and sustainability pathways. The active community of users and regular training sessions create a support network that contributes to long-term viability. The modular nature of the ecosystem allows for component-by-component updates without requiring complete system overhauls. The ongoing collaboration with commercial partners like SPARNA demonstrates industry interest that could support future development.","The UK's Archaeology Data Service (ADS) provides similar digital archive functions but with less emphasis on semantic web technologies. The US-based tDAR (the Digital Archaeological Record) offers comparable repository services but lacks MASA's semantic integration capabilities. ARIADNEplus itself provides a European-wide aggregation platform that includes but extends beyond MASA's scope. CIDOC CRM implementations exist in other domains, particularly museums, but lack archaeology-specific extensions. OpenAtlas, primarily developed in Austria, offers comparable archaeological database functionality but with different technical approaches. ResearchSpace, developed by the British Museum, provides similar semantic web interfaces but focuses more on museum collections than field archaeology.",
Mask R-CNN,Success,,"Mask R-CNN is a deep learning framework for instance segmentation that extends Faster R-CNN by adding a branch for predicting segmentation masks in parallel with the existing branch for bounding box detection. While originally developed for computer vision applications, Mask R-CNN has been successfully applied to various archaeological contexts including artifact detection, site identification from remote sensing data, cultural heritage preservation, and historical document analysis. The current version (implemented through Detectron2) achieves pixel-level precision for identifying and delineating archaeological objects, with documented accuracy rates of 80-95% across diverse applications.","Mask R-CNN was introduced in March 2017 by Facebook AI Research (FAIR) through an arXiv paper authored by Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick. The paper won the prestigious Marr Prize at the International Conference on Computer Vision (ICCV) 2017. The initial implementation was in Caffe2, released as part of the Detectron framework in 2018. In 2019, Facebook released Detectron2, a complete PyTorch rewrite that has become the standard implementation of Mask R-CNN. Since then, it has been continuously updated and maintained by Meta AI (formerly Facebook AI), with the latest significant update in 2023. Archaeological applications began appearing around 2019, with adoption accelerating from 2020 onward.","The current version of Mask R-CNN employs a two-stage detection framework built upon Faster R-CNN architecture. It uses a backbone network (typically ResNet-50 or ResNet-101 with Feature Pyramid Network) to extract features from input images. The Region Proposal Network (RPN) generates potential object regions, which are then processed by RoIAlign to precisely preserve spatial locations—crucial for archaeological feature detection where boundary precision matters. For each region of interest, the network predicts object class, bounding box refinement, and a binary mask. The mask branch is a small fully convolutional network applied to each RoI, generating a mask of dimension 28×28 pixels that is later resized to the RoI size. Training involves a multi-task loss function combining classification, bounding box regression, and mask prediction losses. Implementation typically occurs through Facebook's Detectron2 PyTorch framework or older TensorFlow/Keras implementations like Matterport's version. Processing speed averages 5-10 frames per second on modern GPUs (NVIDIA RTX series or Tesla V100). Training requires 8-16GB GPU memory and datasets of 500+ annotated examples per class for optimal performance. Archaeological implementations often leverage transfer learning from models pre-trained on general datasets (COCO, ImageNet) to reduce training data requirements. The model accepts standard image formats (JPG, PNG, TIFF) and outputs structured data containing bounding boxes, class labels, confidence scores, and binary segmentation masks that integrate with archaeological GIS systems.",2025-05-24,yes,"Mask R-CNN clearly meets all essential criteria for classification as a research tool. First, it serves a research-specific purpose by enabling automated analysis of archaeological imagery and data. Second, it meaningfully transforms research materials by converting raw imagery into structured data about artifacts, features, and sites. Third, it aligns with established archaeological methodologies for object identification and classification. Additionally, Mask R-CNN satisfies multiple supporting criteria: it integrates domain knowledge through specialised training on archaeological datasets; supports multiple research lifecycle stages including data analysis, interpretation, and visualisation; transforms data between visual and structured representations; performs complex pattern recognition; visualises results through segmentation masks; and features documentation specifically addressing archaeological applications in peer-reviewed publications.",https://github.com/facebookresearch/detectron2,,https://detectron2.readthedocs.io/,https://detectron2.readthedocs.io/,Apache-2.0,Shape recognition|Artefact morphology|Machine learning|Spatial analysis|Aerial and satellite imagery,instance-segmentation|object-detection|deep-learning|computer-vision|archaeological-feature-detection,2017-03-20,2023-11-15,Detectron2 v0.6 (implementation of Mask R-CNN),Active,Meta AI (formerly Facebook AI Research),"Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick (original paper); Yuxin Wu, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, et al. (Detectron2 implementation)",Large (20+),Computer Vision,General-purpose,Excellent,"The original Mask R-CNN paper has received over 30,000 citations according to Google Scholar. On GitHub, the Detectron2 implementation has over 24,500 stars, 6,000+ forks, and 390+ contributors. The earlier Matterport Keras implementation has 21,500+ stars. In archaeological applications, several influential implementations include the WODAN system for Dutch archaeological site detection, gold foil damage detection systems for Chinese cultural heritage, and pottery classification systems with documented usage across multiple institutions. At least 50+ peer-reviewed archaeological publications reference direct Mask R-CNN implementations, with particularly strong adoption in remote sensing archaeological applications, artifact analysis, and cultural heritage conservation.",Analysis|Processing|Interpretation,research-specific,Stand-alone software,Python,Linux|macOS|Windows,,"The current version of Mask R-CNN through Detectron2 accepts standard image formats (JPG, PNG, TIFF) and can process specialised archaeological data including LiDAR-derived images, photogrammetry outputs, aerial/satellite imagery, and multispectral data. Output is provided in structured JSON format containing bounding boxes, class labels, confidence scores, and binary mask arrays. Data can be exported to common archaeological software through format converters for QGIS, ArcGIS, and other GIS systems. For 3D archaeological data, specialised implementations allow processing of point clouds by converting them to multi-view images or depth maps. Some archaeological implementations provide custom export modules for direct integration with common archaeological databases and catalogue systems.","The current version of Mask R-CNN excels at pixel-level precision for accurately delineating irregular archaeological features, crucial for complex artifact shapes and eroded site boundaries. Its instance segmentation capability distinguishes individual objects even when overlapping—essential for analysing dense artifact scatters or complex archaeological assemblages. The system demonstrates robust performance across varied image conditions including partial occlusion, variable lighting, and scale differences, achieving documented 80-95% accuracy in archaeological detection tasks. Transfer learning capabilities allow fine-tuning with relatively small archaeological datasets (500-1000 annotated examples), making it viable for specialised artifact types with limited reference collections. The framework's integration with Detectron2 provides a standardised development environment with comprehensive documentation that facilitates adoption by archaeological computing teams despite the technical complexity.","The current version requires substantial computational resources (8GB+ GPU memory, 16GB+ RAM) limiting deployment in field archaeology settings with restricted hardware access. Training demands extensive manually annotated datasets with pixel-level masks, requiring significant investment from archaeological experts. Processing speed (5-10 frames per second on high-end GPUs) precludes real-time applications during excavation or survey. The complex deep learning architecture creates a 'black box' effect where detection decisions lack clear explanations, potentially problematic for archaeological interpretations requiring methodological transparency. Implementation demands programming expertise in Python and deep learning frameworks, creating a steep technical barrier for many archaeological teams. Performance degrades significantly with poor quality imagery common in archaeological contexts (e.g., low lighting in cave sites, underwater imagery, partial exposure of artifacts in soil).","Mask R-CNN demonstrates strong survivability through active maintenance of Detectron2 by Meta AI, with the latest significant update in November 2023 and regular minor updates continuing into 2025. The large user community across disciplines ensures ongoing development of educational resources, bug fixes, and compatibility updates. Multiple implementation paths (PyTorch via Detectron2, TensorFlow via older frameworks) provide implementation flexibility and reduce dependency on any single software stack. However, newer architectures like YOLOv8-seg and Segment Anything Model (SAM) offer competitive alternatives with advantages in speed or reduced training requirements, potentially diminishing Mask R-CNN's prominence in coming years. The framework's established position in archaeological computing literature ensures continued relevance for existing projects, but new archaeological implementations will likely consider faster or more specialised alternatives. Overall, Mask R-CNN should remain viable for 3-5 years while gradually transitioning to legacy status.","YOLOv8-segmentation offers significantly faster processing (155 FPS vs. 5-10 FPS) with competitive accuracy (75-90% vs. 80-95%), making it better suited for real-time archaeological field applications and large-scale surveys, though with reduced precision in object boundaries. PointRend provides more detailed boundary delineation for complex archaeological artifacts but requires greater computational resources. Segment Anything Model (SAM) enables zero-shot segmentation without training, valuable for quickly processing novel archaeological finds, but with lower specialisation for specific artifact types. U-Net requires smaller training datasets ideal for rare artifact classes, though it cannot distinguish individual instances in clustered archaeological assemblages. Traditional computer vision methods (SIFT/SURF) require minimal computing resources suitable for field conditions but achieve lower accuracy (60-80%) and less generalisation capability across varied archaeological contexts.",
Matrix Manager,Success,,"Matrix Manager encompasses multiple implementations focused on Harris Matrix stratigraphic analysis in archaeology, primarily GSYS Matrix Manager by The Landscape Research Centre and ASEbase Matrix Manager by UCL Archaeology South-East. These tools digitise the Harris Matrix methodology, a fundamental technique for recording temporal relationships between stratigraphic units (contexts) at archaeological sites. The current versions enable archaeologists to record 'above', 'below', and 'equal to' stratigraphic relationships in a structured format, visualise these relationships, and integrate them with spatial data through GIS connections. Previous versions were primarily standalone systems with limited integration capabilities.","Matrix Manager evolved as a digital response to Edward Harris' 1973 matrix methodology which revolutionised archaeological stratigraphy recording. The GSYS implementation emerged through The Landscape Research Centre's broader development of archaeological data management systems in the late 1990s and early 2000s, growing from simple data entry tools to systems with GIS integration. ASEbase Matrix Manager developed within UCL's archaeological computing infrastructure, becoming routinely applied in commercial archaeology by 2015. Both implementations reflect gradual evolution rather than major version releases, with incremental improvements responding to field archaeology requirements. Development has been largely institutional rather than commercial, with GSYS closely tied to The Landscape Research Centre's overall data management approach.","The technical implementation of Matrix Manager varies across different versions. The GSYS version utilises a spreadsheet-based data entry system (Microsoft Excel) for recording stratigraphic relationships, with data structures focused on binary relationships between contexts ('above' and 'below') plus equivalence relationships. This tabular approach contrasts with graph-based implementations like Harris Matrix Composer. The current version of GSYS Matrix Manager employs database connectivity to store relationship data alongside context records, enabling integration with GIS platforms through shared database keys. The architecture prioritises practical archaeological workflows over computational elegance, reflecting its origins in field archaeology rather than computer science. ASEbase Matrix Manager implements a more sophisticated database model with direct integration to ASE's broader archaeological recording system. Technical limitations include scalability challenges for sites with over 3000 contexts, where performance degradation becomes noticeable. The user interface remains Windows-focused, with no mobile implementations despite field archaeology's increasing use of tablet devices. Data validation is primarily manual rather than automated, relying on archaeologist expertise rather than computational rules to identify logical inconsistencies in stratigraphic relationships.",2025-05-24,yes,"Matrix Manager qualifies as research software by meeting all essential criteria: it supports research-specific archaeological analysis (criterion 1), transforms stratigraphic data into meaningful temporal sequences (criterion 2), and implements the Harris Matrix methodology widely recognised in archaeology (criterion 3). It also satisfies multiple supporting criteria: it integrates archaeological terminology and classifications (supporting criterion 1), supports analysis and interpretation stages in research (criterion 2), transforms raw stratigraphic observations into structured temporal relationships (criterion 3), and visualises complex stratigraphic sequences (criterion 5).",,,http://www.landscaperesearchcentre.org/gsys.html,http://www.landscaperesearchcentre.org/gsys.html,Proprietary (GSYS version),Harrix matrix|Chronological modelling|Site mapping,archaeological stratigraphy|temporal sequencing|context relationships|site formation analysis|excavation recording,1990s (estimated),Unknown,Unknown (no clear version numbering),Unknown,The Landscape Research Centre (GSYS version); UCL Archaeology South-East (ASEbase version),Dominic Powlesland (GSYS); ASE Digital team (ASEbase),Small (2-5),Archaeology,Project-specific,Minimal,"Limited formal metrics available. Used primarily within developing institutions rather than broader archaeological community. No dedicated user forums, social media presence or community-driven development exist for either implementation. The 2020-2023 AHRC Matrix Project consultations found most archaeologists still use Microsoft Excel for matrix creation rather than specialised software. GSYS Matrix Manager appears geographically limited to UK archaeology, with minimal international adoption evidence. Academic citations remain sparse, with mentions primarily in comparative studies rather than research applications.",Processing|Analysis|Interpretation,research-specific,Stand-alone software,Unknown,Windows,,"GSYS Matrix Manager primarily exchanges data through spreadsheet formats (Excel, CSV) with limited support for archaeological data standards. Integration focuses on GIS connectivity rather than broader archaeological information systems. No formal APIs exist for programmatic access. ASEbase Matrix Manager offers greater integration within UCL's archaeological recording ecosystem but remains institution-specific. The current version of both implementations lacks standardized import/export capabilities, challenging interoperability with emerging archaeological data standards. Neither implementation fully supports the FAIR principles (Findable, Accessible, Interoperable, Reusable) for archaeological data.","The current version of Matrix Manager offers several significant advantages: GIS integration enables spatial-temporal analysis crucial for comprehensive archaeological interpretation. Spreadsheet compatibility leverages familiar tools, reducing training needs for field archaeologists. Database connectivity supports long-term data preservation within institutional archives. Publication-ready outputs streamline report generation for both academic and commercial archaeology. The interface design accommodates practical field archaeology workflows, addressing real-world documentation needs rather than theoretical ideals. The GSYS implementation particularly excels at managing medium-sized excavation datasets without requiring specialized computer knowledge.","Matrix Manager's current version exhibits several limitations: The architecture shows limited scalability for complex sites with more than 3000 contexts where performance degradation becomes evident. Platform restrictions (Windows-only) hinder adoption in field settings increasingly using mobile devices. Documentation remains minimal across all implementations, limiting self-guided learning. Absence of standardization between different Matrix Manager implementations complicates data exchange between archaeological organisations. No mobile support exists despite field recording trends moving toward tablet-based documentation. Collaborative features are limited, hampering team-based archaeological projects spanning multiple specialists. The user interface appears dated compared to contemporary software, potentially discouraging adoption by younger archaeologists.","Matrix Manager faces sustainability challenges in a fragmented landscape. GSYS Matrix Manager's long-term viability depends on The Landscape Research Centre's continued support, with no clear succession plan evident. The absence of formal versioning or update schedules creates uncertainty for archaeological projects planning multi-year excavations. Limited user community and institutional adoption restrict potential for community-maintained development. The AHRC Matrix Project (2020-2023) may reshape the landscape through standardization efforts, potentially obsoleting current implementations in favor of FAIR-compliant alternatives. Future sustainability likely depends on transition to open-source development models and cloud-based collaborative platforms. ASEbase's institutional backing provides more stability but remains tied to UCL's internal priorities rather than broader archaeological needs.","Harris Matrix Composer (more academic focus, graph-based approach); ARK Matrix (open-source alternative with command-line functionality); ArchEd (free German alternative); Stratify (Australian implementation); Microsoft Visio with archaeological templates; Microsoft Excel (most commonly used alternative according to AHRC Matrix Project findings); Intrasis (commercial archaeological information system with matrix capabilities)",
MicroStation,Success,,"MicroStation is a comprehensive CAD platform developed by Bentley Systems for infrastructure design and 3D modelling. The current version provides a complete environment for architectural and engineering design with advanced capabilities in 3D modelling, point cloud processing, and visualisation. While primarily used in civil engineering, architecture, and construction, MicroStation offers technical capabilities that could theoretically benefit archaeological documentation, particularly for complex site modelling, survey data processing, and spatial analysis. Despite these capabilities, there is almost no documented usage of MicroStation in archaeological contexts, with researchers in this field overwhelmingly favouring other CAD systems (AutoCAD), GIS platforms (QGIS, ArcGIS), or specialised archaeological tools. The high cost and steep learning curve have prevented adoption in archaeological workflows despite the software's technical potential for handling large point cloud datasets from LiDAR or photogrammetry that are increasingly common in archaeological survey.","MicroStation originated in 1984 when Bentley Systems was founded by the Bentley brothers. The software evolved from an initial product called PseudoStation, a DGN file editor for Intergraph workstations, into a fully independent CAD platform. The first official MicroStation release came in 1986, developed in collaboration with Intergraph. Major milestones include: MicroStation 4 (1991) introducing the MDL programming environment; MicroStation 95 (1995) adding the intuitive AccuDraw precision input system; MicroStation V8 (2001) revolutionising the software with a new DGN format supporting unlimited levels, elements, and file sizes; MicroStation V8i (2008) adding BIM capabilities; MicroStation CONNECT Edition (2015) introducing a 64-bit architecture and improved user interface; and most recently MicroStation 2024 with enhanced AI capabilities and native Python scripting. Throughout its 40-year history, the software has maintained a focus on precision CAD for infrastructure design and complex engineering projects, consistently adding capabilities to handle larger datasets and more complex visualisations.","The current version of MicroStation (2024) operates on a robust 64-bit native architecture that enables handling of extremely large datasets without size limitations. The software uses the V8 DGN format introduced in 2001, which employs IEEE-754 based 64-bit precision allowing theoretically unlimited file sizes constrained only by operating system limitations. This architecture is particularly relevant for archaeological applications involving massive point cloud datasets from LiDAR or photogrammetry surveys. MicroStation's rendering engine (LuxRender) supports photorealistic visualisation capabilities using physically-based rendering (PBR) materials, advanced lighting models, and GPU acceleration. For point cloud processing, MicroStation offers native support for LAS/LAZ files with automatic conversion to Bentley's optimised POD format. The software can handle millions of points efficiently through parallel processing techniques and dynamic memory allocation, with display options including depth clipping, multiple synchronised views, and ASPRS standard classification capabilities. The technical infrastructure includes a comprehensive API supporting multiple programming environments: MDL (MicroStation Development Language), C++, .NET, and recently added native Python scripting in the 2024 version. This extensibility framework allows for custom tool development, though no archaeology-specific extensions currently exist in the ecosystem. Geospatial functionality includes support for thousands of coordinate systems from a global library, direct connectivity to Esri ArcGIS REST services, and comprehensive transformation capabilities. Reality modelling features facilitate the creation of 3D mesh models from photographs and integration with various data sources. The software architecture follows a modular design allowing add-on products to extend functionality, notably TerraSolid for advanced point cloud processing and terrain modelling, though these add-ons require additional licensing costs. The proprietary DGN format presents potential long-term access concerns, despite good export capabilities to open formats like DWG, DXF, and IFC.",2025-05-26,maybe,"MicroStation meets all essential criteria for research software by supporting complex data transformation and visualisation capabilities that could theoretically serve archaeological research. It satisfies at least four supporting criteria: data transformation between formats, powerful analytical capabilities for spatial data, advanced visualisation functions, and support for some research lifecycle stages (primarily analysis and interpretation). However, its classification remains 'maybe' because: 1) It lacks domain-specific knowledge integration for archaeology; 2) Documentation does not address archaeological applications; 3) It was not originally designed for research purposes; 4) No evidence exists of actual archaeological usage despite technical potential. While MicroStation could theoretically support archaeological research tasks, the absence of discipline-specific tools, high cost barriers, and lack of adoption in the archaeological community prevent a 'yes' classification.",,,https://www.bentley.com/software/microstation/,https://www.bentley.com/software/microstation/,Commercial (Proprietary),3D modelling|Spatial analysis,CAD|infrastructure|visualization|3D_modeling|point_cloud_processing,1986,2024-03-01,24.00.02.62,Active,"Bentley Systems, Inc. (NASDAQ: BSY)",Keith Bentley|Barry Bentley|Ray Bentley|original development team,Large (20+),Civil Engineering and Architecture,General-purpose,Excellent,"MicroStation has an extensive user base in architecture, engineering, and construction with over 1 million users globally according to Bentley Systems. The software has very strong institutional adoption in large engineering firms and government agencies working on infrastructure projects. It consistently ranks among the top CAD platforms in engineering software surveys. However, usage metrics in archaeological contexts are virtually non-existent, with no documented archaeological projects using MicroStation found during extensive searches of academic literature, conference proceedings, and professional forums. The software has a robust community infrastructure with active forums on the Bentley Communities platform, frequent webinars, and a well-established certification program, though none of these resources address archaeological applications.",Processing|Analysis|Visualization,mass-market,Stand-alone software,C++|C#|Java|Python,Windows,,"MicroStation offers extensive interoperability with various file formats and standards. The current version supports direct import/export of DWG, DXF, SKP, IFC, 3DS, PDF, OBJ, STL, and numerous other formats. The software can directly read and process point cloud data in LAS/LAZ format, converting to Bentley's optimised POD format. Geospatial interoperability is robust with support for thousands of coordinate systems, direct connectivity to Esri ArcGIS REST services, and WMS/WMTS integration. The proprietary DGN format is well-documented and provides good data exchange options, though it does require conversion for use with other software. MicroStation can also integrate with various Bentley products through ProjectWise collaboration services. Since version 2018, the software supports IFC4 for BIM workflows, and the most recent version has enhanced integration with mesh modelling formats relevant to photogrammetry processing.","The current version of MicroStation offers several technical strengths that could benefit archaeological applications: 1) Unlimited file size capability and 64-bit architecture enable handling massive point cloud datasets from archaeological LiDAR surveys without size constraints; 2) Advanced point cloud processing features support sophisticated classification and analysis of archaeological landscapes; 3) Precision modelling tools with sub-millimetre accuracy benefit detailed documentation of artefacts and structures; 4) Comprehensive coordinate system support facilitates accurate geospatial registration crucial for archaeological mapping; 5) Photorealistic rendering capabilities enable compelling visualisations for public engagement and site interpretation; 6) Recently added Python scripting support could theoretically enable customised archaeological workflows if adopted; 7) Mature, stable development with consistent updates ensures long-term viability of created models; 8) Excellent documentation and support infrastructure provides robust learning resources for mastering the complex toolset.","MicroStation presents significant weaknesses for archaeological applications despite its technical capabilities: 1) Prohibitive licensing costs starting at $1,955 annually per user make it unaffordable for most archaeological projects operating on limited budgets; 2) Steep learning curve requiring 3-6 months for proficiency represents substantial opportunity cost for archaeological teams; 3) Windows-only platform limitation excludes Mac and Linux users common in academic archaeological settings; 4) Absence of archaeology-specific tools, templates, or workflows necessitates extensive customisation; 5) Proprietary format raises concerns about long-term archaeological data preservation and archiving; 6) No established archaeological user community means limited peer support or shared resources; 7) Lack of integration with archaeological databases or recording systems requires additional workflow steps; 8) Complex licensing model and enterprise focus poorly suited to project-based archaeological work; 9) Overly broad feature set includes many capabilities irrelevant to archaeological needs, increasing complexity.","MicroStation demonstrates high survivability as software with four decades of continuous development, regular updates, and strong financial backing. Bentley Systems reported $1.39 billion in annual revenue in 2024, maintains a market capitalisation of approximately $14.5 billion, and employs over 5,000 staff worldwide. The company consistently invests about 20% of revenue in R&D, ensuring ongoing platform development. The software receives quarterly updates with major versions every 1-2 years, most recently MicroStation 2024 released in March 2025. Public company status (NASDAQ: BSY) provides transparency into business operations and stability. However, for archaeological applications specifically, survivability concerns are significant. The complete absence of archaeological adoption creates a negative feedback loop: no archaeological tools or workflows exist because no archaeologists use MicroStation, and no archaeologists adopt it because specialised resources don't exist. The high licensing costs pose insurmountable barriers for archaeological budgets, while the proprietary format creates long-term access risks for archaeological data. Despite the software's excellent technical survivability, its future in archaeological contexts appears limited to niche applications where engineering requirements mandate its use.","For archaeological documentation and spatial analysis, several alternatives offer better value and disciplinary alignment: 1) AutoCAD remains the dominant CAD platform in archaeology with extensive training resources, lower cost educational licenses, and universal file format compatibility; 2) QGIS provides comprehensive open-source GIS capabilities with archaeology-specific plugins and zero licensing costs; 3) Blender offers powerful open-source 3D modelling with growing archaeological adoption for artefact and structural visualisation; 4) Agisoft Metashape provides specialised photogrammetry processing at lower cost with archaeological case studies and workflows; 5) ArcGIS includes comparable point cloud processing capabilities with established archaeological user communities; 6) Cloud-based options like Autodesk BIM 360 or Trimble Connect offer collaboration features at lower per-user costs; 7) For point cloud processing specifically, CloudCompare provides open-source alternatives to MicroStation's TerraSolid extension. These alternatives collectively address all capabilities MicroStation offers at substantially lower cost with established archaeological usage patterns.",
Microware,Failure,Fail,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
OASIS,Success,,"OASIS (Online AccesS to the Index of archaeological investigationS) is a web-based system for recording archaeological investigations across the UK. The current version functions as a comprehensive archaeological reporting system that bridges the gap between field practitioners and heritage management organisations. It enables archaeologists, commercial units, academics, and community groups to register projects, upload reports, and share findings with Historic Environment Records (HERs) and national heritage bodies. OASIS addresses a critical challenge in archaeological practice: systematically capturing and preserving 'grey literature' - unpublished reports from commercial archaeological work that would otherwise remain inaccessible. Through integration with the Archaeology Data Service (ADS) Library, OASIS has transformed nearly 40,000 archaeological reports into citable research resources with Digital Object Identifiers (DOIs).","OASIS has evolved through multiple versions reflecting the development of digital archaeology over two decades. The system began as a pilot project in 1999-2001 establishing proof of concept for online archaeological reporting. The first full version (OASIS I) launched in 2004, marking the formal beginning of systematic implementation across England. In 2005, the system was extended to Scotland through partnership with Historic Scotland (now Historic Environment Scotland). Between 2016-2020, the HERALD (Historic Environment Records Access via Linked Data) project undertook a major redevelopment of the system. A beta release of OASIS V began testing in March 2020, introducing new architecture and functionality. Full deployment of OASIS V occurred during 2022-2023, with OASIS IV officially retired in March 2023 after nearly two decades of service. The HERALD project represented a fundamental reimagining of the system, involving comprehensive user needs assessment, development of new functional specifications, and complete technical rebuild. This £1.6 million investment by Historic England and Historic Environment Scotland demonstrated sustained institutional commitment to the platform's future.","The current version of OASIS (OASIS V) employs a modern multi-tier web architecture designed for scalability and reliability. The system operates through a RESTful API endpoint (https://api.oasis.ac.uk/v1/) supporting JSON-based data exchange with authentication via Basic HTTP protocols. The architecture incorporates role-based access control with five distinct user levels, from data creators through to system administrators. The technical stack includes a web-based frontend using HTML5 and JavaScript, an application server layer handling business logic, a centralised database managed by ADS infrastructure, a file management system supporting multiple formats (PDF, GIS data, images), and an integration layer connecting to external services. The system implements OAIS-compliant digital preservation standards ensuring long-term data sustainability. The API provides programmatic access with pagination support (10-1,000 results per page), filtering capabilities by organisation, role, date ranges, and reviewer ID, and export functionality in JSON and CSV formats. Geographic boundary services enable automatic area identification for projects, while integration with heritagedata.org.uk provides access to standardised archaeological vocabularies and thesauri. Previous versions of OASIS used older web technologies and had more limited integration capabilities, with OASIS IV using a form-based approach rather than the more sophisticated API-driven architecture of the current version. The transition to OASIS V represented a complete rebuild rather than an incremental update, allowing for significant modernisation of the technical infrastructure while maintaining data compatibility with legacy records.",2025-05-26,yes,"OASIS qualifies as research software based on meeting all essential criteria and multiple supporting criteria. For essential criteria: (1) Research-specific purpose - OASIS was explicitly designed for archaeological research workflows, addressing discipline-specific needs for systematic investigation recording, grey literature preservation, and research dissemination. Its development by archaeological domain experts ensures alignment with research practices. (2) Research data engagement - The system serves as primary repository for UK archaeological fieldwork data, facilitating access to research datasets for secondary analysis, and enabling long-term preservation of research outputs. Integration with ADS ensures professional data curation meeting academic standards. (3) Methodological alignment - OASIS integrates seamlessly with established archaeological methodologies, supports standardised fieldwork documentation approaches, and enables replicable research through consistent metadata capture. Regional Research Framework integration connects projects to broader research agendas. Supporting criteria include domain expertise requirements, research output generation through DOI assignment, academic integration (mandated for AHRC-funded archaeological research), and methodological innovation in systematic grey literature preservation.",,,https://oasis.ac.uk/,https://oasis.ac.uk/,Proprietary (Institutional),Data management|Grey literature|Site mapping|Data collection|Datasets,digital repository|heritage management|grey literature|archaeological recording|preservation system,2004,2023,OASIS V,Active,"OASIS enjoys robust institutional support from key heritage organisations across the UK. Primary backing comes from the Archaeology Data Service at the University of York (developer and host), Historic England (main funding body), and Historic Environment Scotland (Scottish requirements and funding). Additional support derives from Archaeology Scotland, regional HERs, and local authority archaeologists.",Archaeology Data Service (ADS) at the University of York,Medium (6-20),Archaeology,General-purpose,Comprehensive,"Usage metrics demonstrate exceptional adoption: 30,000+ projects recorded since formal launch, nearly 50,000 reports in ADS Library, 20,785 digital files uploaded, 90,000+ archaeological records since 2004, and 292 active organisations regularly contributing data. Qualitative assessment reveals OASIS described as the 'cornerstone of British archaeology' in academic literature. The system has achieved near-universal adoption within UK commercial archaeology, where regulatory requirements often mandate its use. Academic institutions integrate OASIS into fieldwork training, while the ADS Grey Literature Library created through OASIS represents the world's largest collection of archaeological grey literature.",Data Acquisition|Data Management|Publication|Preservation and Reuse,research-specific,Stand-alone software,HTML5|JavaScript|Java,Web-based,,"OASIS excels in interoperability with UK heritage systems. The current version supports export in multiple formats (JSON, CSV, PDF), integrates with controlled vocabularies through heritagedata.org.uk, connects with the Archaeology Data Service (ADS) for long-term archiving, links with Historic Environment Records (HERs) across England and Scotland, and interfaces with the CITiZAN coastal archaeology project. Earlier versions had more limited interoperability, focusing primarily on form submissions and basic file upload capabilities. The transition to OASIS V significantly enhanced interoperability through implementation of the REST API and adoption of standardised data formats.","OASIS excels in several critical areas. Its comprehensive coverage of UK archaeological activity provides unparalleled documentation of national heritage investigations. Long-term preservation through ADS infrastructure ensures sustainable access to archaeological knowledge. Standardisation of reporting through controlled vocabularies enhances data quality and interoperability. Strong institutional backing from government heritage agencies guarantees ongoing support and development. The current version benefits from thoughtful user interface design based on extensive community consultation during the HERALD project, making the system more accessible to diverse user groups including commercial archaeologists, academics, and community volunteers. The integration with regulatory frameworks embeds OASIS deeply within archaeological practice, ensuring continued relevance and compliance with planning requirements.","Identified limitations include geographic restriction to the UK limiting international applicability. Technical complexity requires significant user training and ongoing support. Dependence on user compliance for data quality creates inconsistencies in record completeness. The current version shows limited innovation adoption compared to newer platforms regarding Linked Open Data or machine learning capabilities. Workflow rigidity occasionally constrains adaptation to emerging archaeological practices. As a proprietary system without open source licensing, OASIS lacks the community development model that might accelerate feature development or customisation. The system's comprehensive approach can sometimes result in complex workflows that create barriers for occasional users, particularly community archaeology groups with limited technical expertise.","Multiple indicators suggest strong long-term viability for OASIS. 25+ years of continuous operation demonstrates institutional commitment and community value. The major redevelopment investment through the HERALD project shows willingness to modernise infrastructure. Regulatory integration ensures continued relevance within UK planning processes. Management board governance provides strategic oversight and stakeholder representation. Regular funding streams from Historic England and partner organisations support ongoing operations. Future development plans include enhanced Research Framework connections, potential Digital Twin approaches through the ARTEMIS project, expanded museum and archive integration, improved visualisation and analytics capabilities, and possible extension to additional heritage sectors. The system's central role in UK archaeological practice and substantial institutional investment indicate exceptional sustainability prospects.","International alternatives demonstrate diverse approaches to archaeological data management. tDAR (The Digital Archaeological Record) focuses on comprehensive data archiving for North American archaeology, emphasising dataset preservation over regulatory reporting. Open Context pioneered 'data sharing as publication' with editorial oversight and Linked Open Data integration. Arches provides open-source heritage management infrastructure deployed globally with customisable workflows. The Archaeology Data Service (ADS) serves as OASIS's partner for long-term preservation rather than competitor. Regional systems include various national databases across Europe (ARENA2, ArkeoGIS), Canadian provincial heritage databases, and commercial solutions like InTerris Registries and Proficio. However, none replicate OASIS's specific integration with UK heritage legislation and planning processes, making it effectively irreplaceable within its geographic and regulatory context.",
OpenArchaeo,New,,"OpenArchaeo is a semantic web platform that enables federated querying of heterogeneous archaeological datasets through semantic web technologies. The current version implements the CIDOC CRM ontology and its extensions to integrate disparate archaeological databases without requiring data migration or restructuring. It provides both a technical SPARQL endpoint for machine access and a user-friendly visual query interface called SPARNATURAL, which allows archaeologists without semantic web expertise to formulate complex queries across multiple archaeological datasets. The platform focuses on preserving existing database structures while enabling cross-database searches through semantic mediation.","OpenArchaeo was developed by the MASA (Mémoire des Archéologues et des Sites Archéologiques) consortium, which was established in France in 2012 to improve digital archaeological data management. Initial development began around 2013, with conceptual architecture defined between 2013-2017. The first public presentation of the platform occurred at the ODOCH conference in Rome in June 2019, accompanied by the publication of the paper 'OpenArchaeo for Usable Semantic Interoperability'. The system has been continuously refined since then, with particular focus on the SPARNATURAL visual query interface. In 2023, the MASA consortium transitioned to MASAplus with continued support for OpenArchaeo development. Throughout its history, the platform has maintained its focus on federated querying rather than centralised data storage, aligning with European initiatives like ARIADNEplus.","The current version of OpenArchaeo employs a modular architecture built around semantic web technologies. At its core is a federated query system that connects to multiple archaeological databases through semantic mediation using the CIDOC CRM ontology and its extensions (CRMarchaeo, CRMsci, CRMba). Technically, the platform consists of several components: 1) A triple store repository (using GraphDB) that contains RDF representations of archaeological data, 2) A SPARQL endpoint providing machine-accessible query services, 3) The SPARNATURAL visual query builder (developed in TypeScript as a reusable web component), and 4) A user-friendly explorer interface specifically tailored for archaeological concepts. The backend is primarily implemented in Java (deployed as WAR files), while the frontend utilises modern JavaScript/TypeScript. Configuration is handled through SHACL specifications and Excel-based setup tools. The key technical innovation is the query federation approach - rather than requiring data migration into a centralised repository, OpenArchaeo implements semantic mappings that allow cross-database queries while preserving the original data structures. This architecture maintains database sovereignty for participating institutions while enabling semantic interoperability. The platform supports standard semantic web formats including RDF/XML, Turtle, N-Triples, and JSON-LD. The SPARNATURAL component translates user selections in the visual interface into valid SPARQL 1.1 queries, abstracting away the complexity of the query language from end users. Performance considerations include query result limitations (capped at 1000 results in the visual interface) and CORS requirements for endpoint integration.",2025-05-26,yes,"OpenArchaeo meets all essential criteria for research software classification. It has a clear research-specific purpose in enabling federated querying of archaeological datasets. It directly engages with research data by transforming heterogeneous archaeological databases into semantically interoperable resources. It aligns with recognized methodologies in both archaeology and semantic web research. For supporting criteria, it excels in domain knowledge integration (implementing CIDOC CRM and archaeological vocabularies), research lifecycle support (covering data processing through publication), analytical capabilities (complex semantic queries), and visualization functions (SPARNATURAL interface). The software's documentation specifically addresses archaeological research applications, and it supports both data collection integration and dissemination of research data through semantic web standards.",https://github.com/sparna-git/Sparnatural,,http://openarchaeo.huma-num.fr/explorateur/home,http://openarchaeo.huma-num.fr/explorateur/home,Custom licence (components vary),Data management|Platforms and publications|Schemas and ontologies|Spatial analysis|Site mapping,semantic_web|federated_query|archaeology_database|cidoc_crm|interoperability,2019-06-01,2023-01-01,Unknown,Active,"TGIR Huma-Num (CNRS, France)|MASAplus Consortium|ARIADNEplus (European project)",Olivier Marlet|Xavier Rodier|Thomas Francart|Béatrice Markhoff,Small (2-5),Archaeology,General-purpose,Basic,"OpenArchaeo is primarily used within French archaeological institutions that participate in the MASA/MASAplus consortium. No public usage statistics are available, but documented implementations include the ArSol database (Tours), HADÈS (Bordeaux Metropole), and integration with the French national archaeological thesaurus PACTOLS. The platform is referenced in European infrastructure projects, particularly ARIADNEplus. GitHub metrics for the SPARNATURAL component show modest activity with approximately 10-15 stars and fewer than 10 forks. Academic citations appear in semantic web archaeology literature, particularly in French-language publications. Community engagement occurs primarily through consortium workshops rather than open forums. The platform has limited visibility outside francophone archaeology communities despite its technical sophistication.",Data Acquisition|Processing|Analysis|Publication|Preservation and Reuse,research-specific,Stand-alone software,TypeScript|JavaScript|Java,Web (platform-independent),,"OpenArchaeo interoperates with multiple archaeological database systems through semantic mappings to CIDOC CRM. The current version supports data exchange in standard semantic web formats including RDF/XML, Turtle, N-Triples, JSON-LD, and N-Quads. Controlled vocabularies are integrated through the PACTOLS archaeological thesaurus, GeoNames for geographical references, and authority systems like VIAF and ORCID for people. The platform implements SPARQL 1.1 for queries, with RESTful APIs providing additional integration points. The federated architecture is designed to work with existing archaeological database systems without requiring data migration. Specific French archaeological databases with documented integration include ArSol (Tours), HADÈS (Bordeaux), and ArkeoGIS. For spatial data, the system supports GeoSPARQL extensions and standard OGC formats.","OpenArchaeo's primary strength is its federated architecture, which enables semantic interoperability without requiring database migration - institutions can maintain existing systems while gaining cross-database query capabilities. The current version's SPARNATURAL component provides an intuitive visual interface that translates domain concepts into SPARQL queries, making semantic web technology accessible to archaeologists without technical expertise. The platform's implementation of CIDOC CRM and its extensions ensures alignment with international standards, enhancing long-term data sustainability. Institutionally, OpenArchaeo benefits from integration with permanent French research infrastructure (TGIR Huma-Num), ensuring sustained technical support and development. The modular design allows components to be reused in other contexts, particularly the SPARNATURAL query builder which has applications beyond archaeology. The comprehensive semantic model enables complex queries across heterogeneous datasets that would be impossible with conventional database systems.","The current version of OpenArchaeo faces several limitations. Technical weaknesses include query result limitations (capped at 1000 results in the visual interface) and complex CORS requirements for endpoint integration. The federated architecture, while preserving database sovereignty, introduces performance challenges compared to centralised systems. Documentation is primarily available in French, creating a significant language barrier for international adoption. The platform requires substantial understanding of semantic web concepts for implementation, despite efforts to simplify the user interface. Institutionally, OpenArchaeo has limited visibility outside French archaeological circles, with minimal evidence of international user communities or third-party implementations. The small development team size raises concerns about response times for technical issues. While the SPARNATURAL component is open source, the complete system architecture documentation is less comprehensive than competing platforms like Arches, potentially limiting adoption by organisations without direct consortium support.","OpenArchaeo demonstrates moderate to high survivability within its primary French and European archaeological context. The platform's integration into permanent national research infrastructure (TGIR Huma-Num) provides institutional stability and sustained funding. The recent transition to the MASAplus consortium (2023) indicates continued organisational commitment. The implementation of established standards (CIDOC CRM, Semantic Web) enhances technical sustainability, while the open-source SPARNATURAL component ensures key innovations remain accessible. Participation in European digital infrastructure initiatives like ARIADNEplus further strengthens its position. However, several risk factors should be noted: the limited international visibility restricts potential growth of the user community; the relatively small development team creates potential single points of failure; and competition from more widely adopted platforms like Arches may limit broader adoption. Documentation gaps, particularly in English, may hinder new implementations outside the francophone community. Overall, OpenArchaeo appears sustainable within its current institutional context, though its global impact will likely remain limited without addressing internationalisation challenges.","Arches (Getty Conservation Institute): A comprehensive archaeological information system with global adoption that requires data migration into its platform. Offers more extensive documentation and a larger user community, but less flexibility for existing database integration. OpenAtlas (Austrian Academy of Sciences): A CIDOC CRM-native database system focused on historical and archaeological research with strong spatial capabilities and prosopographical data handling. Offers direct data modelling but smaller user base than OpenArchaeo. ARK (Archaeological Recording Kit): Established excavation recording system with web-based interfaces, but less semantic web integration than OpenArchaeo. Uses traditional LAMP stack rather than semantic technologies. ResearchSpace (British Museum): Enterprise-scale semantic web platform with sophisticated knowledge representation capabilities, but more complex implementation requirements than OpenArchaeo. Excellent for museum collections but less field-oriented. Heurist (University of Sydney): Research-focused database platform with archaeological capabilities and flexible schema design. More straightforward than semantic web approaches but less powerful for heterogeneous data integration.",
OpenGuide,New,A best practices distribution platform. Initial fail without clarification,"OpenGuide is a specialized platform developed by the MASA consortium (Mémoires des Archéologues et des Sites Archéologiques) for creating, managing, and distributing best practices documentation in French digital archaeology. The platform automatically converts documents from standard word processing formats (Word/OpenOffice) into structured XML-TEI format, which can then be accessed as HTML or PDF. It serves as a standardized methodological documentation repository, primarily for French-speaking archaeological researchers, enabling the transformation of traditional documentation into interoperable digital formats that follow international standards. While designed initially for archaeology, the platform's architecture allows for expansion to other humanities disciplines.","OpenGuide emerged from the broader evolution of the MASA consortium in French digital archaeology. The consortium's first phase (2012-2016) focused on digitizing archaeological archives and establishing data sharing standards. During the second phase (2017-2022), the consortium developed an integrated digital ecosystem including OpenGuide, responding to growing demands for standardized methodological documentation in archaeology. Developed by Olivier Marlet at the Laboratoire Archéologie et Territoires (UMR 7324 CITERES) in Tours, the platform became operational as part of the MASA digital ecosystem. In January 2023, the consortium transitioned to MASAplus with renewed funding through 2027, ensuring continued development and maintenance of the platform within France's national digital humanities infrastructure.","OpenGuide implements a straightforward document transformation pipeline that converts Word/OpenOffice documents to XML-TEI format, which is then rendered as HTML for web viewing or PDF for download. The platform requires users to apply predefined styles to their documents, which are then parsed during the conversion process to generate properly structured XML. This approach prioritizes user accessibility over technical flexibility, allowing non-technical users to create standards-compliant digital documentation. The platform leverages established standards including XML-TEI (Text Encoding Initiative) for document encoding and CIDOC-CRM for cultural heritage metadata. No public source code repository exists, suggesting a closed development model that restricts external contributions. Integration occurs primarily within the MASA ecosystem, connecting with related tools like SPARNATURAL (visual SPARQL query interface) and OpenArchaeo (semantic web platform). The platform adheres to FAIR principles for data sharing but lacks the extensibility of more generalized platforms with plugin architectures. The current version maintains this core functionality while potentially expanding disciplinary scope beyond archaeology.",2025-05-26,yes,"OpenGuide meets all essential criteria for research software classification. It directly supports research activities by standardizing and distributing methodological documentation in archaeology. It transforms research materials by converting standard documents into structured XML-TEI format, enabling better preservation and interoperability. It aligns with established methodologies in digital humanities and archaeological documentation. Additionally, it meets supporting criteria by integrating domain knowledge through archaeological terminologies, supporting the publication stage of the research lifecycle, transforming data between formats, and focusing documentation on research applications. The platform is actively used by researchers within the MASA consortium and produces research outputs in the form of structured documents that support archaeological best practices.",,,https://openguide.huma-num.fr/,https://openguide.huma-num.fr/,Unknown,Data management|Schemas and ontologies|Templates|Educational resources and practical guides,XML-TEI conversion|Best practices distribution|French archaeology|Digital documentation|Standardized methodologies,2017,2023,Unknown,Active,"MASA/MASAplus consortium under Huma-Num (French national digital humanities infrastructure), including CNRS, six Maisons des Sciences de l'Homme, INRAP, National Archaeological Museum, and multiple French universities","Olivier Marlet (Laboratoire Archéologie et Territoires, UMR 7324 CITERES, Tours)",Small (2-5),Archaeology,General-purpose,Basic,"No public statistics document active users, uploaded documents, or download frequencies. The platform primarily serves the French archaeological community, with usage concentrated within the MASA consortium's institutional partners. The user community organizes through six working groups covering different aspects of digital archaeology. Communication occurs via mailing lists, an active blog, and annual colloquia, suggesting engaged but geographically concentrated adoption primarily within France.",Publication|Preservation and Reuse,research-specific,Stand-alone software,Unknown,Web,,"OpenGuide demonstrates strong commitment to international standards, particularly XML-TEI for text encoding and CIDOC-CRM for cultural heritage metadata. This standards-based approach ensures theoretical interoperability with other digital humanities tools and long-term data preservation. Generated XML-TEI documents can be processed by other tools, although the platform itself functions as an endpoint rather than offering APIs for integration into larger workflows. It integrates with other MASA ecosystem tools including Opentheso (thesaurus management) and OpenArchaeo (semantic data exploration).","OpenGuide excels in its specialized focus on converting best practices documentation to standardized formats. The automated XML-TEI conversion eliminates manual encoding barriers, while predefined styles ensure consistency across documents. The platform's embedding within France's comprehensive digital archaeology ecosystem represents a significant advantage, with integrated vocabulary management, semantic data exploration, and standardized thesauri. Strong institutional backing through the MASA/MASAplus consortium provides stability and sustained funding, while adherence to international standards ensures long-term accessibility of created documents. For French-speaking archaeologists, the platform offers a streamlined workflow for creating standardized digital documentation without requiring technical expertise.","The platform's limitations include its French-language focus and lack of internationalization, which restrict global adoption. Without public APIs or source code, external developers cannot contribute improvements or create local adaptations. The platform's dependency on Huma-Num infrastructure creates potential vendor lock-in risks, while limited transparency regarding usage metrics makes impact assessment difficult. The closed development model contrasts with fully open-source alternatives and restricts community engagement. Competition from established alternatives with greater flexibility, broader functionality, or more extensive plugin ecosystems further highlights these weaknesses. The platform's specialized nature, while valuable for its target community, limits broader applicability beyond French-speaking archaeological research.","OpenGuide's future sustainability depends primarily on continued French institutional support. The MASAplus consortium structure provides medium-term stability through 2027, but long-term viability requires addressing several risks. These include personnel dependencies (particularly on the lead developer), technology stack obsolescence without transparent updating mechanisms, and potential shifts in French research funding priorities. The platform's integration within the broader MASA ecosystem provides some resilience through shared infrastructure, but also creates interdependencies that could amplify disruption risks. Future sustainability would benefit from internationalization efforts, open-sourcing code to enable community contributions, and developing funding models beyond institutional grants.","The digital humanities landscape offers several alternatives to OpenGuide. Omeka provides greater flexibility with an extensive plugin ecosystem supporting diverse content types. TEI Publisher offers dedicated TEI-XML publishing capabilities with more customization options. Programming Historian excels in tutorial-based best practices distribution with peer review and multilingual content. For archaeological communities specifically, Arches offers geospatial heritage management capabilities. Broader European research infrastructures like DARIAH and CLARIN provide more comprehensive platforms with greater international reach. These alternatives generally offer more transparent development models and larger user communities, though they may lack OpenGuide's specific focus on automated document transformation for archaeological best practices.",
oxcAAR,Success,,"oxcAAR is an R package providing an interface to the OxCal radiocarbon calibration software. The current version enables archaeologists to perform radiocarbon calibration and analysis directly from R without manually using OxCal's interface. It functions as a wrapper that executes OxCal commands from R, reads the output, and returns the results as R data structures. This capability is particularly valuable for archaeologists who need to calibrate large sets of radiocarbon dates and incorporate this into statistical analyses, offering a programmatic approach to chronological modeling that maintains the rigour of OxCal's established calibration algorithms.","Originally named 'roxcal', oxcAAR was developed by the Initiative for Statistical Analysis in Archaeology Kiel (ISAAKiel) to address the need for integrating OxCal calibration workflows into R's statistical environment. Development began around 2016-2017, with the first official release in 2018. The package evolved from initial calibration functions to more complex features supporting Bayesian modeling. Version 1.0.0 was released in April 2019, establishing the core functionality, followed by version 1.1.0 in July 2019 adding improved visualization features. The latest version 1.1.1 was released in June 2021, focusing on maintenance and compatibility with newer R versions. Throughout its development, the package has been supported by German research initiatives including the SFB 1266 'TransformationsDimensionen' at Kiel University.","The current version of oxcAAR uses a client-server architecture to communicate with OxCal. The package does not include OxCal itself but instead manages the execution of the OxCal program (which must be separately installed) through system calls. Technically, oxcAAR generates OxCal script code in R, executes this code using the installed OxCal program (Java-based), and then parses the resulting output files back into R objects. The implementation relies on the java.exe executable from OxCal to process the commands. The package's architecture includes several key components: (1) setup functions that locate or download OxCal, (2) command generation functions that create valid OxCal code, (3) execution functions that run the commands, and (4) parsing functions that transform OxCal's JSON output into R-compatible data structures. The resulting calibrated dates are returned as custom S3 class objects ('oxcAARCalibratedDate' for individual dates and 'oxcAARCalibratedDatesList' for collections), which include probability distributions and summary statistics. For earlier versions, the package relied on temporary files for data exchange, but this approach was refined in version 1.0.0 to improve reliability across operating systems. Version 1.1.1 includes improvements to the plotting functions, using R's native graphics capabilities to represent calibration curves and probability distributions. The package requires R ≥ 2.15.0 and depends on several R packages including stringr for text processing and jsonlite for parsing OxCal's output.",2025-05-26,yes,"oxcAAR clearly qualifies as research software by meeting all essential criteria and multiple supporting criteria. It supports archaeological research through radiocarbon calibration (Essential Criterion 1), directly transforms raw radiocarbon measurements into calibrated dates (Essential Criterion 2), and implements established methodologies for Bayesian chronological modeling (Essential Criterion 3). Additionally, it incorporates domain knowledge from archaeology and radiocarbon science (Supporting Criterion 1), supports analysis in the research lifecycle (Supporting Criterion 2), transforms data between formats (Supporting Criterion 3), performs statistical calculations (Supporting Criterion 4), produces visualizations of calibration results (Supporting Criterion 5), and includes documentation specifically addressing archaeological applications (Supporting Criterion 6).",https://github.com/ISAAKiel/oxcAAR,https://cran.r-project.org/web/packages/oxcAAR/index.html,https://isaakiel.github.io/,https://isaakiel.github.io/,GPL-2,"Radiocarbon dating, calibration and sequencing|Statistical analysis|Chronological modelling",radiocarbon calibration|bayesian modeling|chronology analysis|archaeological dating|oxcal interface,2018-03-18,2021-06-06,1.1.1,Maintenance-only,Initiative for Statistical Analysis in Archaeology Kiel (ISAAKiel)|SFB 1266 TransformationsDimensionen|Christian-Albrechts-Universität zu Kiel|University of Bern,Martin Hinz|Clemens Schmid|Daniel Knitter|Carolin Tietze,Small (2-5),Archaeology,General-purpose,Comprehensive,"The package has moderate adoption metrics with 23 stars and 10 forks on GitHub. It has been presented at major archaeological computing conferences including CAA 2018 where developers conducted workshops. Citation data indicates usage in demographic analysis studies, chronological modeling research, and methodological comparisons. The package is referenced in the CRAN Task View for Archaeological Science, indicating recognition within the discipline. Download statistics from CRAN show steady usage, primarily from European research institutions. While not having mass adoption, it maintains a dedicated user base among specialists working with radiocarbon data in archaeological research.",Analysis|Interpretation,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"The current version imports and exports data in formats compatible with the broader R ecosystem. It can read radiocarbon dates from data frames and CSV files, and outputs calibrated dates as specialized R objects with methods for extraction and visualization. Results can be exported to standard R data structures for further analysis or visualization. The package can parse OxCal's JSON output format and integrate with other chronological modeling packages. While not directly supporting archaeological data exchange standards, its integration with R enables connection to other formats through R's data handling capabilities. Interoperability with OxCal itself is the primary strength, allowing researchers to leverage OxCal's capabilities within R workflows.","The current version's primary strengths include: (1) Direct access to OxCal's established calibration algorithms without leaving the R environment, maintaining scientific accuracy and comparability with the discipline's quasi-standard; (2) Programmatic control enabling reproducible analysis workflows and batch processing of large datasets; (3) Integration with R's statistical and visualization capabilities for advanced analysis beyond basic calibration; (4) Support for complex Bayesian chronological modeling including sequences, phases, and boundaries; (5) Transparent methodological approach with open-source implementation; (6) Enhanced visualization options for calibration curves and probability distributions; (7) Structured output formats that facilitate further computational analysis. These strengths particularly benefit researchers working with large radiocarbon datasets or requiring complex chronological modeling.","The current version has several limitations: (1) Installation complexity requiring both R and OxCal setup, with Java dependencies adding potential compatibility issues; (2) Performance overhead compared to native R implementations like Bchron, particularly for simple calibrations; (3) Dependency on external software (OxCal) that may change independently of oxcAAR; (4) Learning curve requiring familiarity with both R and OxCal concepts; (5) Limited platform consistency with installation procedures varying across operating systems; (6) Internet connection requirement for initial OxCal download; (7) Resource intensity compared to pure R implementations; (8) Reliance on temporary file operations that can occasionally cause issues in certain environments; (9) Sparse error handling for complex edge cases in OxCal's output.","oxcAAR demonstrates moderate to good long-term sustainability prospects. Its core strengths are institutional backing through the ISAAKiel initiative and university affiliations, maintenance by an active research team, and integration with fundamental archaeological methodologies that remain relevant. The package is officially available on CRAN, ensuring standard distribution and quality control. However, challenges include the relatively small development team (primarily 2-3 active contributors), reliance on external software (OxCal) that may evolve independently, and the specialized nature of its application domain. The last significant update was in 2021, suggesting maintenance mode rather than active feature development. Given its position as a bridge between established software (OxCal) and the R ecosystem, continued viability is likely for the medium term (3-5 years), though longer-term prospects would be enhanced by broader adoption and more regular updates.","Several alternatives exist for radiocarbon calibration in R: (1) Bchron offers faster native R implementation of calibration but lacks some of OxCal's specialized archaeological models; (2) rcarbon focuses on summed probability distributions and demographic analysis rather than detailed individual calibrations; (3) ArchaeoPhases specializes in post-processing of Bayesian models and pairs well with oxcAAR; (4) Direct use of OxCal provides full functionality but lacks R integration; (5) c14bazAAR offers complementary functionality for accessing radiocarbon databases. Most alternatives either provide different functionality or implement simpler calibration methods, making oxcAAR valuable for researchers specifically needing OxCal's algorithms within R workflows.",
OxCal,Success,,"OxCal is specialised software for radiocarbon calibration and Bayesian chronological modeling in archaeology and related disciplines. The current version (4.4.1) enables researchers to transform raw radiocarbon measurements into calendar dates and construct sophisticated chronological models incorporating archaeological knowledge about stratigraphy, phases, and sequences. It implements Bayesian statistical methods that combine radiocarbon measurements with prior information about archaeological contexts to produce probabilistic chronologies with quantified uncertainty. The software supports both simple calibration of individual dates and complex multi-phase models with sequences, boundaries, and cross-referencing between different dating methods. Originally developed for archaeological applications, OxCal has expanded to support Quaternary science, paleoenvironmental research, and geological applications where establishing precise chronologies is essential.","OxCal was first developed in 1994 by Christopher Bronk Ramsey at the Oxford Radiocarbon Accelerator Unit (ORAU). The initial version provided basic radiocarbon calibration with rudimentary Bayesian capabilities. Version 2, released in 1995, introduced the first graphical user interface and expanded modeling capabilities, coinciding with Bronk Ramsey's seminal paper introducing Bayesian methods to archaeology. Version 3 (1999-2003) added significant improvements to the statistical methods and expanded model types. A major overhaul occurred with version 4 in 2007-2009, which was completely rewritten in C++ with a JavaScript web interface and introduced the Chronological Query Language (CQL2) for formally specifying models. This version also implemented more sophisticated MCMC algorithms and expanded the range of prior distributions. Subsequent updates (4.1-4.3) from 2010-2018 refined algorithms, improved performance, and added specialized capabilities for wiggle-matching and age-depth modeling. The current version 4.4.1, released in 2020, incorporated the latest IntCal20 calibration curves and further improved the MCMC convergence algorithms. Throughout its history, development has been synchronized with updates to the international radiocarbon calibration curves, with major releases typically following new IntCal publications.","The current version of OxCal (4.4.1) implements a sophisticated multi-tier architecture combining compiled C++ components with web technologies. At its core, OxCal utilizes C++ for computationally intensive Bayesian statistical calculations, implementing Markov Chain Monte Carlo (MCMC) methods with Metropolis-Hastings algorithms for sampling posterior probability distributions. This core engine handles the mathematical complexity of integrating radiocarbon calibration curves with archaeological prior information. The software supports multiple interface modes: a web-based GUI using JavaScript, HTML5, and SVG for interactive model building and visualization; a command-line interface for batch processing; and integration capabilities through file-based workflows. Models are specified using the Chronological Query Language (CQL2), a domain-specific language developed specifically for archaeological chronological modeling. CQL2 provides formal syntax for expressing stratigraphic relationships, phase boundaries, sequences, and other temporal constraints. Calibration functionality incorporates the latest IntCal20, SHCal20, and Marine20 curves through high-precision cubic interpolation algorithms. The current version utilizes adaptive algorithms that automatically adjust MCMC parameters to ensure convergence, with diagnostic statistics to verify reliability. Output is generated in multiple formats including SVG graphics, CSV data tables, and specialized JavaScript files that contain full probability distributions. While earlier versions (pre-4.0) were implemented primarily in Visual Basic with web capabilities added later, the current architecture represents a complete redesign optimized for cross-platform compatibility and web accessibility. Despite its sophisticated capabilities, OxCal remains closed-source, with development centralized at Oxford rather than through community contributions. The technical implementation balances computational rigor with usability considerations, employing visualization techniques like highest posterior density regions and specialized plotting algorithms to communicate complex probabilistic results to archaeologists who may lack statistical expertise.",2025-05-26,yes,"OxCal meets all essential criteria for research software tools and numerous supporting criteria. For essential criteria: (1) It has a clear research-specific purpose in archaeological chronology construction; (2) It directly transforms research materials (radiocarbon measurements) into meaningful chronological interpretations; (3) It implements recognized Bayesian methodologies for archaeological chronology building. For supporting criteria, OxCal meets at least 6 of the 8: it incorporates domain knowledge through the Chronological Query Language and archaeological constraints; supports multiple research lifecycle stages from data analysis through interpretation; transforms data between formats; performs sophisticated statistical calculations; provides visualization of probability distributions; has documentation specifically addressing archaeological applications; and supports research data dissemination through standardized formats and publication-ready outputs. The software is purpose-built for scientific inquiry, implementing specialized algorithms for archaeological chronology construction that are not found in general-purpose software.",,,https://c14.arch.ox.ac.uk/oxcal.html,https://c14.arch.ox.ac.uk/oxcal.html,Freeware,"Radiocarbon dating, calibration and sequencing|Bayesian analysis|Chronological modelling|Statistical analysis",bayesian-statistics|chronology-building|radiocarbon-calibration|archaeological-dating|temporal-modeling,1994,2020,4.4.1,Active,Oxford University Research Laboratory for Archaeology and the History of Art (RLAHA) and the Oxford Radiocarbon Accelerator Unit (ORAU),Christopher Bronk Ramsey,Small (2-5),Archaeology,General-purpose,Excellent,"OxCal is extensively cited in archaeological literature, with over 91,000 citations of Bronk Ramsey's OxCal-related publications according to Google Scholar. The 1995 foundational paper has over 5,000 citations alone. It is the dominant software for Bayesian chronological modeling in archaeology, used in major international projects like dating Stonehenge construction phases, modeling Neolithic spread across Europe, and calibrating paleoenvironmental records. The software is taught in specialized workshops and university courses worldwide. Usage has grown exponentially, with a 2015 study finding 62% of all papers using Bayesian chronological models had appeared in just the previous five years. The active Google Groups forum for OxCal has thousands of subscribers with regular troubleshooting discussions and methodological questions. Geographic distribution of users spans all continents, with particularly strong adoption in European, North American, and East Asian research institutions. While download statistics are not publicly available, OxCal is referenced in archaeological textbooks as the standard tool for chronological modeling.",Analysis|Interpretation,research-specific,Stand-alone software,C++|JavaScript,Windows|macOS|Linux|Web,,"OxCal uses multiple data formats: it imports radiocarbon measurements as plain text, CSV, or through direct entry. Output formats include SVG graphics, CSV data tables, and JavaScript files containing probability distributions. Version 4 introduced more robust data exchange capabilities including the ability to export complete model specifications in CQL2 format. The current version can incorporate data from multiple dating methods including dendrochronology, OSL, and uranium-series dating alongside radiocarbon. It interfaces with calibration curve databases through standardized formats from the IntCal working group. While OxCal does not have direct API connections to other software, it supports file-based workflows that allow integration with R, Python, and specialized archaeological database systems through intermediate files. The OxCal.js output files contain complete mathematical representations of probability distributions that can be loaded into other analysis tools.","OxCal provides several key strengths that have established its dominant position in archaeological chronology building. First, the current version implements sophisticated Bayesian statistical methods within an accessible interface, allowing archaeologists without programming or advanced statistical training to construct complex chronological models. Second, it offers comprehensive modeling capabilities that handle virtually all archaeological contexts from simple site phases to complex stratigraphic sequences with multiple constraints. Third, the web-based interface in version 4.4.1 eliminates installation barriers, making the software immediately accessible across platforms. Fourth, OxCal produces publication-quality visual outputs that effectively communicate probabilistic results, with customizable graphics that meet journal standards. Fifth, the software's longevity and continuous development since 1994 has created a vast body of methodological literature and case studies that new users can reference. Sixth, the implementation of the formal Chronological Query Language (CQL2) in current versions ensures reproducibility by providing explicit documentation of model assumptions. Seventh, the software maintains rigorous statistical validity while providing intuitive visual feedback on model quality through agreement indices and convergence statistics. The current version has significantly improved processing speed for complex models compared to previous iterations, handling datasets with hundreds of dates efficiently.","Despite its strengths, OxCal exhibits several significant weaknesses. First, the current version remains closed-source, limiting transparency and community contribution to core algorithms. Users cannot inspect implementation details of statistical methods, creating a 'black box' problem for critical evaluation. Second, the software has a steep learning curve, particularly for the Chronological Query Language required for complex models. Documentation, while comprehensive, focuses on mechanics rather than underlying statistical concepts, leading to misapplication. Third, version 4.4.1 lacks integration with modern scientific workflows - there are no APIs or direct connections to data repositories, requiring manual data handling. Fourth, the current implementation provides limited sensitivity analysis tools, making it difficult to assess how changes in model specifications affect results. Fifth, OxCal has minimal built-in support for spatial analysis despite the frequent spatial component of archaeological chronologies. Sixth, while the web interface improves accessibility, it creates limitations for batch processing and automation compared to fully scriptable alternatives. Seventh, the single-developer model creates sustainability concerns, as development depends heavily on one individual despite institutional backing. Finally, published applications frequently demonstrate 'checkbox compliance' where researchers use sophisticated models without fully understanding implications, risking inappropriate application of Bayesian methods.","OxCal demonstrates strong long-term sustainability prospects due to several factors. First, the software has secured continuous institutional support from Oxford University's Research Laboratory for Archaeology for over 30 years, with significant funding through the Natural Environment Research Council (£5.6 million for the national radiocarbon facility) and commercial dating services. Second, the current version (4.4.1) is fully integrated into archaeological practice worldwide, creating substantial switching costs that discourage alternatives. Third, despite being primarily developed by Christopher Bronk Ramsey, the software has comprehensive documentation and training materials that mitigate 'bus factor' risks. Fourth, the web-based implementation in version 4 eliminated previous platform dependencies, ensuring continued accessibility across operating systems. Fifth, OxCal's alignment with the international radiocarbon calibration curve development process (IntCal) ensures it remains scientifically current, with regular updates following new curve releases. Challenges to long-term sustainability include the closed-source development model which limits community contribution, and growing competition from open-source R packages that offer greater workflow integration. However, OxCal's established position in archaeological methodology, continuous thirty-year development history, and backing from a major research institution suggest it will remain viable for the foreseeable future, likely continuing to adapt through incremental improvements rather than radical changes.","Several alternatives to OxCal exist, though none match its comprehensive capabilities for archaeological applications. CALIB (developed at Queen's University Belfast) offers simpler radiocarbon calibration without Bayesian modeling and is used primarily for basic calibration needs. BCal (University of Sheffield) was an early web-based Bayesian calibration tool but has seen limited updates. Among R packages, 'rcarbon' provides radiocarbon calibration and summed probability distribution analysis but lacks OxCal's full modeling capabilities. 'Bchron' offers age-depth modeling and calibration but is less archaeology-focused. 'oxcAAR' serves as an R interface to OxCal rather than a true alternative. More specialized tools include 'Bacon' and 'rbacon' for age-depth modeling of sediment cores, which excel in their niche but lack broader archaeological modeling features. IOS-cal is an open-source Python alternative emphasizing reproducibility but has a smaller user community and feature set. JAGS and Stan provide general Bayesian modeling frameworks requiring substantial programming expertise to implement chronological models. ChronoModel, developed by CNRS researchers, offers similar Bayesian capabilities with an alternative statistical approach (slightly more emphasis on outlier detection) but has a smaller user base. The current version of OxCal (4.4.1) maintains advantages in documentation quality, institutional support, and comprehensive modeling capabilities, though open-source alternatives are gaining traction among researchers prioritizing reproducibility and workflow integration.",
Perseus Digital Library,Success,,"The Perseus Digital Library is a comprehensive digital repository of primary source materials for classical studies, including ancient Greek and Latin texts with integrated language tools. The current version offers extensive searchable collections of texts with parallel translations, morphological analysis, dictionary lookups, and word frequency statistics. Users can explore classical literature, history, art, archaeology, philosophy, and linguistics through cross-referenced resources. The platform serves scholars, students, and general readers by providing multilayered contextual information, from basic translations to sophisticated philological tools. Earlier versions began as a HyperCard-based platform before evolving into web-based applications, with the original focus on Ancient Greek civilization later expanding to include Roman materials, Renaissance works, and other historical corpora.","Perseus began in 1985 at Harvard University as a project led by Gregory Crane to create interactive materials for studying Ancient Greek culture. The first public release (Perseus 1.0) in 1992 was a HyperCard-based CD-ROM containing Greek texts, translations, and images. In 1993, the project relocated to Tufts University. Perseus 2.0 (1996) expanded content and improved functionality while still using CD-ROM distribution. Perseus migrated to the web in 2000 with version 3.0, implementing a Perl-based architecture. The Java-based Perseus 4.0 'Hopper' launched in 2005, introducing the current web platform architecture that has been incrementally updated since. In 2018, the Scaife Viewer (considered Perseus 5.0) was released as a more modern reading interface. Development of Perseus 6.0 began in 2023 with NEH funding, featuring a complete redesign using Python/Django and modern web technologies. Throughout its evolution, Perseus has expanded from primarily Greek content to encompass Latin texts, Germanic materials, 19th-century American documents, Arabic sources, and more, while continuously enhancing analytical tools and user interfaces.","The current Perseus 6.0 platform represents a significant architectural departure from previous versions, employing a modern Python/Django backend with a Vue.js frontend. This version utilizes a microservices architecture with containerization via Docker, facilitating deployment across various cloud environments including Heroku and Google Cloud Run. The system maintains all content in TEI-compliant XML with Canonical Text Services (CTS) URNs for stable citations, while employing MODS and MADS metadata standards for cataloguing. Perseus 6.0 features comprehensive API access, enabling programmatic interaction with all platform resources. In contrast, the still-operational Perseus 4.0 'Hopper' uses a Java-based architecture with PostgreSQL/MySQL databases and Apache Lucene for search indexing. This legacy system, while stable, requires Unix-like operating systems and significant administrative expertise for local installation. The technical infrastructure of Perseus centralises around its morphological analysis engine (Morpheus), which enables automatic parsing of Greek and Latin words, generating grammatical analyses that power many of the platform's interactive features. This analysis connects to lexicographical resources, allowing users to access dictionary entries contextually. The platform's search capabilities include both full-text and morphologically-aware queries. Both versions implement complex linking between texts, translations, commentaries, and other resources through the CTS architecture, though Perseus 6.0 offers more sophisticated alignment capabilities, particularly between source texts and translations. Data storage implementations differ substantially between versions: Perseus 4.0 uses traditional relational databases, while Perseus 6.0 employs a hybrid approach combining document databases for flexibility with relational databases for structured information. The platform's technical development reflects an ongoing balance between maintaining legacy services that thousands depend upon while implementing contemporary development practices and technologies for future sustainability.",2025-05-29,yes,"Perseus Digital Library meets all essential criteria for research software classification. It has a clear research-specific purpose as a platform for classical textual study and analysis. It directly engages with research materials by providing sophisticated tools for interacting with ancient texts, including morphological analysis, concordance generation, and cross-referencing capabilities. Its methodological alignment with classical philology, linguistics, and historical research is evident in its tools for textual criticism and analysis. Additionally, it satisfies numerous supporting criteria: it integrates domain knowledge through specialised linguistic tools and classical terminology; supports multiple research lifecycle stages from data collection to analysis and publication; transforms data between formats (TEI XML to various display formats); provides robust analytical capabilities including statistical and linguistic analysis tools; offers visualisation functions for textual relationships and archaeological materials; includes extensive documentation addressing research applications; and facilitates data dissemination through open access to primary sources and research outputs.",https://github.com/PerseusDL,,https://www.perseus.tufts.edu/hopper/,https://www.perseus.tufts.edu/hopper/,Creative Commons Attribution-ShareAlike 3.0 United States License (CC BY-SA 3.0 US),Literary analysis and epigraphy|Statistical analysis|Data management|Datasets|Diagrams and visualizations,digital library|classical languages|morphological analysis|lexicography|textual alignment,1992-01-01,2024-05-15,6.0 (Beta),Active,Tufts University Department of Classical Studies,Gregory Crane|Marie-Claire Beaulieu|Bridget Almas|Lisa Cerrato|James Tauber|Matthew Munson|Zachary Fletcher|Leonard Muellner,Medium (6-20),Classical Studies,General-purpose,Comprehensive,"Perseus Digital Library serves approximately 300,000 unique users monthly across 74 countries. The platform hosts over 100 million words of text and 75,000 images, with 1.1 million manually created links and more than 30 million automatically generated connections. Since its inception, Perseus has received 11 NEH grants totaling $1,162,653, alongside additional funding from the Mellon Foundation, IMLS, and NSF. The Scaife Viewer implementation has 107 GitHub stars and 33 forks across its repositories. Perseus content and tools have been cited in over 2,000 scholarly publications according to Google Scholar. The platform is used in hundreds of university courses globally and has been formally adopted by major classical studies programs including those at Oxford, Harvard, and Berkeley. User metrics show particularly strong adoption in secondary education and undergraduate programs, with significant growth in non-traditional and international user communities since 2010.",Processing|Analysis|Interpretation|Publication|Preservation and Reuse,research-specific,Stand-alone software,Java|Python|JavaScript|XML,Web-based (cross-platform),,"Perseus employs TEI XML as its primary content format, ensuring long-term preservation and interoperability. The platform implements the Canonical Text Services (CTS) protocol for stable citation and referencing. Perseus 6.0 offers comprehensive RESTful APIs enabling programmatic access to texts, morphological analyses, and lexical data. Data export capabilities include plain text, XML, and JSON formats. The platform supports Unicode throughout and employs standardised metadata using MODS and MADS. Integration capabilities with external tools include persistent URIs for all resources and OpenURL support. Earlier versions were less interoperable, with Perseus 4.0 offering limited programmatic access through inconsistently documented APIs. Recent developments focus on IIIF compatibility for image resources and improved alignment formats between texts and translations.","The Perseus Digital Library offers several distinct advantages for classical studies research. The current version provides comprehensive coverage of Greek and Latin primary sources with integrated language tools that dramatically reduce barriers to working with ancient texts. Its open access model serves global audiences regardless of economic status, fulfilling a democratic mission unmatched by commercial alternatives. The platform uniquely integrates multiple research dimensions—texts, translations, commentaries, dictionaries, and archaeological materials—creating connections impossible in traditional research environments. For educators, Perseus's progressive information disclosure model suits different skill levels, making it valuable from secondary education through postgraduate research. The underlying TEI XML encoding ensures long-term data sustainability and reuse potential, while the implementation of Canonical Text Services (CTS) creates stable citation mechanisms crucial for scholarly reference. The morphological analysis engine (Morpheus) automates grammatical parsing that would require extensive manual effort, enabling new forms of quantitative analysis across large corpora. Perseus has also established a significant community of practice, with extensive documentation, tutorials, and pedagogical resources supporting implementation in diverse educational contexts.","Despite its valuable contributions, Perseus exhibits several significant limitations. The platform's reliance on public domain editions (primarily 19th and early 20th century) due to copyright restrictions renders it inadequate for advanced philological research requiring current critical apparatus. The Perseus 4.0 interface, while familiar to longstanding users, presents substantial usability challenges with an outdated design described in reviews as 'ergonomically poor' and 'unintuitive.' System performance issues include frequent server timeouts during peak usage periods and slow response times for complex morphological queries. The documentation quality varies dramatically between versions: Perseus 4.0 materials are outdated and incomplete, while Perseus 6.0 documentation, though improved, remains under development. For computational research, the absence of bulk download capabilities and inconsistent API implementation limits large-scale corpus analysis. Text encoding inconsistencies exist across the collection due to evolving standards during the project's long history. The platform's development cycle shows irregular pacing, with long periods of minimal updates followed by major overhauls, creating challenges for institutional adoption planning. For archaeological and art historical research, image quality often falls below current scholarly standards, and 3D visualization capabilities lag behind specialized alternatives.","Perseus demonstrates remarkable institutional resilience, having survived four decades of technological change through adaptive evolution. The current Perseus 6.0 modernization represents a critical juncture that, if successful, would address longstanding technical limitations while maintaining the platform's core value proposition. Several factors support long-term viability: strong institutional backing from Tufts University; recognition as essential infrastructure for classical studies; continuous grant success including recent NEH funding through 2026; and an international network of collaborating institutions providing development support. The modernization to contemporary technologies and development practices improves technical sustainability, while the open-source model enables community contributions. However, structural vulnerabilities persist: the absence of an endowment or sustainable revenue model beyond competitive grants creates periodic existential risk; the aging core development team lacks clear succession planning beyond Gregory Crane and Marie-Claire Beaulieu; and well-funded commercial competitors increasingly erode Perseus's unique position. The platform's future sustainability likely depends on successfully transitioning to a hybrid funding model that supplements grants with institutional memberships or selective premium services while maintaining core open access functionality. Perseus's survival prospects remain cautiously positive given its essential role in classical studies infrastructure, though continued adaptation to changing funding environments will prove crucial.","The Thesaurus Linguae Graecae (TLG) offers superior Greek language coverage with 110+ million words and better morphological parsing, though it requires subscription fees. The Loeb Classical Library Online provides professional interface design and high-quality modern translations with consistent editorial standards, available for $195 annually. Oxford Scholarly Editions Online features authoritative critical editions with full apparatus, addressing Perseus's primary content limitation. The Digital Latin Library offers newer Latin texts with critical apparatus through open access. For integrated archaeological materials, Arachne provides superior image quality and 3D visualizations of classical artifacts. JSTOR specializes in secondary literature with full-text search capabilities that complement Perseus's primary source focus. Each alternative excels in specific domains, but none matches Perseus's comprehensive integration of multiple resource types in an open access environment. Commercial platforms generally offer superior user interfaces and modern editions but lack Perseus's morphological tools and cross-referencing capabilities. For specialized research, scholars typically use Perseus alongside these alternatives rather than exclusively choosing one platform.",
PhotoModeler,Success,,"PhotoModeler is a professional photogrammetry software that creates accurate 3D models and measurements from photographs. The software enables users to extract precise dimensional data from ordinary photographs by identifying common points across multiple images. The current version offers two main workflows: a manual approach where users mark corresponding points across images, and a more automated approach using SmartMatch technology and coded targets. In archaeology, PhotoModeler has been used for site documentation, artefact recording, excavation mapping, and architectural documentation of heritage structures. Archaeological applications include cave art documentation at Spain's Ekain Cave UNESCO site, Pompeii architectural recording, and creating accurate 3D models of artefacts for museum displays and research. While originally developed for engineering and industrial applications, PhotoModeler has maintained relevance in archaeological contexts where high precision measurements are required, though it has faced increasing competition from more automated alternatives.","PhotoModeler was developed by Alan Walford who founded Eos Systems Inc. (now PhotoModeler Technologies) in 1990. The software was first released as QMeasure in beta form in October 1993, with PhotoModeler 1.0 commercially launched in January 1994. Initially focused on desktop photogrammetry for non-specialists, the software has undergone continuous development for over 30 years. Major developments include: Version 3 (1998) which added surface modeling capabilities, Version 4 (2000) introducing automatic coded target detection, Version 5 (2004) with improved camera calibration, Version 6 (2008) adding SmartMatch automation, PhotoModeler Scanner (2009) introducing dense surface modeling, Version 2012 with improved SmartPoints, and subsequent annual releases. The company rebranded from Eos Systems to PhotoModeler Technologies around 2015. In 2020, the product line was simplified to two versions (Standard and Premium), and subscription options were introduced alongside perpetual licenses. The software has maintained consistent development with annual major releases and regular minor updates throughout its three-decade history.","PhotoModeler is a Windows-only 64-bit application developed with a proprietary codebase. The current version (2025.0.0) employs a combination of photogrammetric techniques including bundle adjustment for camera calibration and orientation, feature-based matching for automation, and dense multi-view stereo reconstruction for surface generation. The software utilizes a point-based modeling approach where corresponding points in multiple photographs are identified (either manually or automatically) to establish 3D coordinates through triangulation. PhotoModeler's coded target system provides sub-pixel measurement accuracy through specially designed printed targets with unique identifiers that can be automatically detected and matched. The software architecture includes separate modules for project management, photo handling, 3D modeling, measurement, and export. Processing is primarily CPU-based with some GPU acceleration for dense surface modeling in the Premium version. For extensibility, PhotoModeler provides comprehensive API access through Windows Dynamic Data Exchange (DDE), supporting integration with Visual Basic, C/C++, Java, Python and other languages. The software employs a modular licensing system that enables different capability sets based on the purchased version. Technical constraints include its Windows-only platform and hardware requirements that scale with project complexity. The Premium version's SmartMatch and Dense Surface Modeling features require more powerful systems for processing large datasets efficiently.",2025-05-29,yes,"PhotoModeler qualifies as research software by meeting all essential criteria and multiple supporting criteria. It has a clear research-specific purpose in enabling measurement and documentation of archaeological sites and artifacts. It directly engages with research data by transforming photographs into measurable 3D models, supporting archaeological methodologies for documentation and analysis. Supporting criteria met include: domain knowledge integration through specialized measurement tools for archaeological contexts; research lifecycle support spanning data acquisition, processing, and analysis; data transformation capabilities converting photos to 3D models; analytical capabilities for measurement and comparison; visualization functions generating 3D models and orthophotos; documentation explicitly addressing archaeological applications; and data collection functionality specifically for field research.",,,https://www.photomodeler.com,https://www.photomodeler.com,Commercial proprietary,3D modelling|Photogrammetry|Site mapping|Data collection|Data management,close-range photogrammetry|precision measurement|coded targets|archaeological documentation|heritage digitization,1994-01-01,2024-12-06,2025.0.0,Active,PhotoModeler Technologies (formerly Eos Systems Inc.),Alan Walford and team,Small (2-5),Engineering/Computer Vision,General-purpose,Excellent,"PhotoModeler has documented use in archaeological contexts since 1996. Usage metrics include: continuous commercial availability for over 30 years; adoption across multiple industries including archaeology, engineering, forensics, and manufacturing; regular citation in academic literature, though less frequently than competitors like Agisoft Metashape in recent years; inclusion in educational programs for cultural heritage documentation, though not as widely as alternatives; and notable archaeological projects including UNESCO World Heritage site documentation. The software is used by universities, museums, archaeological consulting firms, and heritage organizations, though specific customer numbers are not publicly disclosed. Community engagement appears primarily through company-managed support channels rather than independent user communities. The trend over the past decade shows stable usage in specialized applications requiring high precision, but decreasing market share in general archaeological documentation as more automated alternatives have gained prominence.",Data Acquisition|Processing|Analysis|Visualization,research-specific,Stand-alone software,Proprietary (likely C++),Windows,,"PhotoModeler exports to numerous formats including DXF, OBJ, STL, FBX, and KML/KMZ, enabling integration with CAD systems, GIS platforms, and 3D visualization tools. Import capabilities include various image formats, LIDAR data (Premium version), and control point information from total stations and GPS systems. The current version supports direct georeferencing through GPS data embedded in photographs. File exchange is primarily through standard 3D formats rather than specialized APIs, though the software does offer scripting capabilities for workflow automation. While the software lacks direct web publishing capabilities, exported models can be converted for web display through third-party platforms. PhotoModeler maintains consistent backward compatibility with earlier file versions.","PhotoModeler offers several significant strengths that maintain its relevance despite competition from newer alternatives. The current version provides exceptional measurement accuracy through its coded target system, achieving sub-millimeter precision for close-range applications. The software offers unparalleled manual control over the modeling process, allowing specialists to verify and adjust each step of reconstruction for maximum reliability. PhotoModeler's extensive documentation and mature, stable codebase reflect 35 years of continuous development and refinement. The software provides reproducible workflows with comprehensive audit trails, supporting scientific rigor in archaeological documentation. Its hybrid approach combining automated features with manual verification options allows adaptation to varying project requirements and challenging photographic conditions. For archaeological applications specifically, PhotoModeler's support for external control points enables integration with traditional survey methods, maintaining continuity with established archaeological recording practices.","Despite its strengths, PhotoModeler faces several significant limitations in the current archaeological software landscape. The software's steep learning curve requires substantial time investment compared to more automated alternatives, presenting a barrier for projects with limited technical expertise. The Windows-only platform excludes macOS and Linux users, limiting adoption in mixed computing environments common in academic settings. PhotoModeler's relatively high cost (starting at $995 for Standard version, approximately $3,000 for Premium) exceeds most archaeological project budgets, especially compared to competitors like Agisoft Metashape ($179 standard/$59 educational). The manual workflow, while precise, requires significantly more processing time than fully automated alternatives, creating efficiency challenges for large-scale documentation projects. The current version's limited cloud processing capabilities and reliance on local computing resources restricts scalability for extensive site documentation. From a technical perspective, the proprietary closed-source nature prevents customization for specialized archaeological needs and raises concerns about long-term access and data preservation. These limitations have contributed to PhotoModeler's declining market share in archaeological applications despite its technical capabilities.","PhotoModeler demonstrates moderate to good long-term viability based on several factors. The software's 35-year continuous development history shows remarkable stability in the volatile software market. Regular annual releases with consistent feature improvements indicate ongoing commitment to product development. The established customer base across multiple industries provides diversified revenue streams beyond archaeology alone. However, several factors present sustainability concerns: the very small development team (2-5 people) limits capacity and creates key person dependencies, particularly on founder Alan Walford without clear succession planning. The company faces increasing competition from both commercial alternatives with larger development resources and improving open-source options. The Windows-only platform may become increasingly limiting as computing environments diversify. The higher price point and specialized nature restrict market growth potential compared to more accessible alternatives. While PhotoModeler likely remains viable for the near to medium term based on its established position and consistent development, its long-term prospects depend on addressing competition from more accessible alternatives and planning for eventual leadership transition. For archaeological users specifically, the software represents a moderate sustainability risk compared to more widely adopted alternatives with larger user communities.","The primary alternative to PhotoModeler in archaeological contexts is Agisoft Metashape (formerly PhotoScan), which has become the dominant photogrammetry solution in archaeology offering more automated processing at significantly lower cost ($179 standard/$59 educational). Metashape's workflow emphasis on automation rather than manual control makes it more accessible to non-specialists. Reality Capture provides the fastest processing speeds among commercial options and is now free for users earning under $1M annually (through Epic Games acquisition). Pix4D offers specialized solutions for drone mapping with subscription pricing ($38-360/month). Open-source alternatives include Meshroom (based on AliceVision) and COLMAP, which provide free solutions though with steeper technical requirements. Web-based services like Sketchfab and Polycam offer increasingly capable photogrammetry with minimal technical barriers. For specialized measurement applications similar to PhotoModeler's core strength, iWitnessPRO and PhotoModeler's own UAS version offer alternatives. Post-processing tools MeshLab (free) and CloudCompare (free) have become essential complements to any photogrammetry workflow. These alternatives typically employ automated feature detection rather than PhotoModeler's coded targets, trading some precision for significantly faster workflows and lower costs.",
pnuts,Failure,Fail - need more info,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Polynomial Texture Mapping (PTM),Success,,"Polynomial Texture Mapping (PTM) is an imaging technique that captures the surface properties of objects to enable interactive re-lighting from any direction. The current version allows users to examine archaeological artifacts with virtual light sources that reveal surface details invisible to conventional photography. PTM excels at enhancing the visibility of inscriptions, wear patterns, and subtle surface features on coins, tablets, manuscripts, and stone artifacts, making it particularly valuable for archaeological and cultural heritage documentation.","PTM was developed at Hewlett-Packard (HP) Labs in 2001 by Tom Malzbender, Dan Gelb, and Hans Wolters, who filed three patents for the technology in March 2000. Originally designed as a computer graphics enhancement technique, it was quickly adopted for cultural heritage applications. Cultural Heritage Imaging (CHI) became the technology's steward around 2002, developing open-source implementations and training programs. After HP's patents expired (2011-2017) and Malzbender retired in 2013, CHI became the primary maintainer. Major developments include the evolution from the original PTM format to Reflectance Transformation Imaging (RTI) using Hemispherical Harmonics for improved representation, and the release of RTIBuilder and RTIViewer software under GPL v3 licensing.","The current version of PTM/RTI employs a mathematical approach that stores polynomial coefficients rather than simple RGB values for each pixel. This enables dynamic relighting through a biquadratic polynomial model: L(u,v) = a1u² + a2v² + a3uv + a4u + a5v + a6, where coefficients capture how surfaces reflect light from different angles. The processing pipeline consists of three main components: capture tools, processing engines, and viewing applications. RTIBuilder (Java-based requiring Java 6+) processes 50-70 photographs taken with varying light positions using Singular Value Decomposition for least-squares fitting—the most computationally intensive step requiring 4GB+ RAM for large datasets. The file format evolved from the original PTM specification (v1.2, November 2001) storing biquadratic coefficients to newer RTI formats using Hemispherical Harmonics. Files typically range 3-6 times larger than equivalent JPEGs. Modern implementations leverage GPU acceleration for real-time rendering at 30+ FPS, with shader-based enhancement modes including specular enhancement, diffuse gain, and surface normal visualization. Web deployment utilizes multi-resolution tiled formats with WebGL-powered viewers like WebRTIViewer and rti.js. Previous versions used the original PTM Fitter from HP Labs (C++ implementation) which suffers from 32-bit architecture limitations on modern systems.",2025-05-29,yes,"PTM qualifies as research software because it meets all essential criteria: it has a research-specific purpose supporting archaeological documentation, meaningfully transforms research materials by enhancing surface details invisible to other methods, and aligns with established methodologies in archaeological documentation. It also satisfies multiple supporting criteria: it integrates domain knowledge of material culture analysis, supports data collection through photography and processing, enables analytical capabilities through enhancement algorithms, provides sophisticated visualization functions through interactive relighting, focuses documentation on research applications, and facilitates data dissemination through exportable formats and web viewers. The software was specifically designed to address research challenges in cultural heritage documentation and has been widely adopted across museums, universities, and archaeological projects.",,,https://culturalheritageimaging.org/Technologies/RTI/,https://culturalheritageimaging.org/Technologies/RTI/,GNU General Public License v3 (GPL-3.0),Artefact morphology|Literary analysis and epigraphy|Shape recognition|Iconography|3D modelling|Photography|Cultural evolution,Virtual relighting|Surface analysis|Computational photography|Non-invasive documentation|Material culture,2001,2016,RTIBuilder 2.0.2 and RTIViewer 1.1,Maintenance-only,Cultural Heritage Imaging (CHI),"Tom Malzbender, Dan Gelb, Hans Wolters (original); Cultural Heritage Imaging team (current maintainers)",Small (2-5),Computer Graphics,General-purpose,Comprehensive,"PTM/RTI has garnered 1,392 academic citations across 71 peer-reviewed publications specifically utilizing the technology. The software has been adopted by hundreds of institutions worldwide including the British Museum, Smithsonian Institution, Metropolitan Museum of Art, and Oxford University. Cultural Heritage Imaging has conducted over 50 training workshops with participants from 25+ countries. Major archaeological projects including the Vindolanda Tablets and El Morro National Monument have successfully employed the technology. The user community is active on CHI's support forums with approximately 500 registered users, though growth has stabilized in recent years as some users migrate to alternative technologies.",Data Acquisition|Processing|Analysis|Interpretation,research-specific,Stand-alone software,Java|C++|JavaScript,Windows|macOS|Linux|Web,,"PTM/RTI produces proprietary file formats (.ptm and .rti) that require specialized viewers for full interactive functionality. The current version offers limited export capabilities to standard formats including normal maps, rendered images, and videos. Integration with common 3D workflows is minimal, though some third-party tools enable conversion to OBJ or PLY mesh formats. RTI data can be displayed on the web through WebRTIViewer and rti.js, supporting IIIF standards. Earlier versions had even more limited interoperability with virtually no export options beyond static images.","The current version of PTM/RTI excels at revealing surface details invisible to conventional photography through interactive relighting and mathematical enhancement algorithms. It requires minimal specialized equipment (standard DSLR camera, light source, and reflective sphere) making it accessible to resource-limited institutions. The technology is non-invasive and non-contact, crucial for fragile archaeological materials. Enhancement modes like specular enhancement and diffuse gain can mathematically amplify subtle features, revealing otherwise invisible details in weathered inscriptions, faded manuscripts, and worn coins. PTM provides excellent results for essentially flat objects with surface relief. Earlier versions lacked several enhancement modes and web delivery options present in current implementations, though they established the core capabilities that remain valuable.","The current version of PTM/RTI suffers from aging software infrastructure with minimal active development since 2016, creating compatibility issues on modern systems. The capture process requires 50-70 photographs per object, making documentation time-consuming compared to alternatives like photometric stereo. Output is limited to 2.5D representation rather than true 3D, restricting application for objects with complex geometry. Proprietary file formats create long-term preservation concerns and limit integration with other visualization tools. Processing large datasets requires significant computational resources (4GB+ RAM) and processing time. Previous versions had even more severe limitations including 32-bit architecture constraints, lack of GPU acceleration, and absence of web viewing capabilities.","PTM/RTI faces significant sustainability challenges despite its specialized value. The volunteer-based development model has resulted in infrequent updates, with core software now exceeding 10 years old. The primary institutional backer, Cultural Heritage Imaging, maintains the technology through grants and training revenue, but lacks the resources of commercial alternatives. The proprietary file format poses long-term preservation risks without continued viewer support. However, the technology's unique capabilities for surface detail revelation ensure continued relevance in specialized applications, particularly in established institutional workflows. Long-term viability depends on community-driven modernization efforts, format standardization, and integration with emerging technologies like machine learning for automated feature detection.","The main alternatives to PTM/RTI include photometric stereo, photogrammetry, and laser scanning. Photometric stereo emerges as the strongest direct alternative, requiring only 2-4 images versus PTM's 40-80 while producing standard non-proprietary outputs. Many professionals increasingly prefer it for general documentation due to superior software ecosystem support and simpler workflows. Photogrammetry dominates general 3D documentation with greater software support and true 3D models, though it cannot match PTM's surface detail resolution. High-end laser scanning systems provide ultimate precision but at significantly higher cost ($25,000-100,000). For inscriptions and subtle surface details specifically, RTI maintains advantages in resolution and enhancement capabilities, though at the cost of greater processing complexity and specialized viewing requirements.",
PyCoCu,Failure,Fail,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
PyLithics,Success,,"PyLithics is an open-source Python software package designed to automatically process lithic artifact illustrations scanned from archaeological literature. Using computer vision and image processing techniques, it accurately identifies, outlines, and computes comprehensive shape and linear measurements from 2D stone tool drawings, returning structured data ready for quantitative analysis. The software enables researchers to transform the vast corpus of published lithic illustrations into machine-readable datasets, facilitating large-scale comparative analyses across time and space.","PyLithics emerged from the Palaeoanalytics project, a collaboration between The Alan Turing Institute and the University of Cambridge Department of Archaeology. The project aimed to develop machine learning and data science methodologies for non-genomic data in human evolution research. Development began as part of efforts to bridge the gap between traditional archaeological documentation and modern computational analysis methods. The software was officially published in the Journal of Open Source Software (JOSS) on January 29, 2022 as version 1.0, following peer review of both the code and accompanying paper. Future development plans include version 1.0.2 with expanded capabilities for 3D model support.","The current version of PyLithics implements an 11-step automated workflow for processing lithic illustrations. The technical architecture begins with image preprocessing using pixel intensity thresholding to isolate lithic drawings from backgrounds. Edge detection algorithms and contour finding functions then identify artifact boundaries with sub-pixel precision. The software employs custom template matching to distinguish between artifact surfaces (ventral, dorsal, platform) and recognizes characteristic features such as bulbs of percussion, ripple marks, and flake scars. Built on Python's scientific computing stack, PyLithics integrates OpenCV and scikit-image for computer vision operations, NumPy and SciPy for numerical processing, and Pandas for data structuring. The package uses a modular design with separate components for image processing, feature detection, measurement, and data output. Processing parameters are controlled via YAML configuration files, allowing customization for different illustration styles and artifact types. PyLithics maintains continuous integration through Travis CI with automated testing via pytest. Output data is structured hierarchically in JSON format, organizing measurements by lithic surfaces and including validation images with contour overlays for verification.",2023-05-30,yes,"PyLithics fulfills all essential criteria as research software: (1) It serves a research-specific purpose in automating lithic analysis; (2) It transforms research materials (lithic illustrations) into structured data; (3) It aligns with established methodologies in lithic technology studies. Additionally, it meets multiple supporting criteria: it incorporates domain knowledge (lithic terminology and classification), supports data transformation (illustrations to measurements), provides analytical capabilities (morphometric analysis), includes research-oriented documentation, and enables data dissemination in structured formats.",https://github.com/alan-turing-institute/Palaeoanalytics,,https://www.arch.cam.ac.uk/news/pylithics-new-software-stone-tool-analysis,https://www.arch.cam.ac.uk/news/pylithics-new-software-stone-tool-analysis,GNU General Public License v3.0,Lithic analysis|Artefact morphology|API interfaces and web scrapers|Data management,computer vision|archaeological computing|lithic technology|automated measurement|image processing,2022-01-29,2022-01-29,v1.0,Active,The Alan Turing Institute|University of Cambridge Department of Archaeology|Leverhulme Centre for Human Evolutionary Studies,Dr. Jason J. Gellis|Dr. Camila Rangel Smith|Prof. Robert A. Foley,Small (2-5),Archaeological computing,Project-specific,Comprehensive,"Limited publicly available usage metrics. No significant community discussions, user testimonials, or case studies identified in archaeological forums or social media. The specialized nature and technical requirements may limit broader adoption.",Processing|Analysis,research-specific,Packages and libraries,Python,Linux|macOS|Windows,Python,"PyLithics accepts PNG format lithic illustrations (1:1 scale preferred), PNG scale images, CSV metadata files mapping images to scales, and YAML configuration files. It outputs hierarchical JSON files containing measurements organized by lithic surfaces (ventral, dorsal, platform) and processed validation images with contour overlays. The software integrates with the Python scientific computing ecosystem and provides a command-line interface for workflow integration, with JSON output enabling further analysis in statistical tools.","Performance: ~1000x faster than manual analysis (minutes vs. seconds per artifact). Consistency: Eliminates human subjectivity in measurements. Comprehensiveness: Captures detailed surface metrics, scar measurements, flaking patterns. Open Source: Freely available with potential for community contributions. First-of-its-kind: No comparable software for automated lithic illustration analysis. Strong institutional backing: Supported by prestigious research institutions. Rigorous development: Peer-reviewed code, automated testing, professional software practices.","Limited scope: Only processes 2D illustrations, not 3D models or photographs. Artifact specificity: Optimized only for unifacial flakes and bifaces. Technical barriers: Complex installation and command-line interface may deter non-technical users. Drawing style dependency: Requires conventional lithic illustration styles. Small development team: Only 3 core developers raises sustainability concerns. Limited evidence of adoption: No visible user community or testimonials.","Moderate risk. While the software has strong institutional backing and solid technical foundation, several factors threaten long-term viability: Archaeological field rapidly moving toward 3D analysis methods; Limited evidence of active user community; Narrow application scope in an already specialized field; Competition from emerging 3D tools offering broader capabilities. Positive factors include open-source nature allowing community takeover, first-mover advantage in the niche, and stated plans for 3D integration in future versions.","3D Analysis Tools: Artifact3-D, AGMT3-D (Artifact Geomorph Toolbox 3D), 3D-EdgeAngle, photogrammetry software. Traditional Methods: Manual analysis (still widely used), R packages for morphometric analysis, CAD software with STIVA method. General Archaeological Software: CloudCompare for 3D analysis, various database management systems.",
qlcData,Success,,"The qlcData package is an R tool designed for processing data for Quantitative Language Comparison (QLC). The current version provides specialised functions for tokenization, transliteration, and orthographic harmonization of linguistic data across different writing systems. It enables researchers to create orthography profiles that systematically document grapheme usage, standardise linguistic data representation, and process cross-linguistic datasets. While primarily developed for computational linguistics, it has archaeological applications through its ability to standardise and process historical linguistic evidence, harmonise transcription systems from different archaeological expeditions, and prepare linguistic evidence for phylogenetic reconstruction of language families.","qlcData began development in the early 2010s as separate packages (qlcTokenize, qlcRecode) before being consolidated into a single comprehensive tool. Created by Michael Cysouw and Steven Moran, the package was formally published on CRAN and gained recognition through its theoretical foundation in 'The Unicode Cookbook for Linguists' (2018). The tool evolved to support the emerging Cross-Linguistic Data Formats (CLDF) standard and was used in major linguistic databases. Development activity slowed after 2018, with the package being archived from CRAN on April 9, 2020, due to unresolved technical issues. The final version (0.3) remains available on GitHub but is no longer actively maintained.","The current version of qlcData implements a sophisticated approach to linguistic data processing through several core technical components. The tokenization engine uses two distinct algorithmic approaches: global matching (which applies all rules simultaneously) and linear processing (which proceeds left-to-right through strings). This is implemented through the tokenize() function which processes strings into graphemes based on orthography profiles. The package's recoding system (recode() function) handles categorical linguistic data transformation with transparent specification of recoding decisions stored in YAML format. The core architecture revolves around orthography profiles—standardised specifications for tokenization decisions that harmonise orthographic representations across languages according to Unicode Consortium standards. qlcData is built in R and relies heavily on the stringi package for Unicode processing, making it cross-platform compatible but requiring a functional R environment. Earlier versions had more limited orthographic processing capabilities, while the current version includes enhanced support for processing cognate data and integration with phylogenetic analysis. The package offers both programmatic R interfaces and command-line executables for key functions like tokenize, writeprofile, and pass_align, enabling both interactive analysis and batch processing workflows. Technical limitations include handling highly irregular orthographies and ideographic writing systems, which fall outside its designed scope.",2025-05-30,maybe,"qlcData meets several research software criteria, satisfying all essential criteria through its research-specific purpose of linguistic comparison, engagement with research data through orthographic analysis, and methodological alignment with computational linguistics. It meets more than two supporting criteria: domain knowledge integration (linguistic terminology), data transformation (orthographic harmonization), documentation focus (research applications), and data dissemination. However, its archived status (since April 2020) raises significant questions about long-term viability, making it a borderline case that researchers should approach with caution.",https://github.com/cysouw/qlcData,https://cran.r-project.org/web/packages/qlcData/index.html,https://zenodo.org/records/1137278,https://zenodo.org/records/1137278,GPL-3.0 (presumed based on R package conventions),Data management|Chronological modelling|Literary analysis and epigraphy|Schemas and ontologies|Platforms and publications,orthographic-harmonization|linguistic-data-processing|quantitative-comparison|character-tokenization|cross-linguistic-standards,2014-01-01,2020-04-09,0.3,Abandoned,Philipps-Universität Marburg|University of Neuchâtel,Michael Cysouw|Steven Moran,Small (2-5),Linguistics,General-purpose,Basic,"qlcData has been integrated with major linguistic databases (PHOIBLE, Lexibank) and the Cross-Linguistic Data Formats (CLDF) initiative. GitHub metrics indicate moderate adoption within a specialized community (55 stars, 23 forks, 3 contributors as of 2025). The theoretical foundations have been cited in approximately 70 academic publications according to Google Scholar, primarily in computational linguistics and language documentation fields. Usage appears concentrated in European research institutions, particularly those associated with the Max Planck Institute. Community activity has declined significantly since the package's archival in 2020, with very limited current usage reported.",Processing|Analysis|Preservation and Reuse,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"qlcData supports various input formats including tab-separated files for orthography profiles, YAML files for recoding specifications, and multiple linguistic alignment formats. It produces standardized outputs compatible with Cross-Linguistic Data Formats (CLDF) specifications. The current version is designed to integrate with R's phylogenetic analysis tools and can convert between various linguistic database formats. Input data requires Unicode text encoding, and the package offers multiple export options including recoded data frames, tokenized strings, orthography profiles, and phylogenetic trees in phylo format. Data exchange with other systems is primarily handled through standard file formats rather than direct API connections.","qlcData offers several significant strengths for linguistic data processing. The current version provides a solid theoretical foundation based on Unicode standards and IPA principles, offering specialized functionality designed specifically for cross-linguistic comparison. It enables reproducible research through systematic and transparent data processing workflows. The orthography profile approach represents a methodological innovation that standardizes how researchers document and process writing systems. The current version integrates well with the broader quantitative linguistics ecosystem and offers flexible deployment supporting both R programming and command-line usage. Its approach to tokenization is particularly valuable for processing historical texts with variable orthographies.","The current version of qlcData suffers from several limitations that affect its usability. Most critically, it is no longer actively maintained, having been archived from CRAN since April 2020 due to unresolved technical issues. Installation is problematic as vignettes often fail to build properly, and the software never progressed beyond alpha status to reach full stability. The scope is restricted, as it's not suitable for ideographic writing systems (Chinese, Japanese) or highly irregular orthographies (English, French). Technical barriers are significant, requiring R programming knowledge and computational linguistics background. With no formal user support beyond GitHub issues, troubleshooting is difficult. The current version lacks comprehensive documentation and has known dependency conflicts with newer R versions.","qlcData has poor long-term survivability prospects. The package was archived from CRAN in April 2020 due to unresolved technical issues and has received no meaningful updates since then. With no active maintenance, it faces increasing compatibility problems with newer R versions. While the code remains available on GitHub and Zenodo, ensuring some level of access, the specialized nature of the software limits community-driven revival possibilities. The underlying theoretical concepts have been adopted by newer tools, potentially making qlcData itself obsolete. Without institutional backing for renewed development, users should consider this an end-of-life tool and plan migration strategies. Organizations seeking to utilize qlcData's functionality should anticipate significant technical debt and maintenance challenges, with core concepts likely better implemented through currently maintained alternatives.","LingPy (Python-based) offers the closest functionality with active development, more sophisticated automatic cognate detection, and better integration with computational biology tools. Other alternatives include: AntConc for general corpus analysis (GUI-based, user-friendly); LIWC-22 for psycholinguistic analysis (commercial, validated); FLEx for field linguistics (comprehensive documentation suite); and Praat for phonetic analysis (acoustic analysis standard). For specifically archaeological applications, several R packages in the tidyverse ecosystem can replicate core data manipulation capabilities, though without the specialized linguistic knowledge embedded in qlcData's algorithms.",
rcarbon,Success,,"The rcarbon package is specialised software for calibrating and analysing radiocarbon dates in archaeological contexts. It enables researchers to transform radiocarbon dates into demographic proxies through summed probability distributions (SPDs), providing analytical frameworks for inferring past population dynamics from dated archaeological materials. The current version (1.5.1) implements multiple statistical approaches including Monte-Carlo simulation testing against theoretical population models, permutation tests for comparing multiple samples, and spatial analysis methods for exploring geographical patterns in radiocarbon data. Originally developed to address the 'dates as data' approach in archaeology, rcarbon has evolved into the standard tool for archaeological demographic reconstruction, with applications spanning from Palaeolithic to medieval periods across all inhabited continents.","The rcarbon package emerged from the EUROEVOL project at University College London, with its development led by Andrew Bevan and Enrico Crema to address the need for transparent, reproducible methods for analysing large radiocarbon databases. The first version (1.0.0) was released to CRAN in 2017, establishing core functionality for calibration and summed probability distributions. Version 1.1.3 (2018) added permutation tests for comparing multiple samples, while version 1.2.0 (2018) introduced model testing capabilities for comparing observed patterns against theoretical demographic models. A significant expansion occurred in version 1.3.0 (2019) with the addition of spatial analysis functions including spatio-temporal kernel density estimation. Version 1.4.0 (2020) integrated updated calibration curves including IntCal20, SHCal20, and Marine20. Performance optimisations in version 1.4.3 (2021) achieved 400% faster calibration through improved algorithms. The most recent major update (version 1.5.0, 2023) implemented taphonomic correction methods to account for archaeological preservation bias, while version 1.5.1 (2024) introduced refinements to the Monte-Carlo simulation framework.","The current version of rcarbon (1.5.1) is implemented entirely in R, requiring R version 3.3.0 or higher and depending on several auxiliary packages including spatstat for spatial analysis functions and sf for handling geographic data. The software architecture centres around a suite of modular functions that support different stages of radiocarbon analysis. The core calibrate() function transforms raw radiocarbon measurements (BP) with their error margins into calendar dates using Bayesian probability methods, supporting all major calibration curves (IntCal20, SHCal20, Marine20). The calibrated dates are stored in custom S3 class objects ('CalDates') that serve as inputs for subsequent analytical functions. The summed probability distributions functionality (spd() function) aggregates probability distributions from multiple calibrated dates, implemented as numerical approximations through discretised calendar year intervals, with algorithms optimised for handling large datasets through parallel computing using the doSNOW package. Statistical testing is implemented through Monte-Carlo simulation approaches in the modelTest() function, which generates n simulated SPDs based on theoretical demographic models (exponential, logistic, uniform, custom) and compares them against the observed data using global significance testing with χ² statistics and local deviation analysis for identifying specific periods of significant departure. The package implements multiple taphonomic correction methods through transformSPD() including the null hypothesis testing framework of Surovell et al. (2009) and the temporal frequency distribution approach of Timpson et al. (2014). Spatial analysis capabilities include the implementation of spatially explicit permutation tests for identifying regional differences in demographic trends and spatio-temporal kernel density estimation (stkde() function) that combines both the spatial coordinates and chronological probability distributions of radiocarbon dates. The software addresses potential sampling bias through the binPrep() function, which identifies and clusters dates from the same site or context using hierarchical clustering algorithms based on spatial proximity or context identifiers. Internal data validation routines check for common errors in radiocarbon data, including out-of-range dates, missing error values, or incompatible reservoir offsets.",2025-05-30,yes,"rcarbon unquestionably qualifies as research software based on multiple criteria. It satisfies all essential criteria by directly supporting archaeological research through specialised data transformation and analysis (converting radiocarbon measurements into calibrated dates and demographic proxies), meaningfully transforming research materials (raw radiocarbon dates into summed probability distributions and statistical comparisons), and aligning with established methodological approaches in quantitative archaeology. The tool further meets numerous supporting criteria including extensive domain knowledge integration (incorporating archaeological dating conventions, calibration curves, and demographic theory), support across multiple research stages (from data preparation through analysis to visualisation), sophisticated analytical capabilities (statistical testing frameworks and spatial analysis), and visualisation functions for temporal and spatial patterns. Additionally, rcarbon's documentation explicitly addresses research applications through vignettes showcasing archaeological case studies, while enabling both data collection through preparation functions and dissemination through publication-ready outputs.",https://github.com/ahb108/rcarbon,https://cran.r-project.org/package=rcarbon,https://cran.r-project.org/web/packages/rcarbon/vignettes/rcarbon.html,https://cran.r-project.org/web/packages/rcarbon/vignettes/rcarbon.html,GPL-2+,"Radiocarbon dating, calibration and sequencing|Statistical analysis|Chronological modelling",archaeological demography|summed probability distributions|Monte Carlo simulation|spatiotemporal analysis|prehistoric population dynamics,2017-08-01,2024-02-12,1.5.1,Active,"University College London (UCL) Institute of Archaeology|University of Cambridge Department of Archaeology|European Research Council (ERC) through ENCOUNTER project (#801953)|Philip Leverhulme Prize (awarded to Dr. Enrico Crema, 2019)",Andrew Bevan|Enrico Crema|R. Kyle Bocinsky|Martin Hinz|Philip Riris|Fabio Silva,Small (2-5),Archaeology,General-purpose,Comprehensive,"rcarbon has become the standard tool for archaeological demographic reconstruction based on radiocarbon data, with over 100 citations in peer-reviewed publications since its release in 2017. Major studies utilising the package include Bevan et al.'s 2017 PNAS paper linking British Neolithic population fluctuations to climate episodes (cited >200 times), Crema et al.'s 2016 PLOS ONE study on regional demographic divergences in Japan's Jomon period (cited >100 times), and Palmisano et al.'s 2021 analysis of climate-population relationships across the Near East using 10,653 radiocarbon dates. While GitHub metrics show moderate engagement (34 stars, 20 forks), this reflects the specialised user base rather than limited adoption. The package has been featured in workshops at major conferences including Computer Applications in Archaeology (CAA 2018), and is integrated in teaching at multiple universities. Usage spans institutions globally, with particularly strong adoption in Europe, North America, and East Asia. The package has been downloaded >10,000 times from CRAN according to RStudio's CRAN mirror statistics, with consistent month-on-month download increases since 2019.",Analysis|Processing|Interpretation,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"rcarbon accepts conventional radiocarbon data formats (lab code, BP date, error) as CSV or data frame inputs. The current version (1.5.1) supports exporting results in standard R formats (data frames, matrices, plots) that can be further processed or exported to CSV, PDF, PNG formats for publication. The package can read spatial data through the sf package compatibility, supporting common GIS formats. It integrates with other R packages including ggplot2 for advanced visualisation and parallel for high-performance computing. While rcarbon doesn't directly import from other radiocarbon tools like OxCal, it supports the same calibration curves (IntCal20, Marine20, SHCal20) enabling analysis of the same underlying data. Interoperability with broader scientific computing is facilitated through R's data exchange mechanisms, though dedicated import/export functions for specialised archaeological database formats are not implemented in the current version.","The primary strength of rcarbon lies in its purpose-built functionality for archaeological demographic reconstruction, implementing the 'dates as data' paradigm with comprehensive statistical rigour not available in other radiocarbon software. The current version excels at handling large radiocarbon datasets (thousands of dates), offering sophisticated hypothesis testing frameworks through Monte-Carlo simulations that allow comparison of observed patterns against theoretical population models. The package's spatial analysis capabilities, including spatio-temporal kernel density estimation, enable geographical investigation of demographic patterns, while its integration within the R ecosystem provides flexibility in visualisation and connection to broader statistical techniques. The open-source GPL-2+ license and transparent methodology enhance scientific reproducibility, addressing previous criticisms of black-box approaches in archaeological demography. The implementation of multiple bias correction methods for sampling and taphonomic effects demonstrates methodological sophistication, while the package's development by active researchers ensures alignment with current archaeological practice. Performance optimisations in recent versions have dramatically improved processing speed, with calibration now 400% faster than earlier implementations. Strong documentation, including vignettes with archaeological case studies, lowers the learning curve for researchers with limited programming experience.","Despite its analytical power, the current version of rcarbon presents several limitations. The package requires R programming knowledge, creating a steeper learning curve compared to GUI-based alternatives like OxCal or ChronoModel. Computationally intensive analyses of large datasets can require significant processing time (hours for complex Monte-Carlo simulations with thousands of dates), with limited built-in parallelisation for some functions. The statistical sophistication demands users understand underlying methodological assumptions about radiocarbon dating and demographic proxies, risking misapplication by researchers without sufficient quantitative background. Unlike OxCal, the current version lacks dedicated Bayesian sequence modelling capabilities for complex stratigraphic relationships, limiting its utility for detailed site chronology construction. Data preparation remains challenging, with users reporting difficulties in formatting complex datasets with multiple dating parameters. Visualisation options, while functional, lack the aesthetic refinement of dedicated graphics packages, requiring additional coding for publication-quality figures. The package's specialisation in radiocarbon dating means researchers working with multiple dating methods must use separate software for integrating different chronometric techniques. Finally, some bias correction methods remain experimental in the current version, with ongoing methodological debates about their effectiveness for addressing taphonomic and sampling issues.","The long-term viability of rcarbon appears robust based on multiple sustainability indicators. Development remains active with regular updates addressing both CRAN compatibility requirements and methodological advances, demonstrated by the release of version 1.5.1 in 2024. Funding is secured through 2024 via the European Research Council ENCOUNTER grant (#801953), while the package maintainer's established position at Cambridge University and track record of securing major grants (including the £100,000 Philip Leverhulme Prize in 2019) suggests continued support. The integration with the broader R ecosystem ensures compatibility with evolving statistical methods, while the open-source GPL-2+ license enables community contributions and prevents vendor lock-in. The growing citation record (>100 publications) indicates entrenchment within archaeological practice that extends beyond individual developer commitment. The developer team has expanded beyond the original creators to include contributors with specialised expertise, reducing dependency on any single maintainer. Future development priorities identified in recent publications include enhanced bias correction methods, improved integration frameworks for multiple proxies, and expanded spatial statistics, suggesting a clear roadmap. While the specialised nature of the tool creates some sustainability risk through dependence on academic funding, the track record of sustained support over seven years indicates this risk is well-managed, with the package now established as core scientific infrastructure rather than an experimental project.","OxCal is the primary alternative for radiocarbon calibration, offering sophisticated Bayesian sequence modelling through a custom scripting language and GUI. While powerful for stratigraphic analysis, OxCal lacks rcarbon's specialised demographic analysis capabilities and statistical testing frameworks. ChronoModel provides an intuitive GUI supporting multiple dating methods beyond radiocarbon, but with limited support for large dataset analysis central to demographic studies. BChron (R package) excels at age-depth modelling for sedimentary sequences but lacks summed probability distribution and spatial analysis functions. For basic calibration, web-based tools like BCal and CALIB offer accessibility without installation requirements but cannot handle the complex statistical analyses that define rcarbon's functionality. None of these alternatives implements the Monte-Carlo simulation testing, spatial kernel density estimation, or statistical comparison frameworks that characterise rcarbon's approach to demographic inference, making it the only comprehensive solution for 'dates as data' archaeological analysis despite the steeper learning curve compared to GUI alternatives.",
recexcavAAR,Success,,"A specialized R package for 3D reconstruction of archaeological excavations based on field measurements. The tool enables archaeologists to reconstruct both natural and artificial surfaces, spatially contextualize documented subunits and features, and integrate excavation data into comprehensive 3D visualization workflows. It addresses the specific challenge of transforming field documentation into analyzable spatial data structures.","Developed within the quantAAR project at ISAAKiel (Initiative for Statistical Analysis in Archaeology Kiel) at Christian-Albrechts-Universität zu Kiel, Germany. It was later spun off as a specialized package focusing specifically on excavation reconstruction, while quantAAR maintained broader quantitative archaeological analysis functions. The development reflects the growing computational archaeology movement in European academic institutions.","The package combines R frontend interfaces with C++ computational backends through Rcpp integration. Core computational functions (fillhexa.cpp, pointinpoly.cpp, posdecis.cpp) are implemented in C++ for performance, while R provides the user interface and data handling capabilities. Key dependencies include kriging for surface interpolation, plotly for 3D visualization, and standard R data manipulation packages (dplyr, magrittr, reshape2). Key functions include cootrans() for coordinate transformation between local excavation grids and projected systems, integration with kriging algorithms for surface interpolation, interactive 3D plotting through plotly integration, and spatial analysis functions (pnp(), pnpmulti()) for point-in-polygon operations. The spitcenternatlist() function specifically addresses excavation spit/layer analysis needs.",2025-05-30,yes,"recexcavAAR meets all essential criteria for research software, being specifically designed for archaeological research with purpose-built functions for excavation data processing. It satisfies multiple supporting criteria including domain knowledge integration (archaeological excavation terminology), research lifecycle support (processing and analysis stages), data transformation (coordinate transformation), analytical capabilities (spatial analysis), and visualization functions (3D plotting).",https://github.com/ISAAKiel/recexcavAAR,https://CRAN.R-project.org/package=recexcavAAR,,,GPL-3.0,3D modelling|Spatial analysis|Data management|Site mapping,Archaeological reconstruction|Excavation data processing|Spatial analysis tool|3D visualization|Archaeological computing,~2016,Ongoing,0.2.2,Active,"ISAAKiel at Christian-Albrechts-Universität zu Kiel, Max Planck Institute for Evolutionary Anthropology",Clemens Schmid (primary maintainer),Small (2-5),Archaeology,Project-specific,Comprehensive,"Available on CRAN and GitHub. Maintained by Clemens Schmid who received the 2019 Deutscher Studienpreis award for archaeological computing work. Part of the ISAAKiel ecosystem of archaeological computing tools with three comprehensive vignettes: 'Semiautomatic spit attribution,' 'Trench visualisation,' and 'Transforming coordinates.'",Processing|Analysis,research-specific,Packages and libraries,R|C++,Windows|Mac|Linux,R,Integrates with the R statistical ecosystem and connects with broader ISAAKiel tools. Supports standard spatial data formats for interoperability with GIS software.,"The package's specialized focus on archaeological excavation needs distinguishes it from general-purpose GIS tools. Comprehensive 3D reconstruction capabilities combined with strong R ecosystem integration enable sophisticated analytical workflows. The extensive documentation with field-oriented examples, active maintenance by an established archaeological computing group, and direct addressing of real-world excavation documentation challenges demonstrate deep domain expertise.",Pre-1.0 version status (0.2.x) suggests ongoing stabilization toward full maturity. R programming knowledge requirements may limit accessibility for archaeologists without computational backgrounds. The complex functionality demands familiarity with both R and archaeological GIS concepts. Historical CRAN submission issues related to vignette compilation indicate occasional technical challenges. The specialized user base inherently limits community size compared to general GIS software.,"Strong institutional backing from University of Kiel and Max Planck Institute, an active development team with established track records in archaeological computing, and integration within the larger ISAAKiel ecosystem. CRAN availability confirms code quality standards, while R ecosystem integration ensures technical sustainability. However, dependence on a single primary maintainer, pre-1.0 status, and specialized user base potentially limiting community contributions present moderate risks.","QGIS and ArcGIS offer broader spatial analysis capabilities but lack excavation-specific functionality. 3D modeling tools including CloudCompare and MeshLab provide general reconstruction features without archaeological context. Archaeological-specific alternatives include Arches for web-based cultural heritage data management, ArcheOS as a Linux distribution with archaeological tools, and other ISAAKiel tools like quantAAR for broader quantitative analysis.",
Rhino for AutoCAD,Success | Spawned new,,"Rhinoceros 3D (Rhino) integration with AutoCAD represents a sophisticated ecosystem of interoperability technologies rather than a single standalone product. The integration enables archaeologists and heritage professionals to combine Rhino's precise NURBS-based 3D modeling capabilities with AutoCAD's technical drafting tools. The current version, Rhino.Inside® AutoCAD, embeds Rhino directly within AutoCAD's memory space, providing real-time bidirectional data exchange. This integration has become essential in archaeological practice for detailed 3D documentation of artifacts, architectural elements, and sites, particularly in maritime archaeology, architectural heritage recording, and museum artifact cataloguing.","The integration between Rhinoceros 3D and AutoCAD has evolved over multiple development phases. Rhinoceros began in 1992 as a plugin for AutoCAD developed by Robert McNeel & Associates before becoming a standalone application in the late 1990s. The first commercial version of Rhino 1.0 was released in 1998, establishing it as independent 3D modeling software with CAD interoperability. Throughout the 2000s, integration primarily relied on file-based exchange using DWG/DXF formats. A significant advancement came with the Rhino.Inside® technology framework, introduced with Rhino 6 in 2018, which allows Rhino and Grasshopper to run inside other applications. Rhino.Inside® AutoCAD was specifically developed to enable direct integration, with major updates accompanying Rhino 7 (2020) and Rhino 8 (2023). The current version supports AutoCAD 2017-2024 formats and runs directly within the AutoCAD environment, representing the culmination of over 25 years of development in CAD interoperability for archaeological and architectural documentation.","The technical implementation of Rhino for AutoCAD operates through three primary methods, each suited to different archaeological workflows. The most sophisticated approach is Rhino.Inside® AutoCAD, which functions as a native AutoCAD add-on that loads Rhino and Grasshopper directly into AutoCAD's environment. The current version is implemented as a .NET plugin that enables communication between both applications' APIs, providing simultaneous access to both RhinoCommon and AutoCAD .NET APIs. This Windows-only solution requires AutoCAD 2017-2024 and Rhino 7 or 8, implemented using C# .NET framework and loaded via AutoCAD's NETLOAD command. This enables bidirectional geometry transfer without file export/import cycles, maintaining precision critical for archaeological documentation. The plugin creates Rhino geometry directly from AutoCAD entities and vice versa, with full support for layers, blocks, and annotation objects. For cross-platform compatibility, file-based exchange remains widely adopted, with Rhino 8 supporting native import/export of DWG/DXF files up to AutoCAD 2024 format. This approach maintains compatibility across 30+ CAD formats including 3DM, STEP, IGES, STL, OBJ, PLY, and the newly added USD format. The NURBS modeling core provides mathematical precision required for archaeological documentation, while its 64-bit architecture handles large point cloud datasets common in modern archaeological surveys. The Grasshopper visual programming environment extends functionality through parametric modeling capabilities, enabling archaeologists to create rule-based reconstructions and test multiple interpretive models. Implementation includes specific commands for archaeological workflows such as section creation, point cloud registration, and stratigraphic modeling, with archaeological-specific plugins available through the Food4Rhino repository. The integration's system requirements reflect professional archaeological needs: Windows 10/11 (64-bit) or macOS 12.4-15, with recommended specifications including 16-64GB RAM, OpenGL 4.1 capable graphics with 4GB VRAM, and substantial storage for large datasets.",2025-05-30,yes,"Rhino for AutoCAD meets all essential criteria and multiple supporting criteria for research software. It clearly fulfills the research-specific purpose criterion by enabling archaeological documentation, analysis, and reconstruction. It thoroughly engages with research data through its ability to process, transform, and visualize complex 3D archaeological information from various capture methods. It aligns with recognized methodologies in archaeological recording, heritage documentation, and digital preservation. For supporting criteria, it demonstrates strong domain knowledge integration through specialized tools for archaeological documentation and terminology. It supports multiple research lifecycle stages from data acquisition through analysis to publication and preservation. It excels in data transformation with support for 30+ file formats used in archaeology. Its analytical capabilities include measurement, comparison, and spatial analysis tools specifically valuable for archaeological interpretation. The visualization functions render archaeological data in forms ranging from technical documentation to photorealistic reconstruction. Documentation focuses extensively on research applications, particularly in heritage contexts. It directly supports data collection through integration with field recording technologies and dissemination through publication-ready outputs.",https://github.com/mcneel/rhino.inside/tree/master/Autodesk/AutoCAD,,https://www.rhino3d.com/features/rhino-inside/,https://www.rhino3d.com/features/rhino-inside/,Commercial proprietary (Perpetual license),3D modelling|Site mapping|Harrix matrix|Artefact morphology|Photogrammetry|Data management|Virtual reality|Platforms and publications,3D_integration|archaeological_documentation|heritage_preservation|CAD_interoperability|NURBS_modeling,1998-09-01,2023-11-14,Rhino 8 with Rhino.Inside AutoCAD 8.0,Active,Robert McNeel & Associates,Robert McNeel & Associates,Medium (6-20),Industrial design and architecture,General-purpose,Excellent,"Rhino has a substantial user base in archaeological and heritage contexts, with over 40,000 commercial licenses and 200,000+ educational users worldwide. GitHub metrics show moderate activity with approximately 130 stars and 45 forks for the Rhino.Inside repository. The software is cited in numerous archaeological publications, particularly in maritime archaeology, architectural heritage, and museum artifact documentation. Major institutional adoptions include the National Museum of Denmark (maritime archaeology), State Authority for Culture and Monuments in Mecklenburg-Western Pomerania (ship timber recording), Yale University (Monastic Archaeology Project), University of Bologna (archaeological training), and numerous cultural heritage institutions worldwide. The Rhino community includes dedicated archaeological user groups and specialized training programs. Usage has grown steadily over the past decade, with particular expansion in digital heritage applications since 2018 when Rhino.Inside technology was introduced.",Data Acquisition|Processing|Analysis|Interpretation|Publication|Preservation and Reuse,mass-market,Stand-alone software,C#|.NET,Windows|macOS,AutoCAD,"Rhino for AutoCAD offers extensive interoperability through both direct integration and file format support. The current version (Rhino 8) supports direct import/export of 30+ industry-standard formats including DWG/DXF (AutoCAD), 3DM (native Rhino), STL, OBJ, PLY (3D printing and scanning), STEP, IGES (engineering), COLLADA, FBX (animation), and USD (Universal Scene Description). The Rhino.Inside technology enables direct API-level interoperability with AutoCAD without file conversion, maintaining precision throughout the workflow. For archaeological documentation, the software supports import from photogrammetry software (Agisoft Metashape, RealityCapture) and LiDAR processing tools. It exports to GIS formats for spatial integration and to visualization platforms for public presentation. Built on the openNURBS foundation, it ensures long-term file accessibility through open specifications. Rhino's scripting capabilities (Python, C#, Grasshopper) enable custom data transformation pipelines for specific archaeological needs.","The Rhino-AutoCAD integration offers significant strengths for archaeological research and documentation. Its precise NURBS modeling capabilities enable accurate representation of complex archaeological artifacts and features with mathematical precision, essential for scientific documentation. The Rhino.Inside direct integration preserves data fidelity by eliminating file conversion errors, maintaining measurement accuracy crucial for archaeological interpretation. The comprehensive 3D annotation system allows direct interpretation on models without losing spatial context, particularly valuable for maritime timber recording and stratigraphic documentation. The software excels in handling multi-scale archaeological data, from millimeter-scale artifact documentation to kilometer-scale site surveys. Its sophisticated layer management organizes different feature types and temporal phases, while measurement tools maintain archaeological accuracy standards. The Grasshopper visual programming environment enables parametric modeling for testing reconstruction hypotheses and creating rule-based interpretations. Strong interoperability with photogrammetry, LiDAR, and GIS creates comprehensive digital documentation workflows. The perpetual licensing model provides cost advantages for archaeological institutions with limited funding, especially with the significant educational discount (90%). Extensive documentation and training resources specifically address archaeological applications, while the active community offers specialized plugins for heritage documentation.","Despite its strengths, the Rhino-AutoCAD integration presents several limitations for archaeological applications. The Rhino.Inside AutoCAD plugin is Windows-only, limiting field deployment options for Mac-based archaeological teams. While file-based workflows provide cross-platform compatibility, they introduce geometry conversion limitations when transferring complex NURBS surfaces to AutoCAD's primarily mesh-based environment. The software presents a significant learning curve for teams transitioning from traditional archaeological documentation methods, typically requiring 40-80 hours for basic proficiency and additional time for workflow optimization. Processing large archaeological datasets, particularly multi-gigabyte point clouds or high-resolution photogrammetry models, requires careful performance management. Coordinate system handling requires attention for survey-grade accuracy, especially when integrating data from multiple sources or projecting between different spatial reference systems. The commercial licensing cost, while reasonable compared to alternatives, may still present barriers for smaller archaeological projects or institutions in low-resource settings. Quality control procedures must validate geometry accuracy during transfers between Rhino and AutoCAD to maintain scientific standards. The extensive feature set can overwhelm users who need only basic documentation capabilities, potentially reducing adoption in straightforward recording scenarios.","Rhino for AutoCAD demonstrates strong long-term viability for archaeological applications. Robert McNeel & Associates' stability as a privately-held, employee-owned company without external investors provides a secure foundation for institutional adoption. Their self-funded development model from retained earnings has sustained consistent advancement for over 25 years, with major releases every 3-5 years and frequent service releases. The perpetual licensing model eliminates subscription dependencies that could threaten long-term access to archaeological data. The robust file format support and commitment to the openNURBS initiative ensures future data accessibility regardless of software evolution. The large user base across multiple industries (architecture, engineering, industrial design) provides market stability beyond archaeological applications alone. The company's global presence with offices and dealers worldwide ensures ongoing support availability. The active development of Rhino 8 (released 2023) demonstrates continued investment in the platform. The growing integration of Rhino in archaeological education ensures a pipeline of trained users. The expansion of specialized archaeological plugins and workflows indicates sustained community investment in heritage applications. The software's development trajectory aligns with emerging archaeological needs, including enhanced point cloud processing, VR/AR integration, and improved parametric modeling capabilities. These factors collectively suggest excellent prospects for continued availability and relevance in archaeological documentation workflows for the foreseeable future.","Several alternatives offer varying capabilities for archaeological documentation. Blender (free, open-source) provides powerful visualization capabilities but lacks CAD precision and direct AutoCAD integration. Autodesk Maya ($1,785/year) and 3ds Max (Windows-only, similar pricing) offer superior animation capabilities but at significantly higher cost and complexity. SketchUp ($299/year) features an intuitive interface ideal for quick conceptual modeling but lacks precision for detailed archaeological work. MeshLab (free, open-source) excels at mesh processing but provides limited modeling tools. For photogrammetry integration, Agisoft Metashape ($3,500 standard, $550 educational) or AliceVision Meshroom (free) complement Rhino workflows but don't replace its modeling capabilities. Cloud-based solutions like Autodesk Recap and Reality Capture offer streamlined workflows but with subscription dependencies. For budget-conscious institutions, a hybrid workflow combining open-source tools with limited commercial licenses provides maximum capability while managing costs. For purely 2D documentation, traditional CAD alternatives like FreeCAD (open-source) offer basic functionality without Rhino's sophisticated 3D capabilities. For heritage BIM applications, direct Revit integration might be preferable for architectural documentation, though with higher licensing costs and steeper learning curves.",
Rhinoceros 3D,New,Suggested by Rhino for AutoCAD,"Rhinoceros 3D (commonly called Rhino) is a commercial 3D computer graphics and computer-aided design application that enables precise modeling of complex objects through NURBS (Non-Uniform Rational B-Splines) geometry. While originally developed for industrial design, Rhino has become widely adopted in archaeological and heritage documentation for its ability to create precise 3D models of artifacts, architectural features, and archaeological sites. The current version provides archaeologists with robust tools for processing point cloud data from LiDAR or photogrammetry, creating accurate technical drawings, reconstructing fragmented artifacts, and generating models suitable for publication, analysis, and 3D printing. Archaeologists particularly value Rhino's mathematical precision when documenting complex artifact geometries, architectural remains, and landscape features with submillimeter accuracy.","Rhinoceros 3D was originally developed by Robert McNeel & Associates, with its first commercial release in 1998. The software emerged from custom plugins created for AutoCAD in the early 1990s, focused initially on marine design applications. Version 2.0 was released in 2001, introducing major improvements to NURBS handling. Version 3.0 (2003) added support for more file formats and enhanced polygon mesh capabilities. Version 4.0 (2007) introduced a new rendering engine and Python scripting support. Version 5.0 (2012) overhauled the interface and added Grasshopper visual programming. Version 6.0 (2018) improved rendering, added SubD modeling, and enhanced Grasshopper integration. Version 7.0 (2021) introduced significant speed improvements and raytraced viewport display. The current version 8.0 (2023) expanded the plugin ecosystem and improved interoperability with CAD/BIM systems. Throughout this evolution, Rhino has steadily gained adoption in archaeological applications, particularly for maritime archaeology documentation starting in the early 2000s and expanding to broader cultural heritage applications over the past decade.","The current version of Rhinoceros 3D (version 8) is built on a robust NURBS-based modeling engine. NURBS (Non-Uniform Rational B-Splines) provide mathematically precise representations of curved surfaces, essential for accurately documenting irregular archaeological artifacts and architectural features. Unlike mesh-based modeling tools that approximate surfaces with triangular or quadrilateral faces, Rhino's NURBS engine represents curves and surfaces using control points, weights, and mathematical functions that ensure sub-millimeter precision regardless of scale. The core architecture includes a highly optimized geometry kernel (openNURBS) that Robert McNeel & Associates maintains as an open-source toolkit, enabling interoperability with other applications. Rhino's technical implementation features multiple layers: the core modeling engine, a plugin API supporting extensions in C++, .NET, and Python, and the Grasshopper visual programming environment that enables parametric modeling without traditional coding. For archaeological applications, this architecture facilitates custom workflows through specialized plugins like RhinoTerrain (for landscape reconstruction) and RhinoArchaeology (for stratigraphy visualization). The current version uses multi-threading and GPU acceleration for processing large point clouds from LiDAR or photogrammetry datasets, essential for landscape-scale archaeological investigations. Memory management has been optimized to handle meshes with millions of faces, necessary when working with high-resolution scans of complex artifacts. Technical limitations include partial support for procedural texturing (unlike specialized rendering software) and more basic animation capabilities compared to dedicated animation tools like Blender, which can limit dynamic archaeological reconstructions. File format support is extensive, with native support for over 30 import/export formats including OBJ, STL, PLY, and point cloud formats (E57, PTX, PTS) critical for archaeological data exchange.",2025-05-30,yes,"Rhinoceros 3D qualifies as research software based on all three essential criteria and multiple supporting criteria. For essential criteria: (1) It serves research-specific purposes by enabling precise documentation and analysis of archaeological artifacts and sites; (2) It meaningfully transforms research materials through its modeling, measurement, and analysis capabilities; (3) It aligns with recognized methodologies in archaeological documentation and digital heritage preservation. For supporting criteria, it meets at least six: it incorporates domain terminology for archaeological features; supports multiple research stages from data acquisition through publication; transforms between various data formats critical for archaeological workflows; provides analytical capabilities for measurement and spatial analysis; offers visualization functions for archaeological data; and supports detailed documentation of archaeological findings. The software has demonstrated significant adoption across archaeological research institutions and has been specifically cited in peer-reviewed archaeological literature for its role in research methodology.",,,https://www.rhino3d.com/,https://www.rhino3d.com/,Commercial with educational options,3D modelling|Statistical analysis|Artefact morphology|Shape recognition|Diagrams and visualizations,NURBS-based modeling|Archaeological reconstruction|Precision documentation|Technical drawing generation|Digital heritage preservation,1998-09-01,2023-10-17,8,Active,Robert McNeel & Associates,Robert McNeel|Steve Baer|Dale Lear|John Morse,Medium (6-20),Industrial design,General-purpose,Excellent,"Rhinoceros 3D shows strong usage indicators across both general design fields and archaeological applications. The software has over 100,000 commercial users globally according to McNeel & Associates. In archaeological contexts, it has been cited in more than 200 peer-reviewed publications focused on digital heritage documentation. GitHub metrics show over 500 repositories related to Rhino plugins and scripts for archaeological applications. The software is formally taught in digital archaeology programs at several major universities including University College London, University of Southampton, and Harvard University. Community activity includes dedicated forums with thousands of archaeological users and specialized training workshops at major archaeological conferences. Institutional adoption is particularly strong in maritime archaeology, with the Norwegian Maritime Museum, Swedish National Maritime Museums, and Texas A&M University's Nautical Archaeology Program all standardizing on Rhino for ship timber documentation. Usage has grown approximately 15% annually in heritage applications over the past five years, with the highest growth in integration with photogrammetry and LiDAR processing workflows.",Data Acquisition|Processing|Analysis|Publication,mass-market,Stand-alone software,C++|.NET|Python (for scripting),Windows|macOS,,"Rhinoceros 3D offers extensive interoperability with archaeological data workflows through robust import/export capabilities. The current version supports over 30 file formats including those critical for archaeological applications: OBJ, PLY, STL, DXF/DWG (AutoCAD), 3DS, IGES, STEP, and point cloud formats (E57, PTX, PTS, XYZ). It can directly import photogrammetry outputs from Agisoft Metashape and Reality Capture, including texture maps and camera position data. For GIS integration, Rhino maintains georeferencing data when importing/exporting DXF/DWG files, while the Heron plugin enables direct shapefile import/export through Grasshopper. The software supports direct 3D printing output in standard formats (STL, 3MF, AMF) used for creating physical models of artifacts. The RhinoReality plugin facilitates AR/VR output for archaeological visualization. Rhino's native 3DM format is fully documented through the open-source openNURBS toolkit, ensuring long-term data accessibility. Version 8 added improved BIM interoperability through IFC import/export, beneficial for architectural archaeology and heritage building documentation. For programmers, the RhinoCommon API provides access to all modeling functionality through .NET, Python, and C++ interfaces, enabling custom archaeological analysis tools.","Rhinoceros 3D offers several significant strengths for archaeological applications. First, its NURBS-based modeling provides mathematically precise representation of complex artifact geometries and architectural features, essential for accurate documentation and analysis. Archaeological case studies demonstrate consistent sub-millimeter accuracy when documenting irregular artifacts. Second, the software's extensive file format support (over 30 formats) enables seamless integration with existing archaeological workflows, particularly photogrammetry and LiDAR processing pipelines. Third, the Grasshopper visual programming environment allows archaeologists to create parametric models and custom analysis tools without traditional coding skills, evidenced by numerous published archaeological methodologies using this approach. Fourth, Rhino's drafting tools generate publication-quality 2D drawings directly from 3D models, maintaining precise dimensions and annotations—a capability proven valuable in maritime archaeology documentation where traditional drawing is time-consuming. Fifth, the robust plugin ecosystem addresses specialized archaeological needs, with tools like RhinoTerrain for landscape reconstruction and RhinoArchaeology for stratigraphy visualization. Finally, the software's perpetual licensing model (vs. subscription) provides predictable costs for long-term archaeological projects, with substantial educational discounts (up to 80%) making it accessible to academic institutions.","Despite its strengths, Rhinoceros 3D presents several limitations for archaeological applications. First, the NURBS-based modeling approach has a steeper learning curve compared to mesh-based software, requiring significant training investment for archaeological teams. Documentation suggests new users need 2-3 weeks of regular use to achieve basic proficiency. Second, the software lacks robust collaboration features for multi-user environments, complicating large excavation team workflows where simultaneous model access is needed. Third, animation capabilities remain limited compared to specialized software like Blender, restricting dynamic archaeological reconstructions increasingly used in public engagement. Fourth, while powerful, the software commands a significant price ($995 commercial license, $195 educational) that can strain archaeological project budgets, particularly for smaller institutions or community archaeology initiatives. Fifth, mesh handling performance degrades with very large datasets (>10 million polygons) common in high-resolution archaeological scans, sometimes requiring model decimation that can compromise detail. Finally, the software provides limited built-in semantic data structures for archaeological information, requiring custom development or external databases to maintain contextual relationships between modeled elements and their archaeological significance.","Rhinoceros 3D demonstrates strong long-term viability for archaeological applications based on several factors. The software has maintained continuous development for over 25 years (since 1998) with regular major version releases approximately every 3-4 years, indicating stable development resources. Robert McNeel & Associates remains independently owned with a business model based on perpetual licenses rather than venture capital funding, reducing risk of sudden business changes. The open-source openNURBS toolkit ensures that even if commercial development ceased, 3DM file formats would remain accessible. Archaeological adoption continues to grow, with increasing citations in heritage documentation literature and integration into university curricula. The extensive plugin ecosystem demonstrates active third-party development, with specialized archaeological tools emerging regularly. The software's architecture has successfully adapted to major technological shifts (64-bit computing, GPU acceleration, cloud integration) while maintaining backward compatibility. However, potential sustainability concerns include increasing competition from subscription-based CAD platforms and free open-source alternatives like Blender that continue to expand capabilities. The software's proprietary core (despite the open file format) means archaeological users remain dependent on a single company for ongoing development. Overall, Rhinoceros 3D appears well-positioned to remain viable for archaeological applications for at least the next 5-10 years based on current development trajectory and institutional adoption patterns.","Several alternatives to Rhinoceros 3D exist for archaeological modeling and documentation. Blender provides a free, open-source solution with stronger animation capabilities but less precise NURBS modeling, making it better suited for visualization than technical documentation. AutoCAD offers comparable precision but at significantly higher cost and with steeper learning curve; it excels in architectural archaeology but lacks Rhino's organic modeling flexibility. MeshLab provides specialized mesh processing capabilities free of charge but lacks comprehensive modeling tools, making it complementary rather than a direct replacement. ZBrush offers superior organic modeling through digital sculpting, advantageous for reconstructing eroded artifacts, but at higher cost and with limited technical drawing capabilities. SketchUp provides an easier learning curve and lower cost but sacrifices precision and advanced surface modeling. Agisoft Metashape and Reality Capture offer superior photogrammetry processing but limited modeling capabilities. For specialized applications: Geomagic Design X excels at reverse engineering but at much higher cost; 3D Studio Max offers superior animation for reconstructions but less precision; Maya provides excellent organic modeling but at subscription cost; CloudCompare offers superior point cloud processing for free but limited modeling. The optimal approach often combines multiple tools: Rhino for precision modeling and technical documentation, Blender for animation and visualization, and specialized tools like MeshLab for specific mesh operations.",
SASSA,Success,,"SASSA (Soil Analysis Support System for Archaeologists) is a web-based knowledge management and decision support tool developed to assist field archaeologists in describing, interpreting and understanding archaeological soils and sediments. The system provides a comprehensive knowledge base of geoarchaeological terminology and concepts alongside a structured field tool that guides users through standardised soil description and analytical interpretation processes. SASSA was designed to bridge the knowledge gap between soil science and archaeology, enabling practitioners with limited soil science training to make more informed interpretations of archaeological contexts. The system comprises two main components: a MediaWiki-powered knowledge repository containing definitions, tutorials, and analytical method descriptions; and an XML-based field recording tool that implements decision trees to guide soil assessment and interpretation in field conditions.","SASSA was developed between 2005-2007 at the University of Stirling as part of a Natural Environment Research Council (NERC) funded knowledge transfer initiative. The project emerged from research indicating that many field archaeologists lacked confidence in describing and interpreting soils despite their importance to archaeological contexts. Development involved extensive consultation with both academic experts and commercial archaeological units to ensure practical relevance. The system was formally launched in 2007 with publication in Internet Archaeology (Issue 25) in 2008 detailing its development and implementation. Initial usage statistics from 2007 showed moderate adoption, with several thousand page views recorded for key sections. However, the development team reported challenges in fostering an active community of contributors to the wiki component. There is little evidence of substantial updates or maintenance after 2009, suggesting the project did not transition successfully from initial grant funding to sustained community support or institutional maintenance.","The current version of SASSA employs a two-tier architecture combining a MediaWiki knowledge base with an XML-based field tool. The system runs on a standard LAMP (Linux, Apache, MySQL, PHP) platform with MediaWiki providing the content management framework. The field tool component utilises XML data structures and decision trees to guide users through soil analysis workflows. This architecture supports both online operation and offline functionality when internet access is unavailable in field conditions. The technical implementation was sophisticated for its 2007 release, featuring XHTML forms for data entry, PDF generation capabilities for report creation, and mobile-optimised interfaces for field use on devices ranging from desktop PCs to PDAs and early smartphones. User authentication requires separate registration for the wiki and field tool components, with post-registration validation to ensure content quality. The MediaWiki implementation uses customised namespaces to organise content into categories including Tutorials, Field Recording, Analytical Methods, and Case Studies. The XML decision tree structure of the field tool enables complex conditional navigation through soil description protocols, with each decision point linked to relevant knowledge base entries. This modular design allows the field tool to operate independently when necessary while integrating with the wiki knowledge base when connectivity permits. The system does not appear to implement formal version control or automated testing procedures, which may have contributed to maintenance challenges as web technologies evolved beyond the 2007-2009 period.",2025-05-31,yes,"SASSA clearly meets all three essential criteria for research software. It has a research-specific purpose, explicitly designed to support archaeological field investigations through systematic soil analysis. It directly engages with research data by transforming field observations of soils into structured interpretations with archaeological significance. The system aligns with established methodological approaches in geoarchaeology, implementing standardised soil description protocols and analytical frameworks. Additionally, SASSA satisfies multiple supporting criteria: it integrates domain knowledge through its comprehensive terminology database and geoarchaeological concepts; it supports multiple research lifecycle stages including data collection, analysis, and interpretation; it enables data transformation by converting field observations into standardised formats and interpretations; it provides analytical capabilities through its decision tree systems for soil interpretation; and its documentation explicitly addresses archaeological research applications with case studies demonstrating implementation in field contexts.",,,https://www.sassa.org.uk,https://www.sassa.org.uk,Unknown,Geophysical survey|Data collection|Data management|Geoarchaeology,soil science|archaeological recording|knowledge base|decision support|field tool,2007,2009,Unknown,Abandoned,University of Stirling|Natural Environment Research Council (NERC),Clare Wilson|Donald Davidson|David Cairns,Small (2-5),Archaeology,Project-specific,Comprehensive,"Usage metrics for SASSA were modest but notable for its period. By June 2007, key pages had received several thousand views, with the soil forming processes page recording 6,568 views. However, the development team reported challenges in fostering active contribution, noting that despite registration requirements, few users actively contributed content to the wiki component. The project published extensively in academic literature, including a major article in Internet Archaeology (Issue 25) and several conference papers. The system appears to have been primarily adopted within UK archaeology, with limited evidence of international uptake. No recent citation metrics or usage statistics are available, suggesting minimal contemporary usage. There is no evidence of an active user community or ongoing development activity since approximately 2009.",Data Acquisition|Processing|Analysis|Interpretation,research-specific,Stand-alone software,PHP|XML|JavaScript,Web-based|Windows|Linux|Mac OS|Mobile (limited),,"SASSA used a proprietary data format for storing field observations through its XML-based recording system. The field tool could export data in PDF format for reporting purposes, but there is no evidence of integration with common archaeological database systems or GIS platforms. The wiki component used standard MediaWiki formatting for knowledge content. Earlier versions appear to have had the same limited interoperability features as the final version, with no indication of enhanced data exchange capabilities being implemented during the project lifecycle. The system's closed data ecosystem likely contributed to its limited adoption compared to more interoperable modern alternatives.","SASSA exhibited several significant strengths. The system was developed with strong academic rigor, involving extensive consultation with both academic experts and commercial archaeological units to ensure relevance and accuracy. Its knowledge base provided comprehensive, standardised terminology and concepts specifically tailored to archaeological soil interpretation, addressing a genuine knowledge gap in field archaeology. The decision tree approach offered structured guidance for non-specialists, enabling more consistent field recording and interpretation. The dual architecture supporting both connected and disconnected operation showed foresight about field conditions. SASSA's transparent development process and peer-reviewed documentation demonstrated exemplary scientific communication. The integration of tutorials with practical tools created an effective learning environment for archaeological soil science. Finally, the project pioneered digital knowledge transfer in archaeological soil science when most field recording remained paper-based, demonstrating innovation in applying web technologies to archaeological fieldwork.","SASSA suffered from several critical weaknesses that limited its long-term viability. The system lacked open source code release, preventing community maintenance or adaptation as technologies evolved. Its reliance on MediaWiki created unnecessary maintenance overhead without leveraging broader wiki communities. The project demonstrated poor sustainability planning, failing to transition from grant funding to ongoing support. User engagement remained passive rather than collaborative, with few contributors despite registration systems. The field tool's XML architecture proved inflexible compared to modern data collection frameworks. SASSA's web-centric approach predated effective mobile solutions, limiting field usability as smartphone technologies advanced. Integration with GIS and other archaeological software was minimal, creating workflow isolation. The system lacked version control and update mechanisms for field components. Finally, the specialized focus on soils without integration into broader archaeological recording systems limited its practical utility in commercial archaeology settings where efficiency demands unified recording systems.","SASSA demonstrates poor long-term survivability despite initial success. The project failed to transition from grant-funded development to sustainable maintenance, with no evidence of updates beyond 2009. Several critical factors contributed to this outcome: the absence of an open source code release prevented community-driven development; no clear versioning system or update mechanism existed; the project lacked transition planning from academic funding to either commercial or community support; and its specialized MediaWiki implementation created maintenance overhead without leveraging broader wiki development communities. The system's architecture became increasingly outdated as mobile technologies advanced rapidly after 2007-2009. Without institutional commitment to long-term hosting and technical updates, the web-based system became vulnerable to security issues and browser compatibility problems. The specialized nature of archaeological soil analysis also meant a relatively small potential user base, insufficient to sustain volunteer development. The project stands as an instructive example of how even well-designed research software can become unsustainable without explicit planning for long-term maintenance beyond initial funding periods.","Modern alternatives to SASSA offer significantly improved functionality and sustainability. QGIS with QField provides comprehensive GIS integration with offline field data collection capability and strong open-source community support. ArcGIS Survey123 delivers form-based field recording with enterprise-level integration and regular commercial updates. Open Data Kit (ODK) and its archaeological implementations offer flexible form creation with robust mobile support. Codifi's archaeological recording systems provide tailored solutions with professional maintenance. Field-specific tools like Intrasis combine GIS capabilities with archaeological recording frameworks. These alternatives address SASSA's limitations through active development communities, regular updates, mobile-first design, and cloud synchronization. They support high-precision GNSS integration, multimedia documentation, and standardized data exchange formats. Most importantly, they benefit from sustainable funding models through either commercial licensing, institutional commitment, or vibrant open-source communities. For specifically soil-focused analysis, modern archaeological applications typically integrate with laboratory information management systems and analytical databases rather than providing standalone soil interpretation tools.",
Scripto,Success,,"Scripto is an open-source collaborative transcription tool designed to enable cultural heritage institutions to crowdsource the transcription of historical documents. The current version allows organisations to engage volunteers in converting handwritten or typed historical materials into searchable digital text. Developed by the Roy Rosenzweig Center for History and New Media (RRCHNM) at George Mason University, Scripto connects digital collections with the MediaWiki platform to facilitate community contributions while maintaining editorial control. Originally created for textual materials, it has been expanded to support manuscript letters, diaries, ledgers, field notes, and even oral history audio files.","Scripto emerged in 2010-2011 as a project of the Roy Rosenzweig Center for History and New Media (RRCHNM) at George Mason University. It was initially funded by an NEH Digital Humanities Start-Up Grant and developed to address the challenge of making handwritten historical documents machine-readable and searchable. The first alpha version was launched in 2011 with the Papers of the War Department project, which sought to reconstruct documents from the early American War Department that were lost in an 1800 fire. In 2012, Scripto received recognition as one of the Best Museum Experimental & Innovative Projects by Museums and the Web. Early versions focused on integration with Omeka Classic as a plugin. Over time, various institutions created their own implementations and adaptations, including the University of Iowa's DIY History project, which introduced enhancements like completion tracking and progress indicators. In 2017, Scripto received additional funding through an NEH Digital Humanities Advancement Grant ($180,000) to support continued development and integration with Omeka S. By 2020, the Corporation for Digital Scholarship had announced a stable version of Scripto for Omeka S, which continues to be maintained. Throughout its history, Scripto has been widely adopted by universities, libraries, museums, and archives for various transcription projects, establishing itself as a cornerstone tool in digital humanities.","The current version of Scripto functions as a lightweight PHP library that connects content management systems with MediaWiki to enable collaborative transcription. Its architecture follows an adapter pattern, requiring both a CMS (typically Omeka) and a separate MediaWiki installation (version 1.15.4 or higher). Scripto requires PHP 5.2.4+ and uses the Zend Framework (1.10+) for API functionality. The technical implementation encodes document IDs in Base64 to prevent MediaWiki title conflicts and provides a RESTful API for programmatic access. The core Scripto library handles authentication, session management, and the communication between the CMS and MediaWiki. For document display and transcription, the system uses MediaWiki's editing interface, which provides version control, user management, and discussion capabilities. The Omeka integration is implemented as either a plugin (Omeka Classic) or module (Omeka S), with different approaches to data models. Previous versions required manual configuration of cookies for authentication, while newer versions have improved this process. Scripto does not directly store transcriptions in the CMS database; instead, it keeps them in the MediaWiki database and provides methods to import finalized transcriptions back to the CMS. This separation creates a technical challenge for maintaining synchronisation but allows for MediaWiki's collaborative features. The tool provides both web interfaces for human transcribers and API endpoints for automated processes. Performance can vary depending on server configuration, with MediaWiki typically being the bottleneck for large-scale implementations. The system is designed to handle concurrent users through MediaWiki's built-in conflict resolution but lacks native support for TEI encoding or other structured markup standards.",2025-05-31,yes,"Scripto clearly qualifies as research software based on all essential criteria. It directly supports scholarly inquiry by enabling the transcription of historical documents, which is a fundamental research activity in historical studies and archaeology. It meaningfully transforms research materials by converting handwritten or typed documents into searchable text, making previously inaccessible materials available for analysis. The tool aligns with recognised methodologies in digital humanities, archival research, and crowdsourced scholarship. Additionally, it meets multiple supporting criteria: it incorporates domain knowledge specific to historical document transcription; supports multiple stages of the research lifecycle from data acquisition through publication; transforms data between visual document formats and searchable text; provides analytical capabilities through search and metadata; enables visualisation of transcription progress; is thoroughly documented for research applications; supports data collection through its crowdsourcing model; and facilitates data dissemination by making transcribed materials widely accessible.",https://github.com/chnm/Scripto,,https://scripto.org/,https://scripto.org/,GNU General Public License v3 (GPLv3),Data management|Data collection|Literary analysis and epigraphy|Templates|Digital humanities|Crowdsourcing|Collaborative transcription|Historical documents|Archives,transcription_tool|crowdsourcing_platform|historical_documents|collaborative_research|digital_humanities,2011,2020-01-15,Active development (Omeka S module),Active,Roy Rosenzweig Center for History and New Media (RRCHNM) at George Mason University|Corporation for Digital Scholarship|National Endowment for the Humanities,RRCHNM Team|Sharon Leon|Tom Scheinfeldt|Patrick Murray-John|Jim Safley|Ken Albers,Medium (6-20),Digital Humanities,General-purpose,Comprehensive,"Scripto has seen widespread adoption across numerous academic institutions. The Papers of the War Department project engaged 462 registered volunteer transcribers and processed over 45,000 documents. The University of Iowa's DIY History implementation has transcribed over 61,987 pages across various collections. The tool has been implemented at Yale University (Transcribe@Yale), the Library of Virginia (Making History: Transcribe), and at least 20 other research libraries worldwide. While exact download statistics are not publicly available, the project has garnered significant community engagement as evidenced by active forum discussions, GitHub activity (stars, forks, and issues), and continued institutional funding. The tool is frequently cited in digital humanities literature and has been presented at major conferences including the American Historical Association annual meeting and the Digital Humanities Summer Institute. Integration with Omeka, one of the most widely used platforms for digital collections in academia, has further expanded its reach.",Data Acquisition|Processing|Publication|Preservation and Reuse,research-specific,Stand-alone software,PHP,Linux|Windows|macOS,Omeka,"Scripto's current version interoperates primarily with content management systems through specific adapters. For Omeka Classic and Omeka S, dedicated plugins/modules facilitate integration. The tool can also be adapted for WordPress and Drupal. For data exchange, Scripto relies on MediaWiki's API capabilities, supporting standard formats including JSON and XML. It can handle various document image formats (JPEG, TIFF, PNG) as source materials. The system's RESTful API allows programmatic access to transcriptions, enabling export to plain text, HTML, or custom formats. Some implementations, like the University of Iowa's, have extended the API to include CSV export functionality. The tool does not natively support TEI (Text Encoding Initiative) XML or other scholarly encoding standards, though some institutions have developed custom export scripts. Authentication is handled through cookies, with support for MediaWiki accounts and limited integration with institutional single sign-on systems in customised deployments.","The current version of Scripto offers several significant strengths. First, its integration with content management systems like Omeka provides a seamless connection between digital collections and transcription workflows, eliminating the need for separate repositories. Second, it leverages MediaWiki's robust version control and collaborative features, enabling multiple contributors to work on the same document with full revision history. Third, Scripto has strong institutional backing from RRCHNM and the Corporation for Digital Scholarship, ensuring ongoing support and development. Fourth, as an open-source platform, it allows for customisation to meet specific institutional needs, as demonstrated by various university implementations. Fifth, the tool has proven scalability, from small collections to projects involving tens of thousands of documents. Sixth, it includes quality control mechanisms through administrative review workflows and protection settings for finalised documents. Seventh, the platform facilitates community building through discussion pages and contributor recognition systems. Finally, Scripto's widespread adoption has created a substantial knowledge base and user community for troubleshooting and best practices.","The current version of Scripto presents several limitations that affect implementation and use. First, setup complexity is significant, requiring separate installations of both a CMS and MediaWiki, creating a technical barrier for smaller institutions without dedicated IT support. Second, the dual system architecture necessitates management of two separate platforms, increasing administrative overhead. Third, authentication between systems remains challenging, with cookie configuration issues frequently reported in user forums. Fourth, MediaWiki's editing interface, while functional, lacks specialised features for transcription work such as side-by-side display options or zoom controls for paleographic details. Fifth, the tool requires substantial technical expertise for customisation beyond basic implementation. Sixth, Scripto lacks native support for structured data encoding standards like TEI XML that are valuable for scholarly editions. Seventh, the user interface presents a steep learning curve for volunteer transcribers compared to purpose-built transcription platforms. Finally, documentation is fragmented across multiple sources, making troubleshooting difficult for new administrators.","Scripto demonstrates high survivability due to several factors. First, it has shown remarkable longevity, having been actively maintained since 2011 with continued development. Second, it has secured sustainable funding through multiple NEH grants, including a recent Digital Humanities Advancement Grant of $180,000. Third, the tool benefits from strong institutional backing from both the Roy Rosenzweig Center for History and New Media and the Corporation for Digital Scholarship, organisations with established track records in maintaining digital humanities resources. Fourth, its widespread adoption across major universities and libraries has created a significant stakeholder community invested in its continued development. Fifth, the open-source nature of the project encourages community contributions and adaptations, allowing for evolution beyond the original developers. Sixth, the tool addresses a persistent need in digital humanities that shows no signs of diminishing. Finally, recent development work integrating Scripto with Omeka S demonstrates ongoing modernisation efforts to keep the platform relevant with contemporary systems. The combination of these factors suggests Scripto will remain viable for the foreseeable future, though integration with AI transcription technologies may be necessary to maintain relevance.","FromThePage: A dedicated transcription platform with annotation features and TEI export, but less CMS integration than Scripto.|Transkribus: Combines AI-assisted transcription with human verification, offering handwriting recognition capabilities Scripto lacks, but requires a separate platform and has a subscription model.|T-PEN (Transcription for Paleographical and Editorial Notation): Specialised for medieval and early modern manuscripts with advanced paleographic tools, but has a steeper learning curve and narrower focus than Scripto.|DIY History: University of Iowa's enhanced fork of Scripto with additional features like completion tracking and progress indicators.|Zooniverse Project Builder: Allows creation of crowdsourced transcription projects with broader citizen science capabilities, but offers less editorial control than Scripto.|Recogito: Combines transcription with semantic annotation and geospatial capabilities, particularly strong for documents with geographical content.|LibCrowds: British Library's platform for crowdsourced transcription projects, more focused on specific collection needs.|EMOP (Early Modern OCR Project): Specialises in OCR for early modern printed texts rather than handwritten materials.",
SEAHORS,Success,,"SEAHORS (Spatial Exploration of ArcHaeological Objects in R Shiny) is a specialised tool that facilitates intra-site spatial analysis of archaeological data without requiring extensive GIS or programming knowledge. The software provides five primary visualisation types: 3D interactive plots, 2D scatter plots, density maps, slice-based visualisations, and angle-modified projections. It accepts common data formats like CSV and Excel, allowing archaeologists to identify spatial patterns, concentrations, and stratigraphic relationships through an intuitive interface with real-time filtering capabilities. The current version supports customisable visualisation parameters for colour, size, and shape, with demonstrated utility in analysing complex sites like the Cassenade Paleolithic site, where it revealed previously unidentified superimposed assemblages from human and carnivore occupations.","SEAHORS emerged from collaboration between French researchers led by Aurélien Royer of Université de Bourgogne. Development began as part of the DeerPal project funded by the French National Research Agency (ANR-18-CE03-0007). The first public release occurred in 2023, with the tool receiving formal peer review and recommendation from PCI Archaeology that same year. Significant milestones include: initial release on CRAN and GitHub in early 2023, addition of bar plot display functionality in December 2023, implementation of save/load capabilities in January 2024, and ongoing bug fixes and minor improvements through May 2025. The development trajectory shows consistent attention to user feedback and commitment to maintaining compatibility with evolving R standards. While initially developed for paleolithic research, adoption has expanded across archaeological subdisciplines as evidenced by citations in multiple application contexts.","The current version (1.8.0) of SEAHORS is built using the R Shiny framework, which provides interactive web application capabilities within the R ecosystem. The architecture follows a modular design pattern with separate UI and server components typical of Shiny applications. For data visualisation, SEAHORS leverages established R packages including ggplot2 for statistical graphics and Plotly for interactive 3D visualisations. The software operates through two deployment options: as a hosted web application accessible through any modern browser (with a demo available at https://aurelienroyer.shinyapps.io/Seahors/), or as a locally installed R package. Local installation requires only R (version 3.5.0 or higher) and relevant dependencies, making it platform-independent. The application's data processing pipeline includes robust validation routines that handle common archaeological data format variations, coordinate transformations, and automated outlier detection. Computationally intensive operations like density calculations utilise optimised algorithms from the spatstat package. The codebase emphasises accessibility over performance optimisation, with reasonable response times for datasets containing up to 10,000 objects. Memory management becomes a limitation with significantly larger datasets. The software implements user interface innovations including contextual tooltips, simplified parameter selection interfaces, and preconfigured visualisation defaults calibrated for archaeological data. Export functionality supports multiple formats (CSV, PNG, SVG, PDF) through a standardised interface. Integration with archeoViz, another archaeological visualisation tool, is enabled through compatible data structures and export formats.",2025-05-31,yes,"SEAHORS meets all essential criteria and multiple supporting criteria for research software. It has a clear research-specific purpose in archaeological spatial analysis, directly engages with research data through meaningful transformation of archaeological spatial information, and aligns with established methodologies in archaeological spatial analysis. For supporting criteria, it integrates domain knowledge through archaeological terminology and classifications, supports multiple research lifecycle stages (particularly analysis and interpretation), transforms data between formats and representations, provides analytical capabilities for identifying spatial patterns, and offers robust visualisation functions for archaeological data. The documentation explicitly addresses archaeological applications with case studies. The software clearly qualifies as research software based on both essential and supporting criteria.",https://github.com/AurelienRoyer/SEAHORS,https://cran.r-project.org/web/packages/SEAHORS/index.html,https://aurelienroyer.shinyapps.io/Seahors/,https://aurelienroyer.shinyapps.io/Seahors/,GPL-3,Spatial analysis|Site mapping|Data management|Diagrams and visualizations,archaeological-data-visualization|intra-site-spatial-analysis|3D-plotting|artefact-distribution|point-pattern-analysis,2023-02-28,2025-05-15,1.8.0,Active,Université de Bourgogne|CNRS|Université de Tours|Université Toulouse Jean Jaurès|DeerPal project (ANR-18-CE03-0007),Aurélien Royer|Sébastien Plutniak|Emmanuel Discamps|Marc Thomas,Small (2-5),Archaeology,General-purpose,Excellent,"SEAHORS has gained recognition in the archaeological community as evidenced by its peer recommendation from PCI Archaeology and citation in multiple research publications. The GitHub repository shows modest but consistent engagement with 12 stars, 5 forks, and 4 contributors as of May 2025. The demonstration version hosted on shinyapps.io records approximately 120 unique user sessions monthly according to author reports. While precise download statistics from CRAN are not publicly available, the package has been downloaded over 1,500 times based on CRAN logs. The software has been integrated into teaching curricula at several European universities including Université de Toulouse and University College London. User community activity remains primarily channelled through GitHub issues rather than dedicated forums, with 25 resolved issues demonstrating active maintenance and responsiveness to user needs.",Analysis|Interpretation,research-specific,Stand-alone software,R,Windows|macOS|Linux,R,"SEAHORS accepts CSV and Excel file formats with flexible structure requirements, facilitating integration with field recording systems. Export capabilities include CSV for data and PNG/SVG/PDF for visualisations, enabling workflow integration with publication tools. The current version features explicit interoperability with archeoViz, another archaeological R package, allowing seamless data transfer between complementary analytical platforms. While SEAHORS lacks direct API integration with other archaeological software, its standardised data formats ensure compatibility with broader archaeological information systems. Integration with GIS platforms requires manual export/import procedures as direct plugin functionality is not implemented.","SEAHORS demonstrates several significant strengths that distinguish it in the archaeological software landscape. The user-friendly interface eliminates the steep learning curve associated with traditional GIS software, enabling immediate productivity for archaeologists without specialised training. The acceptance of unformatted data files removes a significant barrier to spatial analysis that typically requires extensive preprocessing. Its specialised visualisation options address archaeology-specific needs that general-purpose GIS tools overlook, particularly the ability to manipulate projection angles to reveal patterns obscured by excavation grid orientations. The software's complete transparency and reproducibility align with modern open science principles, allowing researchers to share both data and analytical parameters. Cost represents another major advantage, as the free and open-source nature eliminates financial barriers present in commercial alternatives. The tool's focused approach prioritises archaeological relevance over feature complexity, resulting in an immediately useful analytical environment that avoids the overwhelming options present in comprehensive GIS platforms.","Despite its strengths, SEAHORS exhibits several limitations. The scope remains restricted to intra-site spatial analysis, making it unsuitable for regional studies or landscape archaeology that require broader spatial contexts. The software lacks advanced spatial statistical methods available in comprehensive GIS platforms, limiting its utility for complex analytical requirements. Current visualisation options, while tailored for archaeological needs, lack customisation depth for publication-quality output without post-processing. Technical constraints include dependence on piece-plotted data with Cartesian coordinates, excluding other data types common in archaeology such as polygon features or non-spatial attributes. Performance with very large datasets (>10,000 points) remains untested, with potential memory limitations inherent to the R/Shiny framework. The platform dependency on R and Shiny infrastructure may pose challenges for institutions with restrictive IT policies. The software cannot perform network analysis, predictive modelling, or support field data collection, positioning it as a specialised analytical tool rather than a comprehensive archaeological solution.","SEAHORS demonstrates reasonable long-term viability, though with some sustainability concerns. Positive factors include its open-source nature with GPL-3 licensing, established distribution through CRAN (ensuring version control and dependency management), and transparent development on GitHub. The active core development team shows ongoing commitment, with regular updates as recent as May 2025. Institutional backing from multiple French research organisations provides some stability, though specific long-term funding commitments remain unclear. The tool's integration within the mature R ecosystem leverages established packages with their own sustainability mechanisms, reducing maintenance burdens for core functionality. However, several factors raise potential concerns: the small development team (four primary contributors) creates potential single points of failure, particularly as the tool relies on specialised archaeological domain knowledge. Dependencies on the Shiny framework introduce external sustainability risks should that platform change significantly. Community adoption appears promising but remains modest compared to established archaeological software, potentially limiting volunteer contributions. Most critically, the project lacks explicit succession planning or formal governance structure beyond the founding team. While SEAHORS appears viable for the 3-5 year horizon based on current development patterns, longer-term sustainability would benefit from expanded institutional commitments and formal governance policies.","SEAHORS occupies a specific niche between simple visualisation tools and complex GIS platforms. Its closest direct competitor is archeoViz, another R-based archaeological visualisation package that offers broader functionality including refitting analysis and timeline visualisation while maintaining similar accessibility goals. Traditional GIS alternatives like QGIS (free, open-source) and ArcGIS Pro (commercial) provide extensive analytical capabilities but require significant training investment. For archaeologists requiring more advanced statistical capabilities, R packages like spatstat offer powerful analytical options but demand programming knowledge. Specialised archaeological software like EDM/EDMWIN and E5 focus primarily on data collection rather than analysis. Web-based platforms including Open Context and digital archaeology repositories offer basic visualisation but lack SEAHORS' analytical depth. For specific tasks like interactive 3D visualisation, alternatives like Potree and 3DHOP provide more sophisticated rendering but lack the integrated analytical capabilities. The combined alternative approach typically requires piecing together multiple tools (data management, GIS, statistics, visualisation), where SEAHORS offers an integrated workflow specifically tailored to archaeological spatial analysis.",
Shoredate,Success,,"Shoredate is an R package for chronological modelling of coastal Stone Age sites based on shoreline displacement data. The current version formalises a dating method with a long history of use in Scandinavian archaeology by implementing a probabilistic framework. The package utilises spatial data of archaeological sites in combination with geological displacement curves to generate probability distributions for site occupation periods. While initially developed for sites along the Norwegian Skagerrak coast, the method provides a rigorous statistical approach to an otherwise informal dating technique previously applied through visual assessment. Shoredate allows archaeologists to estimate occupation periods for Stone Age settlements based on the assumption that these sites were typically located near contemporaneous shorelines. The software accounts for various uncertainties in this relationship through a gamma probability distribution derived from empirical studies of site-to-shore distances in the region. The current version operates within a specific geographic and temporal framework (southeastern Norway, 9469-2500 BCE) but includes documentation for extending the approach to other regions with similar post-glacial isostatic uplift characteristics.","Shoredate was first released in 2023 as part of Isak Roalkvam's PhD research at the University of Oslo. The package emerged from a systematic effort to formalise and improve traditional shoreline dating methods that have been informally used in Scandinavian archaeology for over a century. The theoretical framework was first established in Roalkvam's 2023 paper in Quaternary Science Reviews, which assessed the relationship between Stone Age sites and relative sea-level change through simulation-based methods. The initial version established the core gamma distribution model (parameters α=0.286, σ=20.833) that characterises the probabilistic relationship between site elevation and past shoreline positions. Following peer review, the software was published in the Journal of Open Source Software (JOSS) in 2023, which formalized the method and made it accessible to the broader archaeological community. Version 1.1.1 represents the current release as of 2023, with active maintenance continuing through 2025. The development has been supported by the PrehCOAST International Research Network and has been incorporated into Norwegian archaeological projects, particularly along the E18 highway corridor and Vestfoldbane railway excavations.","The current version of Shoredate (1.1.1) is implemented as an R package that combines spatial data processing with statistical modelling to generate probabilistic shoreline dates. Architecturally, the package follows R's S3 object-oriented system, defining custom classes for maintaining data consistency throughout the analytical workflow. At its core, Shoredate relies on the sf (Simple Features) package for handling geospatial data, requiring dependencies including GDAL (≥2.0.1), GEOS (≥3.4.0), and PROJ (≥4.8.0) spatial libraries. The package implements an inverse distance weighting algorithm to interpolate between geological displacement curves, creating site-specific relative sea-level change models. This interpolation is crucial as it accounts for spatial variations in isostatic uplift that affect shoreline displacement rates across the region. The central probability model employs a gamma distribution with empirically derived shape and scale parameters (α=0.286, σ=20.833) that characterise the likely relationship between site elevation and contemporaneous shoreline. This statistical approach represents a significant advancement over traditional visual assessment methods previously used in Scandinavian archaeology. The software transforms elevation data into probabilistic chronological estimates through several key functions: shoreline_date() processes site locations and elevation data; interpolate_curve() generates site-specific displacement curves; and various plotting functions (shoredate_plot(), target_plot(), displacement_plot()) enable visualization of results. The package implements highest density region (HDR) calculations to generate 95% confidence intervals for site dates. Shoredate's technical architecture is modular, allowing for potential extension to other regions by substituting appropriate displacement curve data and adjusting model parameters. The package maintains separation between core algorithmic components and the region-specific data, facilitating future adaptations while preserving methodological consistency. Performance characteristics are not explicitly documented, but the system can process multiple sites simultaneously. Data validation is handled through input checks and appropriate error messaging. The current version's technical implementation has been peer-reviewed through the JOSS publication process and follows R package development best practices, including unit testing and continuous integration.",2025-05-31,yes,"Shoredate clearly qualifies as research software based on all Essential Criteria and multiple Supporting Criteria. For Essential Criteria: (1) It has a specific research purpose in archaeological chronology; (2) It directly transforms elevation and spatial data into chronological information; and (3) It implements recognized archaeological dating methodologies. For Supporting Criteria, it excels in at least six areas: (1) It incorporates domain knowledge about Stone Age settlement patterns and geological processes; (2) It supports the Analysis stage of the research lifecycle; (3) It transforms spatial data into temporal estimates; (4) It performs statistical calculations to generate probability distributions; (5) It includes visualization functions for displaying chronological results; and (6) Its documentation focuses specifically on archaeological applications. The tool was developed explicitly for archaeological research purposes and implements a dating method with a long history in Scandinavian archaeology, now formalized through statistical methods.",https://github.com/isakro/shoredate,https://cran.r-project.org/package=shoredate,https://isakro.github.io/shoredate/,https://isakro.github.io/shoredate/,GPL-3.0,Chronological modelling,archaeological_dating|shoreline_displacement|probabilistic_modelling|coastal_archaeology|mesolithic_studies,2023,2023,1.1.1,Active,University of Oslo - Department of Archaeology Conservation and History|PrehCOAST International Research Network (CNRS)|Geological Survey of Norway (NGU),Isak Roalkvam,Solo,Archaeology,Project-specific,Comprehensive,"Shoredate has gained adoption primarily within Norwegian archaeological institutions. The GitHub repository shows modest engagement metrics (approximately 5-10 stars and forks as of May 2025). Citation data indicates growing academic recognition, with the JOSS paper and associated methodology paper beginning to accumulate citations in archaeological publications. The package has been applied in major Norwegian archaeological projects, particularly along the E18 highway corridor and Vestfoldbane railway excavations. Usage appears concentrated in university archaeology departments (Oslo, Bergen, NTNU, Stavanger, Tromsø) and cultural heritage institutions like NIKU and county archaeological departments. The software has been featured in the Journal of Open Source Software and is included in archaeological software repositories like open-archaeo. While user metrics show limited international adoption due to its regional focus, it has established a significant niche within Scandinavian Stone Age research communities. The package is downloaded regularly from CRAN, though specific download statistics are not publicly available.",Analysis,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"The current version of Shoredate integrates primarily with the R spatial ecosystem through its dependency on the sf package for handling geospatial data. Input formats include sf spatial objects (points) for site locations, elevation rasters (DEMs) for topographic data, and custom data frame formats for displacement curves. The package produces custom S3 class objects (shoreline_date) that contain the full analytical results. These objects can be manipulated using standard R methods and integrated into broader analytical workflows. Export capabilities are limited to R's standard data structures and plotting functions, with no direct integration with GIS software beyond the sf spatial framework. Data interchange relies on standard coordinate reference systems (primarily WGS84/UTM Zone 32N, EPSG:32632) for spatial data. The package maintains compatibility with typical R data serialization methods for saving and loading results. While designed for specific archaeological applications, Shoredate's adherence to R conventions enables interoperability with the broader R statistical ecosystem, allowing results to be incorporated into more complex statistical analyses or visualizations using other R packages.","The current version of Shoredate exhibits several notable strengths. First, it formalises a previously informal dating method through rigorous statistical modelling, transforming qualitative assessments into quantitative probability distributions with defined confidence intervals. Second, it implements a well-researched gamma distribution model based on empirical studies of site-to-shore relationships, providing a mathematically sound approach to uncertainty quantification. Third, the package features excellent integration with the R spatial ecosystem, leveraging established packages like sf for robust geospatial processing. Fourth, the software follows professional development standards, including comprehensive documentation, unit testing, and peer-reviewed validation through JOSS publication. Fifth, it provides sophisticated visualization tools that effectively communicate complex probabilistic results to archaeological researchers. The implementation of inverse distance weighting for displacement curve interpolation represents a methodological advancement that accounts for spatial variations in isostatic uplift. The open-source approach ensures transparency and reproducibility of results, addressing growing concerns about methodological rigour in archaeological chronology studies. Finally, the detailed vignettes provide clear guidance for archaeological applications while acknowledging methodological limitations.","The current version of Shoredate faces several significant limitations. Most critically, it has an extremely restricted geographic applicability, functioning only for southeastern Norway's Skagerrak coast between Horten and Arendal. This narrow focus severely constrains its utility for the broader archaeological community. Second, it operates within a limited temporal range (9469-2500 BCE), exclusively addressing Stone Age occupations. Third, the package relies on specific geological data (displacement curves) that may not be available for other regions, creating a substantial barrier to adaptation. Fourth, the single-developer model presents a sustainability risk, with limited evidence of broader community engagement or contribution. Fifth, while the underlying method has been published, the package lacks comprehensive validation studies comparing shoreline dates with independent chronological methods across diverse sites. The software's reliance on the assumption that sites were located near contemporaneous shorelines may not hold for all archaeological contexts, potentially introducing systematic biases. Additionally, the documentation explicitly acknowledges 'unexplored uncertainties' in the methodology, suggesting incomplete understanding of all factors affecting result reliability. Finally, the technical implementation requires users to have R programming experience, limiting accessibility for archaeologists without computational backgrounds.","The current version of Shoredate faces moderate survivability challenges. On the positive side, its publication in JOSS and hosting on CRAN provide institutional frameworks that support long-term availability of the code. The open-source GPL-3.0 license ensures that the software can be maintained by the community even if the original developer withdraws. The formal publication of the methodology in peer-reviewed journals secures the intellectual foundation regardless of software maintenance. However, several factors create sustainability concerns. Most significantly, the package appears to be maintained by a single developer (Isak Roalkvam) with limited evidence of broader community contribution, creating a potential single point of failure. The highly specialized geographic focus limits the potential user base, reducing incentives for community maintenance. The dependency on specific geological data (displacement curves) ties the software to external research outputs that may not be consistently updated. Additionally, R package dependencies require ongoing maintenance as the R ecosystem evolves. The software's survivability would be strengthened by expanding its geographic applicability, building a more diverse development community, and establishing clearer long-term maintenance plans. Without these improvements, Shoredate risks becoming academically valuable but practically abandoned if institutional support diminishes.","Shoredate occupies a unique methodological niche with no direct functional equivalents for shoreline dating of archaeological sites. However, archaeologists seeking chronological modelling tools have several alternatives addressing different dating approaches. For radiocarbon-based chronological modelling, OxCal (University of Oxford) provides comprehensive Bayesian frameworks for calibration and sequence analysis, with a longer development history and broader user base. The rcarbon R package offers specialized functions for analysing radiocarbon date ensembles, including summed probability distributions similar to Shoredate's output format. Chronological Bayesian modelling is also available through ChronoModel (CNRS) and Bchron (R package), both offering probabilistic approaches to chronology building. For temporal GIS applications, TimeMap and TGIS frameworks provide alternatives for spatiotemporal analysis, though with different methodological approaches. Users specifically interested in post-glacial isostatic adjustment might consider GIA (Glacial Isostatic Adjustment) models from geoscience, though these lack direct archaeological dating implementations. For Norwegian Stone Age researchers, traditional manual shoreline dating methods remain an alternative, though lacking Shoredate's statistical rigour and reproducibility. None of these alternatives implement the specific shoreline dating methodology of Shoredate, making it a complementary rather than competitive tool within the archaeological chronology software ecosystem.",
SpadeR,Success,,"SpadeR (Species-richness Prediction And Diversity Estimation with R) is an R package for statistical analysis of biodiversity in ecological research with limited applications in archaeology. Developed by Professor Anne Chao and her team at National Tsing Hua University, it provides computational methods for estimating species richness, diversity, and related metrics from incomplete sampling data. While primarily designed for ecological studies, SpadeR has been applied in archaeological contexts for analyzing assemblages of artifacts and biological remains. The software implements several statistical estimators (including Chao1 and Chao2) to address the challenge of incomplete sampling in biodiversity studies, allowing researchers to estimate the true diversity of a population based on limited samples. The current version offers both command-line functionality through R and a web-based interface for non-programmers.","SpadeR originated as the R implementation of SPADE (Species Prediction And Diversity Estimation), initially developed as a standalone C++ program by Anne Chao and colleagues in the early 2000s. The transition to an R package (SpadeR) improved accessibility and integration with the broader R ecosystem for ecological and statistical analysis. The first documented release of SpadeR on CRAN occurred in 2016, with version 0.1.1 released on September 6, 2016. This version represented a significant modernisation of the original concepts with improved statistical methods and visualisation capabilities. Since 2016, SpadeR has entered a maintenance phase with no major feature updates. Development focus has shifted to iNEXT (iNterpolation and EXTrapolation), which serves as SpadeR's successor with expanded capabilities while maintaining the same theoretical foundations. Despite this transition, SpadeR remains available and functional through both CRAN and GitHub repositories, with continued maintenance ensuring compatibility with current R versions.","The current version of SpadeR (0.1.1) is implemented as an R package with a focus on statistical computing for biodiversity estimation. The software architecture consists of six primary functions: ChaoSpecies for species richness estimation, Diversity for calculating diversity profiles using Hill numbers, ChaoShared for shared species estimation, SimilarityPair and SimilarityMult for similarity measure calculation, and Genetics for genetic differentiation analysis. SpadeR's technical implementation addresses the computational challenges of biodiversity estimation through a comprehensive statistical framework that includes asymptotic estimators, sample coverage approaches, and bootstrap methods for confidence intervals. The package accepts five different data input formats: (1) abundance data (counts of each species), (2) abundance-frequency counts (frequency of abundance patterns), (3) incidence-frequency data (detection/non-detection across sampling units), (4) incidence-frequency counts (frequency of incidence patterns), and (5) incidence-raw data (species-by-sampling-unit matrices). This flexibility accommodates different sampling methodologies common in ecology and potentially applicable to archaeological contexts. SpadeR requires minimal dependencies beyond base R, making installation straightforward through standard package managers. The implementation provides both numerical outputs and graphical visualisations through R's plotting capabilities. For non-programmers, SpadeR Online offers a web interface built using the Shiny framework, accessible at https://chao.shinyapps.io/SpadeR/. The online version provides the same core functionality without requiring R programming knowledge. SpadeR's statistical methods are computationally efficient for typical dataset sizes encountered in ecology and archaeology, though bootstrap procedures for confidence intervals may require significant computational resources for very large datasets. The algorithms implement theoretical frameworks developed and published by Anne Chao and colleagues in peer-reviewed statistical and ecological journals, ensuring scientific validity and transparency.",2025-05-31,maybe,"SpadeR meets the core definition of research software by supporting scholarly inquiry through data analysis and visualization, but its archaeological applications are limited and specialized. It satisfies all three essential criteria: (1) Research-Specific Purpose - supports statistical analysis of biodiversity data for research, (2) Research Data Engagement - transforms assemblage data into meaningful diversity metrics, and (3) Methodological Alignment - implements established statistical methods for biodiversity estimation. Among supporting criteria, it meets at least four: Domain Knowledge Integration (incorporates ecological terminology and classification systems), Analytical Capabilities (performs statistical calculations for diversity estimation), Visualization Functions (generates statistical plots), and Data Transformation (converts raw abundance or incidence data into diversity metrics). The 'maybe' classification reflects that while SpadeR was not specifically designed for archaeology, it has demonstrated utility in specialized archaeological applications, particularly for analyzing stone tool assemblages and biological remains from archaeological contexts. Its methods have been adapted to archaeological problems, as seen in research by Eren et al. published in PLOS ONE, but require careful consideration of the differences between ecological and archaeological sampling contexts. The statistical framework is robust and theoretically sound, but archaeological users must account for taphonomic factors, preservation bias, and cultural selection processes not present in ecological sampling.",https://github.com/AnneChao/SpadeR,https://cran.r-project.org/web/packages/SpadeR/,https://chao.shinyapps.io/SpadeR/,https://chao.shinyapps.io/SpadeR/,GPL-3.0-or-later,Statistical analysis|Zooarchaeology|Palaeobotany|Datasets,biodiversity estimation|species richness|statistical sampling|assemblage analysis|diversity metrics,2016-01-01,2016-09-06,0.1.1,Maintenance-only,National Tsing Hua University,Anne Chao|K. H. Ma|T. C. Hsieh|Chun-Huo Chiu,Small (2-5),Ecology,General-purpose,Excellent,"SpadeR demonstrates solid adoption within ecological research communities, though specific download metrics are not publicly available. Citation analysis shows the underlying statistical methods (Chao1 and Chao2 estimators) have been cited over 52,000 times according to Google Scholar. The software has been used in numerous ecological studies analyzing species richness in various contexts. Archaeological applications are more limited but include notable research by Eren et al. analyzing Clovis stone tools using SpadeR's statistical framework. The software is particularly well-established in Asian biodiversity research communities and conservation biology networks globally. User discussions appear primarily in ecological research forums rather than archaeological contexts, reflecting its primary disciplinary focus. While community engagement with the software itself appears modest, the underlying statistical methods developed by Anne Chao continue to receive substantial recognition in biodiversity research.",Analysis|Processing|Interpretation,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"SpadeR supports multiple data input formats including abundance data, abundance-frequency counts, incidence data, incidence-frequency counts, and incidence-raw data. Outputs include R objects for programmatic use, high-quality plots for publication, and downloadable text files from the online version. The software follows R's standard data structures, facilitating integration with other R packages for additional analysis or visualization. Data exchange with other platforms typically occurs through CSV or text file exports rather than direct API connections. All versions support export of results for further processing.","SpadeR's strengths include: 1) Comprehensive statistical framework based on well-established biodiversity estimation methods, providing mathematical rigor for diversity analysis; 2) Multiple data input format support accommodating various research designs and sampling methodologies; 3) Dual access methods through both R programming interface and web-based tools, making the software accessible to users with varying technical skills; 4) Excellent documentation with detailed explanations of methods, formulas, and interpretations; 5) Strong theoretical foundations published in peer-reviewed literature, ensuring scientific validity; 6) Clear methodology for calculating confidence intervals through bootstrap procedures, enhancing statistical rigor; 7) Implementation of the Hill numbers framework, providing a unified approach to diversity measurement across different orders; 8) Minimal dependencies in the R package, reducing installation complexity and maintenance issues.","SpadeR's weaknesses include: 1) Limited active development since 2016, with the focus shifted to successor software (iNEXT); 2) Steep learning curve for users unfamiliar with statistical concepts in biodiversity estimation; 3) Computational limitations when analyzing very large datasets, particularly for bootstrap confidence intervals; 4) Ecological assumptions underlying the methods require careful consideration when applied to archaeological contexts; 5) Limited community support resources beyond official documentation; 6) Visualization capabilities less sophisticated than contemporary R packages; 7) Bootstrap resampling procedures occasionally fail with certain edge-case data configurations; 8) Archaeological applications require additional methodological considerations not directly addressed in the documentation.","SpadeR demonstrates moderate long-term viability with both strengths and concerns. Positive factors include stable institutional support from National Tsing Hua University, a well-designed codebase following CRAN standards, minimal technical debt, and continued availability on major distribution platforms. The software's theoretical foundations in peer-reviewed research provide lasting scientific value regardless of development status. Risk factors include the development team's shifted focus to iNEXT, limited community contribution infrastructure, and maintenance-only development patterns since 2016. The clear migration path to iNEXT (developed by the same team with consistent theoretical foundations) provides users with long-term sustainability options. Given these factors, SpadeR remains a viable tool for current research but users should consider eventual migration to iNEXT for access to ongoing development and expanded features. The software's stability and reliable implementation of established statistical methods suggest it will remain functional and scientifically valid for the foreseeable future, even without major feature updates.","vegan: The most widely used R package for biodiversity analysis with comprehensive functionality beyond diversity metrics and extensive community support. BiodiversityR: GUI wrapper for vegan that simplifies usage for R beginners while maintaining analytical capabilities. PAST: Standalone software requiring no R knowledge, offering user-friendly interface with broad statistical tools beyond diversity. iNEXT: SpadeR's successor from the same development team, offering enhanced rarefaction/extrapolation methods and improved visualization. adiv: R package specialized in functional and phylogenetic diversity analysis, complementing taxonomic diversity metrics.",
ArcGIS Spatial Analyst,Success,,"A powerful raster-based spatial modeling and analysis extension for ArcGIS Pro and ArcGIS Enterprise. Provides advanced spatial analysis capabilities including distance analysis, surface modeling, hydrology analysis, suitability modeling, density analysis, statistical analysis, interpolation, solar radiation analysis, and visibility analysis. Extensively used in archaeology for predictive modeling, viewshed analysis, least-cost path analysis, and terrain analysis.","Originally developed by Environmental Systems Research Institute (ESRI), founded in 1969 by Jack and Laura Dangermond. First released April 24, 2001 as part of ArcGIS 8.1, building upon decades of ESRI's GIS development experience. Initially designed for environmental sciences and natural resource management, but quickly adopted by archaeologists in the early 1990s. Has evolved through continuous development with major milestones including Python integration (2004), ArcGIS Pro transition (2015), and ongoing architectural improvements through 2025.","Windows-only extension requiring base ArcGIS Pro license. Supports Python 3.x through arcpy.sa module with comprehensive API. Features GPU acceleration for select tools using NVIDIA CUDA. Integrates with R through R-ArcGIS bridge. Supports 84+ vector formats and numerous raster formats via built-in GDAL library. Implements OGC standards (WMS, WFS, WCS). Offers parallel processing support and efficient memory management for large datasets. Recent enhancements include space-time kernel density, multiscale surface analysis, and machine learning integration.",2025-05-31,yes,"Regular bi-annual releases with latest version 3.5 released May 13, 2025. Continuous feature development, bug fixes, and performance improvements. Strong institutional backing from ESRI with dedicated development team. Clear development roadmap and ongoing investment in new technologies including AI/ML integration and cloud computing support.",,,https://www.esri.com/en-us/arcgis/products/arcgis-spatial-analyst/overview,https://www.esri.com/en-us/arcgis/products/arcgis-spatial-analyst/overview,Commercial proprietary license,Spatial analysis|Viewshed analysis|Site mapping|Aerial and satellite imagery|Geophysical survey,geospatial-ai|machine-learning-integration|deep-learning|predictive-analytics|spatial-statistics,2001-04-24,2025-05-13,3.5 (with ArcGIS Pro 3.5),Active,"ESRI (Environmental Systems Research Institute) - ~4,000 employees globally, $1.1-1.3 billion annual revenue, 11 R&D centers worldwide, 45% GIS market share","ESRI development team led by Kevin Johnston (29+ years), Juan Carlos, Sydney Walker, Sarmistha, and others",Large (20+),Geography and Environmental Sciences,General-purpose,Excellent,"Industry standard in archaeological GIS since early 1990s. Used by majority of CRM firms, government agencies, and academic institutions. Regular presence in archaeological conferences (SAA, CAA). Required skill in many archaeological job postings. Cited frequently in archaeological literature.",Planning|Data Acquisition|Processing|Analysis|Interpretation,mass-market,Stand-alone software,C++|C#|Python,Windows,,"High - supports 84+ vector formats via GDAL, OGC standards compliance, database connectivity (PostgreSQL/PostGIS, SQLite, SQL Server, Oracle), Python/R integration, REST API",1. Comprehensive analytical capabilities with 100+ spatial analysis tools 2. Industry standardization ensuring data compatibility 3. Robust performance with GPU acceleration 4. Seamless integration within ArcGIS ecosystem 5. Extensive support resources and training 6. Strong predictive modeling capabilities 7. Advanced terrain and visibility analysis tools,1. High cost and complex licensing model 2. Windows-only platform limitation 3. Steep learning curve requiring specialized training 4. Vendor lock-in with proprietary data formats 5. Limited archaeology-specific features requiring adaptation 6. Environmental determinism bias in archaeological applications 7. Difficulty incorporating social/cultural variables,"Medium - Strong institutional backing and market position ensure continued development, but vendor lock-in risks, proprietary formats, and high costs create long-term dependencies. Migration to alternatives possible but requires significant effort","1. QGIS with plugins (free, open-source, cross-platform, strong archaeological community) 2. GRASS GIS (free, advanced raster analysis, academic backing) 3. SAGA GIS (free, specialized terrain analysis) 4. R spatial packages (free, statistical integration) 5. PostGIS (free, spatial database capabilities)",
STAR,Success,,"STAR (Semantic Technologies for Archaeological Resources) was a semantic web framework for cross-searching heterogeneous archaeological datasets and grey literature. Developed from 2007-2010, it enabled researchers to perform unified queries across previously incompatible excavation records by implementing the CIDOC Conceptual Reference Model (CRM) with archaeological extensions (CRM-EH). The system supported cross-dataset searches through semantic relationships rather than simple keyword matching, allowing users to discover connections between contexts, finds, samples and interpretations across different excavation databases and grey literature reports.","STAR began in 2007 as an AHRC-funded project (Grant AH/D001528/1) led by Professor Doug Tudhope at the University of Glamorgan (now University of South Wales) in collaboration with English Heritage. The project showcased initial demos at CAA 2008 in Budapest with the paper 'A STAR is born'. By 2010, the primary development phase concluded after successfully integrating five major excavation datasets and processing extensive grey literature. STAR subsequently evolved into STELLAR (2010-2011), which simplified the tools for non-specialist users, followed by SENESCHAL (2013-2014), which created HeritageData.org to publish UK cultural heritage vocabularies as linked open data. The STAR methodologies were later scaled up in the ARIADNE (2013-2017) and ARIADNEplus (2019-2022) projects to create pan-European archaeological infrastructure.","The STAR system architecture implemented semantic web technologies to create interoperability between disparate archaeological datasets. The core technical foundation was the CIDOC CRM ontology (ISO 21127) extended with CRM-EH (English Heritage) archaeological extensions. The system comprised several integrated components: a data mapping layer that converted heterogeneous database schemas to RDF/XML, natural language processing pipelines using the GATE toolkit for analysing grey literature, a triple store for semantic data storage, SPARQL endpoints for querying, and web service APIs supporting multiple interface types. The data processing pipeline accepted CSV/TAB delimited files from archaeological databases, applied semi-automatic mapping to CRM-EH patterns through SQL extraction, transformed the data using ANTLR-based templates, and stored results in RDF format accessible via SPARQL. The implementation used .NET Framework 3.5, SQLite databases for temporary storage, and SemWeb RDF libraries. The NLP system performed three-phase semantic enrichment: entity recognition, concept extraction aligned with SKOS vocabularies, and XML annotation coupled with RDF metadata. Performance limitations emerged with complex SPARQL queries, necessitating result limits (first 100 records) and recommendations for combined query approaches. The system accessed RDF data through SPARQL endpoints but included a caching layer to improve response times for common queries.",2023-05-31,yes,"STAR meets all essential criteria as a research-specific tool that engages directly with archaeological research data through semantic modelling and transformation. It aligns with archaeological methodologies by implementing domain-specific ontology extensions (CRM-EH). It satisfies multiple supporting criteria: integrates domain knowledge through CIDOC-CRM and archaeological taxonomies, supports research lifecycle stages from data processing through analysis, transforms data between formats using RDF mappings, provides analytical capabilities through semantic querying, and enables data dissemination through standardised web services.",,,https://hypermedia.research.southwales.ac.uk/kos/star/,https://hypermedia.research.southwales.ac.uk/kos/star/,Creative Commons,Data management|Platforms and publications|Schemas and ontologies,semantic web|ontology|CIDOC-CRM|archaeological data|interoperability,2007,2017,Research Demonstrator (final version),Deprecated,University of South Wales (formerly University of Glamorgan)|English Heritage (now Historic England),Doug Tudhope|Ceri Binding|Keith May,Small (2-5),Archaeology,Project-specific,Comprehensive,"The STAR Research Demonstrator operated from 2007-2017 and was cited in over 50 academic publications. The system integrated five major archaeological datasets: Raunds Roman Analytical Database, Museum of London, Silchester Roman town excavation, Stanwick sampling data, and Raunds prehistoric data. The project's methodologies have been adopted in subsequent large-scale infrastructure projects including ARIADNE, which now serves over 2 million archaeological records across Europe. The CRM-EH ontology extension developed during STAR has become a reference implementation for archaeological extensions to CIDOC-CRM. GitHub repositories related to successor projects (STELLAR) have received modest engagement (7 stars, 5 forks).",Processing|Analysis|Interpretation|Preservation and Reuse,research-specific,Stand-alone software,.NET|Java|SPARQL|XML,Windows,,"STAR implemented robust interoperability through CIDOC-CRM (ISO standard) and the CRM-EH archaeological extension. It supported data exchange through RDF/XML, standard SPARQL endpoints, and REST web services. The system could import data from CSV/TAB delimited files and extract structured information from unstructured grey literature reports. It exposed vocabularies in SKOS format with persistent URIs. Later developments in the STELLAR project added template-based conversion tools to simplify mapping between archaeological datasets and semantic formats.","STAR successfully demonstrated practical semantic interoperability across archaeological datasets with different structures and vocabularies, integrating five excavation databases and over 1,000 grey literature reports. The robust technical framework based on ISO-standard CIDOC-CRM ensured compatibility with international cultural heritage systems while the CRM-EH extension provided archaeological domain specificity. The natural language processing capabilities represented significant innovation, automatically extracting semantic information from unstructured archaeological reports. The project established standards through RDF, SKOS, and SPARQL that aligned with broader semantic web developments, while Creative Commons licensing enabled research reuse. The well-documented technical approach facilitated knowledge transfer to subsequent projects and infrastructure development.","Performance issues emerged as STAR's most significant technical weakness, with SPARQL query timeouts occurring on complex searches combining free text and semantic constraints. The system's scalability limitations became apparent with larger datasets, restricting practical deployment beyond research demonstrations. Technical complexity posed the greatest adoption barrier - effective use required specialist knowledge of ontologies, RDF, and semantic web principles rarely found among practicing archaeologists. The resource-intensive mapping process demanded significant time investment for each new dataset integration, limiting rapid deployment. User interface design prioritized functionality over usability, creating steep learning curves for non-technical users. The system's focus on 'single context recording' methodology limited applicability to archaeological projects using alternative recording systems. Spatial functionality remained basic compared to dedicated GIS platforms archaeologists routinely employed.","While the original STAR software ceased operation with server decommissioning in March 2017, the project demonstrates remarkable survivability through evolved forms. HeritageData.org continues providing vocabulary services based on STAR/SENESCHAL development, serving as the UK's primary platform for archaeological terminology with persistent URIs and SKOS representations. The ARIADNE infrastructure, directly building on STAR methodologies, operates as Europe's primary archaeological data aggregation service integrating millions of records across multiple countries. The core research team remains active, with 2023 publications demonstrating ongoing innovation. STAR's intellectual contributions persist through CIDOC-CRM archaeological extensions adopted internationally, semantic mapping methodologies documented in academic literature, and practical tools integrated into operational systems like OASIS and the Archaeology Data Service.","The Arches Project emerged as STAR's most significant alternative for practical heritage management, offering user-friendly interfaces, active development, and successful global deployments (Los Angeles HistoricPlacesLA, EAMENA). While lacking STAR's sophisticated semantic reasoning, Arches provides production-ready functionality with lower technical barriers. OpenArchaeo offers focused SPARQL endpoint access for French archaeological data, implementing CIDOC-CRM with simplified query interfaces. Within the CIDOC-CRM ecosystem, specialized extensions like CRMarchaeo, CRMsci, and CRMba address domain-specific requirements beyond STAR's archaeological focus. ARIADNEplus represents STAR's conceptual successor at continental scale, aggregating heterogeneous archaeological data through semantic technologies while providing more sustainable infrastructure support.",
STELLAR,Success,Initial fail but mentioned correct tool in passing; had to re-run with clarification,"STELLAR (Semantic Technologies Enhancing Links and Linked Data for Archaeological Resources) is a toolkit designed to enable archaeologists and data managers without semantic web expertise to convert archaeological datasets into linked data conforming to the CIDOC CRM-EH ontology. The current version provides three core applications: STELLAR.Console (command-line utility), STELLAR.Web (browser interface), and STELLAR.Testing (validation tool). These applications allow users to import structured data (CSV/TAB), manipulate it via SQL queries, and apply predefined templates to convert archaeological records to RDF/XML format. STELLAR was specifically developed to bridge the gap between excavation data management and semantic web technologies, making linked data creation accessible to archaeological practitioners without requiring expertise in ontology modelling.","STELLAR emerged from a £110,000 Arts and Humanities Research Council (AHRC) funded project running from March 2010 to March 2011. It was developed at the University of Glamorgan (now University of South Wales) by Professor Douglas Tudhope and Research Fellow Ceri Binding, in collaboration with the Archaeology Data Service and English Heritage. The project built upon previous semantic web initiatives: the FACET project (EPSRC-funded) pioneered thesaurus-based search techniques, followed by the 3-year STAR project (2007-2010) that developed core semantic technologies for archaeological reporting. STELLAR represented the culmination of this research progression, focusing on practical tools for archaeological data managers. The software was publicly released in 2011, with case studies demonstrating applications with major UK archaeological datasets. While active development concluded with the project's completion in 2011, STELLAR's approach influenced subsequent projects including SENESCHAL (2013-2014) for vocabulary services and contributed to the European ARIADNEplus infrastructure. No version numbering system was implemented beyond the initial release.","The STELLAR toolkit's technical implementation centers on a template-based approach to data transformation. The current version is built in C# on the .NET Framework, with core dependencies including ANTLR for template parsing, FileHelpers for structured text processing, and the SemWeb library for RDF operations. The system architecture follows a three-stage workflow: 1) Data Preparation - STELLAR.Console imports CSV/TAB files into an internal SQLite database, allowing users to consolidate data using SQL queries before conversion; 2) Template Application - Predefined templates express relationships between archaeological data fields and CRM entities/properties (templates contain variables that match column headings from the source data, with conditional logic and loops for handling complex mappings); 3) RDF Generation - The system produces RDF/XML output with consistent URI patterns for archaeological entities. The technical innovation lies in the template mechanism, which abstracts semantic web complexity through pattern-based transformation rules. Templates encapsulate the complex entity-relationship mapping between archaeological concepts and the CIDOC CRM-EH ontology. For example, a context record template might create a 'EHE0007.ContextFind' entity with properties linking to context and find entities, handling relationship cardinality and identifier generation automatically. The software implements W3C standards for RDF/XML output, generates consistent URIs for entities, and manages namespaces for linked data publication. Memory management was optimized for large datasets through stream-based processing rather than loading entire datasets. Previous versions during development featured more limited template capabilities and lacked the SQL preparation stage that was added to handle real-world archaeological data complexity.",2025-05-31,yes,"STELLAR fully satisfies all essential criteria for research software. It was specifically designed to support archaeological research (Research-Specific Purpose) by transforming excavation datasets into semantic linked data (Research Data Engagement). Its template-based approach aligns with established methodologies for archaeological data integration (Methodological Alignment). For supporting criteria, STELLAR meets 5 out of the 8: it incorporates domain knowledge through CIDOC CRM-EH ontology integration (Domain Knowledge Integration); supports the data processing and analysis stages of research (Research Lifecycle Support); transforms between CSV/TAB formats and RDF/XML (Data Transformation); performs complex entity-relationship mappings (Analytical Capabilities); and provides documentation specifically addressing archaeological applications (Documentation Focus). Its primary function of enabling semantic web integration for archaeological datasets demonstrates clear research-specific purpose beyond general database capabilities.",https://github.com/cbinding/stellar,,http://hypermedia.research.southwales.ac.uk/kos/STELLAR,http://hypermedia.research.southwales.ac.uk/kos/STELLAR,Creative Commons Attribution 3.0,Data management|Schemas and ontologies|API interfaces and web scrapers|Platforms and publications|Data collection,semantic_web|archaeological_databases|data_transformation|ontology_mapping|rdf_generation,2010-03-01,2011-03-31,1,Abandoned,University of Glamorgan (now University of South Wales)|Archaeology Data Service|English Heritage,Douglas Tudhope|Ceri Binding,Small (2-5),Archaeology,Project-specific,Comprehensive,"STELLAR was initially used to process 5+ major UK excavation archives, including the Channel Tunnel Rail Link Section 1, Hartshill ironworking site, Wellington Quarry, and St Peter's Church data. It produced 10+ academic publications and influenced at least 4 subsequent projects (SENESCHAL, ARIADNE, ARIADNEplus, STELETO). International adoption included the German ArcheoInf project and the German Archaeological Institute creating thesauri for DARIAH. While precise download statistics are unavailable, the software was distributed through university channels. Academic impact continues with citations in digital archaeology literature through 2024, particularly in semantic archaeological data management research. Conference presentations at CAA (Computer Applications in Archaeology) events from 2008-2014 disseminated findings internationally. The relatively small user base reflects its specialized nature as a research tool rather than commercial software, though its conceptual approach has been widely influential in the field.",Processing|Analysis|Preservation and Reuse,research-specific,Stand-alone software,C#,Windows|Linux|macOS,,"STELLAR supports input formats including CSV, TAB-delimited, and fixed-width text files, producing output in RDF/XML and N-Triples formats compliant with W3C standards. The current version implements CIDOC CRM (ISO 21127) and its archaeological extension CRM-EH, along with SKOS for controlled vocabularies. This standards-based approach ensures interoperability with semantic web infrastructure and archaeological data repositories. The system generates consistent URIs for entities and manages namespaces for linked data publication. Integration points include compatibility with the Archaeology Data Service's linked data repository and the broader archaeological semantic web ecosystem through standards compliance. The transformation templates provide a flexible mechanism for mapping various archaeological database schemas to the standardized CIDOC CRM-EH model, supporting interoperability across diverse excavation recording systems.","STELLAR's primary strength is its accessibility for non-specialists, providing guided workflows and predefined templates that reduce barriers to semantic technology adoption in archaeology. The current version's template-based approach successfully abstracts complex ontological relationships, allowing archaeologists to create valid RDF/XML without deep knowledge of semantic web technologies. Its standards-based implementation using established cultural heritage ontologies (CIDOC CRM-EH) ensures long-term compatibility with emerging archaeological information systems. Practical validation with real commercial archaeological datasets demonstrates genuine utility beyond theoretical exercises. The free availability and relatively straightforward installation process made it accessible for budget-conscious archaeological projects. Documentation was comprehensive, including detailed mapping guidelines, user manuals, and examples drawn from actual archaeological datasets. The project's close collaboration with major institutions (English Heritage, Archaeology Data Service) ensured alignment with practical needs of the archaeological community. The toolkit successfully addressed the critical need for semantic interoperability in archaeological data, particularly for legacy datasets from completed excavations.","Several limitations affect STELLAR's practical application. Template modification complexity required rebuilding the application to implement new patterns, creating a technical barrier for advanced users. The current version's reliance on manual mapping processes poses scalability challenges for large-scale data integration projects, lacking automated schema matching capabilities found in newer systems. Initial versions offered limited vocabulary control, often mapping free text rather than controlled terms, which reduced semantic precision. Technical dependencies on specific software environments (.NET Framework) created deployment hurdles for some archaeological organizations. Documentation gaps exist for advanced usage scenarios, requiring expertise to extend beyond provided templates. The workflow separation between data preparation and transformation increases learning complexity compared to integrated platforms. Performance optimization for very large datasets (>100,000 records) remains unaddressed in current implementations. The lack of visual mapping tools makes relationship comprehension difficult for complex archaeological schemas. Maintenance challenges emerged after project funding concluded, with limited community resources for ongoing development. These weaknesses reflect STELLAR's origin as a research project rather than commercial software, with emphasis on conceptual innovation over production-grade implementation.","STELLAR's long-term viability as a standalone tool appears limited, as the software has not been actively maintained since the project's completion in 2011. However, its conceptual framework and approach have demonstrated remarkable sustainability through integration into successor projects and operational services. The software's intellectual foundation continues to influence archaeological linked data initiatives globally. Several factors contribute to its mixed survivability profile: 1) The CIDOC CRM standard remains actively maintained and widely adopted, ensuring continued relevance of STELLAR's core approach; 2) Modern alternatives have incorporated and extended STELLAR's template-based mapping concepts while addressing technical limitations; 3) Documentation remains accessible through academic repositories, allowing knowledge transfer despite limited software maintenance; 4) The code base is available under permissive licensing, enabling reuse of components in newer systems; 5) Technical dependencies on older .NET frameworks create increasing compatibility challenges on modern systems. While the original software may become increasingly difficult to deploy, STELLAR's conceptual contributions to archaeological data integration continue to demonstrate significant impact through derivative systems and services, particularly in the European archaeological data infrastructure landscape.","Alternative tools for archaeological data semantic conversion and management have evolved significantly since STELLAR's development. ARIADNEplus represents the closest conceptual successor, implementing STELLAR's vision at continental scale with over 3.5 million resources and advanced Virtual Research Environments. Unlike STELLAR's standalone approach, ARIADNEplus provides a comprehensive infrastructure with automated mapping services. Open Context shares STELLAR's semantic web focus but emphasizes peer-reviewed data publication over mapping tools, with stronger support for field data collection and integration with external repositories. tDAR (The Digital Archaeological Record) prioritizes long-term preservation and broad accessibility without STELLAR's semantic emphasis, offering more comprehensive file format support but less ontological integration. For practical heritage management, Arches provides enterprise-level capabilities with optional CIDOC CRM compliance, superior visualization features, and active maintenance. Heurist offers flexible humanities database design with less semantic integration but greater customization for project-specific needs. FAIMS focuses on mobile field data collection, integrating with backend systems for semantic processing. Migration from STELLAR remains feasible due to standard RDF output formats, though newer systems offer improved workflow integration and user interfaces. Current community preferences favor larger, well-funded platforms with proven sustainability and comprehensive feature sets.",
straditize,Success,,"STRADITIZE (Stratigraphic Diagram Digitizer) is a specialized Python tool designed to extract data from stratigraphic diagrams, particularly pollen diagrams used in paleoenvironmental research. The current version (v0.1.3) provides a semi-automated workflow for converting published images of stratigraphic plots into reusable numerical data. While originally developed for paleoecology, it has potential applications in archaeology for analyzing environmental data relevant to human-environment interactions and landscape evolution. The tool addresses the critical challenge of accessing 'legacy data' from pre-digital scientific publications, enabling reanalysis and integration of historical datasets into modern research.","Straditize was developed at the Institute of Earth Surface Dynamics, University of Lausanne between 2018-2019 by Philipp S. Sommer as part of the Swiss National Science Foundation-funded HORNET Project. The first official release (v0.1.0) was published in February 2019, coinciding with its publication in the Journal of Open Source Software (JOSS). The software underwent peer review for JOSS publication, receiving approval with minimal requested changes. Development was relatively short-lived, with only minor updates following the initial release. By late 2019, the project had effectively ceased active development, and the repository was eventually marked with an unmaintained status warning. Despite its brief development period, the tool achieved its core functionality objectives and received positive reviews from the scientific community.","The current version of straditize (v0.1.3) implements a sophisticated technical architecture specifically designed for stratigraphic data extraction. The software supports six diagram types: bar plots, line plots, shaded area plots, stacked area plots, filled area plots, and combinations thereof. Its core innovation lies in handling the unique structure of stratigraphic diagrams, where multiple horizontal axes (variables) share a common vertical axis representing depth or time. The implementation features several technical components: an image recognition system for detecting diagram elements, OCR functionality (via tesserocr) for extracting variable names and values from axes, and a column-based reconstruction algorithm for accurately parsing data from complex visualizations. The software is built on Python (≥3.6) with dependencies including numpy, scipy, pandas, matplotlib, and integrates with the psyplot visualization framework. The GUI is implemented using PyQt5, providing an interactive workflow that guides users through a structured digitization process: diagram area selection, column detection, data extraction, artifact removal, and data export. The architecture supports both graphical and command-line interfaces, with the GUI offering embedded documentation and interactive tutorials. Data output formats include CSV and Excel, with metadata preservation for variables, depths, and sources. Technical limitations include dependency on specific versions of PyQt5, installation complexities across different platforms, and performance issues with particularly complex diagrams containing many variables.",2025-05-31,no,"Straditize fails the tool status evaluation due to its explicitly abandoned state. The GitHub repository is clearly marked 'This module is not maintained!!!' and has seen no substantial updates since 2019. While it meets all three essential criteria for research-specific purpose, research data engagement, and methodological alignment, and satisfies at least four supporting criteria (domain knowledge integration, data transformation, analytical capabilities, and visualization functions), its unmaintained status presents prohibitive risks for new research applications. Installation issues remain unresolved, dependencies are becoming outdated, and there is no community support structure to sustain the tool. The single-maintainer model without institutional continuity has proven fatal to long-term viability, despite the tool's technical merits and peer-reviewed validation. As research software requires ongoing maintenance to remain functional through evolving dependencies and platforms, straditize cannot be recommended for current research projects.",https://github.com/Chilipp/straditize,https://pypi.org/project/straditize/,https://pypi.org/project/straditize/,https://straditize.readthedocs.io/en/latest/,GPL-3.0,Data management|Palaeoclimate modelling|Palaeobotany|Diagrams and visualizations,digitization|pollen-diagrams|data-rescue|paleoenvironmental-data|image-processing,2019-02-13,2019-07-25,0.1.3.post1,Abandoned,University of Lausanne|Swiss National Science Foundation,Philipp S. Sommer,Solo,Paleoecology,General-purpose,Excellent,"The tool shows minimal adoption despite academic validation. GitHub metrics reveal only 14 stars, 9 forks, and effectively one contributor (the original author). The software was published in the Journal of Open Source Software (February 2019) and has received fewer than 10 citations in academic literature. Most citations appear in paleoenvironmental studies rather than archaeological applications. There is no evidence of substantial community formation, with the GitHub issues section showing unresolved installation problems and no active discussion. The LandClimI project reported using straditize for digitizing datasets for the European Pollen Database, but widespread institutional adoption is not apparent. Download statistics from PyPI are not publicly available but likely minimal given other indicators. The 2024 PyPI update appears to be an automated metadata change rather than functional development.",Data Acquisition|Processing|Analysis,research-specific,Stand-alone software,Python,Linux|macOS|Windows,,"The current version exports extracted data as CSV and Excel files, preserving both numerical data and metadata about variables, depths, and sources. It can process raster image inputs (PNG, JPG, TIFF) of published diagrams. Internal data structures use pandas DataFrames, facilitating integration with the scientific Python ecosystem. The software lacks direct API interfaces to databases or repositories. Integration with the psyplot visualization framework enables advanced plotting capabilities for verified results. No standardized exchange formats for stratigraphic data are implemented, limiting interoperability with specialized paleoecological or archaeological software. Installation dependencies require specific versions of PyQt5 and other libraries, creating potential compatibility issues across environments.","The current version of straditize offers several notable strengths: (1) Specialized design for stratigraphic data extraction that handles the unique format of multi-variable plots sharing a common depth/time axis—functionality absent in general-purpose digitizers. (2) Semi-automated workflow that balances automation efficiency with human oversight for accuracy. (3) OCR integration for automatic recognition of variable names and values on axes. (4) Advanced artifact detection and removal to address common issues in published diagrams. (5) Peer-reviewed validation through JOSS publication process, confirming software quality and scientific relevance. (6) Excellent documentation and embedded tutorials that guide users through complex workflows. (7) Integration with the scientific Python ecosystem, enabling further analysis of extracted data. (8) Open-source licensing that enables transparency and potential community extensions. The software directly addresses a recognized barrier in paleoenvironmental and archaeological research: accessing quantitative data from published diagrams that would otherwise require manual extraction.","The current version suffers from several critical weaknesses: (1) Explicit abandonment by its sole developer, with the repository prominently marked as unmaintained since 2019. (2) Installation difficulties across platforms, with multiple unresolved GitHub issues reporting failures, particularly on Windows systems. (3) Dependency on specific versions of PyQt5 and other libraries that will become increasingly problematic as the Python ecosystem evolves. (4) Limited adoption beyond its developer, with minimal community formation to sustain development. (5) Overly complex architecture that hinders community contributions and maintenance. (6) Lack of automated testing infrastructure for critical components, increasing the risk of undetected failures as dependencies change. (7) No institutional support structure to ensure continuity beyond the original developer. (8) Narrow specialization that limits the potential user base needed for sustainability. (9) User interface complexity that requires significant learning investment despite attempts at comprehensive documentation. (10) Performance limitations when processing particularly complex diagrams with many variables.","Straditize has extremely poor long-term viability. The current version is explicitly marked as unmaintained by its sole developer, who has moved on to other projects. With only 14 GitHub stars and 9 forks, the software lacks the critical mass of users or contributors necessary to form a sustainable community. The single-maintainer model without institutional continuity has proven fatal, as no organization has stepped forward to adopt the codebase despite its academic publication and validation. The complex architecture and GUI dependencies create substantial technical debt that will only increase as the Python ecosystem evolves. Already, users report installation difficulties across platforms, with unresolved issues dating back years. The tool's specialized nature limits its potential user base, further reducing sustainability prospects. Without intervention, the software will become increasingly difficult to install and use as dependencies evolve, eventually becoming completely non-functional. The European Pollen Database community, as primary beneficiaries, could potentially organize revival efforts, but no evidence suggests this is occurring. Overall, straditize exemplifies the sustainability crisis facing specialized academic software without clear succession planning.","Several alternatives exist for researchers needing to digitize stratigraphic diagrams: (1) WebPlotDigitizer—web-based, actively maintained, and supports multiple plot types though lacks stratigraphic-specific features; (2) Engauge Digitizer—open-source desktop application for digitizing graphs with manual point selection; (3) GetData Graph Digitizer—commercial software with similar functionality but professional support; (4) PlotDigitizer—commercial alternative with automated feature detection; (5) MATLAB's built-in digitization tools for users of that platform; (6) g3data—lightweight Linux tool for graph digitization; (7) Origin Pro's digitization features for scientific publishing. None perfectly replicate straditize's specialized features for stratigraphic diagrams, particularly the handling of multi-variable plots sharing a depth/time axis. For archaeological applications, general-purpose digitizers like WebPlotDigitizer remain the most viable option, requiring more manual work to reconstruct the complex relationships in stratigraphic data. The void left by straditize's abandonment represents an opportunity for incorporating stratigraphic-specific features into maintained alternatives.",
StratiGraf,Success,,"StratiGraf is a commercial archaeological documentation and interpretation software that combines stratigraphic recording, Harris Matrix generation, and comprehensive database management in a single integrated system. Developed by Proleg DPC of Spain, the software organises archaeological data in a hierarchical structure progressing from Site → Excavation → Section → Grid Square → Stratigraphic Unit (SU) → Materials, allowing researchers to maintain relationships between different levels of archaeological recording. The database capabilities record information under three main headings: Identification, Situation, and Documentation, theoretically providing comprehensive coverage of excavation data requirements. It was available in English, Spanish, and Catalan.","Developed by Proleg DPC (Pròleg d.p.c. S.L.) based in Balaguer, Spain, in the late 1990s. The company registered the domain proleg.com in August 1998 and released version 1.1 by 2000. Development progressed through several versions, with 3.5 and 3.6 representing the most recent documented iterations. The software used a tiered commercial licensing model: €560 for the first license, €94 for additional licenses, and €14 for educational institutions. A demonstration version limited to 30 stratigraphic units allowed potential users to evaluate the software before purchase. Development appears to have ceased around 2011, based on the last update to domain registration information and absence from contemporary archaeological software surveys.","StratiGraf was developed as a Windows-only desktop application using proprietary database technology. The earliest documented version (1.1, circa 2000) required Windows NT, 95, or 98, with minimum hardware specifications of a Pentium II 266 MHz processor, 32 MB RAM, and SVGA resolution. The software employed a proprietary database format that became one of its most significant limitations. Unlike contemporary archaeological software that supported standard formats like CSV, XML, or established archaeological data standards, StratiGraf's closed format prevented data import or export to other systems. This design decision effectively isolated user data within the StratiGraf ecosystem, making it impossible to integrate with GIS software, statistical analysis packages, or other archaeological tools commonly used in research workflows. The software was distributed as an executable installer (stratigraf.exe) and offered in three languages: English, Spanish, and Catalan. Platform support remained limited to Windows throughout the software's lifecycle, with no evidence of ports to macOS, Linux, or web-based platforms. This Windows-centric approach, combined with the proprietary data format, positioned StratiGraf poorly for the emerging trends in archaeological computing toward open standards and cross-platform compatibility.",2025-05-31,yes,"StratiGraf meets all essential criteria as research software: it has a research-specific purpose (archaeological documentation), engages directly with research data (stratigraphic units and relationships), and aligns with established methodologies (Harris Matrix). It also satisfies multiple supporting criteria: it incorporates domain-specific terminology, supports multiple research lifecycle stages, transforms data between representations, provides analytical capabilities for stratigraphic relationships, visualises data through Harris Matrix generation, includes documentation focused on research applications, and supports data collection in field settings.",,,,,Commercial/Proprietary,Harrix matrix|Site mapping|Data management|Data collection,Archaeological documentation|Stratigraphic analysis|Harris Matrix generation|Excavation recording|Legacy software,2000,~2011,3.6,Abandoned,Proleg DPC (Pròleg d.p.c. S.L.),Albert Franquesa (Technical Contact),Small (2-5),Archaeology,Project-specific,Basic,"Limited information is available about actual usage. The software used a commercial licensing model with tiered pricing: €560 for the first license, €94 for additional licenses, and €14 for educational institutions. A critical review in Internet Archaeology (2000) by M. Rains noted significant limitations that likely hampered widespread adoption. No evidence of continued usage or community support exists after approximately 2011.",Data Acquisition|Processing|Analysis,research-specific,Stand-alone software,Unknown (likely C++ or Visual Basic),Windows,,"Very limited. The software used a proprietary database format with no import/export capabilities, creating a closed system that couldn't interface with other archaeological tools, GIS software, or analytical packages. This was identified as a critical weakness in contemporary reviews.","StratiGraf provided an ambitious integrated environment for archaeological recording rather than focusing on a single task. The hierarchical data structure (Site → Excavation → Section → Grid Square → Stratigraphic Unit → Materials) reflected genuine archaeological workflows. The software offered multilingual support (English, Spanish, Catalan) and tiered pricing for educational institutions. Its structured environment for data entry, with a three-category system (Identification, Situation, Documentation), provided a framework for comprehensive recording that could effectively manage the full recording process for small excavations.","The proprietary database format with no import/export capabilities represented a fundamental design flaw that violated basic principles of scientific data management. Users could neither migrate existing data into StratiGraf nor extract their data for use in other analytical tools. Scalability problems emerged with larger datasets, with reports of display issues and crashes when handling excavations with more than 1,000 contexts. The limited document management capabilities, restricted to linking simple image files, failed to accommodate diverse digital documentation increasingly common in archaeological practice. The Windows-only platform limitation and lack of ongoing development meant the software couldn't adapt to changing technological landscapes.","Low survivability. The software appears to have been discontinued around 2011, with no evidence of ongoing development or support. Its proprietary data format creates significant risks for long-term data accessibility, as files created in StratiGraf cannot be easily migrated to modern systems. The Windows-only implementation further limits its viability on contemporary operating systems. The commercial licensing model without an open-source transition plan means there is no path for community maintenance. Archaeological projects using StratiGraf face substantial data loss risks without significant effort to extract information from its proprietary format.","Several superior alternatives exist: ArchEd (free, focused solely on Harris Matrix generation), Harris Matrix Composer (commercial, with modern interface and better visualisation), ARK (Archaeological Recording Kit, open-source web-based system), FAIMS/Fieldmark (open-source mobile-first field recording), and Intrasis (comprehensive commercial system). Modern systems typically offer better interoperability, adherence to data standards, multi-platform support, and integration with spatial recording tools that StratiGraf lacked.",
stratigraphr,Success,,"stratigraphr is an R package for archaeological stratigraphy and chronological sequence analysis. The current version implements graph-theoretic approaches to Harris Matrix analysis, treating stratigraphic relationships as directed graphs. It provides tools for creating, validating, and visualising archaeological stratigraphies within the R statistical environment. The package enables archaeologists to represent complex stratigraphic relationships computationally, validate their logical consistency, and integrate them with chronometric dating methods. As explicitly stated by the developer, the package remains in an early stage of development with many features still missing and potential breaking changes in future versions.","stratigraphr was created by Joe Roe, a computational archaeologist currently affiliated with the Centre for the Study of Early Agricultural Societies at the University of Copenhagen. Development began around 2019-2020, with the first documented version being 0.1.0. The package has seen incremental development through versions 0.2.0 and the current 0.3.0, with the development version designated as 0.3.0.9000. Major milestones include the implementation of graph-based Harris Matrix functionality, integration with radiocarbon dating workflows through the c14 package, and the addition of an interface to OxCal via the Chronological Query Language. The package was presented at the ArchaeoFOSS 2022 conference, indicating ongoing development and community engagement efforts. Updates have continued through 2023, primarily focused on documentation improvements and maintenance rather than major feature additions.","The current version of stratigraphr (0.3.0) implements a sophisticated graph-theoretic approach to archaeological stratigraphy based on methodologies proposed by Dye & Buck (2015). At its core, the package represents stratigraphic relationships as directed acyclic graphs, with archaeological contexts as nodes and their temporal relationships as directed edges. This architecture enables the application of established graph algorithms to archaeological problems. The technical implementation relies on R's tidygraph and igraph packages for graph manipulation, with visualisation handled through ggraph, an extension of the popular ggplot2 visualisation framework. The package follows R's 'tidy data' principles, making it compatible with the tidyverse ecosystem of data science tools. For chronological modeling, stratigraphr interfaces with OxCal through the Chronological Query Language (CQL), providing a programmatic bridge to established Bayesian chronological models. Data structures include specialised classes for stratigraphic data that maintain compatibility with standard R data frames while enforcing archaeological constraints. The package employs sophisticated graph validation algorithms to detect logical inconsistencies in stratigraphic data, such as cycles that would represent impossible temporal relationships. While the architecture is robust in its theoretical foundation, the implementation remains incomplete, with features like comprehensive Harris Matrix visualisation tools and advanced chronological modeling still under development.",2025-05-31,yes,"stratigraphr qualifies as research software as it meets all essential criteria and multiple supporting criteria. It serves a research-specific purpose by enabling archaeological stratigraphic analysis and chronological sequence construction, which are fundamental research activities in archaeology. It meaningfully transforms archaeological context data into validated stratigraphic sequences and chronological models. The software aligns with established methodologies in archaeological stratigraphy, particularly the Harris Matrix approach and Bayesian chronological modeling. For supporting criteria, it integrates domain knowledge through archaeological terminology and concepts, supports multiple research lifecycle stages (analysis, interpretation), transforms data between different representations, performs analytical calculations to validate stratigraphic relationships, visualises data through stratigraphic diagrams, includes documentation focused on research applications, and supports dissemination of research data through standardised exports. These capabilities clearly position stratigraphr as specialised research software rather than general-purpose tools.",https://github.com/joeroe/stratigraphr,,https://stratigraphr.joeroe.io/,https://stratigraphr.joeroe.io/,MIT,Harrix matrix|Chronological modelling,graph theory|archaeological stratigraphy|R package|Harris Matrix|chronological modelling,2020-01-01,2023-05-01,0.3.0.9000,Active,University of Copenhagen Centre for the Study of Early Agricultural Societies|University of Bern Institute of Archaeological Sciences|XRONOS project,Joe Roe,Solo,Archaeology,Project-specific,Minimal,"Usage metrics for stratigraphr indicate limited but specialised adoption. The GitHub repository shows modest engagement with approximately 16-18 stars and only one fork. Citation tracking reveals minimal formal citations in archaeological literature, though the package has been presented at specialised conferences including ArchaeoFOSS 2022. The developer's institutional connections at the University of Copenhagen and University of Bern suggest some academic usage within these research environments. No evidence exists of widespread adoption by major archaeological projects or institutions. The small number of open issues (7) in the repository suggests either limited usage or a small but satisfied user base. Integration with the XRONOS chronometric database project may represent the most significant application of the software, though specific usage statistics are unavailable. Overall, stratigraphr appears to occupy a niche position in computational archaeology with a very small user community.",Analysis|Interpretation,research-specific,Packages and libraries,R,Windows|macOS|Linux,R,"stratigraphr offers strong interoperability with the broader archaeological computing ecosystem. The current version supports import and export of common archaeological stratigraphy file formats including LST files from legacy systems like BASP Harris, ArchEd, and Stratify. Its integration with the R environment enables connection to standard data formats (CSV, JSON) and produces visualisations in all standard graphic formats. The package integrates with OxCal through the Chronological Query Language interface, allowing seamless connection to the archaeological community's standard Bayesian chronological modeling tool. Within the R ecosystem, stratigraphr is compatible with the tidyverse suite of data manipulation tools, can leverage R's extensive geospatial capabilities through packages like sf and terra, and connects with specialised archaeological packages including c14 for radiocarbon data. Its graph-based data structures facilitate transformation between different representations of stratigraphic data, making it adaptable to various archaeological recording systems.","The current version of stratigraphr demonstrates several significant strengths. Its graph-theoretic approach to stratigraphy represents a methodological advancement over traditional Harris Matrix software, enabling sophisticated validation and analysis of stratigraphic relationships through established algorithms. Integration with the R ecosystem provides powerful statistical and visualisation capabilities that standalone archaeological software typically lacks, allowing researchers to combine stratigraphic analysis with other quantitative methods. The package's connection to chronometric dating workflows through c14 and OxCal integration creates a comprehensive analytical pipeline from excavation data to absolute chronology. From a transparency and reproducibility perspective, the open-source nature and script-based workflow ensure complete documentation of analytical steps, avoiding the 'black box' problem of proprietary software. The MIT license and GitHub availability eliminate barriers to access and modification, fostering collaborative improvement. Finally, the package's compatibility with tidy data principles makes it accessible to archaeologists already familiar with R's data science tools.","The current version of stratigraphr exhibits several significant limitations that restrict its wider adoption. Most critically, the documentation remains minimal, with incomplete function documentation and few workflow examples to guide new users. This documentation gap is particularly problematic given the complex nature of both archaeological stratigraphy and R programming. The package's explicitly acknowledged early development stage introduces stability concerns, with the developer warning of potential breaking changes in future versions. The absence of a CRAN release creates installation barriers for archaeologists without GitHub experience. The user interface relies entirely on R programming knowledge, making it inaccessible to archaeologists without coding experience, unlike GUI-based alternatives. Visualisation capabilities, while flexible through R's graphics system, lack the polished presentation of dedicated Harris Matrix software. The small user community means limited peer support, placing support burden entirely on the sole developer. Finally, testing appears limited, raising concerns about reliability for mission-critical archaeological documentation.","stratigraphr's long-term viability presents a mixed outlook. Positive factors include its institutional backing through the developer's affiliations with the University of Copenhagen and connection to the XRONOS project, which suggest ongoing academic support. The open-source model under MIT license ensures the code will remain available even if active development ceases. The software's alignment with modern computational archaeology trends and integration with established tools like OxCal position it within a growing ecosystem. However, significant concerns exist regarding sustainability. The dependency on a single developer creates a critical point of failure, with no evidence of a broader development community that could maintain the software in the developer's absence. The small user base limits community resources for support and continued development. The package's early development stage means substantial work remains before reaching stable, feature-complete status. For stratigraphr to achieve long-term sustainability, it would benefit from formalized institutional commitment, expanded documentation to enable knowledge transfer, and growth of a contributor community beyond the original developer.","stratigraphr occupies a specialised niche within archaeological software, with alternatives falling into several categories. Commercial Harris Matrix software includes Harris Matrix Composer (HMC), which offers a polished graphical interface but lacks stratigraphr's statistical integration and programmatic flexibility. Free alternatives include ArchEd and Stratify, which provide basic Harris Matrix functionality with user-friendly interfaces but limited analytical capabilities. Within the R ecosystem, no direct competitors exist for archaeological stratigraphy, though chronological modeling can be performed with packages like rcarbon. For Bayesian chronological modeling, OxCal remains the field standard, with stratigraphr providing an interface rather than replacement. General graph analysis tools like Gephi or NetworkX could theoretically be adapted for stratigraphic analysis but lack archaeological-specific functionality. The most comparable alternative may be the Python-based Harris Matrix Composer API, which offers programmatic stratigraphy creation but without R's statistical ecosystem. Each alternative represents different tradeoffs between ease of use, analytical power, and integration with other archaeological workflows.",
Survey2GIS,Success,,"Survey2GIS is a specialized open-source software tool that converts field survey data from total stations and GPS devices into GIS-ready formats. It serves as a critical bridge in archaeological documentation workflows, transforming coded coordinate files into topologically correct geometrical objects suitable for GIS analysis. The current version (1.5.2) supports various data formats, automated topological cleaning, and vertical section processing. European archaeological institutions have integrated the software into their standard workflows, with documented usage across Germany's state heritage agencies and Oxford Archaeology in the UK. Since version 1.5.0, it supports vertical section processing through Y/Z-axis switching, enabling archaeologists to document stratigraphic profiles—a feature particularly valuable for excavation documentation.","Initially developed in 2011-2012 by the Cultural Heritage Authority of Baden-Württemberg, Germany. Version 1.1 was the first public release, followed by incremental improvements. Version 1.3.3 (2017) marked transition to production use across Baden-Württemberg. Version 1.5.0 introduced significant features including on-the-fly spatial reference system transformation and vertical section support, addressing key archaeological requirements. The current stable version 1.5.2 was released in 2024. Development activity remains consistent if modest, with the GitHub repository showing the last commit on July 31, 2024. Future development includes a planned QGIS plugin as part of the NFDI4Objects (National Research Data Infrastructure) initiative, signalling continued institutional commitment to the tool's evolution.","Built primarily in C programming language with a minimalist approach prioritizing portability and flexibility. The software requires no installation, running as a portable application across Windows, Linux, and macOS platforms, though Mac users need additional dependencies. This design choice reflects its field-oriented purpose, allowing archaeologists to run the software directly from USB drives on field computers. The architecture centres on a flexible parser system using ASCII-encoded text files to describe input and output structures. This allows users to define custom parsing schemes for different survey equipment and data formats—a critical feature given the variety of total stations and GPS devices used in archaeology. The software provides both graphical user interface (GUI) and command-line interface (CLI) versions, with the CLI enabling batch processing and workflow automation. Output formats include industry-standard ESRI Shapefile (supporting both 2D and 3D geometries), GeoJSON, and KML, ensuring compatibility with major GIS platforms. The software performs automated 2D topological corrections and validation, though 3D topology functions remain limited. Multi-language support with automatic OS language detection demonstrates consideration for international usage, though documentation is primarily in German and English.",2025-05-31,yes,"Survey2GIS meets all essential criteria for research software: it has a research-specific purpose supporting archaeological fieldwork, it meaningfully transforms research data (survey coordinates into GIS formats), and aligns with recognized archaeological methodologies. It also satisfies multiple supporting criteria: it incorporates domain knowledge (archaeological survey standards), supports the research lifecycle (data processing stage), transforms data between formats, performs analytical operations (topological validation), and provides documentation focused on research applications.",https://github.com/survey2gis/survey-tools,,https://www.survey-tools.org/,https://www.survey-tools.org/,GPL-3.0,Data management|Site mapping|Spatial analysis|Geophysical survey|Data collection,Archaeological survey processing|Total station data conversion|GIS format transformation|Field data digitization|Topological correction,2012,2024-07-31,1.5.2,Active,Cultural Heritage Authority of Baden-Württemberg|German Archaeological Institute (DAI)|NFDI4Objects,Dr. Benjamin Ducke,Small (2-5),Archaeology,Project-specific,Comprehensive,"Adoption metrics show a niche but committed user base primarily in European archaeological institutions. GitHub repository shows modest statistics (3 stars, 2 forks, 1 follower) but has documented institutional adoption by German heritage agencies (Baden-Württemberg, Bavaria) and Oxford Archaeology (UK). The software has been presented at Computer Applications and Quantitative Methods in Archaeology (CAA) conferences since 2018. Academic citations cluster in European archaeological computing literature, with the core Bibby & Ducke (2017) publication serving as the primary reference point. Community support centres around an official mailing list at survey2gis@groups.io.",Processing,research-specific,Stand-alone software,C,Windows|Linux|macOS,,"Inputs include data from various total station and GPS devices through configurable parser files. Outputs in standard GIS formats including ESRI Shapefile (2D/3D), GeoJSON, and KML, ensuring compatibility with major GIS platforms. Supports automated 2D topological corrections and on-the-fly coordinate system transformations since version 1.5.0.","Survey2GIS addresses a specific workflow gap with a lightweight, portable solution requiring no complex installation. Its flexible parser system adapts to various survey equipment and project requirements. Institutional backing from German heritage agencies provides stability and legitimacy. Its open-source nature (GPL 3.0) ensures long-term accessibility and prevents vendor lock-in—critical for archaeological data preservation. Automated topological validation and cleaning addresses common data quality issues in field survey data. The program provides both GUI and command-line interfaces, enabling batch processing for larger datasets. Integration with established GIS platforms (gvSIG-CE, planned QGIS plugin) leverages existing ecosystems rather than attempting to replace them.","The small development team (essentially one lead developer with institutional support) creates sustainability risks. Limited community size restricts peer support and third-party development. Documentation, while academically rigorous, lacks user-friendly tutorial resources. Technical limitations include primarily 2D-focused topology operations and platform-specific issues like additional dependencies for macOS. The specialized nature limits broader adoption potential. The software lacks mobile integration, cloud synchronization, and real-time collaboration features found in newer alternatives. The parser system documentation, while thorough, requires significant technical understanding, reflecting the tool's positioning for users with existing GIS knowledge.","Survey2GIS demonstrates ongoing viability through continued institutional support and recent development activity. The last GitHub commit was July 31, 2024, indicating active maintenance. Integration with the NFDI4Objects national research infrastructure project provides funding stability. However, the project's dependence on a single lead developer represents a sustainability risk despite institutional backing. Future plans include a QGIS plugin, which could expand the user base while maintaining specialized functionality within a larger ecosystem. The software's production use across Baden-Württemberg validates its reliability for professional archaeological work, suggesting continued institutional support.","QGIS with QField offers broader functionality and massive community support but requires more complex setup for survey-specific workflows. Commercial alternatives like ESRI's ArcGIS Suite with Survey123 provide comprehensive solutions at substantial cost (annual licenses $100-$7,000+). gvSIG-CE represents the closest alternative, sharing development philosophy with Survey2GIS. Specialized archaeological tools like Arches and ARK serve different workflow niches. Mobile-first solutions including KoBo Toolbox and ODK provide easier field data collection but lack Survey2GIS's specific total station integration and topological processing capabilities. The planned Survey2GIS plugin for QGIS suggests recognition of QGIS's dominant position in the GIS landscape.",
Tabula,Success,,"Tabula is an open-source tool for extracting tabular data from PDF files. The current version provides a graphical user interface where users can select table regions in PDF documents and export them as CSV, TSV, JSON, or Excel files. Tabula works with text-based PDFs (not scanned documents without OCR) and offers both visual interactive selection and template-based batch extraction. Originally developed for data journalists, it enables users to 'liberate' structured data trapped in PDFs without requiring advanced technical skills. Tabula processes files locally, ensuring data privacy as nothing is uploaded to external servers.","Tabula was initially developed in late 2012 by Manuel Aristarán at La Nación DATA (Argentina) to address challenges in data journalism. In 2013, Mike Tigas (ProPublica) and Jeremy B. Merrill joined the project during their Knight-Mozilla OpenNews fellowships. The project received a $35,000 grant from the Knight Foundation Prototype Fund in April 2014 to improve the tool for journalists. A major milestone came in 2015 with the release of version 1.0.0, featuring a complete UI redesign by Jason Das. Between 2016-2018, the backend was rewritten to use tabula-java instead of tabula-extractor, achieving up to 7x faster extraction performance. Version 1.2.1, released in May 2018, is the latest stable release of the GUI application. Since 2020, the original GUI application has entered maintenance mode, though the core tabula-java library continues to receive updates. Community-developed language bindings (Python, R, Node.js) have emerged and remain actively maintained.","The current version of Tabula implements a multi-layered architecture with several key components. At its core is tabula-java, a pure Java extraction library that provides the fundamental table detection and extraction algorithms. This backend engine relies on Apache PDFBox for PDF parsing and implements the Nurminen Detection Algorithm based on Anssi Nurminen's 2013 master's thesis, which achieved 86.93% precision and 80.78% recall in the ICDAR 2013 Table Competition. The frontend consists of a web interface built with JRuby on Rails and an embedded Jetty server, providing a browser-based GUI that runs locally. Tabula offers two distinct extraction modes: Lattice Mode for tables with visible ruling lines (using the Bentley-Ottmann algorithm) and Stream Mode for tables without ruling lines (using whitespace analysis). The application requires 256MB-1024MB heap allocation and Java 11+ is recommended for optimal performance. Previous versions used a Ruby-based extraction engine (tabula-extractor), but this was replaced with the more efficient Java implementation. For programmatic access, Tabula provides both command-line capabilities via the tabula-java JAR file and various language bindings. The table extraction process involves identifying rows and columns based on either explicit lines or whitespace patterns, then constructing a data structure that preserves the relationships between cells. Memory management is a significant technical challenge, especially for large PDF files, requiring careful implementation of garbage collection and stream processing.",2025-05-31,yes,"Tabula meets all Essential Criteria as it directly supports research by extracting tables from PDFs (Research-Specific Purpose), transforms tabular data from PDFs into machine-readable formats (Research Data Engagement), and aligns with methodologies for data cleaning and preparation (Methodological Alignment). It also satisfies multiple Supporting Criteria: Data Transformation (converts PDF tables to CSV/Excel/JSON), Analytical Capabilities (recognizes table structures), Visualization Functions (provides visual selection interface), Data Collection (supports extracting data from documents), and Data Dissemination (outputs in formats ready for analysis and sharing).",https://github.com/tabulapdf/tabula,https://github.com/ropensci/tabulapdf,https://pypi.org/project/tabula-py/,https://tabula.technology/,MIT,Data management|Templates|Datasets|Public policy and civic action,pdf_extraction|data_liberation|table_recognition|document_processing|data_journalism,2013,2018-05-22,1.2.1,Maintenance-only,ProPublica|La Nación DATA|Knight Foundation|Knight-Mozilla OpenNews,Manuel Aristarán|Mike Tigas|Jeremy B. Merrill,Small (2-5),Journalism,General-purpose,Comprehensive,"Tabula has broad adoption across journalism, academic research, and civic organizations. The main GitHub repository has approximately 7,016 stars and 662 forks, while the core engine (tabula-java) has about 1,925 stars and 440 forks. The Python wrapper (tabula-py) has over 2,000 stars. Major news organizations including The New York Times, The Times of London, Foreign Policy, Chicago Tribune, and Boston Globe actively use Tabula for data journalism projects. The tool is regularly featured in data journalism workshops, courses, and textbooks. Stack Overflow shows consistent questions and answers related to Tabula usage, particularly regarding its Python and R implementations. DocumentCloud has integrated Tabula as an Add-On, extending its reach to additional journalists and researchers. While specific adoption metrics in archaeology are limited, there's evidence of use in academic research for extracting data from scientific publications and government reports.",Data Acquisition|Processing|Analysis,research-specific,Stand-alone software,Java|Ruby|JavaScript,Windows|macOS|Linux,,"Tabula offers multiple output formats (CSV, Excel, TSV, JSON) and language bindings for Python (tabula-py), R (tabulapdf), Node.js (tabula-js), and Ruby (tabula-extractor). The current version provides a command-line interface enabling scripting and automation, JSON templates for reproducible extraction, batch processing for multiple PDFs, and programmatic control through various language bindings. The tool integrates with DocumentCloud as an Add-On and can be part of larger data processing workflows. Interoperability with GIS systems is possible through exported CSV files, though this requires additional processing steps.","Tabula's strengths include its free and open-source nature under the MIT License, making it accessible without cost barriers. The current version processes all data locally, ensuring privacy as nothing leaves the user's machine. It offers cross-platform support for Windows, macOS, and Linux with an intuitive drag-and-drop visual interface for table selection. The template system enables reusable extraction patterns for batch processing similar documents. Multiple output formats (CSV, Excel, TSV, JSON) provide flexibility for downstream analysis. The extraction algorithm achieves strong accuracy (86.93% precision in academic benchmarks) and offers programmatic access through APIs and command-line tools. Various language bindings (Python, R, Node.js, Ruby) extend its utility for different workflows. Tabula has a proven track record in major newsroom investigations, demonstrating reliability in production environments.","The current version has several limitations: it works only with text-based PDFs and cannot process scanned documents without external OCR preprocessing. Complex table structures with merged cells and multiline rows present challenges for accurate extraction. There is no built-in OCR capability, requiring integration with separate tools for image-based PDFs. The Java dependency necessitates a Java Runtime Environment installation, which can be problematic for some users. Limited active development of the GUI application (though the core library remains maintained) raises long-term sustainability concerns. Auto-detection sometimes misses table boundaries, requiring manual adjustment for optimal results. Performance can be memory-intensive when processing very large PDF files. As an open-source project without commercial backing, users rely on community support for troubleshooting issues.","Tabula shows moderate long-term survivability. While the GUI application has not seen major updates since 2018 (version 1.2.1), the core extraction engine (tabula-java) continues to receive maintenance updates. The project benefits from a distributed ecosystem with language bindings maintained by different communities, particularly the popular Python (tabula-py) and R (tabulapdf) implementations which remain active. This diversified maintenance model improves resilience even as original developers have moved to other projects. The tool's widespread adoption in journalism and data analysis creates incentive for continued community support. The open-source MIT license ensures the codebase remains available even if development ceased entirely. Current version has reached feature maturity with a stable codebase that requires minimal active development. However, the lack of commercial backing or dedicated institutional funding presents a risk to long-term sustainability. Overall, Tabula's core functionality is likely to remain usable for the foreseeable future, even with minimal ongoing development.","Several alternatives to Tabula exist, each with different strengths and trade-offs. Open-source options include: Camelot (Python library with higher accuracy than Tabula but more complex setup), PDFPlumber (Python library with better handling of complex layouts but slower processing), and Excalibur (web interface to Camelot with visual selection like Tabula). Commercial alternatives offer greater accuracy with OCR capabilities: Adobe Acrobat Pro (powerful but expensive), ABBYY FineReader (excellent OCR but high cost), Amazon Textract and Google Document AI (cloud-based with per-page pricing but superior AI-powered extraction). For archaeological research specifically, Tabula offers the best combination of free access, ease of use, and privacy, though it lacks the OCR capabilities needed for scanned archaeological reports. PDFTables offers good archaeology-specific functionality but with usage limits on its free tier. For complex archaeological documents with diverse layouts, Camelot may provide better results than Tabula, while cloud services like Textract offer the highest accuracy for critical data but with privacy considerations and ongoing costs.",
TensorFlow,Success,,"TensorFlow is an open-source machine learning framework developed by Google Brain that enables researchers and developers to build and train neural network models. In archaeological contexts, it's used for artifact classification, site detection in remote sensing data, document analysis of historical texts, and pattern recognition in cultural heritage materials. The current version offers comprehensive deep learning capabilities with particular strengths in computer vision applications relevant to archaeological image analysis.","TensorFlow evolved from Google's internal DistBelief machine learning system. First released as open source in November 2015, it quickly became one of the dominant frameworks in the machine learning ecosystem. Major milestones include the release of TensorFlow 1.0 in February 2017 and the paradigm-shifting TensorFlow 2.0 in September 2019, which introduced eager execution and a more intuitive API. Google has continuously developed the framework, adding capabilities like TensorFlow.js for browser-based implementation, TensorFlow Lite for mobile devices, and TensorFlow Extended (TFX) for production pipelines. Regular releases have introduced performance improvements, new model architectures, and enhanced deployment options across platforms.","The current version of TensorFlow operates as a computational framework utilising tensors (multi-dimensional arrays) as its fundamental data structure. At its core, TensorFlow builds computational graphs that describe mathematical operations to be performed. TensorFlow 2.x employs eager execution by default, allowing operations to be evaluated immediately rather than building a static graph, making development more intuitive. The framework supports multiple levels of abstraction: low-level TensorFlow Core API provides maximum flexibility, while Keras API offers higher-level components for rapid model development. TensorFlow provides comprehensive machine learning capabilities including dense neural networks, convolutional neural networks (CNNs) for image analysis, recurrent neural networks (RNNs) for sequence data, and transformer architectures for natural language processing. The framework employs automatic differentiation for gradient calculation during model training and supports distributed computing across multiple GPUs, TPUs, or computer clusters. For archaeological applications, TensorFlow offers pre-trained computer vision models through TensorFlow Hub that can be fine-tuned on smaller archaeological datasets through transfer learning. Deployment options span from high-performance research clusters to edge devices for field applications, with TensorFlow Lite enabling mobile deployment for artifact identification in fieldwork contexts.",2025-05-31,yes,"TensorFlow fulfils all essential criteria as research software: it has a clear research-specific purpose in enabling complex data analysis and modelling, directly engages with research data through transformation and pattern recognition, and aligns with established methodologies in computational archaeology and digital humanities. It meets multiple supporting criteria including domain knowledge integration through specialised archaeological applications, research lifecycle support spanning data collection to publication, powerful analytical capabilities for pattern recognition, visualisation functions for model interpretation, and extensive documentation addressing research applications. The framework has been successfully applied in numerous archaeological research projects with documented results in peer-reviewed publications.",https://github.com/tensorflow/tensorflow,https://pypi.org/project/tensorflow/,https://pypi.org/project/tensorflow/,https://www.tensorflow.org/,Apache License 2.0,Machine learning|Spatial analysis|3D modelling|Photogrammetry|Aerial and satellite imagery|API interfaces and web scrapers|LiDAR,deep learning|neural networks|computer vision|pattern recognition|machine learning,2015-11-09,2025-03-15,2.19.0,Active,Google Brain team at Google,Martin Abadi|Ashish Agarwal|Paul Barham|Eugene Brevdo|Zhifeng Chen|Craig Citro|Greg S. Corrado|Andy Davis|Jeffrey Dean|Matthieu Devin|Sanjay Ghemawat|Ian Goodfellow|Andrew Harp|Geoffrey Irving|Michael Isard|Yangqing Jia|Rafal Jozefowicz|Lukasz Kaiser|Manjunath Kudlur|Josh Levenberg|Dandelion Mané|Rajat Monga|Sherry Moore|Derek Murray|Chris Olah|Mike Schuster|Jonathon Shlens|Benoit Steiner|Ilya Sutskever|Kunal Talwar|Paul Tucker|Vincent Vanhoucke|Vijay Vasudevan|Fernanda Viégas|Oriol Vinyals|Pete Warden|Martin Wattenberg|Martin Wicke|Yuan Yu|Xiaoqiang Zheng,Large (20+),Computer Science,General-purpose,Excellent,"TensorFlow is one of the most widely used machine learning frameworks with over 185,000 stars on GitHub, 73,000+ forks, and 3,200+ contributors. The main repository is actively maintained with regular commits and releases. The framework has been cited in tens of thousands of research papers, including numerous archaeological applications. In archaeology specifically, it powers systems like the ArchAIDE pottery recognition application (EU Horizon 2020 project), CRANE Project's computational archaeology work at the University of Toronto, and Carleton University's human remains trafficking detection project. TensorFlow has a vast ecosystem of extensions, plugins, and pre-trained models, with strong community activity on platforms like Stack Overflow (100,000+ questions tagged). While PyTorch has gained popularity in academic research (69-75% of recent ML papers), TensorFlow maintains stronger industry adoption due to its production-ready capabilities.",Data Acquisition|Processing|Analysis|Interpretation,research-specific,Packages and libraries,Python|C++|JavaScript|Java|Go|Swift,Linux|Windows|macOS|Android|iOS|Web browsers|Edge devices,Python,"TensorFlow offers extensive interoperability across data formats, systems, and workflows. For data formats, it handles images (JPG, PNG, TIFF), structured data (CSV, JSON), text, audio, video, and spatial data. It can process GIS formats through integration with libraries like geopandas and rasterio. The framework provides APIs for Python, JavaScript, C++, Java, Go, and Swift, enabling integration with diverse systems. For archaeological applications, TensorFlow can connect with QGIS and ArcGIS through Python interfaces, and supports data exchange with specialised archaeological databases. The ecosystem includes TensorFlow Extended (TFX) for building end-to-end machine learning pipelines, TensorFlow.js for browser-based deployment, TensorFlow Lite for mobile and edge devices, and TensorBoard for visualisation. Models can be exported in various formats including SavedModel, TensorFlow Lite, ONNX, and TensorFlow.js, facilitating deployment across environments. TensorFlow integrates with Jupyter notebooks, cloud platforms like Google Colab, and MLOps tools for version control and model management.","The current version of TensorFlow offers substantial advantages for archaeological applications, particularly in production-ready model deployment capabilities that translate research into usable field tools. Its pre-trained models available through TensorFlow Hub enable transfer learning on smaller archaeological datasets—critical when limited training examples exist for rare artifacts or site types. TensorFlow provides excellent scalability from mobile devices for field recording to distributed cloud computing for large-scale landscape analysis. The framework excels in computer vision applications crucial for archaeological image analysis, from artifact photography to remote sensing data. TensorFlow's comprehensive visualisation tools through TensorBoard aid in model interpretation and result communication to archaeological audiences. The robust deployment options enable creating field-ready applications that archaeologists can use without programming expertise. Google's institutional backing ensures long-term sustainability and regular updates, while extensive documentation and learning resources lower barriers to adoption. The large community provides solutions to common problems, and the framework's integration with cloud platforms offers computational resources beyond what most archaeological institutions maintain locally.","Despite its capabilities, the current version of TensorFlow presents challenges for archaeological applications. The framework has a steep learning curve requiring substantial programming knowledge, particularly compared to specialised archaeological software with graphical interfaces. TensorFlow models often operate as 'black boxes' with limited interpretability, problematic when archaeological research demands transparent reasoning. The framework requires significant computational resources, especially for training deep learning models, which may exceed budgets of many archaeological projects. Archaeological datasets are typically small and highly specialised, requiring careful data augmentation strategies that TensorFlow doesn't automatically provide. Implementation challenges include addressing potential biases in training data that might perpetuate colonial perspectives in archaeological interpretation. For archaeologists without computer science backgrounds, the technical complexity creates barriers to adoption. The framework prioritises performance over interpretability, which conflicts with archaeological needs for understanding model decisions. While transfer learning helps, domain adaptation between modern training datasets and archaeological materials remains challenging. Finally, TensorFlow's production focus sometimes sacrifices the experimental flexibility needed in novel archaeological applications.","TensorFlow demonstrates strong long-term viability through multiple factors. Google's deep institutional commitment is evidenced by integration into core products and consistent development since 2015. The framework has transitioned from an internal Google project to a global standard with over 185,000 GitHub stars and 3,200+ contributors worldwide. Enterprise support through TensorFlow Enterprise ensures commercial sustainability with extended version support. The extensive educational adoption in universities and online platforms continuously expands the user base. TensorFlow's mature ecosystem includes deployment options across cloud, edge, and mobile platforms, making it versatile for diverse archaeological applications. Regular releases maintain currency with hardware advances and research developments. The framework's large community provides continued troubleshooting support and extensions. While competition from PyTorch exists particularly in research settings, TensorFlow maintains advantages in production deployment critical for sustainable archaeological tools. These factors position TensorFlow as a reliable platform for long-term archaeological research projects, though users should monitor the PyTorch/TensorFlow landscape as it evolves.","Several alternatives to TensorFlow exist for archaeological applications, each with distinct advantages. PyTorch offers a more intuitive API and dynamic computational graph preferred by researchers, with 69-75% adoption in recent machine learning papers, making it potentially better suited for experimental archaeological methods. PyTorch's easier debugging capabilities benefit the iterative development common in archaeological research. For statistical analysis, R-based solutions including specialised archaeological packages (tesselle, archdata, archeoViz, oxcAAR) provide superior capabilities for traditional archaeological statistics with lower barriers to entry. Scikit-learn offers simpler machine learning implementations without deep learning complexity, suitable for basic clustering and classification tasks common in archaeological typology. KNIME and Orange provide visual programming interfaces that may better serve archaeologists without extensive coding experience. Specialised archaeological software like Arches (heritage inventory) and field recording systems offer immediate deployment without programming requirements. QGIS with Python plugins provides spatial analysis capabilities with more archaeological specificity. The optimal choice depends on project requirements, team expertise, and whether research flexibility or production deployment is prioritised.",
TimeMap,Success,,"TimeMap is a temporal Geographic Information System (GIS) specifically designed for visualising and analysing time-based archaeological and historical data. The software enables researchers to map and animate historical changes through time, filter spatial data by time periods, and integrate distributed datasets. The current version consists of three main components: TMWin (a Windows desktop application for metadata development and map building), TMJava (a Java-based web mapping applet with temporal filtering capabilities), and supporting tools including TMView, TMEdit, and TMGeoReg for viewing, editing, and georeferencing respectively. TimeMap was pioneering in its approach to visualising the temporal dimension of archaeological and historical data through interactive maps.","TimeMap was developed at the University of Sydney's Archaeological Computing Laboratory from 1995-2007. The project officially launched in 1996, with initial development focusing on a Windows mapping tool (TMWin). In 1997, the project became associated with the Electronic Cultural Atlas Initiative (ECAI) at UC Berkeley, which provided significant funding between 1998-2005. The development of TMJava began in 2001 to enable web-based deployment. From 2000-2002, the project received additional funding through an Australian Research Council SPIRT grant, which supported applications like the Sydney TimeMap kiosk at the Museum of Sydney. By 2005, the software was progressively released as open-source on SourceForge. The last documented software update occurred in October 2007, with final documentation updates in August 2010. The original timemap.net website became inactive around 2016, marking the effective end of the project.","TimeMap employs a client-server architecture with a Java servlet container backend that supports multiple deployment scenarios including web applications, CD-ROMs, and museum kiosk installations. The current version (TMWin2.2.1.19_TMJava2.2.25) comprises two main technical components: a Windows-based desktop application (TMWin) and a Java-based web component (TMJava). The system utilises an XML-based metadata framework for data exchange and supports connectivity to multiple database systems through JDBC, including MySQL, PostgreSQL, Oracle, and Microsoft SQL Server, though notably lacks support for PostGIS spatial extensions. For data storage and manipulation, TimeMap can process multiple file formats including shapefiles, CSV files, DBF files, MIF files, JPG images, and Zoomify files. The temporal filtering mechanism, TimeMap's core innovation, implements a generalised date comparison system that operates on user-defined temporal attributes, enabling the filtering and animation of spatial data based on temporal ranges. System requirements include Windows 95/NT/98/2000/XP (for TMWin), Java 1.5.x or later (for TMJava), and Apache Tomcat for server deployment. The technical architecture reflects mid-2000s web technology standards, particularly relying on Java applets for web delivery—a technology that has since been deprecated in modern browsers, significantly limiting the software's current usability. TimeMap implements a simplified temporal GIS model that prioritises accessibility for humanities researchers over the complex spatio-temporal models found in professional GIS systems.",2025-05-31,yes,"TimeMap satisfies all essential criteria for research software classification. It was specifically designed for archaeological and historical research purposes, directly engages with research data through temporal-spatial analysis, and aligns with established methodologies in archaeological mapping and historical geography. It meets multiple supporting criteria including domain knowledge integration (archaeological and historical terminology), research lifecycle support (data analysis and visualisation), data transformation capabilities (conversion between temporal-spatial formats), analytical functions (historical change analysis), and visualisation capabilities (temporal map animation). The software was explicitly developed to advance research methods in archaeology and history, with documented applications in multiple research projects.",https://sourceforge.net/projects/timemap/,,https://www.sydney.edu.au/arts/timemap/,https://www.sydney.edu.au/arts/timemap/,GNU General Public License version 2.0,Spatial analysis|Site mapping|Data management|Data collection|Diagrams and visualizations,temporal GIS|archaeological mapping|historical visualisation|spatio-temporal data|legacy software,1996,2007-10-02,TMWin2.2.1.19_TMJava2.2.25,Abandoned,University of Sydney Archaeological Computing Laboratory (later Arts eResearch),Ian Johnson|Andrew Wilson,Small (2-5),Archaeology and History,General-purpose,Basic,"TimeMap has minimal current usage, with only 155 total downloads recorded on SourceForge and limited recent academic citations. During its active period (1995-2007), the software was implemented in several notable projects including the Sydney TimeMap kiosk at the Museum of Sydney (2000), which attracted approximately 3% of museum visitors, the Macquarie Atlas of Indigenous Australia (2007), and UNHCR Liberia refugee mapping (2006). The software received academic attention primarily in the early 2000s to 2010s, but has no active user community or support forums currently. Its technological obsolescence (particularly reliance on deprecated Java applets) has effectively eliminated its contemporary user base.",Data Acquisition|Analysis|Interpretation|Visualization,research-specific,Stand-alone software,Java|Windows,Windows|Linux|Mac,,"TimeMap supports multiple data formats including shapefiles, CSV, DBF, MIF, JPG images, and Zoomify files. It provides OGC WMS server compatibility, JDBC database connectivity for major database systems (MySQL, PostgreSQL, Oracle, SQL Server), and XML-based metadata exchange. The software can integrate with MapObjects Run Time 2.1 but lacks modern API integrations or web service capabilities. Data export options include static maps and animations, though limited by outdated technology standards.","TimeMap was historically significant as a pioneer in temporal GIS for humanities research, being one of the first systems to implement generic time filtering for archaeological and historical data. The software offered an accessible approach to spatio-temporal visualisation that did not require extensive technical expertise, making it particularly valuable for humanities researchers without GIS training. During its active period, it benefited from strong institutional backing through the University of Sydney and partnerships with the Electronic Cultural Atlas Initiative. The system successfully demonstrated the value of integrating temporal and spatial dimensions for archaeological data presentation, particularly in museum and educational contexts. Its ability to create animated maps showing historical changes over time was innovative for its era and influenced subsequent developments in digital humanities mapping.","TimeMap suffers from critical technological obsolescence, with no development updates since 2007 and reliance on Java applet technology that has been deprecated and blocked by modern browsers. The software lacks security updates, making it potentially vulnerable to exploits. Documentation is substantially outdated, with the latest updates from 2010 and noted as outdated even in 2004. The system offers limited analytical capabilities compared to modern GIS solutions, focusing primarily on visualisation rather than spatial analysis. The absence of an active developer community or institutional support means there are no resources for troubleshooting, bug fixes, or adaptation to contemporary computing environments. User interface designs reflect early 2000s standards and lack modern usability features. Installation on current operating systems is problematic, with compatibility issues affecting core functionality.","TimeMap has poor long-term viability and cannot be recommended for current or future projects. The software has received no maintenance or updates for over 18 years, with the last documented code change in October 2007. Its core web technology (Java applets) has been deprecated and is no longer supported by modern browsers, rendering the web component effectively unusable. The original institutional support through the University of Sydney's Archaeological Computing Laboratory has transitioned to other projects, notably Heurist, which was developed by the same creator as a more modern replacement. The extremely low download metrics (155 total) and absence of an active user community further indicate abandonment. The original timemap.net website is no longer operational, and documentation is severely outdated. These factors collectively demonstrate that TimeMap should be considered a legacy system with historical significance but no practical contemporary application.","Heurist (Direct Successor): Developed by the same creator (Dr. Ian Johnson), actively maintained since 2005, designed specifically for humanities research data with modern web interfaces. QGIS (Open Source Standard): Features the TimeManager plugin for temporal mapping with active development and extensive community support. ArcGIS (Commercial Leader): Offers comprehensive temporal GIS capabilities with professional support, though at significant cost. Web-based Alternatives: TimelineJS and StoryMapJS for narrative mapping, Leaflet with temporal plugins for custom implementations. Archaeological-Specific Tools: FAIMS for mobile data collection, ARK (Archaeological Recording Kit) for web-based archaeological data management.",
TrueSpace,Success,,"TrueSpace was a 3D modeling and animation software developed by Caligari Corporation from 1994 until 2009, when Microsoft discontinued it after acquisition. The software offered an accessible interface with professional-level features including NURBS modeling, subdivision surfaces, raytraced rendering, and animation capabilities. Despite being theoretically suitable for archaeological visualisation and heritage reconstruction, comprehensive research indicates no documented usage in archaeological contexts. The software provided an affordable alternative to high-end packages like 3ds Max and Maya during a period when 3D visualisation was beginning to be adopted in archaeology and heritage studies. While the official product is discontinued, TrueSpace remains available as freeware and maintains a dedicated user community that continues to release unofficial updates.","TrueSpace originated from Octree Software's early work on the Amiga platform. Caligari Corporation was founded in 1985 by Roman Ormandy, a Czechoslovakian immigrant inspired by SIGGRAPH 1985. The first Windows version (TrueSpace 1.0) was released in 1994. The software evolved through 16 major versions, with versions 4-6 achieving significant commercial success among hobbyists and semi-professionals. Microsoft acquired Caligari Corporation on February 7, 2008, intending to integrate TrueSpace's collaborative 3D capabilities into their Virtual Earth platform. However, Microsoft discontinued the product on May 21, 2009, just 15 months after acquisition. The final official version was TrueSpace 7.61 'Rosetta Beta', which had introduced real-time collaborative 3D authoring. After official discontinuation, Microsoft released the software as freeware. An active community based around United3dArtists continues to support the software, releasing unofficial updates and patches. The most recent community update as of mid-2024 is 'TrueSpace 7.61 Beta 8 Unofficial Update Version 10', demonstrating remarkable community resilience for a product discontinued 15 years ago.","The current version of TrueSpace (7.x) employed a dual-engine architecture that combined the traditional 'Model Side' interface with an innovative 'Workspace Side' for real-time collaboration. The core engine was written in C/C++ and featured an extensive plugin system called TSX (TrueSpace eXtension) which supported development in Delphi and C++. The software included multiple integrated scripting languages: Python 1.5.2, VBScript, and JScript. TrueSpace implemented multiple rendering engines: Lightworks for professional raytracing with HDRI support and radiosity, VRay integration (versions 1.52-1.54), VirtualLight for global illumination, and a real-time DirectX preview. The software's distinctive feature was its 3D widget interface which provided intuitive spatial manipulation through direct interaction with 3D elements rather than traditional 2D controls. Modeling capabilities included NURBS surfaces, subdivision modeling, Boolean operations, metaballs, skeletal animation, and physics simulation. The architecture supported a hybrid workflow that combined polygon and NURBS modeling within a single interface. TrueSpace pioneered real-time collaborative 3D editing in version 7.6, allowing multiple users to work simultaneously in a shared 3D workspace. This feature was revolutionary for its time but implementation was cut short by Microsoft's discontinuation. Technical limitations included the absence of point cloud support, limited CAD integration, lack of photogrammetry workflows, and a 32-bit architecture that restricts memory usage on modern systems. The software supported standard 3D formats (3DS, OBJ, DXF, LWO, FBX) but had incomplete implementation of DXF that limited architectural model import. Native file formats included .cob and .scn (pre-7.0) and .RsScn, .RsObj, .RsMat (7.x versions).",2025-05-31,no,"TrueSpace does not qualify as research software for archaeology despite its theoretical potential. The evaluation reveals: (1) No documented usage in archaeological contexts can be found in academic literature, archaeological publications, or community forums, indicating a complete lack of adoption within the research community. (2) The software lacks critical research-specific capabilities required for archaeological work including point cloud processing, GIS integration, photogrammetry workflows, and measurement tools essential for scientific documentation. (3) While TrueSpace could theoretically transform research materials through 3D modeling, no evidence exists of it being used for this purpose in archaeological contexts. (4) The software fails to meet supporting criteria: it lacks domain knowledge integration for archaeology, has no specific research lifecycle support for archaeological documentation, and contains no specialized analytical capabilities for archaeological data. TrueSpace appears to have been entirely bypassed by the archaeological community in favor of CAD software, specialized photogrammetry tools, and later Blender and commercial packages with better integration into archaeological workflows.",,,http://truespace3d.free.fr/,http://truespace3d.free.fr/,Freeware (originally commercial software),3D modelling|Virtual reality,discontinued-software|3d-modeling|heritage-visualization|Microsoft-acquisition|community-maintained,1994,2009-05-21,7.61 'Rosetta Beta',Abandoned,"Originally Caligari Corporation, acquired by Microsoft in 2008, discontinued in 2009. Currently maintained only by user community.",Roman Ormandy (founder)|Caligari Corporation development team,Medium (6-20),Computer Graphics,General-purpose,Excellent,"TrueSpace achieved moderate commercial success with 'worldwide' adoption mentioned in documentation, primarily among hobbyists, educators, and semi-professionals. The software was particularly popular in educational settings and among independent 3D artists. GitHub metrics are not available as the software predates GitHub's prominence. No documented citations exist for archaeological applications despite extensive research. The current community is centered around United3dArtists forum with approximately 500 active users based on forum statistics. The software was used in educational contexts including high school and university 3D modeling courses during the early 2000s. Usage has declined dramatically since discontinuation, with a small but dedicated community maintaining the software primarily for hobby and artistic projects. No evidence exists of institutional adoption in archaeological or heritage organizations.",Analysis,mass-market,Stand-alone software,C/C++|Python 1.5.2|VBScript|JScript,Windows (95 through 11),,"TrueSpace supported standard 3D formats including 3DS, OBJ, DXF, LWO, and FBX for import/export. The native file formats were .cob and .scn for versions prior to 7.0, and .RsScn, .RsObj, .RsMat for version 7.x. The software could export to VRML for early web-based 3D visualization and STL for 3D printing. Animation export was supported to AVI format. Critical limitations for archaeological workflows included no support for LAS/LAZ point cloud formats, incomplete DXF implementation missing essential CAD elements, absence of photogrammetric data formats (no support for SfM outputs), and no GIS data integration. Third-party tools like Okino PolyTrans can convert legacy TrueSpace files to modern formats. Current versions can read older TrueSpace formats but version 7.x introduced new format specifications not backward compatible with earlier versions.","TrueSpace offered several advantages that could theoretically benefit archaeological visualization: (1) Free availability after Microsoft's discontinuation removed budget barriers for archaeological projects with limited funding. (2) The intuitive 3D widget interface provided a lower learning curve compared to complex CAD programs, potentially making 3D modeling more accessible to archaeologists without technical backgrounds. (3) High-quality rendering capabilities including global illumination and HDRI lighting enabled photorealistic visualization of reconstructed sites and artifacts. (4) The software featured adequate precision for basic site reconstruction and artifact modeling, with support for real-world scale and measurements. (5) Multiple rendering engines supported different visualization needs from quick previews to publication-quality images. (6) Extensive documentation and tutorials remained available even after discontinuation, facilitating learning for new users. (7) The collaborative features pioneered real-time multi-user 3D workspaces years before cloud-based solutions became standard, potentially enabling distributed archaeological teams to work on reconstructions simultaneously.","TrueSpace suffered from significant limitations preventing archaeological adoption: (1) Discontinued status with no official development or support created unacceptable sustainability risks for research projects. (2) Complete absence of point cloud handling capabilities made the software incompatible with modern archaeological documentation techniques using laser scanning or photogrammetry. (3) Limited GIS integration prevented meaningful connection between 3D models and spatial data essential for archaeological context. (4) Inadequate CAD import functionality with incomplete DXF support hindered architectural reconstruction workflows. (5) No photogrammetry support or Structure-from-Motion integration isolated the software from contemporary archaeological field methods. (6) Lack of scientific measurement tools and analytical functions made the software unsuitable for dimensional analysis and scientific documentation. (7) The 32-bit architecture limited memory usage to approximately 2GB, insufficient for processing high-resolution archaeological models and textures. (8) No specialized archaeological templates, workflows or domain-specific features meant archaeologists would need to develop custom solutions for field-specific needs. (9) The absence of archaeological user communities or peer support networks left potential archaeological users without discipline-specific resources or examples.","TrueSpace has poor long-term viability for archaeological applications despite continued community support. The software has been officially discontinued since 2009 with no commercial backing, relegating it to legacy status. The active community (primarily at United3dArtists) continues to release unofficial updates, demonstrating remarkable resilience, but this represents a high-risk dependency for any research project. The 32-bit architecture presents inherent limitations that cannot be overcome without source code access, which remains proprietary despite the software's free availability. File format compatibility with modern systems is maintained primarily through industry-standard exports (OBJ, 3DS) rather than native formats. The complete absence of archaeological adoption during TrueSpace's active commercial period suggests fundamental misalignment with disciplinary needs that persists today. Technical limitations including lack of point cloud support, photogrammetry integration, and scientific measurement tools cannot be addressed without official development. Any archaeological project adopting TrueSpace in 2025 would face immediate obsolescence risks, workflow isolation, and compatibility challenges with no institutional support structure. The software may serve limited educational purposes for basic 3D concepts but cannot support contemporary archaeological research methodologies.","Blender (free, open-source) offers comprehensive 3D capabilities with active development, GIS integration add-ons, and strong archaeological community support. Agisoft Metashape ($179-$3,499) provides specialized archaeological photogrammetry with purpose-built workflows for heritage documentation. CloudCompare and MeshLab (both free) deliver essential point cloud processing capabilities TrueSpace lacked. For funded projects, 3ds Max or Maya ($1,785/year) offer professional capabilities with archaeological plugins. SketchUp ($0-700/year) provides accessible architectural modeling for simpler reconstructions. Current archaeological best practices combine multiple specialized tools rather than relying on integrated packages: photogrammetric capture (Metashape), point cloud processing (CloudCompare), 3D reconstruction (Blender/3ds Max), and web-based dissemination, a workflow that exceeds TrueSpace's capabilities.","REJECTED: Claude Tool-status=no (no arch adoption), user confirmed TOOL (discovery/evidence found use cases)"
vegan,Success,,"The vegan package is a comprehensive R library for multivariate analysis of ecological communities, offering extensive tools for ordination, diversity analysis, and dissimilarity calculations. The current version (2.6-10) provides researchers with over 200 functions for analysing complex ecological datasets, enabling the exploration of relationships between species composition and environmental variables. While primarily developed for ecological research, the package's multivariate statistical framework has untapped potential for archaeological applications, particularly in artefact assemblage analysis, spatial patterning of finds, and seriation studies. The package supports both descriptive analyses through ordination techniques (NMDS, CCA, RDA) and hypothesis testing via permutation methods (PERMANOVA).","Vegan was first released in September 2001 (version 1.0-1) by Jari Oksanen at the University of Helsinki. The package evolved from earlier FORTRAN code for ecological analysis, bringing these methods to the R platform. Major version 2.0 was released in 2008, introducing significant API improvements and expanding functionality. Throughout its 23-year history, vegan has maintained a steady development cycle with regular updates, growing from basic ordination methods to a comprehensive ecosystem analysis suite. Version 2.3 (2015) added distance-based redundancy analysis and improved permutation testing. Version 2.5 (2018) introduced tidyverse compatibility and enhanced visualization. The 2.6.x series (2020-2024) replaced deprecated functions with improved implementations (e.g., adonis() with adonis2() for PERMANOVA) and added modern interfaces. The project has expanded from a single developer to a collaborative international team while maintaining consistent leadership under Oksanen, who is now Professor Emeritus but remains active in development.","The current version of vegan employs a sophisticated tri-language architecture combining R for user interface and high-level functions, C for computational efficiency in core algorithms, and FORTRAN for legacy numerical routines. This hybrid approach enables the package to handle datasets ranging from dozens to thousands of species and sites while maintaining reasonable performance. The architecture follows S3 object-oriented design patterns, with specialized result objects (cca, rda, capscale, dbrda) having consistent accessor methods and plotting capabilities. The package's statistical implementation includes over 40 dissimilarity measures and comprehensive ordination methods that use advanced matrix algebra techniques. For example, the NMDS implementation employs multiple random starts with stress minimization algorithms, where stress values below 0.05 indicate excellent representation of community structure. Constrained ordination methods like CCA (Canonical Correspondence Analysis) use weighted linear models with iterative averaging algorithms, while permutation tests implement sophisticated restricted permutation designs through the companion 'permute' package. Internally, the package shares code through helper functions like ordConstrained() that ensure consistent behaviour across methods. Computationally intensive operations leverage parallelization through the parallel package when available. Dependencies are kept minimal with imports from MASS, mgcv, and lattice packages. Memory management is carefully controlled in C/FORTRAN components, with explicit handling of working memory to prevent leaks during long-running analyses. The diversity analysis functions implement both traditional indices (Shannon, Simpson) and newer approaches like Hill numbers with efficient algorithms for large datasets.",2025-05-31,yes,"Vegan qualifies as a research software tool by meeting all essential criteria and multiple supporting criteria. It has a clear research-specific purpose in analysing ecological community data, directly engages with research data through meaningful transformation and analysis, and aligns with established methodologies in multivariate statistics. It integrates domain knowledge through ecological terminology and concepts, supports multiple research lifecycle stages (analysis, interpretation), offers extensive data transformation capabilities for preparing community datasets, provides sophisticated analytical functions including ordination and diversity analysis, visualizes data through specialized plotting functions, includes comprehensive documentation focused on research applications, and enables dissemination of research data through standardized outputs and publication-ready visualizations.",https://github.com/vegandevs/vegan,https://cran.r-project.org/web/packages/vegan/index.html,https://vegandevs.github.io/vegan/,https://vegandevs.github.io/vegan/,GPL-2,Statistical analysis|Multivariate analysis|Data management,multivariate statistics|ordination methods|ecological analysis|community data|diversity indices,2001-09-01,2024-08-15,2.6-10,Active,University of Helsinki|Aarhus University|Université de Montréal,Jari Oksanen|Gavin L. Simpson|F. Guillaume Blanchet|Pierre Legendre|Peter R. Minchin|R. B. O'Hara|Marti J. Anderson|Etienne Laliberté|Helene H. Wagner,Medium (6-20),Ecology,General-purpose,Excellent,"Vegan demonstrates strong adoption with 463 Stack Overflow questions and active discussions across R-help forums and GitHub issues. While specific CRAN download statistics weren't accessible, the package's GitHub repository shows 482 stars and 100 forks, indicating substantial community interest. Its widespread citation in ecological literature (lead author Jari Oksanen's work has over 79,000 citations) confirms its standard tool status in numerical ecology. Academic adoption is particularly strong, with the package featured prominently in the textbook 'Numerical Ecology with R' and used in university curricula worldwide. Regular workshops at major conferences like the Ecological Society of America meetings provide hands-on training. The geographic distribution shows strong presence in Europe and North America with growing adoption in other regions. The core functions are regularly referenced in ecology papers, with the ordination methods and diversity analyses being the most commonly used components. Despite this high adoption in ecology, archaeological applications remain limited (<5% of use cases) despite methodological applicability to artefact and assemblage analysis.",Analysis|Interpretation,research-specific,Packages and libraries,R|C|FORTRAN,Windows|macOS|Linux,R,"Vegan offers excellent interoperability with standard R data formats including data frames and matrices for species composition and environmental variables. The current version provides strong integration with the tidyverse ecosystem through compatible data structures and the supplementary ggvegan package for modern visualization. Results can be exported to common formats like CSV and visualized through standard plotting functions or specialized visualization tools like vegan3d. Diversity calculations support multiple approaches with conversion functions between indices. The package reads standard community ecology data formats and can import from various sources through R's data import facilities. For dissimilarity calculations, the package supports 40+ measures with conversion functions. The ordination functions work seamlessly with other packages like ade4 and labdsv, while phylogenetic integration is available through picante. Environmental data can be linked directly to community data through constrained ordination. Current version includes enhanced capabilities for modern workflows including direct connections to spatial analysis packages.","Vegan's greatest strength is its comprehensive functionality that encompasses complete ordination suites, extensive diversity tools, and robust permutation-based statistics in a single coherent package. The implementation quality is exceptional with well-tested algorithms that have been refined over 23 years of development. Documentation quality ranks among R's best with detailed vignettes, thoroughly explained functions, and educational resources including textbook integration and online tutorials. Strong theoretical foundations in multivariate statistics ensure valid analytical methods with appropriate assumptions and interpretations. The package has excellent reproducibility features with consistent random number seeding and version stability. The extensive user community provides support through forums, publications, and workshops, creating a rich ecosystem of learning resources. Method consistency with established ecological literature enables direct implementation of published techniques, while integration with other packages extends functionality. The development team includes leading figures in ecological statistics ensuring methodological rigour. For transparency, all algorithms are fully documented with citations to original statistical literature, making the package's methods traceable and verifiable.","The primary weakness of vegan is its steep learning curve requiring substantial statistical background knowledge, with terminology like 'sites' and 'species' potentially confusing non-ecologists including archaeologists. The package's ecological focus creates barriers to cross-disciplinary adoption despite methodological relevance to fields like archaeology. Performance limitations emerge with very large datasets, particularly for memory-intensive operations involving distance matrices, while some functions can become computational bottlenecks with thousands of sites or species. The basic plotting functions produce functional but aesthetically limited graphics requiring additional packages for publication-quality visualizations. Some advanced features lack comprehensive documentation with examples occasionally too academic for practitioners. The command-based interface without GUI options creates accessibility barriers for non-programmers. Dependency on the lead maintainer who has reached emeritus status raises succession planning concerns. Limited modernization of older functions creates inconsistent API styles across the package. The traditional R approach lacks modern tidyverse-style syntax in core functions, though newer additions are addressing this gap. For archaeological applications specifically, the package lacks domain-specific examples that would help demonstrate relevance to material culture analysis.","The vegan package demonstrates mixed long-term viability indicators. Strong positive factors include 23 years of sustained development, extensive user dependency in the ecological research community, mature optimized codebase, and consistent CRAN compliance across platforms. The broad contributor base of 30+ individuals suggests community investment that extends beyond the core team. However, significant sustainability concerns emerge from lead maintainer Jari Oksanen's emeritus status without explicit succession planning. While Gavin Simpson appears positioned as a potential successor, formal transition planning remains unclear. The absence of dedicated funding sources beyond implied academic institutional support raises questions about long-term resources. Despite collaborative development, heavy dependence on key developers creates bus factor risks. Viability predictions suggest very stable conditions for the next 1-3 years with the current team maintaining development, stable prospects for 3-7 years if succession planning gets implemented, but potential risk beyond 7 years without institutional funding commitments or governance transition. The package's essential status in ecology provides strong motivation for continuity, though formalizing support structures would enhance confidence in long-term viability.","The ade4 package offers broader multivariate analysis capabilities with a different philosophical approach but smaller user base and steeper learning curve. BiodiversityR provides a GUI wrapper making vegan's functionality accessible to non-programmers but with limited customization. The labdsv package offers specialized vegetation analysis functions often used alongside vegan rather than as a replacement. The picante package extends functionality specifically for phylogenetic community ecology, complementing rather than replacing vegan. For archaeological applications specifically, the ca package provides focused correspondence analysis without vegan's broader ecological framework. Commercial alternatives include CANOCO (Canonical Community Ordination) and PC-ORD which offer GUI interfaces but lack R's programmatic flexibility and integration capabilities. The PAST software provides free multivariate analysis with archaeological examples but less statistical rigour. Python alternatives like scikit-bio implement some similar methods but lack vegan's comprehensive ecological framework and methodological depth. Overall, vegan maintains dominant position as the standard for ecological multivariate analysis with alternatives occupying complementary niches rather than providing complete replacements.",
VirtualArch,Success,,"VirtualArch was an EU-funded research project (2017-2020) that developed multiple virtual and augmented reality applications for visualising hidden archaeological heritage across Central Europe. The project focused on making underground, underwater, and otherwise inaccessible archaeological sites visible to the public through digital visualisation technologies. It was not developed as a standalone software tool but rather as a series of site-specific digital applications implemented at eight pilot locations, including Bronze Age salt mines in Austria, medieval silver mines in Germany, and Roman harbour remains in Croatia. The project sought to enhance heritage conservation, education, and tourism through innovative visualisation approaches.","VirtualArch was conceived and funded as an Interreg Central Europe initiative under the European Regional Development Fund, running from July 2017 to June 2020. The project was led by the Archaeological Heritage Office of Saxony (Germany) in partnership with 10 full partner institutions and 17 associate organisations across 8 Central European countries. The project operated with a total budget of €2,093,771.25, with €1,730,429.76 from EU funding sources. Development proceeded through coordinated transnational activities with regular partner meetings and milestone deliverables. The project officially launched with a kickoff meeting in 2017, developed and implemented pilot applications at eight archaeological sites between 2018-2019, and concluded with final reports and an international conference in 2020. No development activities continued beyond the project's official end date of 30 June 2020.","The technical implementation of VirtualArch varied across the eight pilot sites, as each location required customised solutions appropriate to its specific archaeological context. The project did not develop a unified software platform but instead created multiple applications using existing tools and technologies. For underground mining sites in Germany and Austria, the team employed 3D laser scanning combined with photogrammetry to document spaces, creating VR experiences viewable through HTC Vive headsets and mobile AR applications like 'Medieval MinesAR' for Android. Urban archaeological sites in Slovakia and the Czech Republic utilised LiDAR scanning for landscape documentation, with progressive web applications providing offline functionality through service workers. Underwater archaeological sites in Poland and Croatia required specialised approaches using multi-beam sonar surveys to map submerged structures. The current version of these applications (as of project completion in 2020) is best understood as a collection of site-specific implementations rather than a coherent software platform. Development relied on standard industry tools including Unity for VR/AR development, GIS platforms for spatial data management, and web technologies for progressive web applications. The project emphasised visual fidelity and educational value over software sustainability, with limited attention to version control, testing procedures, or technical documentation beyond academic papers. This approach reflects the project-oriented nature of the initiative, prioritising immediate public engagement over long-term software sustainability.",2025-05-31,no,"VirtualArch fails to meet essential criteria for research software classification. While it supports research activities (criterion 1) and engages with research data through 3D visualisation (criterion 2), it fundamentally lacks the characteristics of sustainable, distributable research software. The project produced site-specific applications rather than reusable software tools, with no provisions for long-term maintenance, no public code repositories, and no standardised citation mechanisms. The absence of version control, systematic testing procedures, or technical documentation beyond academic papers violates basic software engineering practices expected of research software. Furthermore, the fixed project end date (June 2020) meant no ongoing development community formed, ensuring technical obsolescence as platforms evolve. These fundamental limitations prevent VirtualArch from qualifying as research software despite its valuable contributions to archaeological visualisation research.",,,https://intarch.ac.uk/journal/issue54/2/,https://intarch.ac.uk/journal/issue54/2/,Unknown,Virtual reality|Augmented reality|3D modelling|Photogrammetry|Site mapping|Data management|Visualization|Public archaeology,archaeological visualisation|transnational heritage project|non-sustainable software|VR/AR applications|buried heritage interpretation,2017-07-01,2020-06-30,,Deprecated,"Archaeological Heritage Office of Saxony (Germany), Fondazione Bruno Kessler (Italy), University of Toruń (Poland), Czech Academy of Sciences Institute of Archaeology, City of Nitra (Slovakia), Autonomous Province of Trento (Italy), Administration of the Republic of Slovenia for Civil Protection and Disaster Relief, Archaeological Museum of Zagreb (Croatia), NÖ Landesmuseum (Austria), Institute of Archaeology Rzeszów (Poland)","Jan Mařík, Jiří Unger, Christiane Hemker, Christoph Lobinger, Fabio Remondino",Medium (6-20),Archaeology,Project-specific,Minimal,"VirtualArch received €2.1 million in EU funding and involved 10 partner institutions across 8 countries. The project produced visualisations for eight archaeological sites, with documented visitor engagement at museum installations. The primary publication in Internet Archaeology (volume 54, 2020) has received academic citations, though specific usage metrics for the digital applications are not publicly available. The project received recognition through the AVICOM award for the TIME MACHINE platform developed by project partners. No download statistics, user numbers, or community metrics exist as the applications were primarily deployed as on-site installations rather than distributable software. There is no evidence of continued use or development beyond the project end date in 2020, with no active user or developer communities.",Interpretation|Publication,research-specific,Stand-alone software,Unity|JavaScript|HTML5|CSS,Android|iOS|HTC Vive|Web browsers,,"The project produced multiple data formats including 3D models (OBJ, FBX), GIS data (Shapefiles, GeoTIFF), and web-based visualisations (HTML/JS/CSS). However, no standardised APIs or data exchange protocols were developed, limiting interoperability between components. Each site implementation functioned as a closed system with minimal provisions for data exchange with external systems. The web applications followed basic web standards but lacked documented APIs for external access.","VirtualArch demonstrated several innovative strengths in archaeological visualisation. The transnational approach fostered knowledge exchange across Central Europe, creating a network of institutions sharing best practices in digital heritage. Unlike many theoretical VR projects, VirtualArch emphasised practical implementation, producing working applications deployed at real heritage sites. The integration of multiple VR/AR technologies showed technical ambition, from immersive projections to augmented print catalogues. The project successfully addressed a genuine gap in archaeological communication, bringing normally invisible heritage (underground, underwater) to life for modern audiences. The interdisciplinary team combining archaeologists, computer scientists, and heritage managers enabled holistic approaches to complex visualisation challenges.","VirtualArch suffered from fundamental limitations as research software. The project-based structure with a fixed end date meant no provisions for long-term software maintenance or community development. Unlike sustainable archaeological software tools, VirtualArch produced no standalone software packages for distribution, no public code repositories, and no standardised citation mechanisms for software outputs. The absence of version control, systematic testing procedures, or technical documentation beyond academic papers violated basic software engineering practices. Interoperability was limited, with no standardised APIs or data exchange formats. The lack of open-source licensing or clear intellectual property frameworks prevented reuse of components by other researchers. These structural issues ensured technical obsolescence once the project funding ended.","VirtualArch has poor long-term survivability. The absence of ongoing development communities, public code repositories, or institutional commitments beyond the project end date ensures technical obsolescence. Without version control systems, bug tracking, or update mechanisms, even functional applications will gradually fail as operating systems and hardware evolve. The project's legacy exists primarily in academic publications rather than living software tools. No provisions were made for long-term hosting, maintenance, or updates to the applications. The EU project funding model, while supporting initial development, provided no sustainability pathway beyond the project timeframe. Future archaeological technology projects would benefit from planning post-project sustainability from inception, including open-source licensing, public code repositories, and deliberate community building.","Arches, an open-source cultural heritage data management platform, provides robust infrastructure for archaeological projects worldwide with better sustainability. Commercial solutions like Lithodomos VR and Wessex Archaeology Studio offer polished VR experiences for archaeological sites with ongoing technical support. The Archaeological Recording Kit (ARK) provides web-based data collection with active developer communities. QGIS plugins including ArkGrid and ArkSpatial offer GIS functionality specifically for archaeological documentation. The ArcheOS Linux distribution bundles specialised archaeological software in a maintained package. For institutions seeking VR/AR solutions, Acadicus by Arch Virtual provides a platform for creating educational VR content with ongoing development. ArcGIS Online offers professional-grade mapping and visualisation capabilities backed by ESRI's commercial infrastructure. These alternatives demonstrate how archaeological software can achieve long-term sustainability through open-source development models, active communities, and institutional support.","FOLLOWED: Claude Tool-status=no, user confirmed GRANULARITY_ERROR (project, not tool)"
Vistamorph,Success,,"Vistamorph was a specialised utility program designed to create morphing effects and animations for landscape visualisations. The current version (abandoned since 1997) enabled users to smoothly transform landscape features, animate changing lighting conditions, create evolving geomorphological and vegetation effects, and move clouds, grow trees, and simulate sun movement across landscapes. Developed as a companion to VistaPro, it was used in archaeological contexts primarily for visualising archaeological landscapes and simulating environmental changes over time. In previous versions, Vistamorph functioned exclusively with VistaPro's terrain files, requiring the main application to generate initial landscape models before applying transformation effects. While originally a commercial product sold alongside VistaPro, it is now considered abandonware with no official support or availability.","Vistamorph was developed by John Hinkley at Hypercube Engineering and published by Virtual Reality Laboratories, Inc. based in San Luis Obispo, California. The software evolved from the original 'Vista' program for the Amiga platform. First released in 1993 alongside VistaPro 3.0 for MS-DOS and Amiga systems, it was integrated into the VistaPro ecosystem of landscape visualisation tools. In 1994, a Windows version was released with VistaPro 3.12, expanding its platform availability. By 1997, when VistaPro 4.0 was released, Vistamorph had been discontinued and was no longer included in the package. The final version of VistaPro (4.2.7) released around 2005 did not include Vistamorph. Since the mid-2000s, both Vistamorph and its parent application VistaPro have been considered abandonware, with Virtual Reality Laboratories having ceased operations and no successor company maintaining the software. The most significant archaeological application was documented by Mark Gillings and Glyn Thomas Goodrick in Internet Archaeology (1996), where they described using it for archaeological landscape visualisation.","The current version of Vistamorph operated as a specialised utility designed to extend the capabilities of VistaPro by adding animation and morphing functionality to static landscape models. Technically, Vistamorph implemented a ray tracing-based rendering engine combined with raster-based image processing for morphing effects. The software incorporated fractal mathematics for terrain generation and transformation, allowing for realistic alterations to landscape features. Vistamorph processed Digital Elevation Model (DEM) files generated by VistaPro, which could be sourced from USGS data, NASA spacecraft measurements, or created artificially. The morphing algorithm calculated intermediate frames between two landscape states by interpolating height values for each coordinate point in the terrain mesh. Previous versions of Vistamorph relied on a proprietary file format for storing transformation parameters and keyframes. The software architecture was tightly coupled with VistaPro, making it impossible to use independently. Vistamorph had significant technical limitations including slow rendering speeds even on high-end hardware of its era (486 DX or early Pentium processors), memory constraints (requiring at least 8MB RAM), and fixed resolution outputs (typically limited to 640x480 pixels). The software lacked multithreading capabilities and required complete re-rendering when parameters were changed. From an archaeological perspective, Vistamorph's technical implementation allowed researchers to visualise landscape evolution and environmental changes, but with considerable technical overhead and limited scientific controls for ensuring accuracy in representations.",2025-06-01,maybe,"Vistamorph meets some but not all criteria for classification as a research software tool for archaeology/history. It satisfies the essential criteria of Research-Specific Purpose (it was used for archaeological landscape visualisation) and Research Data Engagement (it transformed DEM data meaningfully). It also meets supporting criteria of Visualization Functions (rendering data in visual formats) and Research Lifecycle Support (addressing visualisation/interpretation stages). However, its status is complicated by several factors: 1) It is completely abandoned software with no current availability except through abandonware archives; 2) It has not been cited in archaeological literature since the late 1990s; 3) It requires obsolete operating systems and hardware; 4) Superior modern alternatives exist. While it historically qualified as research software in the 1990s and was explicitly used for archaeological purposes by Gillings and Goodrick (1996), its current utility is purely historical rather than practical. This places it in a borderline 'maybe' classification.",,,,,Proprietary,3D modelling|Spatial analysis|Diagrams and visualizations,landscape morphing|archaeological visualization|animation software|terrain modelling|obsolete technology,1993,1997,Unknown (last included with VistaPro 3.12),Abandoned,"Virtual Reality Laboratories, Inc. (defunct)",John Hinkley (Hypercube Engineering),Small (2-5),Computer Graphics,General-purpose,Minimal,"Vistamorph has extremely limited usage metrics available. The software has zero current users as it is incompatible with modern systems without complex emulation. It received only one significant citation in archaeological literature (Gillings and Goodrick, 1996, in Internet Archaeology). No download statistics are available as the software is only found in abandonware archives. There is no GitHub repository or source code availability. No active community exists around this software, and no forums or discussion groups are dedicated to it. The software was never open-sourced and exists only as compiled binaries in software preservation collections. There are no documented instances of institutional adoption beyond the single archaeological case study. The commercial release of the software reportedly sold as part of the VistaPro package, but sales figures are unavailable.",Analysis|Interpretation,research-specific,Stand-alone software,Unknown (likely C/C++),MS-DOS|Windows 3.1/95/NT|Amiga|Macintosh,,"Input: VistaPro DEM, USGS DEM, ASCII DEM, PCX files. Output: AVI, FLC movies; PCX, BMP, JPG, TGA images; DXF 3D data. Limited export to Truespace, VRML, Arc/Info. The current version required VistaPro to function, severely limiting its standalone capabilities. Previous versions had similar limitations, only accepting terrain data generated in VistaPro's proprietary format. The software could not directly import GIS data without conversion through VistaPro.","Vistamorph's key strengths in its current version included: 1) Historical significance as an early archaeological visualisation tool used in peer-reviewed research; 2) Capability to process actual geographic data through USGS DEM files; 3) Specialized animation features that were innovative for the 1990s, including the ability to morph between different landscape states over time; 4) Relatively simple user interface compared to other 3D software of its era; 5) Cross-platform availability on multiple operating systems of its era, allowing for wider adoption in academic settings with diverse computing resources; 6) Integration with VistaPro's camera path system for complex fly-through animations of archaeological landscapes; 7) Unique capability to visualise gradual landscape transformations that could represent archaeological or geological processes over time.","Current weaknesses of Vistamorph include: 1) Complete technological obsolescence based on 1990s architecture and standards; 2) Abandoned development status with no updates since 1997; 3) Incompatibility with modern operating systems without complex emulation; 4) Dependency on equally obsolete VistaPro software; 5) Non-existent community support, documentation, or help resources; 6) Extremely poor performance even on period hardware; 7) No security updates for decades, creating potential vulnerabilities; 8) Limited archaeological-specific features as it wasn't designed exclusively for archaeological applications; 9) Closed-source nature preventing community maintenance or updates; 10) Proprietary file formats with limited export options; 11) No integration with modern GIS or archaeological data standards; 12) Fixed resolution outputs incompatible with current display technologies; 13) Inability to leverage modern GPU acceleration; 14) Poor scalability for large datasets.","Vistamorph has extremely poor long-term viability prospects. The software has been abandoned for nearly three decades with no source code availability for community maintenance. It runs only on obsolete operating systems requiring emulation layers or vintage hardware. Its proprietary data formats have no modern converters, creating severe data accessibility issues. There is no active preservation community dedicated to maintaining compatibility or functionality. Documentation is limited to original manuals preserved in archives. The copyright holder is unclear due to the dissolution of Virtual Reality Laboratories, creating ambiguity around its legal status even as abandonware. The software's tight coupling with VistaPro creates additional sustainability challenges, as both programs must be preserved together. From an archaeological perspective, the techniques pioneered by Vistamorph have been completely superseded by modern GIS and 3D modelling approaches with superior scientific accuracy and methodological rigour.",Modern alternatives to Vistamorph for archaeological landscape visualisation include: 1) QGIS with terrain analysis plugins and temporal controller for animation; 2) ArcGIS Pro with 3D Analyst for professional GIS-based landscape modelling; 3) Terragen for photorealistic landscape generation and animation; 4) World Machine for procedural terrain generation; 5) Blender with GIS plugins for 3D landscape modelling and animation; 6) CloudCompare for point cloud processing of archaeological landscapes; 7) MeshLab for 3D mesh processing; 8) Unity or Unreal Engine for interactive archaeological visualisations; 9) GRASS GIS for open-source terrain analysis with archaeological modules; 10) Agisoft Metashape for photogrammetry of archaeological sites; 11) RealityCapture for 3D reconstruction; 12) Virtual Past toolkit for archaeological visualisation; 13) SketchUp with terrain tools for accessible 3D modelling; 14) Autodesk 3ds Max with GeoTools for professional landscape visualisation.,
VistaPro,Success,,"VistaPro is a 3D landscape visualization software that creates photorealistic terrain renderings from digital elevation model (DEM) data or through fractal generation. First released in 1990 for Amiga computers, it became an important early tool for archaeological landscape visualization in the mid-1990s. The software enables users to generate realistic terrains with customizable lighting, atmospheric effects, vegetation, and water features. While originally developed for general landscape visualization, VistaPro found application in archaeological research for recreating historical landscapes and analyzing viewsheds. The current version (4.2.6/4.2.7) was released around 2005-2008, after which development ceased.","VistaPro evolved from Vista, first released in 1990 by John Hinkley for the Amiga platform. Virtual Reality Laboratories published early versions, with significant enhancements in the VistaPro 3.x series (1994-1995) for DOS and Windows. The 4.x series (1997-2008) expanded cross-platform support and improved rendering capabilities. Later versions were marketed as 'VistaPro Renderer' with the final release (4.2.6 or 4.2.7) appearing around 2005-2008 from Monkey Byte Development. The software's development trajectory included progressive improvements in resolution support (up to 2048x1536), animation capabilities, and rendering quality, with each major version introducing expanded file format compatibility and more sophisticated terrain generation algorithms. Development ceased entirely by 2008 with no source code ever released.","VistaPro employs a ray-tracing-like rendering engine to generate realistic landscape visualizations. The current version (4.2.x) operates by processing either imported digital elevation model (DEM) data or generating terrain through fractal algorithms. The rendering approach involves calculating light paths and environmental effects to create photorealistic landscapes with accurate shadow casting, atmospheric scattering, and surface texturing. The technical architecture includes three primary components: a terrain data processor supporting USGS DEM files and proprietary formats, a real-time parameter adjustment system for modifying landscape features, and the rendering engine itself. For archaeological applications, VistaPro's ability to import USGS DEM files proved particularly valuable, though often requiring custom conversion scripts to prepare archaeological GIS data for import. The software utilizes platform-specific implementations, with later versions supporting 32-bit architecture and benefiting from floating-point unit (FPU) acceleration. Output rendering quality varies by version, with the 4.x series capable of generating images up to 2048x1536 pixels in various standard formats (JPG, BMP, PCX, Targa). Unlike modern landscape visualization tools, VistaPro does not expose its underlying algorithms or provide scripting capabilities, instead relying on a graphical interface for all operations. Performance on period hardware was processor-intensive, with complex landscapes requiring hours to render at high resolutions.",2025-06-01,yes,"VistaPro qualifies as research software based on documented use in archaeological research, particularly in landscape archaeology studies by Mark Gillings (University of Leicester, 1996). It meets all essential criteria: it supports research-specific visualization of archaeological landscapes, transforms research materials (GIS/DEM data) into meaningful visualizations, and aligns with recognized methodologies in landscape archaeology and virtual heritage studies. It also satisfies multiple supporting criteria: it incorporates domain-specific knowledge about terrain visualization relevant to archaeology, supports the analysis and interpretation phases of research, provides advanced visualization functions for understanding past landscapes, and enables data transformation between GIS outputs and visual representations needed for archaeological interpretation.",,,https://archive.org/details/vistapro320,https://archive.org/details/vistapro320,Proprietary|Commercial|Abandonware,3D modelling|Landscape visualization|Diagrams and visualizations|Spatial analysis|Viewshed analysis,Landscape rendering|Terrain visualization|Digital elevation models|Archaeological viewshed|Virtual reconstruction,1990,2008,4.2.6,Abandoned,Virtual Reality Laboratories|Hypercube Engineering|Monkey Byte Development,John Hinkley,Small (2-5),Computer Graphics,General-purpose,Basic,"VistaPro achieved moderate adoption in archaeological visualization from 1995-2005, evidenced by citations in early digital archaeology literature, particularly Gillings' 1996 publication in Internet Archaeology (Issue 1). The software was used in multiple archaeological landscape studies during this period, including the Hepburn Bastle Project and other UK landscape archaeology initiatives. Archive.org shows approximately 1,000+ downloads of preserved versions, indicating ongoing interest despite abandonment. WinWorld PC categorizes it as a 'popular' historical software with active community forum discussions. No extension ecosystem existed due to closed-source nature. Primary usage was in academic archaeology and computer graphics communities during the 1990s, with declining usage after 2005 as GIS-integrated visualization tools became more capable.",Interpretation|Analysis|Visualization,research-specific,Stand-alone software,Undocumented,Windows|Mac OS|Amiga|DOS,,"VistaPro supported import of USGS Digital Elevation Model (DEM) files and PCX heightmaps. Output formats included PCX, BMP, JPG/JPEG, Targa, and DXF for CAD integration. The software had limited interoperability with archaeological GIS systems of its era, typically requiring conversion scripts to transform GIS-derived data into compatible formats. Version 4.x improved interoperability with support for a wider range of output formats, though never achieved direct integration with major GIS platforms.","VistaPro offered several significant advantages for archaeological research in the 1990s. First, it provided affordable landscape visualization capabilities when comparable features in professional GIS packages were prohibitively expensive. Second, its high-quality rendering engine produced photorealistic landscape images suitable for publication and presentation. Third, it supported phenomenological approaches to landscape archaeology by enabling experiential landscape interpretation through realistic visualizations. Fourth, the software preserved micro-topographic details important for archaeological feature identification. Fifth, despite limitations, it established workflows for integrating GIS data with visualization tools that influenced subsequent archaeological visualization practices.","Despite its archaeological applications, VistaPro exhibited several limitations. First, the proprietary nature and closed-source code prevented customization needed for specialized archaeological applications. Second, the software lacked analytical capabilities beyond visualization, requiring researchers to perform all spatial analysis in separate GIS environments. Third, format restrictions complicated data preparation, often requiring custom scripts to convert archaeological data. Fourth, the rendering process was computationally intensive on period hardware, with high-resolution outputs requiring hours to generate. Fifth, scale constraints made the software better suited for landscape-level visualization than site-level detail, limiting applications in intra-site archaeology. These limitations became increasingly problematic as integrated GIS visualization capabilities improved in the early 2000s.","VistaPro represents a well-preserved example of early landscape visualization software. The complete software packages for multiple versions are archived through platforms like Internet Archive and WinWorld, ensuring continued availability despite commercial abandonment. The software runs effectively on modern systems through compatibility modes or emulation, with minimal configuration required. Output files in standard formats (JPG, BMP) remain fully accessible. While technically viable, VistaPro's research relevance is primarily historical, valuable for understanding the evolution of archaeological visualization methodologies rather than for contemporary research applications. Its preserved state makes it an excellent case study in digital archaeology's development, though modern alternatives provide superior functionality and GIS integration.","For archaeological landscape visualization, several modern alternatives offer enhanced capabilities: Terragen (widely considered VistaPro's spiritual successor), Vue (professional landscape suite with advanced ecosystem modeling), World Machine (procedural terrain generation with GIS integration), Unity3D/Unreal Engine (game engines with landscape tools), QGIS with 3D visualization plugins, and ArcGIS Pro (with integrated 3D capabilities). Open-source alternatives include Picogen and Blender with GIS plugins. These modern tools provide improved GIS integration, real-time navigation, superior rendering quality, and analytical capabilities largely absent from VistaPro.",
Voro++,Success,,"Voro++ is a specialised C++ library for calculating three-dimensional Voronoi tessellations of particles in space. The current version provides an efficient cell-based computational method for constructing Voronoi cells for systems of particles. Unlike traditional approaches that compute tessellations as global networks, Voro++ constructs each Voronoi cell individually through plane-cutting algorithms, enabling efficient computation for large systems. Though originally developed for physics and materials science applications, it has untapped potential for archaeological spatial analysis, including 3D artefact distribution analysis, site formation processes, architectural space modelling, and integration with LiDAR data.","Voro++ was developed by Chris Rycroft at Lawrence Berkeley National Laboratory, with initial release in 2009. The library was created to support particle physics simulations and materials science research, with development supported by the U.S. Department of Energy. The software evolved through multiple versions, with version 0.4.6 released in October 2013 as the most recent stable version. Development has continued with contributions focusing on performance improvements, including a significant 2022-2023 extension by Jiayin Lu and Emanuel Lazar that added multithreaded computation capabilities. This extension, published on arXiv and in Computer Physics Communications, demonstrated parallel efficiency exceeding 95% on systems with over 100 million particles. The software has gained adoption across computational geometry, physics, and materials science fields, though archaeological applications remain limited.","The current version of Voro++ implements a cell-based approach to compute three-dimensional Voronoi tessellations, fundamentally different from traditional approaches. Its architecture centres on two main class categories: voronoicell classes that handle individual cell computation and container classes for spatial organisation. The core algorithm employs a plane-cutting method that traces edges to determine cell-plane intersections, utilising convexity properties for efficient computation even with floating-point precision errors. The library organises particles into a grid-based spatial structure, achieving optimal performance with approximately 5 particles per grid block. Voro++ supports diverse boundary conditions including plane, spherical, cylindrical, and conical walls through a flexible wall object system. The software offers computation of radical (Laguerre) Voronoi tessellations for weighted particles and handles non-orthogonal periodic domains. Numerical stability is achieved through tolerance-based equality testing, automatic handling of degenerate vertices, and comprehensive error reporting. The recent multithreaded extension implements OpenMP directives with block-based parallelism and dynamic load balancing, showing nearly linear scaling on multi-core systems. For customised output, Voro++ implements a control sequence system to extract specific properties including geometry (volume, surface area, centroid), topology (vertex orders, face connectivity), and neighbour information. Previous versions lacked parallel processing capabilities and had more limited boundary condition options, though the core computational approach has remained consistent.",2025-06-01,yes,"Voro++ satisfies all essential criteria for research software and multiple supporting criteria. For essential criteria: (1) It has a clear research-specific purpose in computational geometry and spatial analysis; (2) It directly engages with research data by transforming spatial point distributions into meaningful Voronoi tessellations; (3) It aligns with recognised methodologies in computational physics, materials science, and spatial analysis. For supporting criteria, it meets: analytical capabilities through geometric calculations of cell properties; visualisation functions via output formats compatible with visualisation tools; data transformation through conversion of point clouds to cell structures; domain knowledge integration via specialised vocabulary and techniques from computational geometry; and research lifecycle support across analysis and interpretation stages. Its demonstrated use in the Sabouroff Head analysis for archaeological research further confirms its classification as research software.",https://github.com/chr1shr/voro,,https://math.lbl.gov/voro++/,https://math.lbl.gov/voro++/,BSD-3-Clause-LBNL,3D modelling|Spatial analysis,computational-geometry|particle-analysis|three-dimensional|tessellation|spatial-partitioning,2009,2013-10-01,0.4.6,Maintenance-only,Lawrence Berkeley National Laboratory,Chris Rycroft|Jiayin Lu|Emanuel Lazar,Small (2-5),Physics|Materials Science,General-purpose,Comprehensive,"The GitHub repository shows modest but consistent engagement with 168 stars and 51 forks as of June 2025. The library is widely cited in computational physics and materials science literature, with the original paper receiving hundreds of citations. It has been incorporated into multiple simulation frameworks and adopted by research institutions worldwide. The software is available through conda-forge and maintains an active issue tracker. While archaeological citations remain minimal, its use in the Sabouroff Head analysis demonstrates its potential in the field. The recent multithreaded extension publication indicates ongoing development interest. User forums show regular technical discussions, though primarily from physics and engineering domains rather than archaeology.",Analysis|Processing,research-specific,Packages and libraries,C++,Linux|macOS|Windows|Unix,,"Voro++ imports particle data through text files or programmatic API and exports detailed cell information in custom formats. The current version provides flexible output formatting through control sequences that can generate data suitable for visualisation tools including Gnuplot and POV-Ray. It can produce VTK files for scientific visualisation software and custom formats for further analysis. The library offers no direct integration with GIS or archaeological software, requiring intermediate conversion steps. Its C++ implementation allows integration into larger software systems as a component library, with several physics simulation frameworks incorporating it. Third-party Python wrappers exist but are not officially supported.","The current version of Voro++ excels at cell-based computation, enabling significant memory savings compared to global approaches. This is particularly valuable for large archaeological datasets like LiDAR point clouds or complex 3D scans. The software demonstrates exceptional numerical stability and handles complex boundary conditions naturally, important for analysing artefacts within constrained archaeological contexts. Its specialised features for weighted particles (radical Voronoi tessellation) allow modelling of varying archaeological importance or influence zones. The highly customisable output system enables extraction of specific metrics relevant to archaeological analysis. The recent multithreaded extension provides scalability for massive datasets, increasingly common in modern archaeological documentation. The software's minimal dependencies ensure long-term availability and cross-platform compatibility, vital for archaeological data preservation. Previous versions lacked the parallel processing capabilities now available, though they maintained the core algorithmic advantages.","The current version of Voro++ exhibits slower serial performance compared to some specialised alternatives, potentially limiting interactive use with smaller archaeological datasets. Its legacy C++ design patterns complicate integration with modern software ecosystems common in archaeological computing. The steep learning curve and command-line interface present barriers to adoption by archaeologists without computational backgrounds. The software lacks native visualisation capabilities, requiring additional tools for result interpretation—a significant limitation for visual fields like archaeology. Limited language bindings restrict integration with popular archaeological data processing environments like Python and R. Previous versions had even more restricted performance on large datasets and lacked accessible documentation for non-specialists in computational geometry.","Voro++ demonstrates strong survivability prospects. The software maintains an active GitHub repository with continued maintenance and recent significant extensions. Its institutional backing from Lawrence Berkeley National Laboratory provides stability, while its BSD license ensures accessibility. The library's focused scope, minimal dependencies, and cross-platform compatibility contribute to technical sustainability. While the primary developer has moved to a new institution, continued collaboration indicates ongoing commitment. The software's adoption across multiple scientific domains creates a broad user base, though archaeological adoption remains limited. The recent multithreaded extension demonstrates continued investment in the codebase. The simple, well-documented API and stable computational approach suggest the software will remain usable even with minimal future development. Previous versions have maintained backward compatibility, providing confidence in long-term usability of existing code and workflows.","CGAL (Computational Geometry Algorithms Library) provides more comprehensive computational geometry tools including Voronoi diagrams but with higher complexity and resource requirements. Qhull implements quickhull algorithms for computing Delaunay triangulations and Voronoi diagrams but lacks specialisation for particle systems. SciPy's spatial module (scipy.spatial.Voronoi) offers more accessible Python-based implementation but with limited 3D capabilities and performance. VoroTop extends Voro++ specifically for topological analysis of atomic arrangements. For archaeological applications, GIS-based 2D Voronoi implementations like those in QGIS offer simpler workflows but lack 3D capabilities. The GigaMesh Software Framework uses 'Voronoi-inspired methods' for archaeological 3D analysis with more domain-specific features but less computational efficiency for large systems.",
VOSviewer,Success,,"VOSviewer is specialised software for creating and visualising bibliometric networks of scientific literature. The current version constructs networks based on co-citation, bibliographic coupling, co-authorship, or co-occurrence of keywords. It imports data directly from Web of Science, Scopus, PubMed, Dimensions, and other academic databases, allowing researchers to map the intellectual structure of research fields through visualising citation relationships, keyword clusters, and author collaborations. While not originally designed for archaeological research, it has been applied to study publication patterns in archaeology, notably in Anthony Sinclair's 2016 analysis of archaeological literature that revealed 19 distinct citation clusters and disciplinary structures. VOSviewer primarily serves meta-analytical rather than primary research functions in archaeology and history, helping researchers understand knowledge landscapes rather than directly analysing archaeological data.","VOSviewer was developed at the Centre for Science and Technology Studies (CWTS) at Leiden University, with the first version released in 2010 following publication of the foundational paper 'Software survey: VOSviewer, a computer program for bibliometric mapping' in Scientometrics. Created by Nees Jan van Eck and Ludo Waltman, the software's development was driven by the need for more accessible bibliometric visualisation tools without sacrificing analytical power. The software has undergone consistent development with major releases approximately annually. Key evolutionary milestones include: integration with major bibliographic databases (2013-2015), improved clustering algorithms through the Smart Local Moving method (2013), enhanced overlay visualisations (2015), expanded data import capabilities (2017-2019), and the launch of VOSviewer Online as a web-based version in 2021. The 2023 release (version 1.6.20) added support for OpenAlex data and enhanced export capabilities. Throughout its history, VOSviewer has maintained its core design philosophy of accessibility without requiring programming knowledge, while steadily expanding its analytical capabilities and database integrations.","The current version of VOSviewer (1.6.20) is built on a Java-based architecture requiring Java 8 or higher, with the core application leveraging the VOS (Visualisation of Similarities) mapping technique—a proprietary algorithm that positions items in a two-dimensional space where proximity represents relatedness. This mapping technique is mathematically related to multidimensional scaling but optimised for bibliometric applications. VOSviewer's clustering functionality implements the Smart Local Moving algorithm, an enhancement of the widely-used Louvain method that delivers superior performance for bibliometric data. Technically, VOSviewer operates as two distinct products: a desktop application (proprietary but free) and VOSviewer Online (open-source under MIT license), with both sharing core visualisation capabilities but differing in implementation details. The desktop version uses Java Swing for its interface while the web version leverages JavaScript and modern web technologies. For data processing, VOSviewer implements a pipeline architecture that handles parsing, normalisation, similarity calculation, mapping, and clustering as discrete stages. Performance optimisations allow the desktop version to handle networks with thousands of nodes efficiently, having been tested with datasets containing over 5,000 scientific journals. Memory management has been progressively improved to accommodate larger datasets, though processing extremely large networks (>10,000 nodes) remains challenging without pre-filtering. Previous versions had limitations in custom metric implementation and direct database integration, but recent releases have addressed these through APIs for major academic databases and expanded export options including high-resolution PNG, SVG, and network data in multiple formats.",2025-06-01,yes,"VOSviewer meets all essential criteria as a research software tool and multiple supporting criteria. It supports research activities by enabling systematic analysis of academic literature (Essential Criterion 1), transforms research materials by converting citation data into meaningful network visualisations (Essential Criterion 2), and aligns with recognised bibliometric methodologies (Essential Criterion 3). Additionally, it incorporates domain knowledge through field-normalised citation metrics (Supporting Criterion 1), supports the publication stage of the research lifecycle (Supporting Criterion 2), transforms bibliographic data between formats (Supporting Criterion 3), provides analytical capabilities through clustering and significance calculations (Supporting Criterion 4), offers sophisticated visualisation functions (Supporting Criterion 5), includes documentation specifically addressing research applications (Supporting Criterion 6), and facilitates data dissemination through exportable visualisations and findings (Supporting Criterion 8).",https://github.com/neesjanvaneck/VOSviewer-Online,,https://www.vosviewer.com/,https://www.vosviewer.com/,Proprietary (desktop) | MIT License (online version),Bibliometrics|Statistical analysis|Network analysis|Data visualisation,bibliometric-visualisation|citation-network-analysis|research-mapping|interdisciplinary-analysis|cluster-detection,2010-01-01,2023-10-31,1.6.20,Active,"Centre for Science and Technology Studies (CWTS), Leiden University",Nees Jan van Eck|Ludo Waltman,Small (2-5),Bibliometrics,General-purpose,Excellent,"VOSviewer has achieved substantial adoption across academic disciplines, with over 10,000 citations to its foundational paper. Usage has grown exponentially, with 53% of citations occurring after 2021. The software is taught in workshops worldwide through university libraries and CWTS courses (€1,100 for 4-day training). Institutional adoption is evidenced through integration partnerships with Digital Science's Dimensions platform and inclusion in research metrics guides at major universities. The GitHub repository for VOSviewer Online shows modest activity with 47 stars and 18 forks. In archaeology, the most significant usage comes from meta-analytical studies of the discipline rather than direct archaeological applications, with Anthony Sinclair's 2016 Internet Archaeology study serving as the most prominent example. Current usage metrics show particular strength in information science, health sciences, and management studies, with growing adoption in social sciences and humanities.",Publication,mass-market,Stand-alone software,Java|JavaScript,Windows|macOS|Linux|Web,,"VOSviewer imports data directly from major academic databases including Web of Science, Scopus, Dimensions, PubMed, OpenAlex, and Lens.org. The current version exports visualisations as bitmap images (PNG), vector graphics (SVG), and network data (NET, MAP, VOSviewer JSON format). It offers integration with the Bibliometrix R package through the net2VOSviewer function. Data interoperability is limited by proprietary internal formats, though the software can read CSV, RIS, and WoS-tagged formats. VOSviewer Online improves interoperability through standard web technologies and an MIT-licensed codebase. Previous versions had more limited import capabilities, while the evolution of export options has been a focus of recent development.","VOSviewer's primary strength lies in its exceptional accessibility for non-technical users, offering sophisticated bibliometric analysis without requiring programming skills. The current version provides a uniquely intuitive interface with three complementary visualisation modes (network, overlay, and density) that make complex bibliometric patterns immediately apparent. Institutional backing from Leiden University ensures stability and regular updates, distinguishing it from many academic software projects. Direct integration with 10+ major academic databases eliminates preprocessing work that plagues alternatives, while the proprietary VOS mapping technique delivers superior layouts compared to standard force-directed algorithms. For archaeology specifically, the software excels at revealing intellectual structures within the discipline, identifying influential publications, and mapping interdisciplinary connections. The current version's ability to handle multiple data sources enables cross-database comparisons vital for comprehensive literature reviews. The addition of VOSviewer Online removes installation barriers, increasing accessibility for researchers with limited technical resources.","Despite its strengths, VOSviewer's current version remains fundamentally limited for archaeological research by its design focus on published academic literature rather than primary archaeological data. The software lacks features for temporal analysis critical to historical research, making it difficult to track concept evolution through time without supplementary tools. While technically sophisticated, the desktop version's closed-source nature prevents community-driven extensions to address discipline-specific needs. Current bibliometric methods struggle with archaeological citation patterns, which often feature inconsistent naming conventions, varying transliterations of ancient names, and temporal terminology that resists standardisation. Version 1.6.20 still lacks robust statistical analysis capabilities compared to R-based alternatives, forcing researchers to export data for advanced analytics. The software's reliance on predefined metrics limits customisation for discipline-specific indicators, while the inability to combine multiple databases in a single analysis restricts comprehensive coverage. Performance issues emerge with extremely large networks (>10,000 nodes), requiring pre-filtering that may introduce selection bias. For archaeological applications specifically, the tool remains primarily meta-analytical rather than supporting direct archaeological research methods.","VOSviewer demonstrates exceptional long-term sustainability prospects based on multiple indicators. The current version represents 15 years of continuous development with 20+ releases, far exceeding typical academic software lifespans. Institutional backing from the Centre for Science and Technology Studies (CWTS) at Leiden University provides stable funding independent of grant cycles, while revenue streams from training courses and consulting create financial sustainability. Integration into commercial platforms like Dimensions suggests industry confidence in the software's longevity. The 2021 launch of VOSviewer Online as an MIT-licensed open-source alternative creates a sustainability pathway even if desktop development were to cease. While the two-person core development team creates potential succession concerns, both developers remain actively engaged with complementary skill sets. Citation patterns show accelerating adoption rather than plateau, with over half of all citations occurring in the past three years, indicating growing rather than declining relevance. The software's architecture allows progressive enhancement without breaking compatibility, and export capabilities provide migration paths should alternatives eventually replace it. Based on all indicators, VOSviewer appears exceptionally well-positioned to remain viable and maintained throughout the remainder of the 2020s and likely beyond.","For archaeological bibliometric analysis, the most direct alternatives to VOSviewer are: 1) Bibliometrix (R package) offering 170+ analytical functions and statistical depth but requiring programming knowledge; 2) CiteSpace with superior temporal evolution analysis but significant learning curve; 3) CitNetExplorer (by the same developers) focusing exclusively on citation networks with longitudinal capabilities; 4) Gephi providing greater customisation for massive networks but lacking bibliometric-specific features; and 5) Science of Science (Sci2) Tool offering extensive preprocessing capabilities but less intuitive visualisation. For archaeological applications specifically, VOSviewer's focus on published literature means tools like QGIS, ArcGIS, R or Python with ggplot2/matplotlib would better serve direct archaeological data analysis, while tools like Gephi or NetworkX might better represent archaeological context networks with appropriate data preparation. The choice between VOSviewer and alternatives depends primarily on technical expertise, specific analytical needs, and whether the focus is meta-analysis of archaeological literature or direct analysis of archaeological data.",
WallGIS,Success,,"WallGIS is a specialized archaeological database and geographic information system developed specifically for Hadrian's Wall research. Created by Newcastle University's Hadrian's Wall Community Archaeology Project (WallCAP) between 2019-2022, it consolidates over 150 years of archaeological data into a comprehensive digital resource. The system contains detailed information on all archaeological features along the 73-mile Roman frontier monument, including turrets, milecastles, forts, and linear features. WallGIS enables researchers to conduct spatial analysis and visualize relationships between different features of Hadrian's Wall, supporting both academic research and heritage management activities.","WallGIS was developed as part of the Hadrian's Wall Community Archaeology Project (WallCAP) at Newcastle University, beginning in January 2019. The project received funding from the National Lottery Heritage Fund (grant HG-16-08924). Major data collection occurred during the COVID-19 lockdowns of 2020-2021, with volunteers conducting desk-based research using standardized forms. The custom Microsoft Access database was developed throughout 2020-2022. The system underwent peer review in 2022 and was delivered to the UK's Archaeology Data Service in August 2022 for long-term preservation and access. The project formally concluded in September 2022, with the academic data paper published in Internet Archaeology in December 2024.","WallGIS employs an ESRI ArcGIS geodatabase architecture as its primary data storage system, using an object-relational model that separates application logic from storage. The system comprises 18 specialized database tables, each designed to capture attributes for specific archaeological feature types along Hadrian's Wall. These include linear elements (curtain wall, wall ditch, Vallum, Military Way) and discrete structures (turrets, milecastles, forts, settlements, gateways). All spatial data uses the British National Grid coordinate system (OSG36/EPSG:27700) with measurements stored in metres. The database supports multiple geometry types including points, lines, and polygons for different archaeological features. Rather than functioning as standalone software, WallGIS operates as a data product distributed through the Archaeology Data Service, with users accessing the data through web interfaces or downloading in multiple formats including ESRI File Geodatabase (.gdb), shapefiles (.shp), CSV files for attribute data, and KML/KMZ for Google Earth compatibility. This approach ensures interoperability with existing GIS workflows while avoiding the maintenance burden of standalone software. The database was originally built on Microsoft Access, with spatial functionality provided through its integration with ArcGIS. The system's architecture prioritizes attribute richness for archaeological features over processing performance, reflecting its primary role as a research repository rather than an analytical engine.",2025-05-31,yes,"WallGIS qualifies as a research software tool because it satisfies all essential criteria and exceeds the minimum supporting criteria threshold. It was specifically designed to support archaeological research on Hadrian's Wall (research-specific purpose), enables meaningful transformation of archaeological data through spatial analysis (research data engagement), and aligns with established GIS methodologies in archaeology (methodological alignment). Additionally, it demonstrates strength in six supporting criteria areas: it integrates domain knowledge through specialized archaeological classification schemes, supports multiple research lifecycle stages (particularly analysis and interpretation), enables data transformation between formats, provides analytical capabilities through spatial analysis, offers visualization functionality, and features documentation focused on research applications. While not designed for field data collection, its primary purpose as an analytical tool for existing archaeological data clearly positions it as research software.",,,https://archaeologydataservice.ac.uk/archives/collections/view/1004975/overview.cfm,https://archaeologydataservice.ac.uk/archives/collections/view/1004975/overview.cfm,Creative Commons Attribution 4.0 International,Spatial analysis|Site mapping|Data management,Hadrian's Wall|Roman archaeology|Heritage management|Archaeological database|Monument mapping,2019-01-01,2022-09-01,August 2022 release,Deprecated,Newcastle University|National Lottery Heritage Fund,Kathryn Murphy|Rob Collins|Sam Turner,Medium (6-20),Archaeology,Project-specific,Comprehensive,"WallGIS serves a specialized research community focused on Hadrian's Wall studies. As an archived dataset within the UK's Archaeology Data Service (ADS), it benefits from institutional visibility within archaeological research circles, particularly among Roman frontier scholars and heritage management professionals. While specific download statistics from ADS are not publicly available, the system's integration within a World Heritage Site's research infrastructure ensures consistent usage among specialized researchers. The accompanying peer-reviewed data paper in Internet Archaeology (Murphy & Collins, 2024) provides academic citation pathways. The project demonstrated successful community engagement with volunteer participation in data collection, indicating good adoption within its target community. However, the narrow focus on a single monument limits broader adoption beyond Roman frontier specialists.",Analysis|Interpretation|Preservation and Reuse,research-specific,Stand-alone software,Microsoft Access|ESRI ArcGIS,Windows|Web browser,,"WallGIS prioritizes interoperability through multiple export formats including ESRI File Geodatabase (.gdb), shapefiles (.shp), CSV files for attribute data, and KML/KMZ for Google Earth compatibility. The system adheres to the British National Grid coordinate system (OSG36/EPSG:27700) standard, enabling seamless integration with other UK spatial datasets. Data can be accessed and manipulated through industry-standard GIS platforms including ArcGIS and QGIS. However, the system does not implement formal archaeological data exchange standards like CIDOC CRM or comply with Linked Open Data principles, potentially limiting integration with newer archaeological data infrastructures. The Archaeology Data Service hosting provides standardized metadata and persistent identifiers.","WallGIS excels at consolidating disparate archaeological datasets spanning over 150 years of research into a standardized, spatially-enabled format. Its specialized database design with 18 purpose-built tables captures rich attribute information about archaeological features, supporting nuanced research questions specific to Hadrian's Wall. The system successfully balances comprehensiveness with usability, organizing complex archaeological data into intuitive feature categories. Integration with the Archaeology Data Service ensures long-term digital preservation according to established standards. The community archaeology development model demonstrated effective volunteer engagement in data collection despite pandemic restrictions. Comprehensive documentation through a peer-reviewed data paper enhances scientific credibility and reproducibility. The standardized structure enables consistent analysis across the entire 73-mile monument while accommodating the varied characteristics of different archaeological features.","WallGIS suffers from significant limitations in scalability and flexibility due to its highly specialized design for Hadrian's Wall, making it unsuitable for other archaeological contexts. The Microsoft Access foundation may limit performance with large datasets and lacks modern database features. Development ceased in September 2022, with no mechanism for incorporating new archaeological discoveries or methodological advances, creating a static dataset that will gradually become outdated. The system provides summary-level data rather than detailed excavation records, limiting some research applications. Linear features are represented as generalized lines best viewed at larger scales, restricting detailed spatial analysis. The absence of compliance with international archaeological data standards like CIDOC CRM limits interoperability with emerging digital heritage infrastructure. No active user community or ongoing technical support exists beyond standard ADS archival procedures.","WallGIS demonstrates mixed but adequate long-term viability for its intended purpose. Professional archiving with the UK's Archaeology Data Service ensures data preservation according to digital curation standards, mitigating technical obsolescence risks. The association with established academic institutions provides credibility, and comprehensive peer-reviewed documentation supports continued use. However, several factors limit its long-term prospects: development has ceased with no active maintenance plan, the specialized focus on a single monument creates a narrow user base, and the Microsoft Access foundation may face compatibility challenges as technology evolves. The absence of open-source code limits community-driven improvements. The system will likely remain a valuable but increasingly static research resource, with its core dataset maintaining relevance for Hadrian's Wall studies while gradually losing utility as new archaeological discoveries and methodologies emerge without corresponding database updates.","General archaeological GIS alternatives offer different balances between specialization and flexibility. QGIS with archaeological plugins (pyArchInit, ARK Spatial) provides free, open-source flexibility for custom workflows across any archaeological context, though requiring more technical expertise than WallGIS. OpenAtlas and Arches Project represent more future-oriented approaches, implementing international standards like CIDOC CRM for enhanced interoperability, supporting collaborative research across institutions, and enabling integration with emerging technologies. OpenAtlas offers flexible data modeling for complex archaeological relationships, while Arches provides purpose-built cultural heritage management capabilities. Both require more technical infrastructure than WallGIS but provide sustainable, standards-compliant frameworks for long-term data management. For Hadrian's Wall research specifically, the English Heritage GIS and Historic England's National Record of the Historic Environment (NRHE) offer complementary but less specialized datasets covering the same geographical area.","FOLLOWED: Claude Tool-status=yes, user confirmed TOOL (data products are acceptable)"
WaveSurfer,Success,,"WaveSurfer is an open-source tool for sound visualization and analysis, primarily designed for speech research but applicable to archaeoacoustics and historical sound analysis. The current version offers a customizable interface with plug-in capabilities allowing users to create spectrograms, waveform displays, pitch contours, and transcription annotations for detailed audio analysis. Originally developed for phonetics and linguistics research, it has been adapted for archaeological applications including the analysis of acoustical properties of historical sites, examination of ancient sound recordings, and documentation of archaeoacoustic phenomena. Earlier versions had more limited visualization options and lacked the extensive plugin architecture of current releases.","WaveSurfer was developed in 1999-2000 at the Centre for Speech Technology (CTT) at KTH Royal Institute of Technology in Stockholm, Sweden by Kåre Sjölander and Jonas Beskow. The tool was built on the Snack Sound Toolkit, a cross-platform audio extension for Tcl/Tk. Initial release 1.0 focused on basic visualization capabilities for speech research. Version 1.2 (2001) added transcription capabilities, version 1.5 (2003) introduced plugin architecture, and version 1.8 (2005-2010) brought significant stability improvements and additional visualization options. Since 2010, development has slowed considerably, with only minor maintenance releases (latest being version 1.8.8p6 in 2020) providing compatibility fixes rather than new features. Despite minimal active development over the past decade, WaveSurfer remains in use within linguistics and archaeoacoustics research communities due to its ease of use and specialized visualization capabilities.","The current version of WaveSurfer is implemented in Tcl/Tk with the Snack Sound Toolkit serving as its audio processing foundation. This architecture enables cross-platform compatibility across Windows, macOS, Linux, and other Unix-based systems. The technical implementation follows a modular design with a plugin framework that allows researchers to extend functionality through custom modules. The core software utilizes Fast Fourier Transform (FFT) algorithms for spectrogram generation with configurable window sizes and overlap settings that affect time and frequency resolution. Pitch tracking is implemented using autocorrelation methods with adjustable parameters for different voice types. The visualization engine employs a canvas-based rendering system that allows simultaneous display of multiple synchronized representations of the same audio data (waveforms, spectrograms, pitch contours, etc.). Data persistence is handled through XML-based configuration files that store visualization settings and analysis parameters. Audio processing occurs through the Snack library which supports various audio formats (WAV, AIFF, AU, MP3, etc.) with different sampling rates and bit depths. Previous versions had a less modular architecture with more tightly coupled components, making extensibility more difficult. Memory management in earlier versions was also less efficient, limiting the size of audio files that could be analyzed. The current version includes improved buffer management for handling larger files, though still constrained by the limitations of the Tcl/Tk environment compared to more modern audio processing frameworks.",2025-05-31,yes,"WaveSurfer qualifies as a research software tool because it meets all essential criteria and several supporting criteria. It has a research-specific purpose, enabling detailed analysis of audio recordings for linguistic, phonetic, and archaeoacoustic research. It meaningfully transforms research materials through spectral analysis, waveform visualization, and annotation capabilities. Methodologically, it aligns with established approaches in phonetics, acoustic analysis, and archaeoacoustics research. The software integrates domain knowledge (supporting criterion 1) through specialized visualization options for speech analysis, incorporates research lifecycle support (criterion 2) particularly in data analysis and interpretation phases, provides analytical capabilities (criterion 4) through frequency analysis and spectrographic visualization, offers visualization functions (criterion 5) through multiple synchronized audio representations, and its documentation addresses research applications (criterion 6) with specific examples for linguistic analysis.",https://sourceforge.net/projects/wavesurfer/,,http://www.speech.kth.se/wavesurfer/,http://www.speech.kth.se/wavesurfer/,GPL,Aerial and satellite imagery|Datasets|Templates|Diagrams and visualizations,audio analysis|spectrogram visualization|acoustic phonetics|archaeoacoustics|cross-platform,2000-06-01,2020-05-07,1.8.8p6,Maintenance-only,"KTH Royal Institute of Technology, Centre for Speech Technology",Kåre Sjölander|Jonas Beskow,Small (2-5),Linguistics,General-purpose,Basic,"WaveSurfer has been cited in over 1000 academic publications according to Google Scholar. The SourceForge repository shows approximately 500,000 downloads across all versions. Activity on linguistics forums and speech analysis communities shows continued usage despite limited recent development. GitHub repositories referencing WaveSurfer for archaeoacoustic applications exist, though in smaller numbers. Academic course materials from linguistics departments frequently reference the tool for teaching purposes. Notable archaeoacoustic projects including 'Songs of the Caves' (AHRC-funded) utilized WaveSurfer for analysis of Paleolithic cave acoustics. Usage has declined since 2015 in favor of more actively maintained alternatives like Praat, but specialized applications in archaeology maintain a small but consistent user base.",Analysis|Data Acquisition,research-specific,Stand-alone software,Tcl/Tk,Windows|macOS|Linux,,"WaveSurfer supports a wide range of audio file formats including WAV, AU, AIFF, MP3, and can export analysis results in multiple formats. The current version offers interoperability with HTK (Hidden Markov Model Toolkit) for speech recognition research, and can import/export transcriptions in several formats including TIMIT and MLF formats. For archaeoacoustic applications, it can exchange data with specialized acoustic analysis tools through standard audio file formats. Annotation data can be exported to text formats compatible with database systems for cataloging acoustic phenomena. Earlier versions had more limited format support, particularly for compressed audio formats.","The current version of WaveSurfer offers several significant strengths that benefit archaeological and linguistic research: 1) An intuitive, customizable interface that requires minimal training for basic analysis tasks, making it accessible to researchers without extensive technical background; 2) Flexible visualization options including synchronized displays of waveforms, spectrograms, and pitch tracks that provide multiple perspectives on the same audio data; 3) Cross-platform compatibility across Windows, macOS, and Linux systems, facilitating collaboration across different computing environments; 4) Support for a wide range of audio formats, allowing analysis of various archival recordings without conversion; 5) Lightweight system requirements enabling field use on modest hardware; 6) Extensive configuration options for spectrogram analysis, allowing researchers to optimize visualization for specific types of audio materials; 7) Plugin architecture that allows extension for specialized research requirements; 8) Batch processing capabilities for analyzing multiple files with consistent parameters. For archaeological applications specifically, the ability to precisely measure and visualize acoustic properties of recorded spaces provides valuable data for archaeoacoustic research.","The current version of WaveSurfer exhibits several limitations affecting its utility for contemporary research: 1) Development has essentially stalled since 2010, with only minor maintenance updates addressing compatibility issues rather than adding new features or improving core functionality; 2) The underlying Tcl/Tk technology stack is increasingly dated, causing compatibility issues with modern operating systems, particularly recent macOS versions; 3) Limited scripting capabilities compared to alternatives like Praat, restricting automation of complex analysis workflows; 4) The visualization engine, while functional, lacks modern rendering capabilities that would improve clarity of spectral displays; 5) Memory management constraints limit effectiveness when working with very large audio files or batch processing numerous recordings; 6) Documentation, while adequate for basic functions, lacks comprehensive coverage of advanced features and archaeological applications; 7) The plugin system, though powerful, has seen minimal community development in recent years, limiting extension options; 8) Limited integration with modern data science tools and workflows that have become standard in acoustic research; 9) Increasing technical debt as dependencies age and compatibility issues multiply. For version 1.8.8p6 specifically, reported issues with pitch tracking accuracy in stereo files require conversion to mono format before analysis.","WaveSurfer faces significant challenges to its long-term viability as a research tool. The software has received only minimal maintenance updates since 2010, with the most recent release (1.8.8p6) in 2020 primarily addressing compatibility issues rather than enhancing functionality. Its underlying technology stack (Tcl/Tk and the Snack Sound Toolkit) represents aging technology that faces increasing compatibility issues with modern operating systems. The original institutional backing from KTH Royal Institute of Technology appears to have diminished, with no clear succession plan for ongoing development. While the open-source nature of the software theoretically allows community maintenance, the specialized knowledge required to work with its codebase limits the pool of potential contributors. The user community, while still active in linguistics and archaeoacoustics, has been gradually migrating to more actively maintained alternatives. That said, the software's relatively simple requirements and stable codebase suggest it will remain functionally usable on compatible systems for several more years, particularly in specialized archaeological applications where its specific visualization capabilities remain valuable. For long-term research projects, however, migration strategies to more actively maintained alternatives should be considered to ensure continuity of analytical capabilities. The availability of the source code provides some insurance against complete obsolescence, as critical functions could be reimplemented if necessary.","Praat (actively developed open-source speech analysis software with extensive scripting capabilities and a large user community; offers similar visualization options but with more advanced analysis tools); Sonic Visualiser (modern audio visualization platform with plugin architecture, particularly strong for music analysis but applicable to archaeoacoustic research); Audacity (general-purpose audio editor with basic spectral analysis capabilities and active development); ELAN (specialized for multimodal annotation, useful for complex documentation projects combining audio with other data types); WASP (Windows-only alternative specifically designed for teaching phonetics with simplified interface); Speech Analyzer (SIL tool offering similar functionality with focus on linguistic applications); iZotope RX (commercial option with advanced restoration capabilities, valuable for historical recordings)",
Wcvt2Pov,Failure | Spawned new,Fail,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
POV-Ray,New,Split from Wcvt2Pov,"POV-Ray (Persistence of Vision Raytracer) is a free, open-source tool for creating high-quality three-dimensional images through raytracing. It uses a scene description language to define objects mathematically rather than through polygon meshes, making it particularly suitable for creating precise geometric reconstructions. The current version offers advanced features including radiosity, photon mapping, and high dynamic range imaging. While historically used in archaeological visualisations for site reconstructions and artefact modelling during the late 1990s and early 2000s, POV-Ray has largely been supplanted in contemporary archaeological practice by more integrated, user-friendly 3D solutions. POV-Ray remains valuable for precise geometric modelling where mathematical accuracy is paramount, but its text-based workflow and limited integration with modern archaeological documentation methods have reduced its relevance in the field.","POV-Ray originated in 1986 when David Kirk Buck created DKBTrace, a raytracer for the Amiga platform. In July 1991, DKBTrace evolved into POV-Ray when a development team formed on CompuServe's GraphDev forum. The name 'Persistence of Vision' was inspired by Salvador Dalí's painting 'The Persistence of Memory'. Early versions were distributed as shareware with source code available. Version 3.0 (1994) introduced major features including animation capabilities. Version 3.1 (1996) added radiosity and atmospheric effects. Version 3.5 (2002) brought improved surface finishes and spline interpolation. Version 3.6 (2004) enhanced the parsing system and macro capabilities. A critical transition occurred in 2013 when POV-Ray became fully open-source under the AGPL-3.0 license. Version 3.7 (2013-2019) introduced symmetric multiprocessing support, high dynamic range imaging, and subsurface scattering. As of 2025, POV-Ray 3.8 is in beta testing, expected for release in Q1 2025, focusing on code modernisation and performance improvements. The project has maintained a consistent development team structure since 1999 when Chris Cason became the primary coordinator, with Christoph Lipka joining as lead developer in 2009.","The current version of POV-Ray (3.7.0.10) is implemented primarily in C++ with a C-like Scene Description Language (SDL) for scene definition. This architecture separates the rendering engine from scene descriptions, allowing complex scenes to be defined in text files that serve as rendering scripts. POV-Ray's technical approach differs fundamentally from most 3D software by using mathematical descriptions rather than polygon meshes for primitives. The core rendering technology employs recursive ray tracing, which simulates light rays travelling through a virtual environment by tracking their paths and interactions with objects. This produces highly realistic reflections, refractions, and shadows, though at higher computational cost than rasterisation methods. The rendering engine supports multiple illumination models including Phong shading, radiosity (for global illumination), photon mapping (for caustics), and volumetric lighting effects. For geometry, POV-Ray offers native primitives (spheres, cylinders, tori, etc.) defined with mathematical precision, constructive solid geometry (CSG) operations for combining shapes, isosurfaces for arbitrary mathematical functions, and heightfields for terrain representation. Material properties are controlled through pigments (colour patterns), normal modifiers (surface textures), and finishes (reflectivity, transparency). The software implements a full programming language within its SDL, offering loops, conditionals, macros, and include files. POV-Ray 3.7 introduced symmetric multiprocessing (SMP) support for utilising multiple CPU cores, but notably lacks GPU acceleration, resulting in slower render times compared to modern alternatives. The software uses a scanline rendering approach with adaptive anti-aliasing and supports multiple output formats including PNG, JPEG, OpenEXR, and Radiance HDR. Input capabilities include limited mesh import (though with performance limitations for complex models) and heightfield data from image files. POV-Ray's architecture emphasises precision and consistency over interactivity, making it suitable for batch processing and automated rendering pipelines but less effective for interactive workflows. Recent technical developments focus on code modernisation rather than fundamental architectural changes, reflecting its mature development stage.",2025-05-31,maybe,"POV-Ray meets the core definition of research software as it transforms research materials meaningfully through 3D visualisation and supports research activities, particularly in archaeological reconstruction. It aligns with recognised methodologies in computational archaeology for visual hypothesis testing. For the supporting criteria, POV-Ray satisfies: (1) Research Lifecycle Support - it addresses the 'Interpretation' and 'Publication' stages by creating visualisations for analysis and dissemination; (2) Visualization Functions - it renders data in meaningful visual formats, particularly for architectural reconstructions and artefact representations; (3) Analytical Capabilities - it enables spatial analysis through precise geometric modelling. However, POV-Ray falls short in contemporary archaeological research due to its limited integration with modern archaeological documentation methods (photogrammetry, GIS), its steep learning curve requiring programming knowledge, and its inability to directly process data from 3D scanning methods now standard in the field. These limitations place it in a borderline position, where it retains value for specific mathematical visualisation needs but lacks the workflow integration needed for mainstream archaeological research applications.",https://github.com/POV-Ray/povray,,http://www.povray.org,http://www.povray.org,AGPL-3.0,3D modelling|Virtual reality|Platforms and publications|Visualization,raytracing|mathematical-precision|scene-description-language|photorealistic-rendering|archaeological-reconstruction,1991-07-01,2023-09-17,3.7.0.10,Maintenance-only,Persistence of Vision Raytracer Pty. Ltd.,David Kirk Buck (original creator)|Chris Cason (coordinator since 1999)|Christoph Lipka (lead developer since 2009),Small (2-5),Computer Graphics,General-purpose,Comprehensive,"POV-Ray maintains a modest but dedicated community. The GitHub repository shows 1,411 stars and 287 forks with contributions from 21 developers and approximately 811 commits. Official forums at news.povray.org remain active with specialised discussion groups, though participation has declined over the past decade. Stack Overflow hosts approximately 50+ POV-Ray questions with only 5-10 new questions annually. Documentation remains a strength, with comprehensive HTML documentation and third-party tutorials by Friedrich A. Lohmueller and others. Community-maintained resources include an official wiki, though server issues have affected its availability. No academic conferences or regular meetups focus specifically on POV-Ray, though it appears in computer graphics, chemistry, and physics education literature as a visualisation tool. Some universities incorporate POV-Ray into computer graphics courses, but no major programs focus specifically on it. In archaeological research, POV-Ray citations peaked between 1998-2002 but have declined precipitously since 2010 as alternatives gained prominence.",Interpretation|Publication,mass-market,Stand-alone software,C++,Windows|Linux|macOS|Unix,,"POV-Ray's interoperability centres on its Scene Description Language (SDL) files, which are text-based and version-control friendly. For output, the current version supports multiple image formats including PNG, JPEG, TGA, PPM, BMP, OpenEXR, and Radiance HDR. Input capabilities include heightfield data from grayscale images, limited mesh import via its own mesh format, and numerical data through its programming interfaces. POV-Ray can incorporate external data through include files and user-defined functions, enabling integration with custom data sources. However, the software lacks direct integration with contemporary archaeological data formats. It cannot directly import photogrammetry models (OBJ, PLY), LiDAR point clouds, or GIS data (Shapefile, GeoTIFF). Version 3.7 improved interoperability through command-line interfaces for batch processing and scene generation scripts, but still lacks APIs for modern software ecosystem integration. No direct connections exist to archaeological databases or metadata standards, limiting its role in integrated research workflows.","POV-Ray offers mathematical precision for geometric modelling, making it valuable for architectural reconstructions requiring exact dimensional accuracy. Its scene description language enables version control and reproducible research methodologies, with scene files serving as self-documenting archaeological hypotheses. Rendered images achieve photorealistic quality for regular geometric forms including architectural elements and certain artefacts. The software's free availability and cross-platform compatibility make it accessible for projects with limited budgets. Text-based workflows support programmatic scene generation and batch processing for large-scale visualisation projects. POV-Ray's comprehensive documentation and stable feature set reduce dependency risks, while its long development history (since 1991) demonstrates sustainability. Rendering scripts provide full transparency and reproducibility of visualisation methods, satisfying scientific documentation requirements. For specific archaeological applications requiring mathematical precision, POV-Ray can achieve results difficult to replicate in mesh-based systems, particularly for perfect geometric primitives, constructive solid geometry operations, and procedural texture generation to simulate material weathering and aging.","POV-Ray suffers from a text-based workflow requiring programming knowledge, creating barriers for archaeologists without technical backgrounds. The software lacks a user-friendly interface, with scene creation requiring coding rather than visual manipulation. Rendered images are static, limiting interactive exploration increasingly expected in archaeological visualisations. POV-Ray performs CPU-only rendering, making it significantly slower than GPU-accelerated alternatives, while poor mesh handling limits its ability to process complex 3D scanning data now standard in archaeological documentation. The software cannot directly import photogrammetry models, integrate with GIS systems, or export to VR/AR platforms increasingly used for public engagement. Version 3.7 remains unstable on some systems with reported crashes during complex scenes, and the software has no automated testing capabilities for verifying archaeological reconstructions. Limited community resources exist specifically for archaeological applications, with most documentation focused on general-purpose rendering. POV-Ray's workflow isolation prevents seamless integration with contemporary archaeological documentation pipelines, requiring conversion steps that risk data fidelity. These limitations have contributed to its declining relevance in archaeological research despite its technical capabilities.","POV-Ray shows moderate long-term viability with both strengths and significant challenges. The software benefits from stable institutional backing through Persistence of Vision Raytracer Pty. Ltd. and a consistent core development team led by Chris Cason since 1999 and Christoph Lipka since 2009. Its AGPL-3.0 licensing ensures continued availability regardless of organisational changes. The codebase appears well-maintained with regular security updates and structural improvements. However, POV-Ray faces substantial sustainability challenges including an entirely volunteer-driven development model with no commercial funding source beyond donations. This has resulted in slowing development pace evidenced by the six-year gap between 3.7.0 and 3.7.0.10 releases. Technical debt accumulated through its 39-year history creates migration challenges for modern architectures, while an aging user base without significant new adoption threatens knowledge continuity. In the archaeological context, POV-Ray's survivability appears limited to niche applications requiring its mathematical precision. The software will likely remain available and maintained due to its dedicated community, but archaeological usage will continue declining as integrated alternatives advance. For archaeological projects already using POV-Ray, migration paths exist to Blender (via script conversion tools) or specialised scientific visualisation packages that maintain mathematical precision while offering better integration with modern workflows.","Blender offers a complete 3D pipeline with modeling, animation, and rendering through an intuitive visual interface, supporting archaeological workflows including photogrammetry integration. It's free and open-source with extensive community support. 3ds Max/Maya (Autodesk) provide professional-grade capabilities with easier learning curves than POV-Ray, though at commercial pricing ($1,785/year). Agisoft Metashape ($179-$3,499) specialises in photogrammetry, automatically generating 3D models from photographs for artefact and site documentation. CloudCompare (free, open-source) focuses on point cloud comparison for heritage monitoring and documentation. ArcGIS Pro with 3D capabilities ($100-700/year) integrates spatial analysis with visualisation. For projects requiring POV-Ray's mathematical precision, Mitsuba 3 offers research-grade accuracy with differentiable rendering capabilities and modern architecture, though with an equally steep learning curve. LuxCoreRender provides physically-based rendering with a more modern interface while maintaining raytracing quality. These alternatives generally offer better archaeological workflow integration, GPU acceleration, and interactive capabilities, explaining the field's migration away from POV-Ray despite its specific strengths in mathematical precision.",
XVR,Success,,"XVR (eXtreme Virtual Reality) is a virtual reality development framework designed for creating web-deployable 3D applications. Initially developed at PERCRO Laboratory in Pisa, Italy, the framework found significant applications in archaeological research, particularly for predictive modelling and heritage visualization. The current version features a custom scripting language (S3D), virtual machine architecture, and integrated development environment for creating immersive VR applications. In archaeology, XVR was used primarily to visualize GIS data, create interactive 3D landscapes, implement predictive modelling, and develop public-facing heritage experiences. Notable archaeological implementations include the Pisa Coastal Plain Project (2011-2013) that created an interactive 3D environment for archaeological risk assessment.","XVR was developed in the early 2000s at the PERCRO Laboratory at Scuola Superiore Sant'Anna in Pisa, Italy. Led by Franco Tecchia and Massimo Bergamasco, the framework emerged from research into web-deployable virtual reality. Around 2002-2003, VRMedia was established as a spin-off company to commercialize the technology. The framework saw its first archaeological applications around 2005-2006, with major development milestones through 2010. The archaeological implementation peaked around 2011-2013 with the Pisa Coastal Plain Project by Landeschi and Carrozzino, which used XVR to develop a comprehensive virtual environment for archaeological predictive modelling and site visualization. The academic version appears to have been discontinued around 2014-2015, though the commercial enterprise continued through VRMedia Srl. Over its lifetime, XVR evolved from a basic 3D visualization tool to a comprehensive VR development platform with specialized capabilities for archaeological data representation.","The technical architecture of XVR (current version) centres on a virtual machine design that enables cross-platform deployment of virtual reality applications, with particular focus on web delivery. The core of XVR is built around S3D (Script3D), a proprietary object-oriented scripting language specifically designed for VR development. This language is dynamically typed and offers comprehensive wrappers for OpenGL functionality, enabling direct hardware-accelerated 3D graphics. The execution model involves compilation of S3D code into bytecode, which is then executed by the XVR virtual machine within a browser plugin (typically ActiveX for Internet Explorer). The rendering engine leverages OpenGL for 3D graphics, supporting advanced features like GLSL shaders, texture mapping, and lighting models essential for archaeological visualization. For web deployment, XVR uses a browser plugin architecture requiring client-side installation, with primary support for Internet Explorer through ActiveX technology. The development environment, XVR Developer Studio, is Eclipse-based and provides integrated code editing, debugging, and testing capabilities. Data structures within XVR support both imperative and object-oriented programming paradigms, with specialized structures for 3D mesh representation (using the proprietary AAM format), scene graphs, and spatial organization. For archaeological applications, XVR implements custom data structures for GIS integration, allowing conversion and visualization of geospatial data within the 3D environment. Performance optimization includes level-of-detail management, view frustum culling, and efficient memory management techniques. System requirements include Windows OS, OpenGL-compatible graphics hardware, and Internet Explorer with ActiveX support. Previous versions had more limited scripting capabilities and fewer archaeological-specific features, with the evolution showing progressive improvements in performance, features, and ease of development for specialized archaeological visualization needs.",2025-05-30,yes,"XVR qualifies as research software based on all essential criteria. It was specifically developed to support archaeological research activities, particularly predictive modelling and heritage visualization. It directly engages with research materials by transforming geospatial and archaeological data into interactive 3D visualizations. The framework aligns with established methodologies in digital archaeology and scientific visualization. Additionally, it meets multiple supporting criteria: it incorporates domain-specific terminology and procedures for archaeological data representation; supports multiple research lifecycle stages from data analysis to dissemination; transforms data between GIS formats and 3D visualizations; provides analytical capabilities for predictive modelling; offers sophisticated visualization functions for archaeological landscapes; and includes documentation focused on research applications, particularly in archaeology. The software was created within an academic research context and has been documented in peer-reviewed literature as a research tool.",,,http://www.vrmedia.it/,http://www.vrmedia.it/,Proprietary with free academic version (XVR Lite),3D modelling|Virtual reality|Data visualization|Platforms and publications|Drivers and IO|Archaeological risk assessment,web3d|virtual-reality|archaeological-visualization|predictive-modelling|heritage-communication,2002,2014,XVR Developer Studio 2.0.10 Beta,Abandoned,"PERCRO Laboratory, Scuola Superiore Sant'Anna (academic development); VRMedia Srl (commercial continuation)",Franco Tecchia|Massimo Bergamasco|Marcello Carrozzino|Sandro Bacinelli,Medium (6-20),Computer Science/Virtual Reality,General-purpose,Basic,"XVR usage was concentrated in European archaeological research, primarily in Italy. The framework was cited in approximately 20-50 archaeological papers, with peak usage occurring between 2010-2015. The most significant implementation was the Pisa Coastal Plain Project (2011-2013), which received notable academic attention. Development metrics show a small but dedicated community, with limited institutional adoption outside PERCRO and partner organizations. The software was included in EU research projects like BEAMING and VERE, indicating some broader recognition. Community activity was primarily concentrated among specialist users with programming expertise, and the software never achieved widespread adoption due to technical limitations and platform dependencies. GitHub metrics are unavailable as the project predated widespread GitHub usage in academic software development.",Analysis|Interpretation|Publication,research-specific,Stand-alone software,S3D (Script3D),Windows|Web (via Internet Explorer with ActiveX),,"XVR offered limited interoperability focused on model import and export. The current version supported import of various 3D formats through dedicated exporters for common modelling applications (3ds Max, Maya, Blender), with VRML import for scene structures. GIS integration required manual conversion processes to transform GIS data into XVR-compatible formats. The software used a proprietary AAM format for 3D geometry storage. For archaeological applications, custom conversion tools were developed to bridge GIS platforms and XVR, though these lacked standardization. Data exchange was primarily unidirectional (into XVR) with limited export capabilities beyond the runtime environment. Previous versions had even more restricted interoperability, focusing almost exclusively on VRML import.","XVR provided innovative capabilities for archaeological visualization when first released, being one of the earliest platforms enabling web-based delivery of interactive 3D archaeological environments. The framework excelled at integrating GIS data with 3D visualization, allowing researchers to create immersive landscapes populated with archaeological information. Its comprehensive approach to predictive modelling visualization allowed representation of complex probability surfaces in interactive 3D. The custom S3D language offered flexibility for archaeological-specific programming needs, with direct access to low-level graphics functions when required. As an academic initiative, XVR provided free access for research purposes through the XVR Lite version. The software demonstrated practical value through successful implementation in the Pisa Coastal Plain Project, providing a methodological template for subsequent archaeological VR applications. XVR's underlying virtual machine architecture facilitated web deployment, making archaeological visualizations more accessible than desktop-only alternatives of the period.","XVR suffered from significant technical limitations that eventually rendered it obsolete for archaeological applications. The framework's reliance on ActiveX technology and Internet Explorer created severe platform dependencies, limiting adoption primarily to Windows systems. As web standards evolved and ActiveX was deprecated for security reasons, XVR's deployment model became increasingly problematic. The proprietary S3D scripting language presented a steep learning curve for archaeologists without programming backgrounds, restricting the user base to technically proficient researchers. Documentation was limited and primarily academic in nature, lacking comprehensive tutorials or example projects for archaeological applications. Performance limitations were evident in complex archaeological visualizations, particularly when handling large GIS datasets or detailed landscape models. The small user community meant limited peer support and few shared resources compared to mainstream development platforms. As archaeological computing evolved toward open standards and cross-platform compatibility, XVR's closed ecosystem became increasingly isolated. Development appears to have ceased for the academic version around 2014-2015, leaving no path forward for bug fixes or compatibility updates with modern systems.","XVR's long-term survivability as archaeological research software is effectively nil. The framework relied on now-obsolete web technologies, particularly ActiveX and Internet Explorer, which have been deprecated or discontinued. The academic development appears to have ceased around 2014-2015, with no updates or compatibility fixes for modern systems. The small, specialized user community has largely dispersed as researchers migrated to more sustainable platforms. While the commercial entity VRMedia continues to exist, their focus has shifted away from the original XVR framework for archaeological applications. The proprietary nature of the codebase prevents community-driven continuation or adaptation. The underlying virtual machine architecture is incompatible with modern web security models and browser capabilities. Additionally, the emergence of superior alternatives with active development, cross-platform support, and larger communities (such as Unity, Unreal Engine, and web standards like WebGL) has eliminated any practical reason to maintain XVR for archaeological purposes. Any archaeological data or visualizations created in XVR now face significant preservation challenges and should be migrated to more sustainable platforms.","Unity 3D (industry standard game engine with extensive archaeological applications); Unreal Engine (high-fidelity 3D engine used for archaeological visualization); WebGL frameworks like Three.js (modern web-based 3D visualization without plugins); A-Frame (VR framework for web); QGIS with 3D capabilities (for GIS-centric archaeological work); Cesium (web-based geospatial visualization); Potree (point cloud visualization for archaeological data); custom solutions built on modern platforms like WebGL, WebXR and OpenXR standards.",
Zooniverse Project Builder,Success,,"The Zooniverse Project Builder is a free, web-based platform that enables researchers to create citizen science projects without programming expertise. The platform specialises in three main task types: classification (identifying objects in images), annotation (marking specific elements), and transcription (converting handwritten or printed text to digital format). In archaeological contexts, it has been used for site detection in LiDAR data, classifying artefacts, and mapping features in satellite imagery. For historical research, it excels at manuscript transcription, photograph analysis, and extracting data from archival documents. The current version uses a three-tier architecture where projects contain workflows (task sequences) that process subject sets (collections of images or documents).","The Zooniverse platform originated in 2007 with Galaxy Zoo, an astronomy project that revolutionised citizen science by engaging volunteers in galaxy classification. Early projects required months of professional development using the 'Ouroboros' platform, limiting launches to 3-5 projects annually. The pivotal transformation came in 2015 with the release of the Panoptes platform and Project Builder, which democratised project creation by providing self-service tools. Key milestones include: 2011 - Ancient Lives launches, pioneering humanities applications; 2015 - Panoptes platform and Project Builder release; 2016 - Python client introduces programmatic access; 2017 - ALICE transcription aggregation tool development begins; 2019 - Frontend modernisation with React; 2022 - NASA partnership renewal; 2025 - Python client v1.7.0 released with enhanced features. This evolution reflects a philosophy of thoughtful improvements based on researcher needs rather than disruptive changes.","The Zooniverse Project Builder runs on a sophisticated three-tier architecture optimised for global-scale citizen science. The current version's backend is built on Ruby on Rails with PostgreSQL databases, while the frontend uses React and Next.js frameworks for responsive user interfaces. Authentication employs OAuth 2.0 with JWT tokens. The platform comprises several key components: (1) Panoptes API - a RESTful JSON API providing programmatic access to all platform features; (2) Client Libraries - official SDKs in Python, Ruby, and JavaScript; (3) Background Processing - Celery for distributed task scheduling; (4) Cloud Storage - media storage with CDN distribution. The system architecture prioritises horizontal scalability to handle millions of concurrent classifications. The platform supports a range of task interfaces including point/line/polygon drawing tools (critical for archaeological site mapping), hierarchical classifications via dropdown menus, and specialised transcription interfaces with the ALICE aggregation tool. Data aggregation algorithms apply statistical methods to combine multiple volunteer contributions into consensus results. Technical requirements for end users are minimal - just modern web browsers with HTTPS support. Developers can run local instances using Docker containers with Kubernetes orchestration. The internationalization framework enables multilingual deployment, supporting global research communities. Performance optimization includes intelligent subject retirement based on agreement thresholds, ensuring efficient volunteer effort allocation.",2025-05-30,yes,"The Zooniverse Project Builder fully satisfies all essential research software criteria. It has a clear research-specific purpose facilitating citizen science for scholarly inquiry. It directly engages with research data through classification, annotation and transcription workflows. It aligns perfectly with recognised methodologies in digital humanities and archaeology. It satisfies multiple supporting criteria: it incorporates domain knowledge through specialised workflows for humanities research; supports multiple research lifecycle stages from data collection through analysis; transforms data between formats; provides analytical capabilities through consensus algorithms; visualises results through project dashboards; and extensively documents research applications through case studies.",https://github.com/zooniverse/panoptes,https://pypi.org/project/panoptes-client/,https://pypi.org/project/panoptes-client/,https://www.zooniverse.org/,Apache License 2.0,Data collection|Platforms and publications|Transcription|Archaeological|Cultural evolution|3D modelling|LiDAR|Museums|API interfaces and web scrapers|Aerial and satellite imagery,citizen science|crowdsourcing|volunteer transcription|archaeological classification|humanities research platform,2015-06-23,2025-03-07,1.7.0 (Python client),Active,University of Oxford|Adler Planetarium|University of Minnesota-Twin Cities|Citizen Science Alliance,Chris Lintott|Laura Trouille|Lucy Fortson|Brooke Simmons|Grant Miller,Medium (6-20),Astronomy,General-purpose,Excellent,"The Zooniverse Project Builder has attracted over 2.6 million registered volunteers who have contributed to more than 450 research projects since 2007. The platform processes approximately 100,000 classifications daily across 90+ active projects. Notable archaeological projects include Ancient Lives (250,000+ volunteers transcribing Greek papyri) and various LiDAR analysis initiatives. The platform has enabled research resulting in 200+ peer-reviewed publications across disciplines. GitHub metrics show strong development activity with 1,000+ stars, 500+ forks and 100+ contributors across repositories. The Python client has 50,000+ PyPI downloads monthly. Educational adoption includes integration into university curricula and K-12 classroom activities.",Planning|Data Acquisition|Processing|Analysis|Interpretation|Publication,research-specific,Stand-alone software,Ruby|JavaScript|Python|R,Web|Mobile,,"The platform provides comprehensive data interoperability through multiple export formats including CSV for statistical analysis, JSON for complex data structures, and TEI (Text Encoding Initiative) for transcription projects. The data schema captures classification data (user information, timestamps, versions), subject metadata (filenames, custom fields), and workflow configuration (task definitions, retirement rules). IIIF (International Image Interoperability Framework) compliance enables integration with digital library systems. The RESTful API supports real-time data access and custom analytical pipelines. The platform follows FAIR data principles: findable through the public project directory, accessible via open data exports, interoperable through standard formats, and reusable with clear licensing.",The Zooniverse Project Builder offers several significant strengths for archaeological and historical research: (1) Democratised access - researchers can launch sophisticated projects without programming skills or technical infrastructure funding; (2) Massive volunteer community - 2.6+ million registered users enable rapid project completion; (3) Scalability - handles datasets from hundreds to millions of items efficiently; (4) Statistical validation - multiple volunteer consensus algorithms ensure research integrity; (5) Specialised humanities tools - ALICE transcription aggregation provides capabilities unavailable elsewhere; (6) Educational integration - supports classroom adoption with teaching resources; (7) Community features - Talk boards foster volunteer engagement and knowledge sharing; (8) Zero cost - completely free for researchers unlike commercial alternatives; (9) Institutional backing - sustained by major research universities ensuring long-term viability; (10) Open-source flexibility - allows customisation for specific research needs.,"Despite its versatility, the current version of the Zooniverse Project Builder has several limitations: (1) Task complexity ceiling - best suited for tasks reducible to simple, repeatable actions rather than complex interpretive work; (2) Survey limitations - not designed for opinion-based research or complex branching surveys; (3) Upload constraints - 10,000 subject limit per user upload (though waivable upon request); (4) Customisation boundaries - projects requiring features beyond the builder interface need custom development; (5) Learning curve - building optimal workflows requires understanding volunteer behaviour and platform capabilities; (6) Limited direct integration with GIS software for archaeological applications; (7) Mobile responsiveness varies - complex annotation tasks work better on desktop; (8) Data export requires statistical knowledge for proper interpretation; (9) No built-in machine learning assistance for classification (though external integration is possible); (10) Volunteer recruitment responsibility falls on researchers, with success varying by project topic appeal.","The Zooniverse Project Builder demonstrates excellent long-term viability through several key factors: (1) Diversified funding from multiple federal agencies (NSF, NASA, IMLS, NIH, NEH), private foundations, and institutional commitments; (2) Multi-institutional governance through the Citizen Science Alliance, providing resilience against organisational changes; (3) Active development with regular updates and feature additions; (4) Growing volunteer base indicating sustained public interest; (5) Strong publication record establishing legitimacy in academic contexts; (6) Apache 2.0 open-source licensing ensuring code availability regardless of institutional changes; (7) Containerised deployment enabling flexible hosting options; (8) Educational adoption creating stakeholder commitment; (9) 17+ year operational history demonstrating sustainability; (10) Recent achievements like the 2024 White House 'Champions of Open Science' award indicating continued relevance. These factors collectively suggest the platform will remain viable for the foreseeable future, making it a safe investment for long-term research projects.","Several alternative platforms exist for citizen science in humanities research, though none match Zooniverse's comprehensive features and community size: (1) FromThePage - excels at manuscript transcription with specialised paleography tools but requires paid subscriptions and lacks image analysis capabilities; (2) PYBOSSA - offers maximum customisation as an open-source framework but demands significant technical expertise and lacks hosted options since CrowdCrafting's discontinuation; (3) CitSci.org - provides excellent community governance features but lacks sophisticated humanities tools; (4) SPOTTERON - offers polished, branded experiences but at substantial cost (€3,000+ setup plus maintenance); (5) Transkribus - powerful for document transcription with AI assistance but limited to text rather than multi-modal research. For archaeological projects combining multiple task types, Zooniverse remains unmatched in capabilities and accessibility.",
